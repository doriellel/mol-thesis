{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36da6186-7d29-49c4-9771-9aa97fb13c63",
   "metadata": {},
   "source": [
    "### Converting AnthoScore output to expanded .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90f9d17-0f2d-4994-bc94-609dbfd8a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def normalized(string):\n",
    "    return re.sub(r'\\s+', ' ', string.strip())\n",
    "\n",
    "def convert_annotation(score):\n",
    "    \"\"\"\n",
    "     This function converts annotations to numerical values:\n",
    "     negative - 0, positive - 1, inclonclusive - 2\n",
    "    \"\"\" \n",
    "    if score in ['p','p1','p2','p3']:\n",
    "        score = '1'\n",
    "    elif score in ['n1','n2','n3']:\n",
    "        score = '0'\n",
    "    elif score == 'inc':\n",
    "        score = '2'\n",
    "    else:\n",
    "        print(\"score is malformed\")\n",
    "\n",
    "    return score\n",
    "\n",
    "def get_scores_dict(filename):\n",
    "\n",
    "    filedict = {}\n",
    "    \n",
    "    with open(f\"../experiment_2/anthroscore/expectations/csv/{filename}.csv\",\"r\") as csv_file:        \n",
    "        header = csv_file.readline()\n",
    "        reader = csv.reader(csv_file)\n",
    "        for row in reader:\n",
    "            sentence_id = row[0]\n",
    "            sentence_info = row[1:]\n",
    "            filedict[sentence_id] = sentence_info # IDs are unique\n",
    "\n",
    "    return filedict\n",
    "\n",
    "def concat_info(filename,filedict):\n",
    "\n",
    "    with open(f\"../experiment_2/anthroscore/predictions/csv/{filename}.csv\",\"w\") as outfile:\n",
    "\n",
    "        list_check = []\n",
    "        \n",
    "        writer = csv.writer(outfile)\n",
    "        # new_header = ['id','sentence','masked_sentence','AI_phrase','suggested_mask','AI_entity',\n",
    "        # 'anthro_component','original_term','original_noun','expectation','anthroscore']\n",
    "        new_header = ['id','sentence','masked_sentence','AI_phrase','mask','AI_entity','component','expectation','prediction']\n",
    "        writer.writerow(new_header)\n",
    "        infile = open(f\"../experiment_2/anthroscore/predictions/anthroscore_output/sentence_scores/{filename}.csv\",\"r\")\n",
    "        header = infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        for row in reader:\n",
    "\n",
    "            #print(row)\n",
    "            \n",
    "            sentence_id = normalized(row[3])\n",
    "            sentence = normalized(row[1])\n",
    "            masked = normalized(row[2])\n",
    "            #original_term = normalized(row[6])\n",
    "            #original_noun = normalized(row[7])\n",
    "            #anthroscore = normalized(row[8])\n",
    "            anthroscore = normalized(row[4])            \n",
    "            info = [normalized(x) for x in filedict[sentence_id]]\n",
    "            #orig_score = convert_annotation(info[-1])\n",
    "            orig_score = info[-1]\n",
    "            \n",
    "            #write_to_file = [sentence_id,sentence,masked]+info[1:-1]+[original_term,original_noun,orig_score,anthroscore]\n",
    "            write_to_file = [sentence_id,sentence,masked]+info[-5:-1]+[orig_score,anthroscore]\n",
    "            \n",
    "            writer.writerow(write_to_file)\n",
    "            \n",
    "\n",
    "files = [\"adjective_phrases_inconclusive\",\n",
    "         \"adjective_phrases_negative\",\n",
    "         \"adjective_phrases_positive\",\n",
    "         \"comparisons_inconclusive\",\n",
    "         \"noun_phrases_positive\",\n",
    "         \"possessives_positive\",\n",
    "         \"verb_objects_inconclusive\",\n",
    "         \"verb_objects_negative\",\n",
    "         \"verb_objects_positive\",\n",
    "         \"verb_subjects_inconclusive\",\n",
    "         \"verb_subjects_negative\",\n",
    "         \"verb_subjects_positive\"\n",
    "        ]\n",
    "\n",
    "#for file in files:\n",
    "    #file_dict = get_scores_dict(file)\n",
    "    #concat_info(file,file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fad9cfc9-66d1-4123-8af7-8aa09551b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than one <mask> found in ID: 4_arx_2312.10766_1972574_1\n",
      "More than one <mask> found in ID: 4_arx_2312.10766_1972574_1\n",
      "More than one <mask> found in ID: 4_arx_2312.10766_1972574_1\n",
      "More than one <mask> found in ID: 4_arx_2312.10766_1972574_1\n",
      "More than one <mask> found in ID: 4_acl_147_34632_2\n",
      "More than one <mask> found in ID: 4_arx_2411.14133_2196560_0\n",
      "More than one <mask> found in ID: 4_arx_2411.14133_2196560_0\n",
      "More than one <mask> found in ID: 7_acl_245_24395_3\n",
      "More than one <mask> found in ID: 7_acl_245_24395_3\n",
      "More than one <mask> found in ID: 7_arx_2308.12578_1900470_0\n",
      "More than one <mask> found in ID: 7_arx_2308.12578_1900470_0\n",
      "More than one <mask> found in ID: 5_acl_280_13090_8_1\n",
      "More than one <mask> found in ID: 5_arx_2311.06985_1949952_2\n",
      "More than one <mask> found in ID: -4_acl_117_37846_1\n",
      "More than one <mask> found in ID: 6_arx_2408.10159_2130340_1\n",
      "More than one <mask> found in ID: 6_arx_2408.10159_2130340_1\n",
      "\n",
      "['4_arx_2312.10766_1972574_1', '4_acl_147_34632_2', '4_arx_2411.14133_2196560_0', '7_acl_245_24395_3', '7_arx_2308.12578_1900470_0', '5_acl_280_13090_8_1', '5_arx_2311.06985_1949952_2', '-4_acl_117_37846_1', '6_arx_2408.10159_2130340_1']\n"
     ]
    }
   ],
   "source": [
    "def find_all_indices(text, substring):\n",
    "    return [match.start() for match in re.finditer(re.escape(substring), text)]\n",
    "\n",
    "column_names = ['id', 'sentence', 'masked_sentence', 'AI_phrase', 'mask', 'AI_entity', 'anthro_component', \n",
    "                    'anthroscore_entity', 'anthroscore_phrase', 'score', 'anthroscore']\n",
    "df = pd.read_csv(f\"../experiment_1/anthroscore/predictions/txt/removed_sentences.txt\", sep='\\t', header=None, names=column_names,index_col=False)\n",
    "\n",
    "ids = []\n",
    "for _, row in df.iterrows():\n",
    "    masked = row['masked_sentence']\n",
    "    if masked.count('<mask>') > 1:\n",
    "        if row['id'] not in ids:\n",
    "            ids.append(row['id'])\n",
    "        print(f\"More than one <mask> found in ID: {row['id']}\")\n",
    "\n",
    "print()\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d20e9-8e2d-4148-bab7-35865ef436cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
