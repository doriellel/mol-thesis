{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575639f3-fe85-4f8a-8073-933f3920e36f",
   "metadata": {},
   "source": [
    "### Create evaluation sets for AtypicalAnimacy (with masks)\n",
    "\n",
    "Obtain previous and next sentences from dataframes and mask sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606305cf-2c1c-4407-a335-bc9ba57bd7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SentenceID', 'currentSentence', 'prevSentence', 'nextSentence', 'Abstract', 'source_file']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def concat_pkl(directory_path):\n",
    "    pkl_files = [f for f in os.listdir(directory_path) if f.endswith('.pkl')]\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file in pkl_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        try:\n",
    "            df = pd.read_pickle(file_path)\n",
    "            df['source_file'] = file  # Optional: track origin\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    if df_list:\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No pkl files read successfully.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "path = '../data/dataframes'\n",
    "all_sentences_df = concat_pkl(path)\n",
    "print(all_sentences_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b5f81b-1f94-455f-bc56-857fea6483da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjective_phrases_inconclusive\n",
      "error in sentence 7_46407_0: the mask was not found in the sentence\n",
      "Language models (LMs) Language models (LMs)\n",
      "Language models (LMs) are vulnerable to exploitation for adversarial misuse.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 2311.04177_1947144_0: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "Large Language Models (LLMs) are smart but forgetful.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 2308.03688_1891580_0: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 1812.08960_1066534_3: the mask was not found in the sentence\n",
      "A smart autonomous system (SAS) system (SAS)\n",
      "A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 2404.16873_2054324_0: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 2411.14133_2196560_0: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.\n",
      "\n",
      "adjective_phrases_positive\n",
      "error in sentence 2311.03287_1946254_6: the mask was not found in the sentence\n",
      "GPT-4V(ision) GPT-4V(ision)\n",
      "Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together.\n",
      "\n",
      "comparisons_inconclusive\n",
      "error in sentence 289_35148_0: the mask was not found in the sentence\n",
      "Large Language models (LLMs) Large Language models (LLMs)\n",
      "Large Language models (LLMs) have exhibited remarkable abilities in understanding complex texts, offering a promising path towards human-like translation performance.\n",
      "\n",
      "noun_phrases_positive\n",
      "error in sentence 2312.13103_1974911_1: the mask was not found in the sentence\n",
      "multimodal large language models (LLMs) multimodal large language models (LLMs)\n",
      "This paper proposes one of the first clinical applications of multimodal large language models (LLMs) as an assistant for radiologists to check errors in their reports.\n",
      "\n",
      "noun_phrases_positive\n",
      "error in sentence 523_44090_1: the mask was not found in the sentence\n",
      "a large language model (LLM) large language model (LLM)\n",
      "As such, it can be valuable for a large language model (LLM), particularly as an AI assistant, to be able to empathize with or even explain these various standpoints.\n",
      "\n",
      "noun_phrases_positive\n",
      "error in sentence 2306.07207_1860355_0: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "Large Language Models (LLMs), with remarkable conversational capability, have emerged as AI assistants that can handle both visual and textual modalities.\n",
      "\n",
      "noun_phrases_positive\n",
      "error in sentence 2311.06985_1949952_2: the mask was not found in the sentence\n",
      "a large language model (LLM) large language model (LLM)\n",
      "We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or other LLMs, compared to humans.\n",
      "\n",
      "possessives_positive\n",
      "error in sentence 2408.10159_2130340_1: the mask was not found in the sentence\n",
      "Large Language Models (LLMs) Large Language Models (LLMs)\n",
      "Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.\n",
      "\n",
      "possessives_positive\n",
      "error in sentence 2310.02417_1924674_0: the mask was not found in the sentence\n",
      "Large language models (LLMs) Large language models (LLMs)\n",
      "Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.\n",
      "\n",
      "possessives_positive\n",
      "error in sentence 2311.08487_1951454_2: the mask was not found in the sentence\n",
      "the model model\n",
      "This conflict renders LLMs vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.\n",
      "\n",
      "verb_objects_inconclusive\n",
      "error in sentence 2004.11543_1276313_6: the mask was not found in the sentence\n",
      "a deep reinforcement learning model deep reinforcement learning model.\n",
      "Each lesson in the curriculum is learnt by a deep reinforcement learning model.\n",
      "\n",
      "verb_objects_negative\n",
      "error in sentence 1401.5941_495172_4: the mask was not found in the sentence\n",
      "a backpropagation algorithm (MLP-BP) backpropagation algorithm (MLP-BP)\n",
      "Then, a multilayer perceptron is trained by a backpropagation algorithm (MLP-BP) on a data subset, and used to classify the transients as glitch or burst.\n",
      "\n",
      "verb_subjects_negative\n",
      "error in sentence 2304.02210_1820256_0: the mask was not found in the sentence\n",
      "Large language models (LLMs) Large Language models (LLMs)\n",
      "Large language models (LLMs) such as ChatGPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def get_context_for_AA(filename):\n",
    "\n",
    "    with open(f\"../data/AA_evaluation_sentences/{filename}.csv\",\"w\") as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile)\n",
    "        new_header = ['id','prevSentence','currentSentence','maskedSentence','nextSentence','AI phrase','suggested mask','AI entity',\n",
    "                      'anthropomorphic component','targetExpression','animated','context3wmasked','context3w']\n",
    "        writer.writerow(new_header)\n",
    "        infile = open(f\"../data/evaluation_sentences_csv/{filename}.csv\",\"r\")\n",
    "        header = infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        for row in reader:\n",
    "            sentence_id = row[0] \n",
    "            sentence = row[1]\n",
    "            sentence = sentence.strip()\n",
    "            sentence = re.sub(r'\\s+', ' ', sentence) # normalize whitespaces that may have occcurred in preprocessing\n",
    "            sentence_id = '_'.join(sentence_id.split('_')[2:5]) # remove class and dataset prefix added during preprocessing \n",
    "            # retrieve previous and next sentences from dataframe all sentences dataframe\n",
    "            sentence_info = all_sentences_df[all_sentences_df['SentenceID'] == sentence_id]\n",
    "            if not sentence_info.empty:\n",
    "                current_sentence = sentence_info.iloc[0]['currentSentence']\n",
    "                prev_sentence = sentence_info.iloc[0]['prevSentence']\n",
    "                next_sentence = sentence_info.iloc[0]['nextSentence']\n",
    "            else:\n",
    "                prev_sentence = 'NONE'\n",
    "                next_sentence = 'NONE'\n",
    "            # create masked sentence\n",
    "            AI_phrase = row[2].strip()\n",
    "            AI_phrase = re.sub(r'\\s+', ' ', AI_phrase) # normalize whitespaces that may have occcurred in preprocessing\n",
    "            mask = row[3].strip()\n",
    "            mask = re.sub(r'\\s+', ' ', mask) # normalize whitespaces that may have occcurred in preprocessing\n",
    "            mask_position = [match.start() for match in re.finditer(rf'\\b{re.escape(mask)}\\b', sentence, flags=re.IGNORECASE)]\n",
    "            if len(mask_position) == 1:\n",
    "                position = mask_position[0]\n",
    "                masked_sentence = create_masked_sentence(sentence,position,mask)\n",
    "            elif len(mask_position) > 1:\n",
    "                AI_phrase_position = [match.start() for match in re.finditer(rf'\\b{re.escape(AI_phrase)}\\b', sentence,flags=re.IGNORECASE)]\n",
    "                mask_in_phrase_position = [match.start() for match in re.finditer(rf'\\b{re.escape(mask)}\\b', AI_phrase)]\n",
    "                if len(AI_phrase_position) == 1 and len(mask_in_phrase_position) == 1:\n",
    "                    position = mask_in_phrase_position[0] + AI_phrase_position[0]\n",
    "                    masked_sentence = create_masked_sentence(sentence,position,mask)\n",
    "                else:\n",
    "                    for i,position in enumerate(mask_position):\n",
    "                        new_sentence_id = sentence_id + '_' + str(i)\n",
    "                        masked_sentence = create_masked_sentence(sentence,position,mask)\n",
    "            else: # mask not found in sentence at all - should not happen\n",
    "                mask_position = [match.start() for match in re.finditer(re.escape(mask), sentence, flags=re.IGNORECASE)]\n",
    "                print(filename)\n",
    "                print(f\"error in sentence {sentence_id}: the mask was not found in the sentence\")\n",
    "                print(AI_phrase,mask)\n",
    "                print(sentence)\n",
    "                print()\n",
    "            # create context3w and context3wmasked\n",
    "\n",
    "def create_masked_sentence(sentence,position,mask):\n",
    "\n",
    "    masked_sentence = []\n",
    "    len_mask = len(mask)\n",
    "    masked_sentence.append(sentence[:position])\n",
    "    masked_sentence.append(\"<mask>\")\n",
    "    position_after_mask = position+len_mask\n",
    "    masked_sentence.append(sentence[position_after_mask:])\n",
    "    masked_sentence = ''.join(masked_sentence)\n",
    "\n",
    "    return masked_sentence\n",
    "\n",
    "files = [\"adjective_phrases_inconclusive\",\n",
    "         \"adjective_phrases_negative\",\n",
    "         \"adjective_phrases_positive\",\n",
    "         \"comparisons_inconclusive\",\n",
    "         \"noun_phrases_positive\",\n",
    "         \"possessives_positive\",\n",
    "         \"verb_objects_inconclusive\",\n",
    "         \"verb_objects_negative\",\n",
    "         \"verb_objects_positive\",\n",
    "         \"verb_subjects_inconclusive\",\n",
    "         \"verb_subjects_negative\",\n",
    "         \"verb_subjects_positive\"\n",
    "        ]\n",
    "\n",
    "for file in files:\n",
    "    get_context_for_AA(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe5fd4-0ddc-4543-825d-240f9f2bec44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
