{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACL anthology data extraction\n",
    "\n",
    "This notebook provides code for extracting ACL anthologoy data following the dev documentation here: https://acl-anthology.readthedocs.io/latest/api/anthology/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. get ACL anthology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acl_anthology import Anthology\n",
    "anthology = Anthology.from_repo()\n",
    "!pip show acl-anthology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extend anthropomorphic wordlists with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['render', 'betray', 'fulfil', 'suffer', 'hear', 'name', 'bear', 'lie', 'examine', 'see', 'evolve', 'bring on', 'be after', 'view', 'instance', 'mistrust', 'establish', 'carry out', 'even up', 'give rise', 'see to it', 'have_taste_for', 'forget', 'think back', 'dream', 'befuddle', 'theorise', 'grow', 'collaborate', 'blur', 'build up', 'describe', 'envision', 'put up', 'have', 'con', 'brook', 'pass on', 'say', 'sympathise', 'misunderstand', 'feign', 'cerebrate', 'take on', 'execute', 'sense', 'exemplify', 'conciliate', 'favour', 'draw a blank', 'fulfill', 'recrudesce', 'have in mind', 'signify', 'catch up with', 'educate', 'demonstrate', 'seize', 'opine', 'want', 'differentiate', 'ideate', 'figure', 'take apart', 'understand', 'watch', 'conjecture', 'break', 'conceive', 'larn', 'fuddle', 'mean', 'visit', 'try', 'pay', 'discombobulate', 'line', 'realize', 'stomach', 'order', 'identify', 'cozen', 'study', 'acquire', 'make believe', 'make', 'dwell', 'take over', 'wish well', 'cover', 'make up', 'compensate', 'picture', 'report', 'wish', 'select', 'wear', 'trace', 'put on', 'go for', 'fetch', 'rise', 'debate', 'intend', 'get', 'reverence', 'attest', 'theorize', 'take in', 'make grow', 'bring out', 'draw', 'take for granted', 'opt', 'create', 'leave', 'abide', 'palpate', 'misinterpret', 'modernize', 'stick out', 'call up', 'estimate', 'get a line', 'venerate', 'guess', 'deduce', 'sham', 'obscure', 'do', 'gauge', 'get word', 'think', 'indicate', 'rest', 'put across', 'comprise', 'witness', 'date', 'lie in', 'raise', 'put off', 'shin', 'look', 'pick up', 'misapprehend', 'recite', 'construe', 'constitute', 'conceive of', 'derive', 'go steady', 'march', 'clamber', 'invent', 'profess', 'reason', 'farm', 'deduct', 'run', 'hypothesise', 'enjoin', 'hypothesize', 'portray', 'distinguish', 'learn', 'conduct', 'adjudicate', 'carry through', 'choose', 'block', 'key', 'find out', 'make_up', 'affect', 'know', 'fabricate', 'severalize', 'experience', 'cogitate', 'lead on', 'prove', 'go through', 'key out', 'enquire', 'confound', 'confuse', 'uprise', 'dissemble', 'empathize', 'digest', 'assure', 'care', 'pass', 'commend', 'counterbalance', 'explicate', 'usurp', 'recall', 'run across', 'correct', 'originate', 'insure', 'close', 'meet', 'instruct', 'demand', 'fancy', 'believe', \"make up one's mind\", 'imply', 'pass along', 'develop', 'realise', 'stargaze', 'misconceive', 'get into', 'postulate', 'canvas', 'depict', 'listen', 'channel', 'commune', 'blank out', 'transmit', 'rede', 'inquire', 'expect', 'plan', 'scramble', 'bring forth', 'imagine', 'memorise', 'flurry', 'limn', 'cognise', 'shew', 'assume', 'reason out', 'decide', 'dissect', 'struggle', 'venture', 'project', 'be amiss', 'break down', 'commemorate', 'sympathize', 'action', 'judge', 'skin', 'demo', 'visualise', 'prefer', 'bury', 'don', 'evidence', 'illustrate', 'throw', 'accomplish', 'necessitate', 'manifest', 'interpret', 'consist', 'jumble', 'impart', 'account', 'ask', 'feel', 'psychoanalyze', 'receive', 'cognize', 'involve', 'severalise', 'teach', 'consider', 'read', 'get wind', 'conclude', 'misconstrue', 'memorize', 'catch', 'produce', 'translate', 'think of', 'obnubilate', 'ensure', 'bedevil', 'daydream', 'state', 'even out', 'come across', 'desire', 'take', 'empathise', 'call back', 'ascertain', 'train', 'intercommunicate', 'delude', 'suspect', 'act', 'privilege', 'cook up', 'claim', 'infer', 'fox', 'retrieve', 'escort', 'visualize', 'ache', 'devise', 'take care', 'dread', 'presuppose', 'lie down', 'pay off', 'germinate', 'express', 'psychoanalyse', 'show', 'hypothecate', 'recognise', 'mix up', 'arise', 'disconcert', 'cooperate', 'reckon', 'live', 'contrive', 'excogitate', 'sputter', 'speculate', 'manufacture', 'acknowledge', 'communicate', 'recollect', 'be', 'reconcile', 'distrust', 'secern', 'argue', 'settle', 'pick out', 'bid', 'excuse', 'finger', 'prepare', 'attend', 'endure', 'hurt', 'perform', 'revere', 'envisage', 'take heed', 'stand', 'hope', 'put to death', 'go out', 'like', 'carry', 'take up', 'sustain', 'deceive', 'arrogate', 'trust', 'delineate', 'bring about', 'image', 'support', 'tell', 'hazard', 'strike', 'explain', 'secernate', 'recognize', 'regard', 'need', 'analyse', 'canvass', 'determine', 'join forces', 'spring up', 'run into', 'stand for', 'lay claim', 'forge', 'presume', 'recount', 'call for', 'accept', 'convey', 'require', 'discover', 'contend', 'resolve', 'surmise', 'fear', 'woolgather', 'narrate', 'simulate', 'present', 'adopt', 'find', 'represent', 'tell apart', 'analyze', 'get together', 'pretend', 'shinny', 'patch up', 'remember', 'lead astray', 'encounter', 'control', 'check', 'certify', 'fence', 'lose', 'formulate', 'suppose', 'bring', 'favor', 'approximate', 'separate', 'exhibit', 'fight', 'exact', 'construct', 'entail', 'modernise', 'design', 'tolerate', 'even off']\n"
     ]
    }
   ],
   "source": [
    "from tools import wordnet_syns as syns\n",
    "\n",
    "extended_arg0_verbs = syns.extend_word_list('arg0_verbs','v')\n",
    "extended_arg1_verbs = syns.extend_word_list('arg1_verbs','v')\n",
    "extended_adjectives = syns.extend_word_list('adjectives','a')\n",
    "extended_nouns = syns.extend_word_list('nouns','n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Get papers from ACL anthology in a iterable object and initiate keywords for matching relevant titles and abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "all_papers = anthology.papers()\n",
    "\n",
    "# for a case-insensitive re.match with words from title:\n",
    "title_keywords = ['AI','LM','LLM','GPT','ChatGPT'] \n",
    "\n",
    "# for a case insensitive re.search in title:\n",
    "title_phrases = ['artificial intelligence','language model']\n",
    "\n",
    "# for a lemma-based string comparison against entities in the abstract:\n",
    "keywords = ['AI','LM','LMs','LLM','LLMs','model','system','algorithm'] \n",
    "# spaCy lemmatizer does not handle plurals well for LM, LLM, so their plural version was included here too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Functions for retrieving specific patterns for each class from the taxonomy of anthropomorphic structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg0_active_criterion_check(sent,keywords,verb_list):\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    for chunk in sent.noun_chunks:\n",
    "        match = any(re.search(rf\"\\b{re.escape(word)}\\b\", chunk.text, re.IGNORECASE) for word in keywords)\n",
    "        if match and chunk.root.dep_ == 'nsubj' and chunk.root.head.lemma_ in verb_list:\n",
    "            check += 1\n",
    "\n",
    "    if check > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. General function for retreiving sentences matching a criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(cat):\n",
    "\n",
    "    with open(f\"../preprocessed_data/acl_{cat}.txt\",\"w\") as file:\n",
    "\n",
    "        done = False\n",
    "        counter = 0 # initiate counter\n",
    "        sentences_dict = {\"SentenceID\":[],\"currentSentence\":[],\"prevSentence\":[],\"nextSentence\":[],\"Abstract\":[]}\n",
    "        stop_words = ['do','be','have','show'] \n",
    "        verb_list = [v for v in extended_arg0_verbs if v not in stop_words] # exclude stop words\n",
    "    \n",
    "        for idx,paper in enumerate(all_papers):\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            title = [token.text for token in nlp(str(paper.title))]\n",
    "            keyword_match = any(re.match(keyword, word, re.IGNORECASE) for keyword in title_keywords for word in title)\n",
    "            phrase_match = any(re.search(phrase, str(paper.title).casefold(), re.IGNORECASE) for phrase in title_phrases)\n",
    "        \n",
    "            if paper.abstract and keyword_match or phrase_match:\n",
    "                doc = nlp(str(paper.abstract))\n",
    "            \n",
    "                for i,sent in enumerate(doc.sents): # check for matches with the keywords in the noun chunks to find AI entities\n",
    "\n",
    "                    if counter >= 1000:\n",
    "                        done = True\n",
    "                        break # stop when counter reaches 1000\n",
    "\n",
    "                    sent_id = paper.id + \"_\" + str(idx) + \"_\" + str(i)\n",
    "\n",
    "                    # check if at least one of the noun chunks is an AI entity whose root is an anthropomorphic predicate\n",
    "                    if cat == \"arg0_verbs_active\":\n",
    "                        criterion_met = arg0_active_criterion_check(sent,keywords,verb_list)\n",
    "                \n",
    "                    if criterion_met:\n",
    "                        counter += 1\n",
    "                        file.write(sent_id+'\\t'+sent.text+'\\n')\n",
    "                        sentences_dict[\"SentenceID\"].append(sent_id)\n",
    "                        sentences_dict[\"currentSentence\"].append(list(doc.sents)[i].text)\n",
    "                        sentences_dict[\"Abstract\"].append(str(paper.abstract))\n",
    "                        try:\n",
    "                            sentences_dict[\"prevSentence\"].append(list(doc.sents)[i-1].text)\n",
    "                        except IndexError:\n",
    "                            sentences_dict[\"prevSentence\"].append(\"\")\n",
    "                        try:\n",
    "                            sentences_dict[\"nextSentence\"].append(list(doc.sents)[i+1].text)\n",
    "                        except IndexError:\n",
    "                            sentences_dict[\"nextSentence\"].append(\"\")\n",
    "\n",
    "    return sentences_dict                       \n",
    "                                    \n",
    "arg0_verbs_df = pd.DataFrame(data=sentences_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve candidates for sentences in which the AI entity is the arg0 of an anthropomorphic predicate in the active voice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg0_verbs_dict = get_sentences(\"arg0_verbs_active\")\n",
    "arg0_verbs_df = pd.DataFrame(data=arg0_verbs_dict)\n",
    "arg0_verbs_df.to_pickle(\"../preprocessed_data/dataframes/acl_1000_arg0_verbs.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
