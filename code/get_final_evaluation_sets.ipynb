{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36da6186-7d29-49c4-9771-9aa97fb13c63",
   "metadata": {},
   "source": [
    "# Create final evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31972cd3-bea4-42a5-bdd1-9607d7dc37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f992cd-3854-4f91-a939-f1a013f97358",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"adjective_phrases_inconclusive\",\n",
    "         \"adjective_phrases_negative\",\n",
    "         \"adjective_phrases_positive\",\n",
    "         \"comparisons_inconclusive\",\n",
    "         \"noun_phrases_positive\",\n",
    "         \"possessives_positive\",\n",
    "         \"verb_objects_inconclusive\",\n",
    "         \"verb_objects_negative\",\n",
    "         \"verb_objects_positive\",\n",
    "         \"verb_subjects_inconclusive\",\n",
    "         \"verb_subjects_negative\",\n",
    "         \"verb_subjects_positive\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e1177-8325-4d1c-8dbb-341cbf08f27a",
   "metadata": {},
   "source": [
    "### Normalize final evaluation sets\n",
    "\n",
    "Align columns across all experiments and models and normalize scores to labels in [0 1 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90f9d17-0f2d-4994-bc94-609dbfd8a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(string):\n",
    "    return re.sub(r'\\s+', ' ', string.strip())\n",
    "\n",
    "def get_final_prediction(score,model):\n",
    "    \"\"\"\n",
    "     This function converts the anthroscore/AtypicalAnimacy scores to a single numerical value in {0,1,2}\n",
    "    \"\"\"     \n",
    "    AtypicalAnimacy_threshold = 0.3 # this was calculated during the experiment.\n",
    "    score = float(score)\n",
    "\n",
    "    if model == 'anthroscore':\n",
    "        if score > 1.0:\n",
    "            pred = '1'\n",
    "        elif score < -1.0:\n",
    "            pred = '0'\n",
    "        else:\n",
    "            pred = '2'\n",
    "            \n",
    "    elif model == 'AtypicalAnimacy':\n",
    "        if score > AtypicalAnimacy_threshold:\n",
    "            pred = '1'\n",
    "        else:\n",
    "            pred = '0'\n",
    "\n",
    "    return pred\n",
    "\n",
    "def create_final_eval_file(filename,experiment,model,all_indices_dict):\n",
    "    \"\"\"\n",
    "    this function reads info from csv file and writes it to a file with uniform structure to facilitate evaluation.\n",
    "\n",
    "    :param filename (str): name of the file \n",
    "    :param experiment (str): specify the experiment - used in input and output paths, and for obtaining correct indices\n",
    "    :param experiment (str): specify the model - used to obtain final prediction {0,1,2} based on the anthro/AtypicalAnimacy score\n",
    "    :param experiment (dict): pre-defined dictionary containing experiment+model string as key and index dict as value\n",
    "    \n",
    "    \"\"\" \n",
    "    with open(f\"../final_sets/{filename}_{experiment}_{model}_predictions.csv\",\"w\") as outfile:\n",
    "        \n",
    "        writer = csv.writer(outfile)\n",
    "        new_header = ['id','sentence','masked_sentence','AI_phrase','mask','component','expectation','model_score','prediction']\n",
    "        writer.writerow(new_header)\n",
    "        infile = open(f\"../{experiment}/{model}/predictions/csv/{filename}.csv\",\"r\")\n",
    "        header = infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        eval_set = f\"{experiment}_{model}\"\n",
    "        \n",
    "        for row in reader:\n",
    "\n",
    "            indices = all_indices_dict[eval_set]\n",
    "            \n",
    "            sentence_id = normalized(row[indices['id']])\n",
    "            sentence = normalized(row[indices['sent']])\n",
    "            masked_sent = normalized(row[indices['masked_sent']])\n",
    "            AI_phrase = normalized(row[indices['phrase']])\n",
    "            mask = normalized(row[indices['mask']])\n",
    "            component = normalized(row[indices['comp']])\n",
    "            expectation = (normalized(row[indices['exp']])) # should be numerical value {0,1,2}\n",
    "            expectation = int(float(expectation))\n",
    "            prediction = normalized(row[indices['pred']])\n",
    "\n",
    "\n",
    "            final_pred = get_final_prediction(prediction,model)\n",
    "            \n",
    "            write_to_file = [sentence_id,sentence,masked_sent,AI_phrase,mask,component,expectation,prediction,final_pred]\n",
    "            \n",
    "            writer.writerow(write_to_file)\n",
    "        \n",
    "        print(f\"Created {filename}_{experiment}_{model}_predictions.csv in ../final_sets/\")\n",
    "\n",
    "all_indices_dict = {'experiment_1_anthroscore':{'id':0,'sent':1,'masked_sent':2,'phrase':3,'mask':4,'comp':6,'exp':7,'pred':8},\n",
    "              'experiment_1_AtypicalAnimacy':{'id':0,'sent':2,'masked_sent':3,'phrase':5,'mask':6,'comp':8,'exp':10,'pred':15},\n",
    "              'experiment_2_anthroscore':{'id':0,'sent':1,'masked_sent':2,'phrase':3,'mask':4,'comp':6,'exp':7,'pred':8},\n",
    "              'experiment_2_AtypicalAnimacy':{'id':0,'sent':2,'masked_sent':3,'phrase':5,'mask':6,'comp':8,'exp':9,'pred':10}\n",
    "             }\n",
    "\n",
    "for file in files:\n",
    "    create_final_eval_file(file,'experiment_2','anthroscore',all_indices_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa193c3-5e83-4e74-a17d-19b04d418196",
   "metadata": {},
   "source": [
    "### Make sure that the evaluation sets for each experiment and model are identical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4510586-901c-4654-99c0-46104a3c27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_mask_dict(filename,experiment,model):\n",
    "    \n",
    "    with open(f\"../final_sets/{filename}_{experiment}_{model}_predictions.csv\",\"r\") as infile:\n",
    "\n",
    "        id_mask_dict = {}\n",
    "\n",
    "        header = infile.readline()\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        for row in reader:\n",
    "            sentence_id = normalized(row[0])\n",
    "            masked_sentence = normalized(row[2])\n",
    "            if '[MASK]' in masked_sentence:\n",
    "                masked_sentence = masked_sentence.replace('[MASK]','<mask>')\n",
    "            if sentence_id not in id_mask_dict:\n",
    "                id_mask_dict[sentence_id] = masked_sentence\n",
    "            else:\n",
    "                print(\"why is the ID appearing twice?\")\n",
    "\n",
    "        return id_mask_dict\n",
    "\n",
    "def compare_dicts(dict1, dict2):\n",
    "    \n",
    "    assert len(dict1) == len(dict2), \"Evaluation sets are not the same size.\"\n",
    "    for key, value in dict1.items():\n",
    "        assert key in dict2, f\"Sentence ID '{key}' does not exist in both evaluation sets.\"\n",
    "        assert dict2[key] == value, f\"The sentence ID {key} corresponds to two separare masked sentences: {value} != {dict2[key]}\"\n",
    "    \n",
    "for file in files:\n",
    "    anthroscore_exp1_dict = get_id_mask_dict(file,'experiment_1','anthroscore')\n",
    "    atypicalanimacy_exp1_dict = get_id_mask_dict(file,'experiment_1','anthroscore')\n",
    "    anthroscore_exp2_dict = get_id_mask_dict(file,'experiment_2','anthroscore')\n",
    "    atypicalanimacy_exp2_dict = get_id_mask_dict(file,'experiment_2','anthroscore')\n",
    "    compare_dicts(anthroscore_exp1_dict,atypicalanimacy_exp1_dict)\n",
    "    compare_dicts(anthroscore_exp2_dict,atypicalanimacy_exp2_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
