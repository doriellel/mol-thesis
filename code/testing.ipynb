{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans humans Like\n",
      "the system system is\n",
      "The AI assistant assistant is\n",
      "The LLM LLM demonstrated\n",
      "human-like abilities abilities demonstrated\n"
     ]
    }
   ],
   "source": [
    "keywords = ['AI','LM','LMs','LLM','LLMs','model','system','algorithm','chatGPT','GPT'] \n",
    "adj_list = ['suspicious','clever','complex','intelligent','malicious','smart','complex','sad']\n",
    "noun_list = ['assistant','teacher','companion']\n",
    "\n",
    "sample_sent = \"Like humans, the system is cunning. \\\n",
    "            The AI assistant is happy. \\\n",
    "            The LLM demonstrated human-like abilities. \"\n",
    "\n",
    "\n",
    "doc = nlp(sample_sent)\n",
    "sents = doc.sents\n",
    "for sent in sents:\n",
    "\n",
    "    for chunk in sent.noun_chunks:\n",
    "        print(chunk,chunk.root,chunk.root.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/doriellelonke/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/framenet_v17.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'abash', 'accept', 'accompany', 'accuse', 'acquire', 'act', 'add', 'address', 'admire', 'affect', 'agree', 'alert', 'allow', 'annotate', 'anticipate', 'appear', 'apply', 'approve', 'arrive', 'ask', 'assert', 'assist', 'associate', 'attribute', 'augur', 'awake', 'base', 'be', 'become', 'believe', 'belong', 'betoken', 'bid', 'bode', 'break', 'bring', 'build', 'burn', 'buy', 'calculate', 'call', 'capture', 'carry', 'catch', 'categorize', 'cause', 'change', 'choose', 'claim', 'close', 'cloud', 'comb', 'come', 'commit', 'communicate', 'compare', 'complete', 'comprehend', 'compute', 'conceal', 'conceive', 'concern', 'conclude', 'consider', 'consist', 'constrain', 'construe', 'contain', 'contrast', 'convince', 'count', 'cover', 'create', 'crumble', 'darken', 'deceive', 'decide', 'declare', 'define', 'defrock', 'demand', 'denote', 'depart', 'depend', 'depict', 'deprofile', 'describe', 'desire', 'destroy', 'determine', 'develop', 'die', 'differ', 'dig', 'direct', 'discourage', 'discover', 'discuss', 'dissuade', 'distinguish', 'do', 'draw', 'drench', 'drink', 'drive', 'education_teache', 'embed', 'emit', 'emphasize', 'enable', 'enclose', 'encode', 'encounter', 'encourage', 'engage', 'ensure', 'entail', 'establish', 'estimate', 'evade', 'eventive_cognizer_affecte', 'examine', 'exclude', 'execute', 'exemplify', 'exhibit', 'exist', 'expect', 'experience', 'explain', 'express', 'extrapose', 'face', 'fail', 'favor', 'feel', 'figure', 'find', 'finish', 'fit', 'fix', 'focus', 'follow', 'foresee.v', 'forget', 'form', 'gaze', 'get', 'give', 'go', 'govern', 'happen', 'have', 'head', 'hear', 'help', 'hide', 'hit', 'hold', 'holster', 'illustrate', 'imagine', 'impact', 'imply', 'impose', 'improve', 'include', 'incorporate', 'indicate', 'infer', 'influence', 'inform', 'inherit', 'inhibit', 'initiate', 'inspire', 'instantiate', 'intend', 'interact', 'introduce', 'invade', 'invite', 'involve', 'judge', 'keep', 'know', 'leave', 'lie', 'like', 'link', 'list', 'live', 'locate', 'look', 'lose', 'make', 'manifest', 'mark', 'mean', 'meet', 'memorize', 'mention', 'mingle', 'miss', 'modify', 'monitor', 'move', 'mull', 'need', 'note', 'notice', 'obtain', 'occur', 'order', 'outlook', 'overhear', 'paraphrase', 'participate', 'partition', 'pass', 'pay', 'perceive', 'perform', 'persuade', 'pick', 'place', 'plan', 'play', 'portray', 'possess', 'pre', 'prefer', 'present', 'presume', 'presuppose', 'process', 'produce', 'profile', 'prompt', 'protect', 'prove', 'provide', 'put', 'quit', 'rain', 'rattle', 'realise', 'realize', 'reason', 'receive', 'recognize', 'recondition', 'record', 'refer', 'relate', 'remain', 'remember', 'remind', 'replace', 'report', 'represent', 'reproduce', 'require', 'resemble', 'respect', 'respond', 'result', 'retain', 'retrieve', 'return', 'rule', 'run', 'say', 'screen', 'search', 'see', 'seek', 'seem', 'select', 'sell', 'serve', 'set', 'share', 'show', 'sit', 'sleep', 'smell', \"smell:'smell\", 'snap', 'speak', 'specify', 'spend', 'spike', 'splash', 'stand', 'step', 'stereotype', 'structure', 'subsume', 'succeed', 'suggest', 'suppose', 'swinge', 'symbolize', 'take', 'talk', 'tally', 'taste', 'tear', 'tell', 'thank', 'think', 'tie', 'total', 'translate', 'travel', 'treat', 'trust', 'try', 'turn', 'underestimate', 'undergo', 'understand', 'unexpresse', 'use', 'vaguelydiscern', 'verify', 'waffle', 'wait', 'want', 'waste', 'waver', 'wear', 'whinge', 'wish', 'witness', 'work', 'write']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "# List of frames that contain a FE named \"Cognizer\"\n",
    "frames_with_cognizer = []\n",
    "lemmas = []\n",
    "\n",
    "for frame in fn.frames():\n",
    "    #print(frame.name)\n",
    "            \n",
    "    if \"cognizer\" in frame.definition.lower() or \"perceiver\" in frame.definition.lower():\n",
    "\n",
    "        doc = nlp(str(frame.definition))\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'VERB' and token.lemma_ not in lemmas:\n",
    "                lemmas.append(token.lemma_)\n",
    "        frames_with_cognizer.append(frame.name)\n",
    "\n",
    "    elif \"cognizer\" in fe[\"name\"].lower():\n",
    "\n",
    "        doc = nlp(str(frame.definition))\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'VERB' and token.lemma_ not in lemmas:\n",
    "                lemmas.append(token.lemma_)\n",
    "        frames_with_cognizer.append(frame.name)\n",
    "\n",
    "print(sorted(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deem to be\n",
      "give careful consideration to\n",
      "take into consideration for exemplifying purposes\n",
      "show consideration for; take into account\n",
      "think about carefully; weigh\n",
      "judge or regard; look upon; judge\n",
      "look at attentively\n",
      "look at carefully; study mentally\n",
      "regard or treat with consideration, respect, and esteem\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "words = [\"consider\"]\n",
    "\n",
    "for word in words:\n",
    "    #print(wn.synsets(word))\n",
    "    for synset in wn.synsets(word):\n",
    "        print(synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_lines(input_file, output_file):\n",
    "    seen = set()\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            if line not in seen:\n",
    "                seen.add(line)\n",
    "                outfile.write(line)\n",
    "                \n",
    "\n",
    "# Example usage\n",
    "input_path = '../preprocessed_data/untagged_sentences'\n",
    "output_path = 'output.txt'\n",
    "remove_duplicate_lines(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_duplicate_lines_from_folder(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Only process files (skip directories)\n",
    "        if os.path.isfile(input_path):\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            seen = set()\n",
    "            with open(input_path, 'r') as infile, open(output_path, 'w') as outfile:\n",
    "                for line in infile:\n",
    "                    if line not in seen:\n",
    "                        seen.add(line)\n",
    "                        outfile.write(line)\n",
    "\n",
    "# Example usage\n",
    "input_dir = '../preprocessed_data/untagged_sentences'\n",
    "output_dir = '../preprocessed_data/untagged_sentences'\n",
    "remove_duplicate_lines_from_folder(input_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
