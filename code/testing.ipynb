{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humans humans Like\n",
      "the system system is\n",
      "The AI assistant assistant is\n",
      "The LLM LLM demonstrated\n",
      "human-like abilities abilities demonstrated\n"
     ]
    }
   ],
   "source": [
    "keywords = ['AI','LM','LMs','LLM','LLMs','model','system','algorithm','chatGPT','GPT'] \n",
    "adj_list = ['suspicious','clever','complex','intelligent','malicious','smart','complex','sad']\n",
    "noun_list = ['assistant','teacher','companion']\n",
    "\n",
    "sample_sent = \"Like humans, the system is cunning. \\\n",
    "            The AI assistant is happy. \\\n",
    "            The LLM demonstrated human-like abilities. \"\n",
    "\n",
    "\n",
    "doc = nlp(sample_sent)\n",
    "sents = doc.sents\n",
    "for sent in sents:\n",
    "\n",
    "    for chunk in sent.noun_chunks:\n",
    "        print(chunk,chunk.root,chunk.root.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/doriellelonke/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/framenet_v17.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'accept', 'accompany', 'accuse', 'acquire', 'act', 'add', 'address', 'admire', 'affect', 'agree', 'alert', 'allow', 'annotate', 'anticipate', 'apply', 'approve', 'arrive', 'ask', 'assert', 'assist', 'associate', 'augur', 'base', 'be', 'become', 'believe', 'belong', 'betoken', 'bode', 'bring', 'build', 'burn', 'buy', 'calculate', 'call', 'capture', 'carry', 'categorize', 'cause', 'change', 'choose', 'claim', 'close', 'cloud', 'comb', 'come', 'commit', 'communicate', 'compare', 'complete', 'comprehend', 'compute', 'conceal', 'conceive', 'concern', 'conclude', 'consider', 'consist', 'constrain', 'construe', 'contain', 'contrast', 'convince', 'count', 'cover', 'create', 'darken', 'deceive', 'decide', 'define', 'defrock', 'demand', 'denote', 'depart', 'depend', 'depict', 'deprofile', 'describe', 'desire', 'destroy', 'determine', 'develop', 'die', 'differ', 'discourage', 'discover', 'discuss', 'dissuade', 'distinguish', 'do', 'draw', 'drench', 'drink', 'drive', 'education_teache', 'embed', 'emphasize', 'encode', 'encounter', 'encourage', 'engage', 'ensure', 'entail', 'establish', 'estimate', 'eventive_cognizer_affecte', 'examine', 'exclude', 'execute', 'exist', 'expect', 'experience', 'explain', 'express', 'extrapose', 'face', 'fail', 'favor', 'feel', 'figure', 'find', 'finish', 'fit', 'fix', 'focus', 'follow', 'foresee.v', 'forget', 'form', 'get', 'give', 'go', 'govern', 'happen', 'have', 'head', 'help', 'hide', 'hit', 'hold', 'imagine', 'impact', 'imply', 'impose', 'improve', 'include', 'incorporate', 'indicate', 'infer', 'influence', 'inform', 'inherit', 'inhibit', 'initiate', 'inspire', 'instantiate', 'intend', 'interact', 'introduce', 'invade', 'invite', 'involve', 'judge', 'keep', 'know', 'leave', 'lie', 'like', 'link', 'list', 'live', 'locate', 'look', 'lose', 'make', 'manifest', 'mean', 'meet', 'memorize', 'mention', 'mingle', 'modify', 'monitor', 'move', 'mull', 'need', 'note', 'notice', 'obtain', 'occur', 'outlook', 'paraphrase', 'participate', 'partition', 'pass', 'pay', 'perceive', 'perform', 'persuade', 'pick', 'plan', 'play', 'portray', 'possess', 'pre', 'prefer', 'present', 'presume', 'presuppose', 'produce', 'profile', 'prompt', 'protect', 'prove', 'provide', 'put', 'quit', 'rain', 'realise', 'realize', 'reason', 'receive', 'recognize', 'recondition', 'record', 'refer', 'relate', 'remain', 'remember', 'remind', 'report', 'represent', 'reproduce', 'require', 'resemble', 'respect', 'respond', 'result', 'retain', 'retrieve', 'return', 'rule', 'run', 'say', 'search', 'see', 'seek', 'seem', 'select', 'sell', 'serve', 'set', 'share', 'show', 'sleep', 'snap', 'speak', 'specify', 'spike', 'splash', 'stand', 'step', 'stereotype', 'structure', 'succeed', 'suggest', 'suppose', 'swinge', 'symbolize', 'take', 'talk', 'tally', 'tear', 'tell', 'thank', 'think', 'tie', 'total', 'translate', 'treat', 'trust', 'try', 'turn', 'underestimate', 'undergo', 'understand', 'unexpresse', 'use', 'vaguelydiscern', 'verify', 'waffle', 'want', 'waste', 'waver', 'wear', 'whinge', 'wish', 'witness', 'work', 'write']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "# List of frames that contain a FE named \"Cognizer\"\n",
    "frames_with_cognizer = []\n",
    "lemmas = []\n",
    "\n",
    "for frame in fn.frames():\n",
    "    #print(frame.name)\n",
    "            \n",
    "    if \"cognizer\" in frame.definition.lower():\n",
    "\n",
    "        doc = nlp(str(frame.definition))\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'VERB' and token.lemma_ not in lemmas:\n",
    "                lemmas.append(token.lemma_)\n",
    "        frames_with_cognizer.append(frame.name)\n",
    "        #print(frame.definition)\n",
    "\n",
    "print(sorted(lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in fn.frames():\n",
    "    for fe in frame.FE.values():\n",
    "        if \"cognizer\" in fe[\"name\"].lower():\n",
    "            frames_with_cognizer.append((frame[\"name\"], fe[\"name\"]))\n",
    "\n",
    "# Display results\n",
    "for frame_name, fe_name in frames_with_cognizer:\n",
    "    print(f\"Frame: {frame_name}, Frame Element: {fe_name}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
