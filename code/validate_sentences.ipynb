{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the annotated datasets\n",
    "\n",
    "This notebook provides code for validating the evaluation set .txt files and retrieving information about the anthropomorphic components.\n",
    "\n",
    "1. Make sure that no sentence was annotated with conflicting annotations\n",
    "2. Make sure that there are no duplicate sentences in a sentence\n",
    "3. Make sure that the .txt files used to create the evaluation sets are well-formed - i.e, the IDs contain the database prefix (used to locate them in the dataframe) and that each row contains exactly seven tab-separated values.\n",
    "4. Check that the annotations are correct - e.g. the positive set contains only ['p1','p2','p3'] scores, the negative set contains only ['n1','n2','n3'] scores, and the inconclusive set has only 'inc'.\n",
    "5. Retrieving the anthropomorphic components\n",
    "6. Retrieving the AI entity lemmas (i.e. without descriptors and modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "        \n",
    "def get_sentences_dict(cat,score):   \n",
    "\n",
    "    sentences_dict = {}\n",
    "    duplicate_ids = []\n",
    "    duplicate_sentence_pairs = []\n",
    "    \n",
    "    sentences = open(f\"../preprocessed_data/evaluation_sentences/{cat}_{score}.txt\",\"r\")\n",
    "    \n",
    "    for line in sentences.readlines():\n",
    "        line = line.strip()\n",
    "        line = line.split(\"\\t\")\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "        sent_id = line[0]\n",
    "        sent_info = line[1:]\n",
    "\n",
    "        # wellformedness checks\n",
    "        if len(line) != 7:\n",
    "            print(f\"The row with the ID {sent_id} in {cat}_{score}.txt is not well-formed.\")\n",
    "        id_prefix = sent_id[:6]\n",
    "        if not re.match(r\"^[1-7]{1}_(arx|acl)_\", id_prefix):\n",
    "            print(f\"The ID {sent_id} in {cat}_{score} is not well-formed.\")\n",
    "        \n",
    "        if sent_id not in sentences_dict:\n",
    "            if sent_info not in sentences_dict.values():\n",
    "                sentences_dict[sent_id] = sent_info\n",
    "            else: # the sentence appears twice with different IDs \n",
    "                other_id = [key for key in sentences_dict if sentences_dict[key] == sent][0]\n",
    "                duplicate_sentence = (other_id,sent_id)\n",
    "                duplicate_sentence_pairs.append(duplicate_sentence) \n",
    "        else: # the sentence appears twice with the same ID\n",
    "            duplicate_ids.append(sent_id)\n",
    "\n",
    "    return sentences_dict,duplicate_ids,duplicate_sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_num_and_duplicates(cat,score,num):\n",
    "\n",
    "    response = \"No duplicate utterances.\"\n",
    "    print(f\"Checking for duplicate entries in {cat}_{score}.txt...\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0] # dict of ids and sentence info\n",
    "    duplicate_ids = get_sentences_dict(cat,score)[1] # list of duplicate sentences with identical ids\n",
    "    duplicate_sentence_pairs = get_sentences_dict(cat,score)[2] # list of duplicate sentences with different ids\n",
    "    \n",
    "    if len(sentences_dict.keys()) > num:\n",
    "        print(f\"There are more than {num} sentences in {cat}_{score}.txt.\")\n",
    "    elif len(sentences_dict.keys()) < num:\n",
    "        print(f\"There are less than {num} sentences in {cat}_{score}.txt.\")\n",
    "\n",
    "    if duplicate_ids:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The sentences with the following ids appear twice: \",duplicate_ids,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    if duplicate_sentence_pairs:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The following ID pairs refer to the same sentence: \",duplicate_sentence_pairs,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    return response\n",
    "\n",
    "def check_annotations(cat,score):\n",
    "\n",
    "    annotations_dict = {}\n",
    "\n",
    "    if cat == \"noun_phrases\" or cat == 'possessives':\n",
    "        annotations = ['p']\n",
    "    else:\n",
    "        if score == 'positive':\n",
    "            annotations = ['p1','p2','p3']\n",
    "        elif score == 'negative':\n",
    "            annotations = ['n1','n2','n3']\n",
    "        elif score == 'inconclusive':\n",
    "            annotations = ['inc']\n",
    "\n",
    "    print(f\"Checking annotations in {cat}_{score}.txt:\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "\n",
    "    for sent_id,sent_info in sentences_dict.items():\n",
    "        if sent_info[5] not in annotations:\n",
    "            print(f\"Fix incorrect annotation {sent_info[5]} in the sentence with the ID {sent_id}\")\n",
    "        if sent_info[5] not in annotations_dict:\n",
    "            annotations_dict[sent_info[5]] = 1\n",
    "        else:\n",
    "            annotations_dict[sent_info[5]] += 1\n",
    "\n",
    "    return annotations_dict\n",
    "\n",
    "def pairwise_conflict_check(cat,score1,score2):\n",
    "\n",
    "    print(f\"Comparing {score1} cases and {score2} cases for the {cat} set...\")\n",
    "\n",
    "    conflicting_annotation = False\n",
    "\n",
    "    dict1 = get_sentences_dict(cat,score1)[0]\n",
    "    dict2 = get_sentences_dict(cat,score2)[0]\n",
    "\n",
    "    for id1,sent in dict1.items():\n",
    "        if id1 in dict2:\n",
    "            conflicting_annotation = True\n",
    "            print(f\"The {score1} sentence with the ID \",id1,f\" appears in the {score2} set with the same ID\")\n",
    "        elif sent in dict2.values():\n",
    "            conflicting_annotation = True\n",
    "            id2 = [key for keys in dict2.keys() if dict2[key] == sent][0]\n",
    "            print(f\"The {score1} sentence with the ID  \",id1,\n",
    "                  f\" appears in the {score2} set with the ID \",id2)\n",
    "\n",
    "    return conflicting_annotation\n",
    "\n",
    "def check_conflicting_annotations(cat,case,other_cases):\n",
    "\n",
    "    response = \"No conflicting annotations.\"\n",
    "\n",
    "    for other_case in other_cases:\n",
    "\n",
    "        conflicting_annotations = pairwise_conflict_check(cat,case,other_case)\n",
    "        if conflicting_annotations:\n",
    "            check = \"Resolve conflicts before proceeding.\"\n",
    "            print(f\"Conflicting annotations in the {case} and {other_case} sets!!!\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_phrases(cat,score,idx):\n",
    "\n",
    "    ai_components = {}\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        if sent_info[idx] not in ai_components:\n",
    "            ai_components[sent_info[idx]] = 1\n",
    "        else:\n",
    "            ai_components[sent_info[idx]] += 1\n",
    "\n",
    "    return ai_components\n",
    "\n",
    "def get_entities_or_components(cat,score,idx):\n",
    "\n",
    "    components = {}\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        elements = sent_info[idx].split(\",\")\n",
    "        for element in elements:\n",
    "            if element not in components:\n",
    "                components[element] = 1\n",
    "            else:\n",
    "                components[element] += 1\n",
    "\n",
    "    return components\n",
    "\n",
    "def get_phrase_mask_entity_triplets(cat,score):\n",
    "\n",
    "    phrase_mask_entity_triplets = []\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    \n",
    "    for sent_id,sent_info in sentences_dict.items():\n",
    "        phrase_mask_entity_triplets.append((sent_info[1],sent_info[2],sent_info[3]))\n",
    "\n",
    "    return phrase_mask_entity_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sentences for each category\n",
    "\n",
    "The categories are:\n",
    "1. verb_subjects - sentences in which the AI entity is the subject of an anthropomorphic verb (nsubj)\n",
    "2. verb_objects - sentences in which the AI entity is object of an anthropomorphic verb (pobj,dobj)\n",
    "4. adjective_phrases - sentences in which the AI entity is part of an anthropomorphic adjectival phrase\n",
    "5. noun_phrases - sentences in which the AI entity is part of an anthropomorphic noun phrase\n",
    "6. possessives - sentences in which the AI entity is immediately followed by a possessive marker\n",
    "7. comparisons - sentences in which the AI entity is being compared to humans explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate entries in verb_subjects_positive.txt...\n",
      "No duplicate utterances. \n",
      "\n",
      "Comparing positive cases and negative cases for the verb_subjects set...\n",
      "Comparing positive cases and inconclusive cases for the verb_subjects set...\n",
      "No conflicting annotations. \n",
      "\n",
      "Checking annotations in verb_subjects_positive.txt:\n",
      "{'p3': 18, 'p2': 40, 'p1': 2} \n",
      "\n",
      "2 :  AI\n",
      "2 :  AI agent\n",
      "2 :  AI agents\n",
      "1 :  AI system\n",
      "2 :  AI systems\n",
      "4 :  ChatGPT\n",
      "1 :  GPT-3\n",
      "1 :  GPT-4\n",
      "5 :  LLM\n",
      "1 :  LLM-based expert\n",
      "15 :  LLMs\n",
      "2 :  LM\n",
      "7 :  LMs\n",
      "1 :  conversational AI development platform\n",
      "1 :  instruction-tuned model\n",
      "1 :  language model\n",
      "1 :  large generative language model\n",
      "8 :  model\n",
      "2 :  system\n",
      "1 :  trained model\n",
      "Checking for duplicate entries in verb_subjects_negative.txt...\n",
      "No duplicate utterances. \n",
      "\n",
      "Comparing negative cases and positive cases for the verb_subjects set...\n",
      "Comparing negative cases and inconclusive cases for the verb_subjects set...\n",
      "No conflicting annotations. \n",
      "\n",
      "Checking annotations in verb_subjects_negative.txt:\n",
      "{'n2': 28, 'n1': 18, 'n3': 14} \n",
      "\n",
      "2 :  AI\n",
      "1 :  AI artificial intelligence\n",
      "1 :  AI models\n",
      "2 :  AI systems\n",
      "1 :  AI-REML algorithm\n",
      "1 :  Artificial intelligence (AI) models\n",
      "7 :  ChatGPT\n",
      "1 :  ChatGPT model\n",
      "1 :  LLM-based methods\n",
      "5 :  LLMs\n",
      "1 :  LMs\n",
      "1 :  Large Language models (LLMs)\n",
      "1 :  Machine Learning model\n",
      "1 :  Machine Translation system\n",
      "1 :  OCC model\n",
      "1 :  TF model\n",
      "1 :  algorithm\n",
      "1 :  hybrid learning algorithm\n",
      "1 :  image captioning system\n",
      "19 :  model\n",
      "1 :  models\n",
      "1 :  neural language models\n",
      "1 :  paraphrasing model\n",
      "6 :  system\n",
      "1 :  systems\n",
      "Checking for duplicate entries in verb_subjects_inconclusive.txt...\n",
      "There are less than 30 sentences in verb_subjects_inconclusive.txt.\n",
      "No duplicate utterances. \n",
      "\n",
      "Comparing inconclusive cases and positive cases for the verb_subjects set...\n",
      "Comparing inconclusive cases and negative cases for the verb_subjects set...\n",
      "No conflicting annotations. \n",
      "\n",
      "Checking annotations in verb_subjects_inconclusive.txt:\n",
      "Fix incorrect annotation NOTSURE in the sentence with the ID 1_arx_1101.3316_238729_3\n",
      "{'inc': 24, 'NOTSURE': 1} \n",
      "\n",
      "1 :  AI systems\n",
      "3 :  ChatGPT\n",
      "1 :  GPT-3\n",
      "1 :  GPT-4\n",
      "4 :  LLMs\n",
      "2 :  LMs\n",
      "1 :  VL model\n",
      "1 :  algorithm\n",
      "1 :  generation system\n",
      "9 :  model\n",
      "1 :  topic model\n"
     ]
    }
   ],
   "source": [
    "cases_and_nums = {\"positive\":60,\"negative\":60,\"inconclusive\":30}\n",
    "#cases_and_nums = {\"inconclusive\":50}\n",
    "category_is = \"verb_subjects\" # bring it to the runway\n",
    "\n",
    "check_AI_phrases_and_masks = True\n",
    "check_entities_or_anthro = False\n",
    "check_AI_triplets = False\n",
    "\n",
    "for case in cases_and_nums:\n",
    "\n",
    "    # check that the number of utterance matches the expecation, and that the file contains no duplicate sentences\n",
    "    check1 = check_num_and_duplicates(category_is,case,cases_and_nums[case])\n",
    "    print(check1,'\\n')\n",
    "    \n",
    "    # check that the same sentence does not appear twice in two sets of the same category\n",
    "    # not applicable for noun_phrases, possessives (always positive) and comparisons (always inconclusive)\n",
    "    other_cases = [other_case for other_case in cases_and_nums if other_case != case]\n",
    "    if other_cases:\n",
    "        check2 = check_conflicting_annotations(category_is,case,other_cases)\n",
    "        print(check2, '\\n')\n",
    "\n",
    "    # check that the annotations in a given file are correct (i.e. no negative annotations in the positive set)\n",
    "    check3 = check_annotations(category_is,case)\n",
    "    print(check3,'\\n')\n",
    "\n",
    "    # retrieve the AI phrases and their count\n",
    "    # 1: the full AI phrase\n",
    "    # 2: the masked component\n",
    "    if check_AI_phrases_and_masks == True:\n",
    "        idx = 2 # options are 1 and 2\n",
    "        components = get_ai_phrases(category_is,case,idx)\n",
    "        sorted_list = sorted([(key,value) for key,value in components.items()])\n",
    "        for item in sorted_list:\n",
    "            print(item[1],\": \",item[0])\n",
    "    \n",
    "    # retrieve all of the potentially (non-)anthropomorphic components / AI entities and their count\n",
    "    # 3: AI entities\n",
    "    # 4: anthropomorphic components\n",
    "    if check_entities_or_anthro == True:\n",
    "        idx = 4 # options are 3 and 4\n",
    "        anthro_components = get_entities_or_components(category_is,case,idx)\n",
    "        sorted_anthro_list = sorted([(key,value) for key,value in anthro_components.items()])\n",
    "        for item in sorted_anthro_list:\n",
    "            print(item[1],\": \",item[0])\n",
    "\n",
    "    # retrieve the AI phrase,mask,entity triplets and their unique ID\n",
    "    if check_AI_triplets == True:\n",
    "        phrase_mask_entity_triplets = get_phrase_mask_entity_triplets(category_is,case)\n",
    "        for item in phrase_mask_entity_triplets:\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
