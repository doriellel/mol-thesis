{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the annotated datasets\n",
    "\n",
    "This notebook provides code for validating the evaluation set .txt files and retrieving information about the anthropomorphic components.\n",
    "\n",
    "1. Make sure that no sentence was annotated with conflicting annotations\n",
    "2. Make sure that there are no duplicate sentences in a sentence\n",
    "3. Make sure that the .txt files used to create the evaluation sets are well-formed - i.e, the IDs contain the database prefix (used to locate them in the dataframe) and that each row contains exactly seven tab-separated values.\n",
    "4. Check that the annotations are correct - e.g. the positive set contains only ['p1','p2','p3'] scores, the negative set contains only ['n1','n2','n3'] scores, and the inconclusive set has only 'inc'.\n",
    "5. Retrieving the anthropomorphic components\n",
    "6. Retrieving the AI entity lemmas (i.e. without descriptors and modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "        \n",
    "def get_sentences_dict(cat,score):   \n",
    "\n",
    "    sentences_dict = {}\n",
    "    duplicate_ids = []\n",
    "    duplicate_sentence_pairs = []\n",
    "    \n",
    "    sentences = open(f\"../preprocessed_data/evaluation_sentences/{cat}_{score}.txt\",\"r\")\n",
    "    \n",
    "    for line in sentences.readlines():\n",
    "        line = line.strip()\n",
    "        line = line.split(\"\\t\")\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "        sent_id = line[0]\n",
    "        sent_info = line[1:]\n",
    "\n",
    "        # wellformedness checks\n",
    "        if len(line) != 7:\n",
    "            print(f\"The row with the ID {sent_id} in {cat}_{score}.txt is not well-formed.\")\n",
    "        id_prefix = sent_id[:6]\n",
    "        if not re.match(r\"^[1-7]{1}_(arx|acl)_\", id_prefix):\n",
    "            print(f\"The ID {sent_id} in {cat}_{score} is not well-formed.\")\n",
    "        \n",
    "        if sent_id not in sentences_dict:\n",
    "            if sent_info not in sentences_dict.values():\n",
    "                sentences_dict[sent_id] = sent_info\n",
    "            else: # the sentence appears twice with different IDs \n",
    "                other_id = [key for key in sentences_dict if sentences_dict[key] == sent][0]\n",
    "                duplicate_sentence = (other_id,sent_id)\n",
    "                duplicate_sentence_pairs.append(duplicate_sentence) \n",
    "        else: # the sentence appears twice with the same ID\n",
    "            duplicate_ids.append(sent_id)\n",
    "\n",
    "    return sentences_dict,duplicate_ids,duplicate_sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_num_and_duplicates(cat,score,num):\n",
    "\n",
    "    response = \"No duplicate utterances.\"\n",
    "    print(f\"Checking for duplicate entries in {cat}_{score}.txt...\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0] # dict of ids and sentence info\n",
    "    duplicate_ids = get_sentences_dict(cat,score)[1] # list of duplicate sentences with identical ids\n",
    "    duplicate_sentence_pairs = get_sentences_dict(cat,score)[2] # list of duplicate sentences with different ids\n",
    "    \n",
    "    if len(sentences_dict.keys()) > num:\n",
    "        print(f\"There are more than {num} sentences in {cat}_{score}.txt.\")\n",
    "    elif len(sentences_dict.keys()) < num:\n",
    "        print(f\"There are less than {num} sentences in {cat}_{score}.txt.\")\n",
    "\n",
    "    if duplicate_ids:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The sentences with the following ids appear twice: \",duplicate_ids,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    if duplicate_sentence_pairs:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The following ID pairs refer to the same sentence: \",duplicate_sentence_pairs,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    return response\n",
    "\n",
    "def check_annotations(cat,score):\n",
    "\n",
    "    annotations_dict = {}\n",
    "\n",
    "    if cat == \"noun_phrases\" or cat == 'possessives':\n",
    "        annotations = ['p']\n",
    "    else:\n",
    "        if score == 'positive':\n",
    "            annotations = ['p1','p2','p3']\n",
    "        elif score == 'negative':\n",
    "            annotations = ['n1','n2','n3']\n",
    "        elif score == 'inconclusive':\n",
    "            annotations = ['inc']\n",
    "\n",
    "    print(f\"Checking annotations in {cat}_{score}.txt:\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "\n",
    "    for sent_id,sent_info in sentences_dict.items():\n",
    "        if sent_info[5] not in annotations:\n",
    "            print(f\"Fix incorrect annotation {sent_info[5]} in the sentence with the ID {sent_id}\")\n",
    "        if sent_info[5] not in annotations_dict:\n",
    "            annotations_dict[sent_info[5]] = 1\n",
    "        else:\n",
    "            annotations_dict[sent_info[5]] += 1\n",
    "\n",
    "    return annotations_dict\n",
    "\n",
    "def pairwise_conflict_check(cat,score1,score2):\n",
    "\n",
    "    print(f\"Comparing {score1} cases and {score2} cases for the {cat} set...\")\n",
    "\n",
    "    conflicting_annotation = False\n",
    "\n",
    "    dict1 = get_sentences_dict(cat,score1)[0]\n",
    "    dict2 = get_sentences_dict(cat,score2)[0]\n",
    "\n",
    "    for id1,sent in dict1.items():\n",
    "        if id1 in dict2:\n",
    "            conflicting_annotation = True\n",
    "            print(f\"The {score1} sentence with the ID \",id1,f\" appears in the {score2} set with the same ID\")\n",
    "        elif sent in dict2.values():\n",
    "            conflicting_annotation = True\n",
    "            id2 = [key for keys in dict2.keys() if dict2[key] == sent][0]\n",
    "            print(f\"The {score1} sentence with the ID  \",id1,\n",
    "                  f\" appears in the {score2} set with the ID \",id2)\n",
    "\n",
    "    return conflicting_annotation\n",
    "\n",
    "def check_conflicting_annotations(cat,case,other_cases):\n",
    "\n",
    "    response = \"No conflicting annotations.\"\n",
    "\n",
    "    for other_case in other_cases:\n",
    "\n",
    "        conflicting_annotations = pairwise_conflict_check(cat,case,other_case)\n",
    "        if conflicting_annotations:\n",
    "            check = \"Resolve conflicts before proceeding.\"\n",
    "            print(f\"Conflicting annotations in the {case} and {other_case} sets!!!\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anthro_components(cat,score):\n",
    "\n",
    "    anthro_components = {}\n",
    "\n",
    "    print(f\"Retrieving a list of anthropomorphic words in {cat}_{score}.txt:\")\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        if sent_info[4] not in anthro_components:\n",
    "            anthro_components[sent_info[4]] = 1\n",
    "        else:\n",
    "            anthro_components[sent_info[4]] += 1\n",
    "\n",
    "    return anthro_components\n",
    "\n",
    "def get_ai_components(cat,score):\n",
    "\n",
    "    ai_components = {}\n",
    "\n",
    "    print(f\"Retrieving a list of AI entities in {cat}_{score}.txt:\")\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        if sent_info[3] not in ai_components:\n",
    "            ai_components[sent_info[3]] = 1\n",
    "        else:\n",
    "            ai_components[sent_info[3]] += 1\n",
    "\n",
    "    return ai_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sentences for each category\n",
    "\n",
    "The categories are:\n",
    "1. verb_subjects - sentences in which the AI entity is the subject of an anthropomorphic verb (nsubj)\n",
    "2. verb_objects - sentences in which the AI entity is object of an anthropomorphic verb (pobj,dobj)\n",
    "4. adjective_phrases - sentences in which the AI entity is part of an anthropomorphic adjectival phrase\n",
    "5. noun_phrases - sentences in which the AI entity is part of an anthropomorphic noun phrase\n",
    "6. possessives - sentences in which the AI entity is immediately followed by a possessive marker\n",
    "7. comparisons - sentences in which the AI entity is being compared to humans explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate entries in possessives_positive.txt...\n",
      "No duplicate utterances. \n",
      "\n",
      "Checking annotations in possessives_positive.txt:\n",
      "{'p': 60} \n",
      "\n",
      "Retrieving a list of anthropomorphic words in possessives_positive.txt:\n",
      "[(1, 'abductive reasoning'), (1, 'ability to comprehend theoretical concepts and differentiate between constructs'), (1, 'ability to discern and adapt to nuanced instructions'), (1, 'ability to provide a robust interpretation of its decision-making logic'), (1, 'ability to pursue multiple interconnected learning objectives'), (1, 'ability to showcase pedagogical skills'), (1, 'ability to understand'), (1, 'ability to use tools'), (1, 'actions'), (1, 'awareness'), (1, 'capability in understanding and following instructions'), (1, 'capability to understand natural language'), (1, 'capacity to internalize and project instructible personas'), (1, 'causal reasoning ability'), (1, 'cognitive abilities'), (1, 'common-sense reasoning'), (1, 'commonsense knowledge and reasoning abilities'), (1, 'commonsense reasoning capabilities'), (1, 'competence in comprehending performing intricate tasks'), (1, 'conceptual capabilities'), (1, 'considerable proficiency in writing Physics essays and coding abilities'), (1, 'consultation abilities'), (1, 'cooperation and coordination behavior'), (1, 'decision-making information search, deliberation, and causal reasoning abilities'), (1, 'decision-making process'), (1, 'desire'), (1, 'editorial capabilities'), (1, 'feminine-coded abilities'), (1, 'intellectual property'), (1, 'knowledge acquisition capabilities'), (1, 'legal drafting and reasoning capabilities'), (1, 'lies'), (1, 'logic understanding'), (1, 'manipulation'), (1, 'misinterpretations'), (1, 'misunderstandings'), (1, 'personality types'), (1, 'prior legal knowledge'), (1, 'problem-solving capabilities'), (1, 'process for solving a task'), (1, 'rational decisions'), (1, 'reasoning abilities'), (1, 'reasoning capabilities'), (1, 'refusal behavior'), (1, 'related beliefs'), (1, 'social behaviour'), (1, 'strengths in knowledge comprehension and reasoning'), (1, 'tendency to deceive'), (1, 'tendency to hallucinate information'), (1, 'trustworthiness'), (1, 'understanding ability'), (1, 'understanding capabilities'), (1, 'writing'), (2, 'reasoning'), (2, 'understanding'), (3, 'decisions')] \n",
      "\n",
      "Retrieving a list of AI entities in possessives_positive.txt:\n",
      "[(1, 'algorithm'), (1, 'method'), (2, 'AI'), (2, 'GPT'), (2, 'GPT-3'), (2, 'LM'), (5, 'system'), (10, 'ChatGPT'), (14, 'model'), (21, 'LLM')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cases_and_nums = {\"positive\":50,\"negative\":50,\"inconclusive\":20}\n",
    "cases_and_nums = {\"positive\":60}\n",
    "category_is = \"possessives\" # bring it to the runway\n",
    "\n",
    "for case in cases_and_nums:\n",
    "\n",
    "    # check that the number of utterance matches the expecation, and that the file contains no duplicate sentences\n",
    "    check1 = check_num_and_duplicates(category_is,case,cases_and_nums[case])\n",
    "    print(check1,'\\n')\n",
    "    \n",
    "    # check that the same sentence does not appear twice in two sets of the same category\n",
    "    # not applicable for noun_phrases, possessives (always positive) and comparisons (always inconclusive)\n",
    "    other_cases = [other_case for other_case in cases_and_nums if other_case != case]\n",
    "    if other_cases:\n",
    "        check2 = check_conflicting_annotations(category_is,case,other_cases)\n",
    "        print(check2, '\\n')\n",
    "\n",
    "    # check that the annotations in a given file are correct (i.e. no negative annotations in the positive set)\n",
    "    check3 = check_annotations(category_is,case)\n",
    "    print(check3,'\\n')\n",
    "\n",
    "    # retrieve all of the (non-)anthropomorphic components in a given file - the verb/noun/adjective in suspect\n",
    "    anthro_components = get_anthro_components(category_is,case)\n",
    "    sorted_list = sorted([(value,key) for key,value in anthro_components.items()])\n",
    "    print(sorted_list,'\\n')\n",
    "\n",
    "    # retrieve all of the AI components in a given file\n",
    "    ai_components = get_ai_components(category_is,case)\n",
    "    sorted_list = sorted([(value,key) for key,value in ai_components.items()])\n",
    "    print(sorted_list,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
