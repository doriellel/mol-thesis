{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the annotated datasets\n",
    "\n",
    "This notebook provides code for validating the evaluation set .txt files and retrieving information about the anthropomorphic components.\n",
    "\n",
    "1. Make sure that no sentence was annotated with conflicting annotations\n",
    "2. Make sure that there are no duplicate sentences in a sentence\n",
    "3. Make sure that the .txt files used to create the evaluation sets are well-formed - i.e, the IDs contain the database prefix (used to locate them in the dataframe) and that each row contains exactly seven tab-separated values.\n",
    "4. Check that the annotations are correct - e.g. the positive set contains only ['p1','p2','p3'] scores, the negative set contains only ['n1','n2','n3'] scores, and the inconclusive set has only 'inc'.\n",
    "5. Retrieving the anthropomorphic components\n",
    "6. Retrieving the AI entity lemmas (i.e. without descriptors and modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "        \n",
    "def get_sentences_dict(cat,score):   \n",
    "\n",
    "    sentences_dict = {}\n",
    "    duplicate_ids = []\n",
    "    duplicate_sentence_pairs = []\n",
    "    \n",
    "    sentences = open(f\"../preprocessed_data/evaluation_sentences/{cat}_{score}.txt\",\"r\")\n",
    "    \n",
    "    for line in sentences.readlines():\n",
    "        line = line.strip()\n",
    "        line = line.split(\"\\t\")\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "        sent_id = line[0]\n",
    "        sent_info = line[1:]\n",
    "\n",
    "        # wellformedness checks\n",
    "        if len(line) != 7:\n",
    "            print(f\"The row with the ID {sent_id} in {cat}_{score}.txt is not well-formed.\")\n",
    "        id_prefix = sent_id[:6]\n",
    "        if not re.match(r\"^[1-7]{1}_(arx|acl)_\", id_prefix):\n",
    "            print(f\"The ID {sent_id} in {cat}_{score} is not well-formed.\")\n",
    "        \n",
    "        if sent_id not in sentences_dict:\n",
    "            if sent_info not in sentences_dict.values():\n",
    "                sentences_dict[sent_id] = sent_info\n",
    "            else: # the sentence appears twice with different IDs \n",
    "                other_id = [key for key in sentences_dict if sentences_dict[key] == sent][0]\n",
    "                duplicate_sentence = (other_id,sent_id)\n",
    "                duplicate_sentence_pairs.append(duplicate_sentence) \n",
    "        else: # the sentence appears twice with the same ID\n",
    "            duplicate_ids.append(sent_id)\n",
    "\n",
    "    return sentences_dict,duplicate_ids,duplicate_sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_num_and_duplicates(cat,score,num):\n",
    "\n",
    "    response = \"No duplicate utterances.\"\n",
    "    print(f\"Checking for duplicate entries in {cat}_{score}.txt...\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0] # dict of ids and sentence info\n",
    "    duplicate_ids = get_sentences_dict(cat,score)[1] # list of duplicate sentences with identical ids\n",
    "    duplicate_sentence_pairs = get_sentences_dict(cat,score)[2] # list of duplicate sentences with different ids\n",
    "    \n",
    "    if len(sentences_dict.keys()) > num:\n",
    "        print(f\"There are more than {num} sentences in {cat}_{score}.txt.\")\n",
    "    elif len(sentences_dict.keys()) < num:\n",
    "        print(f\"There are less than {num} sentences in {cat}_{score}.txt.\")\n",
    "\n",
    "    if duplicate_ids:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The sentences with the following ids appear twice: \",duplicate_ids,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    if duplicate_sentence_pairs:\n",
    "        response = f\"Resolve duplicates in the {score} set!!!\"\n",
    "        print(\"The following ID pairs refer to the same sentence: \",duplicate_sentence_pairs,\n",
    "             f\" in {cat}_{score}.txt\")\n",
    "\n",
    "    return response\n",
    "\n",
    "def check_annotations(cat,score):\n",
    "\n",
    "    annotations_dict = {}\n",
    "\n",
    "    if cat == \"noun_phrases\":\n",
    "        annotations = ['p']\n",
    "    else:\n",
    "        if score == 'positive':\n",
    "            annotations = ['p1','p2','p3']\n",
    "        elif score == 'negative':\n",
    "            annotations = ['n1','n2','n3']\n",
    "        elif score == 'inconclusive':\n",
    "            annotations = ['inc']\n",
    "\n",
    "    print(f\"Checking annotations in {cat}_{score}.txt:\")\n",
    "\n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "\n",
    "    for sent_id,sent_info in sentences_dict.items():\n",
    "        if sent_info[5] not in annotations:\n",
    "            print(f\"Fix incorrect annotation {sent_info[5]} in the sentence with the ID {sent_id}\")\n",
    "        if sent_info[5] not in annotations_dict:\n",
    "            annotations_dict[sent_info[5]] = 1\n",
    "        else:\n",
    "            annotations_dict[sent_info[5]] += 1\n",
    "\n",
    "    return annotations_dict\n",
    "\n",
    "def pairwise_conflict_check(cat,score1,score2):\n",
    "\n",
    "    print(f\"Comparing {score1} cases and {score2} cases for the {cat} set...\")\n",
    "\n",
    "    conflicting_annotation = False\n",
    "\n",
    "    dict1 = get_sentences_dict(cat,score1)[0]\n",
    "    dict2 = get_sentences_dict(cat,score2)[0]\n",
    "\n",
    "    for id1,sent in dict1.items():\n",
    "        if id1 in dict2:\n",
    "            conflicting_annotation = True\n",
    "            print(f\"The {score1} sentence with the ID \",id1,f\" appears in the {score2} set with the same ID\")\n",
    "        elif sent in dict2.values():\n",
    "            conflicting_annotation = True\n",
    "            id2 = [key for keys in dict2.keys() if dict2[key] == sent][0]\n",
    "            print(f\"The {score1} sentence with the ID  \",id1,\n",
    "                  f\" appears in the {score2} set with the ID \",id2)\n",
    "\n",
    "    return conflicting_annotation\n",
    "\n",
    "def check_conflicting_annotations(cat,case,other_cases):\n",
    "\n",
    "    response = \"No conflicting annotations.\"\n",
    "\n",
    "    for other_case in other_cases:\n",
    "\n",
    "        conflicting_annotations = pairwise_conflict_check(cat,case,other_case)\n",
    "        if conflicting_annotations:\n",
    "            check = \"Resolve conflicts before proceeding.\"\n",
    "            print(f\"Conflicting annotations in the {case} and {other_case} sets!!!\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anthro_components(cat,score):\n",
    "\n",
    "    anthro_components = {}\n",
    "\n",
    "    print(f\"Retrieving a list of anthropomorphic words in {cat}_{score}.txt:\")\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        if sent_info[4] not in anthro_components:\n",
    "            anthro_components[sent_info[4]] = 1\n",
    "        else:\n",
    "            anthro_components[sent_info[4]] += 1\n",
    "\n",
    "    return anthro_components\n",
    "\n",
    "def get_ai_components(cat,score):\n",
    "\n",
    "    ai_components = {}\n",
    "\n",
    "    print(f\"Retrieving a list of AI entities in {cat}_{score}.txt:\")\n",
    "    \n",
    "    sentences_dict = get_sentences_dict(cat,score)[0]\n",
    "    all_sentences_info = sentences_dict.values()\n",
    "    \n",
    "    for sent_info in all_sentences_info:\n",
    "        if sent_info[3] not in ai_components:\n",
    "            ai_components[sent_info[3]] = 1\n",
    "        else:\n",
    "            ai_components[sent_info[3]] += 1\n",
    "\n",
    "    return ai_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sentences for each category\n",
    "\n",
    "The categories are:\n",
    "1. verb_subjects - sentences in which the AI entity is the subject of an anthropomorphic verb (nsubj)\n",
    "2. verb_objects - sentences in which the AI entity is object of an anthropomorphic verb (pobj,dobj)\n",
    "4. adjective_phrases - sentences in which the AI entity is part of an anthropomorphic adjectival phrase\n",
    "5. noun_phrases - sentences in which the AI entity is part of an anthropomorphic noun phrase\n",
    "6. possessives - sentences in which the AI entity is immediately followed by a possessive marker\n",
    "7. comparisons - sentences in which the AI entity is being compared to humans explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate entries in comparisons_inconclusive.txt...\n",
      "No duplicate utterances. \n",
      "\n",
      "Checking annotations in comparisons_inconclusive.txt:\n",
      "{'inc': 50} \n",
      "\n",
      "Retrieving a list of anthropomorphic words in comparisons_inconclusive.txt:\n",
      "{'perform similarly to humans': 2, 'score similarly to human samples in terms of personality': 1, 'inference process similarly to humans': 1, 'human-like inferences': 1, 'human-like expression and reasoning abilitiies': 1, 'process visual information in a human-like way': 1, 'respond to conversations in a human-like manner': 1, 'human-like syntactic and semantic knowledge': 1, 'human-like reasoning': 1, 'human-like fluency': 1, 'human-like conversations': 1, 'human-like mistakes': 1, 'human-like responses in dialogue': 1, 'human-like': 1, 'human-like cognitive abilities': 2, 'creative as humans': 1, 'recognize various entities to the same degree as humans': 1, 'converse with each other as well as humans': 1, 'reason casually as humans would': 1, 'human-like dialogue': 1, 'understand formal languages as well as humans': 1, 'simulate human behavior and serve as human-like agents': 1, 'process recursively nested grammatical structures as reliably as humans': 1, 'human-like communicators': 1, 'performs close to or even slightly better than human annotators': 1, 'better than that of humans': 1, 'like human experts': 1, 'struggle with reverse modeling like humans': 1, 'behave much like humans': 1, 'behave and work like the human mind': 1, 'reason like humans': 1, 'make mistakes,have blind spots,hallucinate,struggle to generalize to new situations like humans': 1, 'have a consonant bias like humans': 1, 'show child-like U-shaped learning curves': 1, 'generating intricate, human-like text': 1, 'human-like developmental stages of exploration': 1, 'exposed to language through media similar to children': 1, 'human-like intuition': 1, 'human-like behavior': 1, 'human-like performance in diverse psychological tasks': 1, 'human-like knowledge of common words': 1, 'human-like skills': 1, 'behaviors similar to human responses': 1, 'organisation of perceptual semantics similar to those observed in humans': 1, 'performance comparable to adult humans': 1, 'human-like translation performance': 1, 'perform at a level comparable to humans': 1, 'cognitive constructs similar to those observed in humans': 1} \n",
      "\n",
      "Retrieving a list of AI entities in comparisons_inconclusive.txt:\n",
      "{'model': 11, 'GPT-3': 2, 'LLM': 17, 'system': 5, 'architecture': 1, 'ChatGPT': 4, 'AI': 3, 'LM': 2, 'GPT-4': 1, 'machine': 1, 'BERT,RoBERTa,GPT-2,GPT-3': 1, 'GPT': 1, 'ChatGPT,GPT,Llama': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cases_and_nums = {\"positive\":50,\"negative\":50,\"inconclusive\":20}\n",
    "cases_and_nums = {\"inconclusive\":50}\n",
    "category_is = \"comparisons\" # bring it to the runway\n",
    "\n",
    "for case in cases_and_nums:\n",
    "\n",
    "    # check that the number of utterance matches the expecation, and that the file contains no duplicate sentences\n",
    "    check1 = check_num_and_duplicates(category_is,case,cases_and_nums[case])\n",
    "    print(check1,'\\n')\n",
    "    \n",
    "    # check that the same sentence does not appear twice in two sets of the same category\n",
    "    # not applicable for noun_phrases (always positive) and comparisons (always inconclusive)\n",
    "    if category_is != \"noun_phrases\" and category_is != \"comparisons\":\n",
    "        other_cases = [other_case for other_case in cases_and_nums if other_case != case]\n",
    "        check2 = check_conflicting_annotations(category_is,case,other_cases)\n",
    "        print(check2, '\\n')\n",
    "\n",
    "    # check that the annotations in a given file are correct (i.e. no negative annotations in the positive set)\n",
    "    check3 = check_annotations(category_is,case)\n",
    "    print(check3,'\\n')\n",
    "\n",
    "    # retrieve all of the (non-)anthropomorphic components in a given file - the verb/noun/adjective in suspect\n",
    "    anthro_components = get_anthro_components(category_is,case)\n",
    "    print(anthro_components,'\\n')\n",
    "\n",
    "    # retrieve all of the AI components in a given file\n",
    "    ai_components = get_ai_components(category_is,case)\n",
    "    print(ai_components,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f37b899a14b1e53256e3dbe85dea3859019f1cb8d1c44a9c4840877cfd0e7ef"
  },
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
