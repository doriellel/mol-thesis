id,sentence,AI phrase,mask,AI entity,anthro component,score
6_arx_2104.14506_1461924_5,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.",an AI model,AI model,model,decisions,p
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.",the GPT-3,GPT-3,GPT-3,misunderstandings,p
6_arx_1912.03652_1215548_4,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,the AI system,AI system,system,misinterpretations,p
6_acl_373_16531_2,Actions by the AI system may be required to bring these objects in view.,the AI system,AI system,system,actions,p
6_arx_2110.06674_1544817_2,"This raises the question of how we should limit the harm caused by AI ""lies"" (i.e. falsehoods that are actively selected for).",AI,AI,AI,lies,p
6_arx_2207.07051_1682949_0,  Reasoning is a key ability for an intelligent system.,an intelligent system,system,system,reasoning,p  
6_acl_71_46015_2,"In this study, leveraging the POPQUORN dataset, we evaluate nine popular LLMs on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.",nine popular LLMs,LLMs,LLM,ability to understand,p
6_arx_2405.01576_2058788_0,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,AI systems,AI systems,system,tendency to deceive,p
6_acl_245_29281_1,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.",LLMs,LLMs,LLM,reasoning capabilities,p
6_acl_916_40326_5,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs.,Chinese LLMs,LLMs,LLM,knowledge acquisition capabilities,p
6_acl_1539_40949_1,"However, this awareness of LMs has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.",LMs,LMs,LM,awareness,p
6_acl_225_32387_1,Numerous benchmarks have been established to assess the reasoning abilities of LLMs.,LLMs,LLMs,LLM,reasoning abilities,p
6_acl_743_29779_6,"Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.",ChatGPT,ChatGPT,ChatGPT,causal reasoning ability,p
6_acl_538_32700_6,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of LLMs and speed up the development of LLMs in journalism.,LLMs,LLMs,LLM,editorial capabilities,p
6_arx_2101.06573_1410315_4,We show how progress has been made in benchmark development to measure understanding capabilities of AI methods and we review as well how current methods develop understanding capabilities.,AI methods,AI methods,method,understanding capabilities,p
6_arx_2307.16180_1887175_4,"Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.",different LLMs,LLMs,LLM,personality types,p
6_arx_2408.10159_2130340_1,"Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.",Large Language Models (LLMs),Large Language Models (LLMs),model,strengths in knowledge comprehension and reasoning,p
6_arx_2503.16460_2280772_5,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.,LLM,LLM,LLM,problem-solving capabilities,p
6_arx_2309.02077_1906881_6,A medical consultation training set is further constructed to improve the consultation ability of LLMs.,LLMs,LLMs,LLM,consultation abilities,p
6_arx_2305.18752_1851808_6,"Moreover, we provide a benchmark to evaluate the ability of LLMs to use tools, which is performed in both zero-shot and fine-tuning ways.",LLMs,LLMs,LLM,ability to use tools,p
6_arx_2309.11805_1916609_6,"Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.",LLMs,LLMs,LLM,capability to understand natural language,p
6_arx_2310.02417_1924674_0,"Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.",Large language models (LLMs),Large language models (LLMs),model,capability in understanding and following instructions,p
6_arx_2305.16867_1849923_1,We propose to use behavioural game theory to study LLMs' cooperation and coordination behaviour.,LLMs,LLMs,LLM,cooperation and coordination behavior,p
6_arx_2305.04388_1837444_1,It is tempting to interpret these CoT explanations as the LLM's process for solving a task.,the LLM,LLM,LLM,process for solving a task,p
6_arx_2005.02335_1282130_0,Explainable machine learning and artificial intelligence models have been used to justify a model's decision-making process.,a model,model,model,decision-making process,p
6_arx_2203.10923_1623785_4,We also discuss issues that are unique to edge applications such as protecting a model's intellectual property and verifying its integrity.,a model,model,model,intellectual property,p
6_arx_2207.09374_1685272_1,"However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for an AI's decision.",an AI,AI,AI,decisions,p
6_arx_2209.15093_1720808_3,We propose conceptual consistency to measure a LLM's understanding of relevant concepts.,a LLM,LLM,LLM,understanding,p
6_arx_2210.05487_1726842_3,We find that the visual grounding improves the model's understanding of semantic similarity both within and across languages and improves perplexity.,the model,model,model,understanding,p
6_arx_2307.00457_1871453_4,"GenRec uses LLMs' understanding ability to interpret context, learn user preferences, and generate relevant recommendation.",LLMs,LLMs,LLM,understanding abilities,p
6_arx_2307.10250_1881245_0,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.",the GPT-4 Large Language Model,GPT-4 Large Language Model,model,abductive reasoning,p
6_arx_2308.10837_1898729_1,"However, effectively integrating LLMs' commonsense knowledge and reasoning abilities into recommendation systems remains a challenging problem.",LLMs,LLMs,LLM,commonsense knowledge and reasoning abilities,p
6_arx_2308.07326_1895218_4,Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions.,GPT,GPT,GPT,ability to discern and adapt to nuanced instructions,p
6_arx_2307.05488_1876483_8,These biases may impact the responses of constructs and should be considered when interpreting ChatGPT's conceptual capabilities.,ChatGPT,ChatGPT,ChatGPT,conceptual capabilities,p
6_arx_2306.11296_1864444_1,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,ChatGPT,ChatGPT,ChatGPT,tendency to hallucinate information,p
6_arx_2303.13712_1813509_7,We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically.,the algorithm,algorithm,algorithm,manipulation,p
6_arx_2211.08380_1747286_6,"In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.",the model,model,model,decisions,p
6_arx_2301.13852_1784916_11,"Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.",ChatGPT,ChatGPT,ChatGPT,polite writing,p
6_arx_2306.03423_1856571_4,"In this experiment, we characterize ChatGPT's refusal behavior using a black-box attack.",ChatGPT,ChatGPT,ChatGPT,refusal behavior,p
6_acl_406_32568_3,"Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.",LLMs,LLMs,LLM,logic understanding,p
6_arx_2309.05163_1909967_10,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.",the LLMs,LLMs,LLM,considerable proficiency in writing Physics essays and coding abilities,p
6_arx_2311.08487_1951454_2,"This conflict renders LLMs vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.",the models,models,model,desire,p
6_acl_865_25015_6,"On the other hand, downstream performance is mainly driven by the model’s size and prior legal knowledge which can be estimated by upstream and probing performance.",the model,model,model,prior legal knowledge,p
6_acl_2210.12530_1733885_3,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.",the LM,LM,LM,common-sense reasoning,p
6_arx_2206.14576_1674996_1,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",GPT-3,GPT-3,GPT-3,"decision-making,deliberation,causal reasoning abilities",p
6_arx_2308.01552_1889444_4,"The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.",ChatGPT,ChatGPT,ChatGPT,competence in comprehending and performing intricate tasks,p
6_arx_2308.06032_1893924_10,"Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.",an LLM,LLM,LLM,legal drafting and reasoning capabilities,p
6_arx_2308.06920_1894812_8,"This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.",ChatGPT,ChatGPT,ChatGPT,cognitive abilities,p
6_arx_2308.07326_1895218_5,"Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.",the LLM,LLM,LLM,capacity to internalize and project instructible personas,p
6_arx_2308.08407_1896299_3,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,an AI system,AI system,system,ability to provide a robust interpretation of its decision-making logic,p
6_arx_2307.05488_1876483_1,The objective of the studies is to assess ChatGPT's ability to comprehend theoretical concepts and differentiate between constructs.,ChatGPT,ChatGPT,ChatGPT,ability to comprehend theoretical concepts and differentiate between constructs,p
6_arx_2307.04274_1875269_7,"Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model's ability to showcase pedagogical skills.",the model,model,model,ability to showcase pedagogical skills,p
6_arx_2306.10645_1863793_3,"We examine ChatGPT's ability to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.",ChatGPT,ChatGPT,ChatGPT,ability to pursue multiple interconnected learning objectives,p
6_arx_2306.06123_1859271_2,"The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.",the model,model,model,reasoning,p
6_arx_2305.16867_1849923_8,These results enrich our understanding of LLMs' social behaviour and pave the way for a behavioural game theory for machines.,LLMs,LLMs,LLM,social behaviour,p
6_arx_2305.14795_1847851_2,"Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs.",the model,model,model,related beliefs,p
6_arx_2305.12763_1845819_3,We find that GPT's decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,GPT,GPT,GPT,rational decisions,p
6_arx_2305.12564_1845620_3,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).",ChatGPT,ChatGPT,ChatGPT,feminine-coded abilities,p
6_arx_2303.03480_1803277_1,Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,the LLM,LLM,LLM,commonsense reasoning capabilities,p
6_arx_1704.00717_835229_5,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",AI,AI,AI,theory of mind,p
