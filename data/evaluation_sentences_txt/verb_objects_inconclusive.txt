2_acl_143_43709_5	Our experiments show that these errors can be identified with high accuracy by an LLM.	an LLM	LLM	LLM	identify	inc
2_acl_511_29547_1	To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.	LLMs	LLMs	LLM	acquire	inc
2_arx_2001.08625_1234038_4	Examination prioritization was performed by the AI, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.	the AI	AI	AI	perform	inc
2_arx_2301.11767_1782831_2	In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.	the AI system	AI system	system	learn	inc
2_arx_2106.07921_1485685_1	I suggest that up to 50% of a radiologists work in 2021 will be performed by AI-models in 2025.	AI-models	AI-models	model	perform	inc
2_arx_2007.15619_1327133_1	This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model.	the model	model	model	identify	inc
2_arx_2302.06852_1791786_1	The simulations are grounded by a neuro-symbolic language that both enables question answering of what is learned by the AI methods and provides a means of explainability.	the AI methods	AI methods	method	learn	inc
2_acl_23_33157_0	Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.	the LLMs	LLMs	LLM	hold knowledge	inc
2_acl_3_26185_65	The text was translated by both ChatGPT and a translator who is an academic in the field of translation and has 10 years of experience.	ChatGPT	ChatGPT	ChatGPT	translate	inc
2_acl_260_9141_4	The final submission was chosen based on the best performances which was achieved by the BERT+BiLSTM model.	the BERT+BiLSTM model	BERT+BiLSTM model	model	achieve	inc
2_arx_1907.08625_1153161_6	These features are best interpreted by a self-consistent relativistic reflection model.	a self-consistent relativistic reflection model	relativistic reflection model	model	interpret	inc
2_acl_430_37198_2	In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by LLMs.	LLMs	LLMs	LLM	interpret	inc
3_acl_696_6286_1	How should we train a language model in this scenario?	a language model	language model	model	train	inc
3_acl_891_29927_2	Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct fixed LLMs to generate appropriate responses on novel tasks, without the need for training data.	fixed LLMs	LLMs	LLM	instruct	inc
3_acl_27_42781_1	A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output.	LLMs	LLMs	LLM	correct	inc
3_acl_27_42781_3	This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches.	LLMs	LLMs	LLM	correct	inc
3_arx_2305.01937_1834993_4	We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.	the LLMs	LLMs	LLM	present	inc
3_acl_920_38624_10_1	We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.	the LLM	LLM	LLM	interact with	inc
3_arx_2309.11000_1915804_0	This paper explores the potential of constructing an AI spoken dialogue system that "thinks how to respond" and "thinks how to speak" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.	an AI spoken dialogue system	AI spoken dialogue system	system	construct	inc
3_acl_794_28930_3	We introduce a new task, “less likely brainstorming,” that asks a model to generate outputs that humans think are relevant but less likely to happen.	a model	model	model	ask	inc
3_arx_2308.01154_1889046_3	We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing.	a light language model	light language model	model	train	inc
3_arx_2304.00385_1818431_9	For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches.	the LLM	LLM	LLM	ask	inc
3_arx_2411.05823_2188250_7	Subsequently, we ask LLMs to predict this masked field.	LLMs	LLMs	LLM	ask	inc
2_arx_2204.06916_1637054_2	Typically, the advice generated by AI is judged by a human and either deemed reliable or rejected.	AI	AI	AI	generate	inc
2_arx_2004.11543_1276313_6	Each lesson in the curriculum is learnt by a deep reinforcement learning model.	a deep reinforcement learning model	deep reinforcement learning model	model	learn	inc
3_acl_814_27535_2	Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API.	an agent	agent	agent	train	inc
2_arx_2012.09755_1397633_5	Specifically, the structural features identified by our algorithm were found to be related to clinical observations of glaucoma.	our algorithm	algorithm	algorithm	identify	inc