id,sentence,AI phrase,mask,AI entity,score
"We propose metrics to evaluate the trade-off between performance improvements and user burden, and investigate whether LLMs can determine when to request help under varying information availability.",LLMs,LLMs,LLM,determine,p3
"In particular, we rewrite Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task.",the model,model,model,understand,p2
‚Ä¢ Do LMs recognize when words are used nonliterally in non-compositional MWEs (e.g. do they know whether there are fleas in the flea market)?,LMs,LMs,LM,recognize,p2
"The increased deployment of LMs for real-world tasks involving knowledge and facts makes it important to understand model epistemology: what LMs think they know, and how their attitudes toward that knowledge are affected by language use in their inputs.",LMs,LMs,LM,think,p2
We propose a framework to analyze what LMs can infer about new entities that did not exist when the LMs were pretrained.,LMs,LMs,LM,infer,p2
"These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict.",an LM,LM,LM,resolve a conflict,p2
We then propose a system that leverages the recently introduced social learning paradigm in which LLMs collaboratively learn from each other by exchanging natural language.,LLMs,LLMs,LLM,collaboratively learn from each other,p3
"Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs.",LLMs,LLMs,LLM,collaborate,p2
"Finally, as it is hard to tell given a privacy parameter ùúñ what was the effect on the trained representation, we present experiments showing that the trained model does not memorize private information.",the trained model,trained model,model,memorize,p2
"That is, the LLM only remembers the answer style for open-ended safety questions, which makes it unable to solve other forms of safety tests.",the LLM,LLM,LLM,remember,p2
"During the test stage, given a test question, the LLM recalls relevant memory to help itself reason and answer it.",the LLM,LLM,LLM,recall,p2
"Motivated by this, we propose that LLMs have an inherent awareness from where the text was copied, likely captured in the hidden states of the LLM.",LLMs,LLMs,LLM,have awareness,p2
And the human evaluations show ChatGPT can truly understand the provided information and generate clearer and more reasonable results.,ChatGPT,ChatGPT,ChatGPT,understand,p2
"In our first experiment, we find that the AI agent decides to trust humans at higher rates when facing actual incentives than when making hypothetical decisions.",the AI agent,AI agent,agent,decide to trust,p2
"As a result, it can be hard to identify what the model actually ""believes"" about the world, making it susceptible to inconsistent behavior and simple errors.",the model,model,model,believe,p2
"In order to effectively collaborate with humans and ensure safety, AI systems need to be able to understand, interpret and predict human moral judgments and decisions.",AI systems,AI systems,system,"understand,interpret,predict human moral judgments and decisions",p2
I survey findings from the recent literature showing that -- even in today's non-robust and error-prone models -- LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals.,LMs,LMs,LM,infer,p2
What does a model remember about such examples seen only a few times during training and how long does that memory persist in the face of continuous training with new examples?,a model,model,model,remember,p2
"In order to engender trust in AI, humans must understand what an AI system is trying to achieve, and why.",an AI system,AI system,system,try to achieve,p2
"Here, we fail to find convincing evidence that GPT-3 is reasoning about more than just individual lexical items.",GPT-3,GPT-3,GPT-3,reason,p2
"In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.",LMs,LMs,LM,teach,p2
"By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score.",LLM,LLM,LLM,deduce,p2
"To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB (Factual Inconsistency Benchmark) that focuses on the task of summarization.",an LLM,LLM,LLM,prefer,p2
"In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question.",the model,model,model,ask,p2
"Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and Chemcrow's performance.",GPT-4,GPT-4,GPT-4,distinguish,p3
Our evaluation shows that the model can create French poetry successfully.,the model,model,model,create French poetry,p3
"First, LLMs sometimes select prohibited choices that should be strictly avoided in medical practice in Japan, such as suggesting euthanasia.",LLMs,LLMs,LLM,select,p2
"However, a large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks.",a large generative language model,large generative language model,model,demonstrate capability in understanding natural language,p1
"‚Ä¢ Do LMs know idioms, and can they infer the meaning of new idioms from the context as humans often do?",LMs,LMs,LM,know,p2
"However, it is unclear whether LMs perform these tasks by cheating with answers memorized from pretraining corpus, or, via a multi-step reasoning mechanism.",LMs,LMs,LM,cheat,p2
We only conduct retrieval for the missing knowledge in questions that the LLM does not know.,the LLM,LLM,LLM,know,p2
"Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs.",a conversational AI development platform,conversational AI development platform,platform,exhibit maturity levels,p3
"Then, the more general LLM-based expert, through prompting techniques, analyzes the nuanced differences between candidate categories and selects the most suitable target category.",the more general LLM-based expert,LLM-based expert,expert,"analyze,select",p2
"To understand when AI agents need to break rules, we examine the conditions under which humans break rules for pro-social reasons.",AI agents,AI agents,agent,break rules,p2
These results suggest that LLMs can autonomously develop effective model-improvement techniques beyond human intuition.,LLMs,LLMs,LLM,autonomously develop model-improvement techniques,p1
"Our experiments show that without external feedback, many LLMs struggle to recognize their need for user support.",many LLMs,LLMs,LLM,struggle to recognize,p2
"By relation-augmented training, the model learns to align the natural language expressions to the relations in the KB as well as reason over the missing connections in the KB.",the model,model,model,"learn,reason",p3
"Consequently, LLMs struggle to recall facts whose subject and object rarely co-occur in the pre-training dataset although they are seen during finetuning.",LLMs,LLMs,LLM,struggle to recall,p2
"In addition, ChatGPT, but not Vicuna, nonliterally interpreted implausible sentences that were likely to have been corrupted by noise, drew reasonable inferences, and overlooked semantic fallacies in a sentence.",ChatGPT,ChatGPT,ChatGPT,"interpret,draw an inference,overlook",p2
"We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points.",ChatGPT,ChatGPT,ChatGPT,pass an exam,p2
"By analyzing call transcripts, AI can quickly determine which calls are most relevant for coaching purposes, and provide relevant feedback and insights to the contact center manager or supervisor.",AI,AI,AI,"determine,provide feedback and insights",p3
"When an LLM encounters questions outside its domain, the system recognizes its knowledge scope and determines whether it can answer the question independently.",the system,system,system,"recognize,determine",p3
"Further, to help LLMs distinguish confusing classes, we design a progressive revision framework, which can improve the thinking steps by correcting hard demonstrations.",LLMs,LLMs,LLM,distinguish,p2
"Our experimental results show that while LLMs demonstrate a notable capacity for logical counterfactual thinking, there remains a discernible gap between their current abilities and human performance.",LLMs,LLMs,LLM,demonstrate a notable capacity for logical counterfactual thinking,p3
"However, it is unclear if this success is limited to explicitly-mentioned causal facts in the pretraining data which the model can memorize.",the model,model,model,memorize,p2
"We introduce Pragmatic Metacognitive Prompting (PMP) to improve the performance of Large Language Models (LLMs) in sarcasm detection, which leverages principles from pragmatics and reflection helping LLMs interpret implied meanings, consider contextual cues, and reflect on discrepancies to identify sarcasm.",LLMs,LLMs,LLM,"interpret,consider contextual cues,reflect",p2
"For instance, it is widely accepted that LLMs perform well in terms of grammar, but it is unclear in what specific cognitive areas they excel or struggle in.",LLMs,LLMs,LLM,excel and struggle in specific cognitive areas,p3
"Our language model proves surprisingly good at identifying the selectional restrictions of English derivational morphemes, a task that requires both morphological and syntactic awareness.",Our language model,language model,model,identify,p3
"AI developers found that our system can help them discover unknown errors made by the AI models, and engage in the process of proactive testing.",our system,system,system,"help discover unknown errors,engage in the process of proactive testing",p3
"Apart from generating the wrong reasoning processes, LLMs can misinterpret the meaning of the question, and also exhibit difficulty in understanding the given questions‚Äô rationales when attempting to correct students‚Äô answers.",LLMs,LLMs,LLM,"misinterpret the meaning,exhibit difficulty in understanding",p2
Our evaluation finds that it is increasingly challenging for LLMs to identify analogies when going up the analogy taxonomy.,LLMs,LLMs,LLM,identify,p3
"Resultantly, the developed model efficiently analyzed the test data with a mean average precision of 0.89.",the developed model,model,model,analyze,p2
"To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration).",the AI agent,AI agent,agent,"understand,coordinate",p2
The experimental results showcase that ChatGPT demonstrates proficiency in identifying topic structures in general-domain conversations yet struggles considerably in specific-domain conversations.,ChatGPT,ChatGPT,ChatGPT,"demonstrate proficiency,struggle",p3
"In the absence of a consensus definition and reliable tools for measurement, we cannot rule out the possibility that AI systems learn to manipulate humans without the intent of the system designers.",AI systems,AI systems,system,learn to manipulate,p3
"When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context.",an LM,LM,LM,infer,p2
