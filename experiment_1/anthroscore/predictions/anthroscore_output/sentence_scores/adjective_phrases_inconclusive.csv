,sentence,masked_sentence,text_id,POS,verb,original_term,original_noun,anthroscore
0,Language models (LMs) are vulnerable to exploitation for adversarial misuse.,Language models (<mask>) are vulnerable to exploitation for adversarial misuse.,4_acl_7_46407_0,403,model,LMs,lms,-0.6600417365493847
1,"While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue.","While governments and businesses are eager to enjoy the benefits of <mask>, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue.",4_arx_2005.06620_1286415_1,439,of,AI,ai innovations,-8.064980499205223
2,Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI.,Integrating <mask> into KE tasks needs to be mindful of potential risks and harms related to responsible AI.,4_arx_2408.08878_2129059_6,416,integrate,LLMs,llms,-5.224869173821585
3,Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI.,Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to <mask>.,4_arx_2408.08878_2129059_6,439,to,AI,responsible ai,-8.133468819524392
4,RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations?,RQ1: Can edited <mask> behave consistently resembling communicative AI in realistic situations?,4_arx_2402.05827_2003466_5,416,edit,LLMs,llms,-2.2119669546089646
5,RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations?,RQ1: Can edited LLMs behave consistently resembling <mask> in realistic situations?,4_arx_2402.05827_2003466_5,416,resemble,AI,communicative ai,-2.3480088368028014
6,"The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.","The results demonstrate the descriptive value of <mask> to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.",4_arx_1904.13086_1118126_10,439,of,model,the resqu model,-5.548319029008585
7,"The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.","The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, <mask>, the environment and some systematic behavioral biases.",4_arx_1904.13086_1118126_10,403,human,system,the intelligent system,-0.917843254931805
8,"Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than the SVM model.","Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than <mask>.",4_acl_1_30970_8,439,than,model,the svm model,-1.4209684241625915
9,"Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for the model.","Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for <mask>.",4_acl_159_43725_0,439,for,model,the model,1.2726868062471564
10,"We find that LMs are highly sensitive to epistemic markers in prompts, with accuracies varying more than 80%.","We find that <mask> are highly sensitive to epistemic markers in prompts, with accuracies varying more than 80%.",4_acl_335_27056_3,429,be,LMs,lms,-4.5757900151010205
11,Analysis shows that LLMs are sensitive to subtle contextual changes and often rely on surface-level cues.,Analysis shows that <mask> are sensitive to subtle contextual changes and often rely on surface-level cues.,4_acl_12_46472_3,429,be,LLMs,llms,-4.548732978365688
12,"These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.","These relationships were found to be central to the development and adoption of <mask>, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy <mask>.",4_arx_2405.16310_2073522_7,439,of,LLMs,llms,-3.50565739946091
13,"These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.","These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on <mask>.",4_arx_2405.16310_2073522_7,439,on,LLMs,untrustworthy llms,-5.775178082605381
14,"This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.","<mask> presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.",4_arx_1906.03595_1135781_6,429,present,AI,this collaborative creative ai,-3.8663067571947605
15,"This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.","This collaborative creative <mask> presents a new paradigm in <mask>, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.",4_arx_1906.03595_1135781_6,439,in,AI,ai,1.4010029261339874
16,Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.,<mask> with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.,4_acl_128_54380_3,429,beat,model,our best morpheme-aware model,-4.460899131557738
17,Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.,Our best morpheme-aware model with properly reused weights beats <mask> by a large margin across multiple languages and has 20%-87% fewer parameters.,4_acl_128_54380_3,416,beat,model,the competitive word-level model,-4.858638332433342
18,"However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks.","However, <mask> may covertly introduce vulnerabilities for downstream tasks.",4_acl_94_36582_1,429,introduce,LLMs,the untrustworthy third-party llms,-3.8896080401024005
19,"An intelligent algorithm which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.","<mask> which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.",4_arx_2207.00477_1676375_2,429,bring,algorithm,an intelligent algorithm,-4.131652730797212
20,"Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.","Amidst the extensive deliberations on policy-making for regulating <mask>, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.",4_acl_155_26876_9,416,regulate,AI,ai development,-2.7925168306909196
21,"Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.","Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which <mask> is more vulnerable towards hallucination.",4_acl_155_26876_9,429,be,LLM,llm,-2.213099294542424
22,This work presents the development of an intelligent system that classifies and segments food presented in images to help the automatic monitoring of user diet and nutritional intake.,This work presents the development of <mask> that classifies and segments food presented in images to help the automatic monitoring of user diet and nutritional intake.,4_arx_2012.03087_1390965_3,439,of,system,an intelligent system,-4.88743565634913
23,"However, given, e.g., economic incentives to create dishonest AI, to what extent can we trust explanations?","However, given, e.g., economic incentives to create <mask>, to what extent can we trust explanations?",4_arx_2001.07641_1233054_2,416,create,AI,dishonest ai,-2.6983739072090422
24,"Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build culturally aware LMs, if used as they are without adjustment.","Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build <mask>, if used as they are without adjustment.",4_acl_862_33024_7,416,build,LMs,culturally aware lms,-1.1273471124773256
25,We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,We show that <mask> (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,4_acl_45_49661_1,429,achieve,RNN-LM,an “attentive” rnn-lm,-2.1789537976975453
26,We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than <mask> (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,4_acl_45_49661_1,439,than,LMs,larger rnn-lms,-4.794794903411866
27,We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of <mask>.,4_acl_45_49661_1,439,of,LMs,10 similar sized rnn-lms,-3.413201839473679
28,"To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.","To address this blind spot, this study introduces <mask> (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.",4_arx_2503.22772_2287084_2,416,introduce,AI,the ai family integration index,-2.4482582589539703
29,"To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.","To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating <mask> into family and caregiving systems.",4_arx_2503.22772_2287084_2,416,integrate,AI,emotionally intelligent ai,-5.180857411977069
30,"We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.","We outline the conceptual foundations of <mask>, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.",4_arx_2502.18676_2261667_3,439,of,AI,thoughtful ai,-6.126450152062235
31,"We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.","We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform <mask> in the future.",4_arx_2502.18676_2261667_3,416,transform,AI,human-ai interaction,-5.099401890650331
