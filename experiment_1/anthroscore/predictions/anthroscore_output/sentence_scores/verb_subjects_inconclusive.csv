,sentence,masked_sentence,text_id,POS,verb,original_term,original_noun,anthroscore
0,"While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which <mask> also derive lexical type-level knowledge from words in context.",1_acl_586_6176_1,429,derive,LMs,extent lms,-0.5809209106668671
1,"In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.","In some applications, however, having an additional context can help <mask> make the right prediction, e.g., by taking the domain or the time of writing into account.",1_acl_5_9514_1,429,make,model,the model,-0.8412891632555137
2,The human evaluation found that our topic model creates coherent topics.,The human evaluation found that <mask> creates coherent topics.,1_acl_65_19388_5,429,create,model,our topic model,-2.4147490073587132
3,"Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that <mask> cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.",1_acl_22_31716_3,429,learn,LLMs,llms,-2.352818953555351
4,"Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, <mask> can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.",1_acl_163_34648_5,429,create,model,our model,-0.7015564645271208
5,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with <mask> following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,1_arx_2110.10185_1548328_5,439,with,AI,ai systems,-5.329328966913575
6,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that <mask> acts in a manner human users find suitable.,1_arx_2110.10185_1548328_5,429,act,system,the generation system,-5.395993256909348
7,Our algorithm considers the channel conditions during the dynamic weight selection process.,<mask> considers the channel conditions during the dynamic weight selection process.,1_arx_2212.07414_1763591_5,429,consider,algorithm,our algorithm,-0.8760093875723163
8,The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.,The test shows that <mask> correctly identifies ~80% of known QSOs with a 25% false positive rate.,1_arx_1101.3316_238729_3,429,identify,model,the model,-3.1213664382123074
9,"At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.","At the same time, <mask> dissects this variability into components that result from individual SNP effects and population structure.",1_arx_1205.6986_345987_9,429,dissect,model,our model,-1.0399687239227227
10,"In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","In other words, <mask> can create content on many topics with high originality as if they were written by someone.",1_arx_2302.04335_1789269_6,429,create,ChatGPT,chatgpt,-0.13511214458895182
11,"However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope.","However, these benchmarks lack the controlled example paradigms that would allow us to infer whether <mask> had truly learned how negation morphemes semantically scope.",1_acl_154_25214_1,429,learn,model,a model,-0.5039632249852453
12,Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems.,<mask> have demonstrated remarkable performance in solving exam-like math word problems.,1_acl_852_33014_0,429,demonstrate,LLMs,recent llms,0.9792174372055378
13,"Our results show that not all extracted utterances are correctly structured, indicating that either LLMs do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.","Our results show that not all extracted utterances are correctly structured, indicating that <mask> do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.",1_acl_2_34276_7,429,acquire,LLMs,either llms,-3.398040998769119
14,"Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena.","Taken together, our results provide an existence proof that <mask> can learn rare grammatical phenomena by generalization from less rare phenomena.",1_acl_53_34920_6,429,learn,LMs,lms,-1.5592040395884261
15,"Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.","Our experiment results suggest that <mask> has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.",1_acl_24_17147_6,429,acquire,GPT-3,gpt-3,0.02878247121016919
16,"The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","<mask> does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.",1_arx_1205.3313_342314_2,429,differentiate,model,the model,-2.3628250689330046
17,"The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.","<mask> has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.",1_arx_2304.10592_1828638_0,429,demonstrate,GPT-4,the recent gpt-4,0.8612887007989738
18,"For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","For example, <mask> should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.",1_acl_11_43395_1,429,identify,model,a model,-2.1725317101586796
19,It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.,It often involves laborious trial-and-error procedures to ensure that <mask> interprets the prompts in alignment with the user's intention.,1_arx_2304.09337_1827383_2,429,interpret,model,the model,-2.6626500160834485
20,We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We observed that <mask> does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,1_arx_2207.08333_1684231_3,429,interpret,model,the vl model,-3.834836537545417
21,Such ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.,Such ability stimulates us to wonder whether <mask> can simulate a person in a higher form than simple human behaviors.,1_acl_814_27535_1,429,simulate,LLMs,llms,-1.4472603071430452
22,The results show that ChatGPT made more changes than the average post-editor.,The results show that <mask> made more changes than the average post-editor.,1_acl_7_34361_5,429,make,ChatGPT,chatgpt,2.6375988106510952
23,"AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","<mask> can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.",1_arx_1908.02624_1160794_1,429,translate,AI,ai systems,-3.5404183660045803
24,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, <mask> can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",1_arx_2304.02868_1820914_3,429,construct,ChatGPT,chatgpt,-4.299381528961565
25,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, ChatGPT can not construct <mask> by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",1_arx_2304.02868_1820914_3,416,construct,model,the world model,-4.458013424746856
26,The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.,<mask> has demonstrated surprising abilities in natural language understanding and natural language generation.,1_arx_2304.02182_1820228_0,429,demonstrate,ChatGPT,the recently released chatgpt,1.3900114826502334
27,Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,Our experiments show that <mask> performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,1_arx_2304.02868_1820914_2,429,perform,ChatGPT,chatgpt,-3.862445885325492
28,We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.,We find <mask> performs poorly at answering straightforward questions about these simple synthetic statutes.,1_arx_2302.06100_1791034_8,429,perform,GPT-3,gpt-3,-4.162454580579665
29,"4) LLMs often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","4) <mask> often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.",1_acl_679_35529_6,429,exhibit,LLMs,llms,-3.7924260549602167
30,We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure.,We cross-check with control cases to ensure that <mask> is not randomly guessing and is indeed identifying an inherent structure.,1_arx_1904.08530_1113570_2,429,guess,AI,the ai,-1.1140751744416768
31,"However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses.","However, <mask> has only seen one response per instruction, lacking the knowledge of potentially better responses.",1_acl_1011_30047_1,429,see,model,the instruction-tuned model,-0.311642752994425
32,"Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.","Traditionally, <mask> have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.",1_arx_1905.04127_1122563_1,429,suffer,AI,ai agents,-4.855990749805699
33,The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.,The semantic dependency feature serves as a global signal and helps <mask> learn simile knowledge that can be applied to unseen domains.,1_acl_78_25975_8,429,learn,model,the model,-1.9253294826003131
34,"This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","This suggests that <mask> may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.",1_arx_2303.17276_1817073_8,429,develop,LLMs,larger and more advanced llms,-2.2825784592699634
