id,sentence,masked_sentence,AI_phrase,suggested_mask,AI_entity,anthro_component,original_term,original_noun,expectation,anthroscore
1_acl_586_6176_1,"While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which <mask> also derive lexical type-level knowledge from words in context.",LMs,LMs,LM,derive knowledge,LMs,extent lms,2,-0.5809209106668671
1_acl_5_9514_1,"In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.","In some applications, however, having an additional context can help <mask> make the right prediction, e.g., by taking the domain or the time of writing into account.",the model,model,model,make a prediction,model,the model,2,-0.8412891632555137
1_acl_65_19388_5,The human evaluation found that our topic model creates coherent topics.,The human evaluation found that <mask> creates coherent topics.,our topic model,topic model,model,create,model,our topic model,2,-2.4147490073587132
1_acl_22_31716_3,"Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that <mask> cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.",LLMs,LLMs,LLM,learn,LLMs,llms,2,-2.352818953555351
1_acl_163_34648_5,"Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, <mask> can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.",our model,model,model,create,model,our model,2,-0.7015564645271208
1_arx_2110.10185_1548328_5,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with <mask> following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,the generation system,generation system,system,act,AI,ai systems,2,-5.329328966913575
1_arx_2110.10185_1548328_5,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that <mask> acts in a manner human users find suitable.,the generation system,generation system,system,act,system,the generation system,2,-5.395993256909348
1_arx_2212.07414_1763591_5,Our algorithm considers the channel conditions during the dynamic weight selection process.,<mask> considers the channel conditions during the dynamic weight selection process.,Our algorithm,algorithm,algorithm,consider,algorithm,our algorithm,2,-0.8760093875723163
1_arx_1101.3316_238729_3,The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.,The test shows that <mask> correctly identifies ~80% of known QSOs with a 25% false positive rate.,the model,model,model,identify,model,the model,2,-3.1213664382123074
1_arx_1205.6986_345987_9,"At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.","At the same time, <mask> dissects this variability into components that result from individual SNP effects and population structure.",our model,model,model,dissect,model,our model,2,-1.0399687239227227
1_arx_2302.04335_1789269_6,"In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","In other words, <mask> can create content on many topics with high originality as if they were written by someone.",ChatGPT,ChatGPT,ChatGPT,create,ChatGPT,chatgpt,2,-0.13511214458895182
1_acl_154_25214_1,"However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope.","However, these benchmarks lack the controlled example paradigms that would allow us to infer whether <mask> had truly learned how negation morphemes semantically scope.",a model,model,model,learn,model,a model,2,-0.5039632249852453
1_acl_852_33014_0,Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems.,<mask> have demonstrated remarkable performance in solving exam-like math word problems.,Recent LLMs,LLMs,LLM,demonstrate,LLMs,recent llms,2,0.9792174372055378
1_acl_2_34276_7,"Our results show that not all extracted utterances are correctly structured, indicating that either LLMs do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.","Our results show that not all extracted utterances are correctly structured, indicating that <mask> do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.",LLMs,LLMs,LLM,acquire,LLMs,either llms,2,-3.398040998769119
1_acl_53_34920_6,"Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena.","Taken together, our results provide an existence proof that <mask> can learn rare grammatical phenomena by generalization from less rare phenomena.",LMs,LMs,LM,learn,LMs,lms,2,-1.5592040395884261
1_acl_24_17147_6,"Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.","Our experiment results suggest that <mask> has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.",GPT-3,GPT-3,GPT-3,"acquire,fail",GPT-3,gpt-3,2,0.02878247121016919
1_arx_1205.3313_342314_2,"The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","<mask> does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.",The model,model,model,differentiate,model,the model,2,-2.3628250689330046
1_arx_2304.10592_1828638_0,"The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.","<mask> has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.",The recent GPT-4,GPT-4,GPT-4,demonstrate abilities,GPT-4,the recent gpt-4,2,0.8612887007989738
1_acl_11_43395_1,"For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","For example, <mask> should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.",a model,model,model,identify,model,a model,2,-2.1725317101586796
1_arx_2304.09337_1827383_2,It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.,It often involves laborious trial-and-error procedures to ensure that <mask> interprets the prompts in alignment with the user's intention.,the model,model,model,interpret,model,the model,2,-2.6626500160834485
1_arx_2207.08333_1684231_3,We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We observed that <mask> does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,the VL model,VL model,model,interpret,model,the vl model,2,-3.834836537545417
1_acl_814_27535_1,Such ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.,Such ability stimulates us to wonder whether <mask> can simulate a person in a higher form than simple human behaviors.,LLMs,LLMs,LLM,simulate,LLMs,llms,2,-1.4472603071430452
1_acl_7_34361_5,The results show that ChatGPT made more changes than the average post-editor.,The results show that <mask> made more changes than the average post-editor.,ChatGPT,ChatGPT,ChatGPT,make changes,ChatGPT,chatgpt,2,2.6375988106510952
1_arx_1908.02624_1160794_1,"AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","<mask> can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.",AI systems,AI systems,system,"translate,identify,streamline,control",AI,ai systems,2,-3.5404183660045803
1_arx_2304.02868_1820914_3,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, <mask> can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",ChatGPT,ChatGPT,ChatGPT,"construct,fail to leverage world knowledge,infer",ChatGPT,chatgpt,2,-4.299381528961565
1_arx_2304.02868_1820914_3,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, ChatGPT can not construct <mask> by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",ChatGPT,ChatGPT,ChatGPT,"construct,fail to leverage world knowledge,infer",model,the world model,2,-4.458013424746856
1_arx_2304.02182_1820228_0,The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.,<mask> has demonstrated surprising abilities in natural language understanding and natural language generation.,The recently released ChatGPT,ChatGPT,ChatGPT,demonstrate surprising abilities,ChatGPT,the recently released chatgpt,2,1.3900114826502334
1_arx_2304.02868_1820914_2,Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,Our experiments show that <mask> performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,ChatGPT,ChatGPT,ChatGPT,"perform competitively,exhibit a low level of intelligence",ChatGPT,chatgpt,2,-3.862445885325492
1_arx_2302.06100_1791034_8,We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.,We find <mask> performs poorly at answering straightforward questions about these simple synthetic statutes.,GPT-3,GPT-3,GPT-3,perform poorly at answering straightforward questions,GPT-3,gpt-3,2,-4.162454580579665
1_acl_679_35529_6,"4) LLMs often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","4) <mask> often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.",LLMs,LLMs,LLM,exhibit overconfidence,LLMs,llms,2,-3.7924260549602167
1_arx_1904.08530_1113570_2,We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure.,We cross-check with control cases to ensure that <mask> is not randomly guessing and is indeed identifying an inherent structure.,the AI,AI,AI,"guess,identify",AI,the ai,2,-1.1140751744416768
1_acl_1011_30047_1,"However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses.","However, <mask> has only seen one response per instruction, lacking the knowledge of potentially better responses.",the instruction-tuned model,instruction-tuned model,model,see,model,the instruction-tuned model,2,-0.311642752994425
1_arx_1905.04127_1122563_1,"Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.","Traditionally, <mask> have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.",AI agents,AI agents,agent,suffer from difficulties,AI,ai agents,2,-4.855990749805699
1_acl_78_25975_8,The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.,The semantic dependency feature serves as a global signal and helps <mask> learn simile knowledge that can be applied to unseen domains.,the model,model,model,learn,model,the model,2,-1.9253294826003131
1_arx_2303.17276_1817073_8,"This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","This suggests that <mask> may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.",larger and more advanced LLMs,LLMs,LLM,develop a tendency,LLMs,larger and more advanced llms,2,-2.2825784592699634
