,id,sentence,AI phrase,mask,AI entity,anthro component,score,anthroscore
0,4_acl_683_21860_6,"Next, an experiment is conducted on the dataset to examine to what extent a pretrained masked language model is aware of the constructions.",a pretrained masked language model,pretrained masked language model,model,aware,p2,-1.763760417654746
1,4_acl_348_35206_2,A desired characteristic of an intelligent system is its ability to recognize the scope of its own knowledge.,an intelligent system,system,system,intelligent,p3,-4.125423641426384
2,4_acl_3_45070_1,LLMs are intelligent and slowly replacing the search engines.,LLMs,LLMs,LLM,intelligent,p2,-4.247897999156674
3,4_acl_396_37165_1,"However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves?",LLMs,LLMs,LLM,conscious,p2,-3.800791003376144
4,4_acl_590_28726_3,"In this way, the captioning model can become aware of the task goal and information need from the PLM.",the captioning model,captioning model,model,aware,p2,1.1517078677753343
5,4_acl_818_37575_1,"In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback.",a responsive model,model,model,responsive,p2,-5.90111280205862
6,4_acl_633_48859_2,"This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about.",the model,model,model,confident,p2,-2.3362483636121656
7,4_acl_243_44794_7,"In addition, we found that the model becomes more confident and refuses to provide an answer in only few cases.",the model,model,model,confident,p2,2.658288152012414
8,4_acl_276_39685_3,(2) Is ChatGPT aware of the underlying commonsense knowledge for answering a specific question?,ChatGPT,ChatGPT,ChatGPT,aware,p2,2.981358761856395
9,4_acl_117_37846_1,"However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not.",LLMs,LLMs,LLM,aware,p2,-1.6929933904433805
10,4_acl_450_41596_3,"The goal is to cultivate culturally cognizant and value-aligned Arabic LLMs capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.",culturally cognizant and value-aligned Arabic LLMs,Arabic LLMs,LLM,"culturally cognizant,value-aligned",p2,-0.680433796263344
11,4_acl_45_49661_2,We also show that an “attentive” RNN-LM needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,"an ""attentive"" RNN-LM",RNN-LM,LM,attentive,p3,-3.437661634251324
12,4_arx_2311.04177_1947144_0,Large Language Models (LLMs) are smart but forgetful.,Large Language Models (LLMs),Large Language Models (LLMs),model,"smart,forgetful",p2,-0.1148606240644252
13,4_arx_1511.03246_676426_3,"In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.",malicious AI,AI,AI,malicious,p2,-0.4491658234539653
14,4_arx_2005.13635_1293430_5,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.,malicious AI,AI,AI,malicious,p2,-4.480066888284107
15,4_arx_2504.03726_2292429_5_1,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",malicious AI Assistants,AI Assistants,AI assistant,malicious,p2,-5.866401879427848
16,4_arx_2504.03726_2292429_5_2,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",potentially manipulative systems,systems,system,manipulative,p2,-5.866401879427848
17,4_arx_2305.02626_1835682_10,"We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.",ethically conscious LLMs,LLMs,LLM,ethically conscious,p2,-2.7468599517831334
18,4_arx_2401.10727_1990281_4,"Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.",the learned LLMs,learned LLMs,LLM,conscious,p2,-3.741938636854774
19,4_arx_1301.6359_402949_3,We consider a number of issues related to the development of the set of patterns which will be used by the intelligent system when interacting with environment.,the intelligent system,system,system,intelligent,p3,-2.236956199910036
20,4_arx_2308.03688_1891580_0,"  Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.",Large Language Models (LLMs),Large Language Models (LLMs),model,"smart,autonomous",p1,-1.3343707247208911
21,4_arx_2403.11805_2028924_0,"Being more powerful and intrusive into user-device interactions, LLMs are eager for on-device execution to better preserve user privacy.",LLMs,LLMs,LLM,eager,p2,-5.483844121502816
22,4_arx_2405.06715_2063927_2,"However, whether the same strategies can help LLMs become more creative remains under-explored.",LLMs,LLMs,LLM,creative,p3,1.9818300712582888
23,4_arx_2008.00312_1328034_4,"To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems.",malicious LMs,LMs,LM,malicious,p2,-4.978392004903162
24,4_acl_693_19140_1,"However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus.",existing DA-training methods,DA-training methods,method,blind,p3,
25,4_arx_2311.07723_1950690_0,"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.",AI systems,AI systems,system,intelligent,p3,-4.322879980435182
26,4_acl_27_55498_4,"The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.",The model,model,model,sensitive,p3,-1.2057704001534877
27,4_arx_2407.11789_2110176_2,"We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.",LLMs,LLMs,LLM,deceptive,p2,-5.1253018040500535
28,4_arx_2305.14985_1848041_7,These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question.,the model,model,model,confident,p2,-1.8133906791198875
29,4_arx_2406.18326_2096614_4,"Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.",the model,model,model,confident,p2,-2.3776551080311514
30,4_arx_2407.13164_2111551_3,"This is in part because LLMs might be overly confident in their predictions, overriding the influence of the constraints.",LLMs,LLMs,LLM,confident,p2,-2.1455167226931167
31,4_arx_1812.08960_1066534_3,"A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.",A smart autonomous system (SAS),system (SAS),system,"smart,autonomous",p2,-3.6779540215163866
32,4_arx_2304.09655_1827701_7,"Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.",ChatGPT,ChatGPT,ChatGPT,aware,p2,-0.856799227501762
33,4_arx_2305.08883_1841939_5,A detection algorithm aware of the list can identify the watermarked text.,A detection algorithm,detection algorithm,algorithm,aware,p2,
34,4_arx_2407.09517_2107904_5,"Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.",a conscious AI model,AI model,model,conscious,p2,-2.2401631552138745
35,4_arx_2501.07290_2230874_1,"Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.",Conscious AI systems,AI systems,system,conscious,p1,-3.304997495476889
36,4_arx_2404.16873_2054324_0,"While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.",Large Language Models (LLMs),Large Language Models (LLMs),model,vulnerable,p3,-0.585147964696711
37,4_arx_2502.18676_2261667_1,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",Thoughtful AI,AI,AI,thoughtful,p3,-7.5583330383706295
38,4_arx_2308.08708_1896600_0,  Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.,current or near-term AI systems,AI systems,system,conscious,p2,1.246905064914969
39,4_arx_2502.00735_2243726_1,"While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.",LLMs,LLMs,LLM,vulnerable,p3,-5.333978674585531
40,4_arx_2411.14133_2196560_0,"Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.",Large Language Models (LLMs),Large Language Models (LLMs),model,vulnerable,p3,-0.4063396248805198
41,4_acl_592_38304_5,"We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.",powerful LLMs,LLMs,LLM,aware,p2,-4.016984679846707
42,4_arx_2306.01879_1855027_7,"In fact, we demonstrate that even a ""blind"" language model that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago.","a ""blind"" language model",language model,model,blind,p3,-2.006395610175293
43,4_arx_1901.00912_1070459_9,We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.,malicious bots,bots,bot,malicious,p2,-3.992072109965495
44,4_arx_2208.12505_1703217_1,"The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.",The OCR model,OCR model,model,confused,p2,-2.83169210186449
45,4_arx_2311.03287_1946254_6,"Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together.",GPT-4V(ision),GPT-4V(ision),GPT-4,"vulnerable,confused",p2,
46,4_arx_2311.17095_1960062_4,"To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask.",the model,model,model,attentive,p2,-2.442462965437361
47,4_arx_1905.13053_1131489_2,"We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.",a smarter-than-human intelligent system,system,system,intelligent,p3,-4.820663720604494
48,4_acl_36_22670_6,"All in all, we demonstrate that our self-aware model improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.",our self-aware model,model,model,self-aware,p3,-2.8579380491831277
49,4_acl_133_36622_2,"We study how to better construct in-context example sets, based on whether the model is aware of the in-context examples.",the model,model,model,aware,p2,-1.7906218887907883
50,4_arx_2501.13533_2237117_7,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",AI persons,AI persons,person,self-aware,p2,-2.4861414623668496
51,4_arx_2502.05605_2248596_0,A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions.,A truly intelligent Large Language Model (LLM),Large Language Model (LLM),model,"intelligent,capable",p3,-1.7177315509455742
