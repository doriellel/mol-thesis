id,sentence,masked_sentence,AI phrase,suggested mask,AI entity,original_term,original_noun,anthropomorphic component,expectation,anthroscore
6_arx_2104.14506_1461924_5,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use <mask>, with or without awareness, or someone who is affected by the decisions of an <mask> model.",an AI model,AI model,model,AI,ai,decisions,p,-6.850026447757019
6_arx_2104.14506_1461924_5,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of <mask>.",an AI model,AI model,model,model,an ai model,decisions,p,-4.717264969147852
6_arx_2104.14506_1461924_5,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of <mask>.",an AI model,AI model,model,AI,an ai model,decisions,p,-4.717264969147852
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.",the GPT-3,GPT-3,GPT-3,GPT-3,a deployed gpt-3,misunderstandings,p,-3.9850025082201608
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.",the GPT-3,GPT-3,GPT-3,GPT,a deployed gpt-3,misunderstandings,p,-3.9850025082201608
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by <mask>.",the GPT-3,GPT-3,GPT-3,GPT-3,the gpt-3,misunderstandings,p,-1.550002939879354
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by <mask>.",the GPT-3,GPT-3,GPT-3,GPT,the gpt-3,misunderstandings,p,-1.550002939879354
6_arx_1912.03652_1215548_4,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,We investigate how inputs of humans can be altered to reduce misinterpretation by <mask> and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,the AI system,AI system,system,system,the ai system,misinterpretations,p,-2.9284242971815715
6_arx_1912.03652_1215548_4,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,We investigate how inputs of humans can be altered to reduce misinterpretation by <mask> and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,the AI system,AI system,system,AI,the ai system,misinterpretations,p,-2.9284242971815715
6_acl_373_16531_2,Actions by the AI system may be required to bring these objects in view.,Actions by <mask> may be required to bring these objects in view.,the AI system,AI system,system,system,the ai system,actions,p,0.34153384804312736
6_acl_373_16531_2,Actions by the AI system may be required to bring these objects in view.,Actions by <mask> may be required to bring these objects in view.,the AI system,AI system,system,AI,the ai system,actions,p,0.34153384804312736
6_arx_2110.06674_1544817_2,"This raises the question of how we should limit the harm caused by AI ""lies"" (i.e. falsehoods that are actively selected for).","This raises the question of how we should limit the harm caused by <mask>"" (i.e. falsehoods that are actively selected for).",AI,AI,AI,AI,"ai ""lies",lies,p,-0.9517374458450742
6_arx_2207.07051_1682949_0,  Reasoning is a key ability for an intelligent system.,  Reasoning is a key ability for <mask>.,an intelligent system,system,system,system,an intelligent system,reasoning,p  ,-1.3288000771196344
6_acl_71_46015_2,"In this study, leveraging the POPQUORN dataset, we evaluate nine popular LLMs on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.","In this study, leveraging the POPQUORN dataset, we evaluate <mask> on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.",nine popular LLMs,LLMs,LLM,LLMs,nine popular llms,ability to understand,p,-4.912523248822676
6_arx_2405.01576_2058788_0,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,We study the tendency of <mask> to deceive by constructing a realistic simulation setting of a company AI assistant.,AI systems,AI systems,system,AI,ai systems,tendency to deceive,p,-3.252950371291096
6_arx_2405.01576_2058788_0,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of <mask>.,AI systems,AI systems,system,AI,a company ai assistant,tendency to deceive,p,-3.2682489777962704
6_acl_245_29281_1,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.","With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of <mask>.",LLMs,LLMs,LLM,LLMs,llms,reasoning capabilities,p,-4.656341475270979
6_acl_916_40326_5,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs.,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of <mask>.,Chinese LLMs,LLMs,LLM,LLMs,chinese llms,knowledge acquisition capabilities,p,-1.8187527793718523
6_acl_1539_40949_1,"However, this awareness of LMs has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.","However, this awareness of <mask> has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.",LMs,LMs,LM,LMs,lms,awareness,p,-4.493531722733042
6_acl_225_32387_1,Numerous benchmarks have been established to assess the reasoning abilities of LLMs.,Numerous benchmarks have been established to assess the reasoning abilities of <mask>.,LLMs,LLMs,LLM,LLMs,llms,reasoning abilities,p,-3.8436958975530704
6_acl_743_29779_6,"Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.","Additionally, the causal reasoning ability of <mask> is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt,causal reasoning ability,p,-3.9805721189198096
6_acl_538_32700_6,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of LLMs and speed up the development of LLMs in journalism.,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of <mask> and speed up the development of <mask> in journalism.,LLMs,LLMs,LLM,LLMs,llms,editorial capabilities,p,-2.2249331950268036
6_arx_2101.06573_1410315_4,We show how progress has been made in benchmark development to measure understanding capabilities of AI methods and we review as well how current methods develop understanding capabilities.,We show how progress has been made in benchmark development to measure understanding capabilities of <mask> and we review as well how current methods develop understanding capabilities.,AI methods,AI methods,method,AI,ai methods,understanding capabilities,p,-3.117560457834731
6_arx_2307.16180_1887175_4,"Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.","Specifically, extensive experiments will be conducted to explore: 1) the personality types of <mask>, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.",different LLMs,LLMs,LLM,LLMs,different llms,personality types,p,-2.7186801138544237
6_arx_2408.10159_2130340_1,"Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.","Leveraging the strengths of Large Language Models (<mask>) in knowledge comprehension and reasoning, recent approaches are eager to apply <mask> to sequential recommendation.",Large Language Models (LLMs),Large Language Models (LLMs),model,LLMs,llms,strengths in knowledge comprehension and reasoning,p,-0.5346041198084208
6_arx_2503.16460_2280772_5,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess <mask>.,LLM,LLM,LLM,LLM,llm problem-solving capabilities,problem-solving capabilities,p,-4.89152685882507
6_arx_2309.02077_1906881_6,A medical consultation training set is further constructed to improve the consultation ability of LLMs.,A medical consultation training set is further constructed to improve the consultation ability of <mask>.,LLMs,LLMs,LLM,LLMs,llms,consultation abilities,p,-0.7694079463120858
6_arx_2305.18752_1851808_6,"Moreover, we provide a benchmark to evaluate the ability of LLMs to use tools, which is performed in both zero-shot and fine-tuning ways.","Moreover, we provide a benchmark to evaluate the ability of <mask> to use tools, which is performed in both zero-shot and fine-tuning ways.",LLMs,LLMs,LLM,LLMs,llms,ability to use tools,p,-2.57800933575572
6_arx_2309.11805_1916609_6,"Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.","Inspired by the superior performance of <mask>, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.",LLMs,LLMs,LLM,LLMs,llms,capability to understand natural language,p,-4.093205853742077
6_arx_2310.02417_1924674_0,"Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.","Large language models (<mask>), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.",Large language models (LLMs),Large language models (LLMs),model,LLMs,llms,capability in understanding and following instructions,p,-0.23708941801941563
6_arx_2305.16867_1849923_1,We propose to use behavioural game theory to study LLMs' cooperation and coordination behaviour.,We propose to use behavioural game theory to study <mask>.,LLMs,LLMs,LLM,LLMs,llms' cooperation and coordination behaviour,cooperation and coordination behavior,p,-4.006531429550087
6_arx_2305.04388_1837444_1,It is tempting to interpret these CoT explanations as the LLM's process for solving a task.,It is tempting to interpret these CoT explanations as <mask> for solving a task.,the LLM,LLM,LLM,LLM,the llm's process,process for solving a task,p,-2.9964593756553235
6_arx_2005.02335_1282130_0,Explainable machine learning and artificial intelligence models have been used to justify a model's decision-making process.,Explainable machine learning and artificial intelligence models have been used to justify <mask>.,a model,model,model,model,a model's decision-making process,decision-making process,p,-5.746756380725893
6_arx_2203.10923_1623785_4,We also discuss issues that are unique to edge applications such as protecting a model's intellectual property and verifying its integrity.,We also discuss issues that are unique to edge applications such as protecting <mask> and verifying its integrity.,a model,model,model,model,a model's intellectual property,intellectual property,p,-4.516063512976579
6_arx_2207.09374_1685272_1,"However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for an AI's decision.","However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for <mask>.",an AI,AI,AI,AI,an ai's decision,decisions,p,-3.7065856515950735
6_arx_2209.15093_1720808_3,We propose conceptual consistency to measure a LLM's understanding of relevant concepts.,We propose conceptual consistency to measure <mask> of relevant concepts.,a LLM,LLM,LLM,LLM,a llm's understanding,understanding,p,-4.329273164336804
6_arx_2210.05487_1726842_3,We find that the visual grounding improves the model's understanding of semantic similarity both within and across languages and improves perplexity.,We find that the visual grounding improves <mask> of semantic similarity both within and across languages and improves perplexity.,the model,model,model,model,the model's understanding,understanding,p,-6.319571965848066
6_arx_2307.00457_1871453_4,"GenRec uses LLMs' understanding ability to interpret context, learn user preferences, and generate relevant recommendation.","GenRec uses <mask> to interpret context, learn user preferences, and generate relevant recommendation.",LLMs,LLMs,LLM,LLMs,llms' understanding ability,understanding abilities,p,-7.287083996653548
6_arx_2307.10250_1881245_0,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",the GPT-4 Large Language Model,GPT-4 Large Language Model,model,model,the gpt-4 large language model's abductive reasoning,abductive reasoning,p,-3.3953633750574497
6_arx_2307.10250_1881245_0,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",the GPT-4 Large Language Model,GPT-4 Large Language Model,model,GPT-4,the gpt-4 large language model's abductive reasoning,abductive reasoning,p,-3.3953633750574497
6_arx_2307.10250_1881245_0,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",the GPT-4 Large Language Model,GPT-4 Large Language Model,model,GPT,the gpt-4 large language model's abductive reasoning,abductive reasoning,p,-3.3953633750574497
6_arx_2308.10837_1898729_1,"However, effectively integrating LLMs' commonsense knowledge and reasoning abilities into recommendation systems remains a challenging problem.","However, effectively integrating <mask> and reasoning abilities into recommendation systems remains a challenging problem.",LLMs,LLMs,LLM,LLMs,llms' commonsense knowledge,commonsense knowledge and reasoning abilities,p,-3.592335393710794
6_arx_2308.07326_1895218_4,Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions.,Our findings underscore <mask> and ability to discern and adapt to nuanced instructions.,GPT,GPT,GPT,GPT,gpt's versatility,ability to discern and adapt to nuanced instructions,p,-1.8559019229300482
6_arx_2307.05488_1876483_8,These biases may impact the responses of constructs and should be considered when interpreting ChatGPT's conceptual capabilities.,These biases may impact the responses of constructs and should be considered when interpreting <mask>.,ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's conceptual capabilities,conceptual capabilities,p,-4.213554281346642
6_arx_2306.11296_1864444_1,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,This effectively mitigates <mask> to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's tendency,tendency to hallucinate information,p,-3.993726133031453
6_arx_2303.13712_1813509_7,We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically.,We then consider a decision maker who is aware of <mask> and responds strategically.,the algorithm,algorithm,algorithm,algorithm,the algorithm's manipulation,manipulation,p,-7.053260420318566
6_arx_2211.08380_1747286_6,"In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.","In addition, OREO-LM provides reasoning paths as rationales to interpret <mask>.",the model,model,model,model,the model's decision,decisions,p,-4.739286273046979
6_arx_2301.13852_1784916_11,"Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.","Using explainability, we observe that <mask> is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's writing,polite writing,p,-3.3296965546431583
6_arx_2306.03423_1856571_4,"In this experiment, we characterize ChatGPT's refusal behavior using a black-box attack.","In this experiment, we characterize <mask> using a black-box attack.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's refusal behavior,refusal behavior,p,-3.0536429567709895
6_acl_406_32568_3,"Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.","Our analysis of GPT-series models over a rule subset reveals significant gaps in <mask> compared to human performance, especially in compositional and structural complex rules with certain bias patterns.",LLMs,LLMs,LLM,LLMs,llms’ logic understanding,logic understanding,p,-3.498837237874593
6_arx_2309.05163_1909967_10,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.","However, given <mask> in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.",the LLMs,LLMs,LLM,LLMs,the llms' considerable proficiency,considerable proficiency in writing Physics essays and coding abilities,p,-3.979703135746149
6_arx_2309.05163_1909967_10,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.","However, given the <mask>' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by <mask>.",the LLMs,LLMs,LLM,LLMs,llms,considerable proficiency in writing Physics essays and coding abilities,p,-1.38751930907679
6_acl_865_25015_6,"On the other hand, downstream performance is mainly driven by the model’s size and prior legal knowledge which can be estimated by upstream and probing performance.","On the other hand, downstream performance is mainly driven by <mask> and prior legal knowledge which can be estimated by upstream and probing performance.",the model,model,model,model,the model’s size,prior legal knowledge,p,-2.445636459770892
6_acl_2210.12530_1733885_3,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with <mask> based on the metadata.",the LM,LM,LM,LM,the lm's common-sense reasoning,common-sense reasoning,p,-6.0203062858010075
6_arx_2206.14576_1674996_1,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.","More specifically, we assess <mask>, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",GPT-3,GPT-3,GPT-3,GPT-3,gpt-3's decision-making,"decision-making,deliberation,causal reasoning abilities",p,-3.839571891035053
6_arx_2206.14576_1674996_1,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.","More specifically, we assess <mask>, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",GPT-3,GPT-3,GPT-3,GPT,gpt-3's decision-making,"decision-making,deliberation,causal reasoning abilities",p,-3.839571891035053
6_arx_2308.01552_1889444_4,"The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.","The results highlight <mask> in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's competence,competence in comprehending and performing intricate tasks,p,-5.158615034125871
6_arx_2308.06032_1893924_10,"Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.","Our research is the first to systematically study <mask> in litigation, as well as in securities law and cryptocurrency-related misconduct.",an LLM,LLM,LLM,LLM,an llm's legal drafting and reasoning capabilities,legal drafting and reasoning capabilities,p,-1.8678818056092084
6_arx_2308.06920_1894812_8,"This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.","This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein <mask> enhance the design and development of potential pharmaceutical solutions.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's cognitive abilities,cognitive abilities,p,-6.389291024661013
6_arx_2308.07326_1895218_5,"Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.","Furthermore, historical figure simulations highlighted <mask> to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.",the LLM,LLM,LLM,LLM,the llm's capacity,capacity to internalize and project instructible personas,p,-2.2795441480824987
6_arx_2308.08407_1896299_3,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,Explainability is usually referred to as <mask> to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,an AI system,AI system,system,system,an ai system's ability,ability to provide a robust interpretation of its decision-making logic,p,-3.1174945485463255
6_arx_2308.08407_1896299_3,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,Explainability is usually referred to as <mask> to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,an AI system,AI system,system,AI,an ai system's ability,ability to provide a robust interpretation of its decision-making logic,p,-3.1174945485463255
6_arx_2307.05488_1876483_1,The objective of the studies is to assess ChatGPT's ability to comprehend theoretical concepts and differentiate between constructs.,The objective of the studies is to assess <mask> to comprehend theoretical concepts and differentiate between constructs.,ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's ability,ability to comprehend theoretical concepts and differentiate between constructs,p,-3.9968797975631034
6_arx_2307.04274_1875269_7,"Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model's ability to showcase pedagogical skills.","Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on <mask> to showcase pedagogical skills.",the model,model,model,model,the model's ability,ability to showcase pedagogical skills,p,-4.399378666492165
6_arx_2306.10645_1863793_3,"We examine ChatGPT's ability to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.","We examine <mask> to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's ability,ability to pursue multiple interconnected learning objectives,p,-6.54370543590543
6_arx_2306.06123_1859271_2,"The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.","The possibility of manipulating, fooling or fairwashing evidence of <mask> has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.",the model,model,model,model,the model's reasoning,reasoning,p,-3.78023537544426
6_arx_2305.16867_1849923_8,These results enrich our understanding of LLMs' social behaviour and pave the way for a behavioural game theory for machines.,These results enrich our understanding of <mask> and pave the way for a behavioural game theory for machines.,LLMs,LLMs,LLM,LLMs,llms' social behaviour,social behaviour,p,-5.2193432480349315
6_arx_2305.14795_1847851_2,"Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs.","Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to <mask>.",the model,model,model,model,the model's related beliefs,related beliefs,p,-4.014607727852409
6_arx_2305.12763_1845819_3,We find that GPT's decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,We find that <mask> are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,GPT,GPT,GPT,GPT,gpt's decisions,rational decisions,p,-2.608622487544782
6_arx_2305.12564_1845620_3,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).","Moreover, we find that this seemingly default perception of <mask> as male can reverse when <mask>'s feminine-coded abilities are highlighted (e.g., providing emotional support for a user).",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt,feminine-coded abilities,p,1.486452424089176
6_arx_2305.12564_1845620_3,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).","Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when <mask> are highlighted (e.g., providing emotional support for a user).",ChatGPT,ChatGPT,ChatGPT,ChatGPT,chatgpt's feminine-coded abilities,feminine-coded abilities,p,-1.870552676255766
6_arx_2303.03480_1803277_1,Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,Our approach makes use of Large Language Models (LLMs) for this task by leveraging <mask> for making sequential navigational decisions.,the LLM,LLM,LLM,LLM,the llm's commonsense reasoning capabilities,commonsense reasoning capabilities,p,-8.852032071394428
6_arx_1704.00717_835229_5,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.","In this work, we argue that for <mask> to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",AI,AI,AI,AI,human-ai teams,theory of mind,p,-5.25610649390449
6_arx_1704.00717_835229_5,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.","In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of <mask> (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",AI,AI,AI,AI,ai's mind,theory of mind,p,-4.400850879344407
