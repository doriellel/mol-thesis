,sentence,masked_sentence,text_id,POS,verb,original_term,original_noun,anthroscore
0,"Next, an experiment is conducted on the dataset to examine to what extent a pretrained masked language model is aware of the constructions.","Next, an experiment is conducted on the dataset to examine to what extent <mask> is aware of the constructions.",4_acl_683_21860_6,429,be,model,a pretrained masked language model,-1.763760417654746
1,A desired characteristic of an intelligent system is its ability to recognize the scope of its own knowledge.,A desired characteristic of <mask> is its ability to recognize the scope of its own knowledge.,4_acl_348_35206_2,439,of,system,an intelligent system,-4.125423641426384
2,LLMs are intelligent and slowly replacing the search engines.,<mask> are intelligent and slowly replacing the search engines.,4_acl_3_45070_1,429,be,LLMs,llms,-4.247897999156674
3,"However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves?","However, a critical question emerges: Are <mask> conscious of the existence of these decoding strategies and capable of regulating themselves?",4_acl_396_37165_1,429,be,LLMs,llms,-3.800791003376144
4,"In this way, the captioning model can become aware of the task goal and information need from the PLM.","In this way, <mask> can become aware of the task goal and information need from the PLM.",4_acl_590_28726_3,429,become,model,the captioning model,1.1517078677753343
5,"In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback.","In practical use, users might provide feedback based on <mask>, hoping for a responsive model that can complete responses according to their feedback.",4_acl_818_37575_1,439,on,model,the model’s output,-7.088072701329958
6,"In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback.","In practical use, users might provide feedback based on the model’s output, hoping for <mask> that can complete responses according to their feedback.",4_acl_818_37575_1,439,for,model,a responsive model,-4.714152902787282
7,"This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about.","This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that <mask> is least confident about.",4_acl_633_48859_2,429,be,model,the model,-2.3362483636121656
8,"In addition, we found that the model becomes more confident and refuses to provide an answer in only few cases.","In addition, we found that <mask> becomes more confident and refuses to provide an answer in only few cases.",4_acl_243_44794_7,429,become,model,the model,2.658288152012414
9,(2) Is ChatGPT aware of the underlying commonsense knowledge for answering a specific question?,(2) Is <mask> aware of the underlying commonsense knowledge for answering a specific question?,4_acl_276_39685_3,404,be,ChatGPT,chatgpt,2.981358761856395
10,"However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not.","However, when <mask> face different types of questions, it is worth exploring whether <mask> are aware that some questions have limited answers and need to respond more deterministically but some do not.",4_acl_117_37846_1,429,face,LLMs,llms,-1.6929933904433803
11,"However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not.","However, when <mask> face different types of questions, it is worth exploring whether <mask> are aware that some questions have limited answers and need to respond more deterministically but some do not.",4_acl_117_37846_1,429,be,LLMs,llms,-1.6929933904433803
12,"The goal is to cultivate culturally cognizant and value-aligned Arabic LLMs capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.","The goal is to cultivate <mask> capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.",4_acl_450_41596_3,416,cultivate,LLMs,culturally cognizant and value-aligned arabic llms,-0.680433796263344
13,We also show that an “attentive” RNN-LM needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,We also show that <mask> needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,4_acl_45_49661_2,429,need,RNN-LM,an “attentive” rnn-lm,-3.4376616342513238
14,Large Language Models (LLMs) are smart but forgetful.,Large Language Models (<mask>) are smart but forgetful.,4_arx_2311.04177_1947144_0,403,models,LLMs,llms,-0.11486062406442521
15,"In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.","In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of <mask>.",4_arx_1511.03246_676426_3,439,of,AI,malicious ai,-0.4491658234539653
16,"In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.","In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of <mask>.",4_arx_1511.03246_676426_3,439,of,AI,malicious ai,-0.4491658234539653
17,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying <mask>.,4_arx_2005.13635_1293430_5,416,identify,AI,malicious ai,-4.480066888284107
18,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying <mask>.,4_arx_2005.13635_1293430_5,416,identify,AI,malicious ai,-4.480066888284107
19,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",4_arx_2504.03726_2292429_5_1,439,to,AI,malicious ai assistants,-5.866401879427848
20,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",4_arx_2504.03726_2292429_5_1,439,to,AI,malicious ai assistants,-5.866401879427848
21,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",4_arx_2504.03726_2292429_5_2,439,to,AI,malicious ai assistants,-5.866401879427848
22,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",4_arx_2504.03726_2292429_5_2,439,to,AI,malicious ai assistants,-5.866401879427848
23,"We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.","We apply our OTF scheme on <mask> (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.",4_arx_2305.02626_1835682_10,439,on,LLMs,two llms,-4.951949106898288
24,"We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.","We apply our OTF scheme on two LLMs (Llama-13B and <mask>), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.",4_arx_2305.02626_1835682_10,410,llama-13b,ChatGPT,chatgpt,-0.9607796127393691
25,"We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.","We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for <mask>.",4_arx_2305.02626_1835682_10,439,for,LLMs,more ethically conscious llms,-2.327851135711743
26,"Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.","Therefore, in this paper, we propose MLLM-Tool, <mask> incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.",4_arx_2401.10727_1990281_4,403,tool,system,a system,-4.836361748944999
27,"Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.","Therefore, in this paper, we propose MLLM-Tool, a system incorporating <mask> and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.",4_arx_2401.10727_1990281_4,416,incorporate,LLMs,open-source llms,-3.340439040182977
28,"Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.","Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that <mask> can be conscious of multi-modal input instruction and then select the function-matched tool correctly.",4_arx_2401.10727_1990281_4,429,be,LLMs,the learned llms,-3.049015121436346
29,We consider a number of issues related to the development of the set of patterns which will be used by the intelligent system when interacting with environment.,We consider a number of issues related to the development of the set of patterns which will be used by <mask> when interacting with environment.,4_arx_1301.6359_402949_3,439,by,system,the intelligent system,-2.2369561999100362
30,"  Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.","  Large Language Models (<mask>) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.",4_arx_2308.03688_1891580_0,403,models,LLMs,llms,-1.3343707247208911
31,"Being more powerful and intrusive into user-device interactions, LLMs are eager for on-device execution to better preserve user privacy.","Being more powerful and intrusive into user-device interactions, <mask> are eager for on-device execution to better preserve user privacy.",4_arx_2403.11805_2028924_0,429,be,LLMs,llms,-5.483844121502816
32,"However, whether the same strategies can help LLMs become more creative remains under-explored.","However, whether the same strategies can help <mask> become more creative remains under-explored.",4_arx_2405.06715_2063927_2,429,become,LLMs,llms,1.9818300712582886
33,"To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems.","To bridge this gap, this work studies the security threats posed by <mask> to NLP systems.",4_arx_2008.00312_1328034_4,439,by,LMs,malicious lms,-4.978392004903162
34,"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.","As <mask> become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.",4_arx_2311.07723_1950690_0,429,become,AI,ai systems,-5.639337664163911
35,"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.","As <mask> become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.",4_arx_2311.07723_1950690_0,429,become,AI,ai systems,-5.639337664163911
36,"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.","As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how <mask> generalize human feedback to situations where it is unreliable.",4_arx_2311.07723_1950690_0,429,generalize,LLMs,llms,-1.6899646129777253
37,"The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.","<mask> is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.",4_acl_27_55498_4,429,be,model,the model,-1.2057704001534875
38,"We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.","We investigate the ability of <mask> to be deceptive in the context of providing assistance on a reading comprehension task, using <mask> as proxies for human users.",4_arx_2407.11789_2110176_2,439,of,LLMs,llms,-5.1253018040500535
39,"We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.","We investigate the ability of <mask> to be deceptive in the context of providing assistance on a reading comprehension task, using <mask> as proxies for human users.",4_arx_2407.11789_2110176_2,416,use,LLMs,llms,-5.1253018040500535
40,These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question.,These three modules perform the divide-and-conquer procedure iteratively until <mask> is confident about the final answer to the main question.,4_arx_2305.14985_1848041_7,429,be,model,the model,-1.8133906791198875
41,"Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.","<mask> constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.",4_arx_2406.18326_2096614_4,429,construct,method,our method,-0.15300185377980635
42,"Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.","Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether <mask> is significantly more confident under the original benchmark.",4_arx_2406.18326_2096614_4,429,be,model,the model,-4.602308362282496
43,"This is in part because LLMs might be overly confident in their predictions, overriding the influence of the constraints.","This is in part because <mask> might be overly confident in their predictions, overriding the influence of the constraints.",4_arx_2407.13164_2111551_3,429,be,LLMs,llms,-2.1455167226931167
44,"A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.","<mask> (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.",4_arx_1812.08960_1066534_3,429,combine,system,a smart autonomous system,-3.6779540215163866
45,"Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.","Results suggest that <mask> is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.",4_arx_2304.09655_1827701_7,429,be,ChatGPT,chatgpt,-0.856799227501762
46,"Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.","Consequently, we argue that the emergence of <mask> is plausible in the near term.",4_arx_2407.09517_2107904_5,439,of,model,a conscious ai model,-2.2401631552138745
47,"Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.","Consequently, we argue that the emergence of <mask> is plausible in the near term.",4_arx_2407.09517_2107904_5,439,of,AI,a conscious ai model,-2.2401631552138745
48,"Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.","Consequently, we argue that the emergence of <mask> is plausible in the near term.",4_arx_2407.09517_2107904_5,439,of,AI,a conscious ai model,-2.2401631552138745
49,"Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.","<mask> would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.",4_arx_2501.07290_2230874_1,429,deserve,AI,conscious ai systems,-3.304997495476889
50,"Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.","<mask> would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.",4_arx_2501.07290_2230874_1,429,deserve,AI,conscious ai systems,-3.304997495476889
51,"While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.","While recently Large Language Models (<mask>) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.",4_arx_2404.16873_2054324_0,403,models,LLMs,llms,-0.585147964696711
52,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike <mask> that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",4_arx_2502.18676_2261667_1,439,unlike,AI,conventional ai systems,-7.986592783189815
53,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike <mask> that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",4_arx_2502.18676_2261667_1,439,unlike,AI,conventional ai systems,-7.986592783189815
54,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike conventional AI systems that operate on <mask>, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",4_arx_2502.18676_2261667_1,439,on,model,"a turn-based, input-output model",-9.928795328475102
55,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike conventional AI systems that operate on a turn-based, input-output model, <mask> autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",4_arx_2502.18676_2261667_1,429,generate,AI,thoughtful ai,-5.944842148499209
56,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike conventional AI systems that operate on a turn-based, input-output model, <mask> autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",4_arx_2502.18676_2261667_1,429,generate,AI,thoughtful ai,-5.944842148499209
57,  Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.,  Whether <mask> could be conscious is a topic of scientific interest and increasing public concern.,4_arx_2308.08708_1896600_0,429,be,AI,current or near-term ai systems,1.2469050649149693
58,  Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.,  Whether <mask> could be conscious is a topic of scientific interest and increasing public concern.,4_arx_2308.08708_1896600_0,429,be,AI,current or near-term ai systems,1.2469050649149693
59,"While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.","While <mask> have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.",4_arx_2502.00735_2243726_1,429,demonstrate,LLMs,llms,-5.333978674585531
60,"Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.","Large Language Models (<mask>) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from <mask>.",4_arx_2411.14133_2196560_0,403,models,LLMs,llms,-0.4063396248805198
61,"Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.","Large Language Models (<mask>) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from <mask>.",4_arx_2411.14133_2196560_0,439,from,LLMs,llms,-0.4063396248805198
62,"We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.","We find that <mask> are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.",4_acl_592_38304_5,429,be,LLMs,powerful llms,-3.5419437657887087
63,"We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.","We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating <mask>.",4_acl_592_38304_5,416,evaluate,LLM,llm personalization,-4.492025593904705
64,"In fact, we demonstrate that even a ""blind"" language model that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago.","In fact, we demonstrate that <mask> that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago.",4_arx_2306.01879_1855027_7,429,outperform,model,"even a ""blind"" language model",-2.006395610175293
65,We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.,We conclude by discussing <mask> may affect the fight between malicious bots and the public.,4_arx_1901.00912_1070459_9,429,affect,AI,how future ai developments,-4.071884303735828
66,We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.,We conclude by discussing <mask> may affect the fight between malicious bots and the public.,4_arx_1901.00912_1070459_9,429,affect,AI,how future ai developments,-4.071884303735828
67,We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.,We conclude by discussing how future AI developments may affect the fight between <mask> and the public.,4_arx_1901.00912_1070459_9,439,between,ots,malicious bots,-3.8324477224248295
68,"The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.","<mask> easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.",4_arx_2208.12505_1703217_1,429,get,model,the ocr model,-1.809473674351369
69,"The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.","The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during <mask>.",4_arx_2208.12505_1703217_1,439,during,model,the model inference,-3.853910529377611
70,"To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask.","To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that <mask> is most attentive to, we are able to better resolve the entire extent of the segmentation mask.",4_arx_2311.17095_1960062_4,429,be,model,the model,-2.442462965437361
71,"We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.","We prove that it is impossible to precisely and consistently predict what specific actions <mask> will take to achieve its objectives, even if we know terminal goals of the system.",4_arx_1905.13053_1131489_2,429,take,system,a smarter-than-human intelligent system,-4.241575104379338
72,"We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.","We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of <mask>.",4_arx_1905.13053_1131489_2,439,of,system,the system,-5.39975233682965
73,"All in all, we demonstrate that our self-aware model improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.","All in all, we demonstrate that <mask> improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.",4_acl_36_22670_6,429,improve,model,our self-aware model,-2.8579380491831277
74,"We study how to better construct in-context example sets, based on whether the model is aware of the in-context examples.","We study how to better construct in-context example sets, based on whether <mask> is aware of the in-context examples.",4_acl_133_36622_2,429,be,model,the model,-1.7906218887907883
75,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.","<mask> are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",4_arx_2501.13533_2237117_7,430,assume,AI,ai agents,-1.8734640621828564
76,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.","<mask> are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",4_arx_2501.13533_2237117_7,430,assume,AI,ai agents,-1.8734640621828564
77,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.","AI agents are often assumed to pursue fixed goals, but <mask> may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",4_arx_2501.13533_2237117_7,429,be,AI,ai persons,-3.098818862550843
78,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.","AI agents are often assumed to pursue fixed goals, but <mask> may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",4_arx_2501.13533_2237117_7,429,be,AI,ai persons,-3.098818862550843
79,A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions.,<mask>) should be capable of correcting errors in its responses through external interactions.,4_arx_2502.05605_2248596_0,429,be,model,a truly intelligent large language model (llm,-1.7177315509455742
80,A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions.,<mask>) should be capable of correcting errors in its responses through external interactions.,4_arx_2502.05605_2248596_0,429,be,LLM,a truly intelligent large language model (llm,-1.7177315509455742
