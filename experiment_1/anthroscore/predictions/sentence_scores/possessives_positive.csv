,sentence,masked_sentence,text_id,POS,verb,original_term,original_noun,anthroscore
0,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use <mask>, with or without awareness, or someone who is affected by the decisions of an <mask> model.",6_arx_2104.14506_1461924_5,416,use,AI,ai,-6.850026447757019
1,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of <mask>.",6_arx_2104.14506_1461924_5,439,of,model,an ai model,-4.717264969147852
2,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of <mask>.",6_arx_2104.14506_1461924_5,439,of,AI,an ai model,-4.717264969147852
3,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.",6_acl_183_18630_5,416,teach,GPT-3,a deployed gpt-3,-3.9850025082201608
4,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.",6_acl_183_18630_5,416,teach,GPT,a deployed gpt-3,-3.9850025082201608
5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by <mask>.",6_acl_183_18630_5,439,by,GPT-3,the gpt-3,-1.550002939879354
6,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by <mask>.",6_acl_183_18630_5,439,by,GPT,the gpt-3,-1.550002939879354
7,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,We investigate how inputs of humans can be altered to reduce misinterpretation by <mask> and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,6_arx_1912.03652_1215548_4,439,by,system,the ai system,-2.9284242971815715
8,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,We investigate how inputs of humans can be altered to reduce misinterpretation by <mask> and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,6_arx_1912.03652_1215548_4,439,by,AI,the ai system,-2.9284242971815715
9,Actions by the AI system may be required to bring these objects in view.,Actions by <mask> may be required to bring these objects in view.,6_acl_373_16531_2,439,by,system,the ai system,0.34153384804312736
10,Actions by the AI system may be required to bring these objects in view.,Actions by <mask> may be required to bring these objects in view.,6_acl_373_16531_2,439,by,AI,the ai system,0.34153384804312736
11,"This raises the question of how we should limit the harm caused by AI ""lies"" (i.e. falsehoods that are actively selected for).","This raises the question of how we should limit the harm caused by <mask>"" (i.e. falsehoods that are actively selected for).",6_arx_2110.06674_1544817_2,439,by,AI,"ai ""lies",-0.9517374458450742
12,  Reasoning is a key ability for an intelligent system.,  Reasoning is a key ability for <mask>.,6_arx_2207.07051_1682949_0,439,for,system,an intelligent system,-1.3288000771196344
13,"In this study, leveraging the POPQUORN dataset, we evaluate nine popular LLMs on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.","In this study, leveraging the POPQUORN dataset, we evaluate <mask> on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.",6_acl_71_46015_2,416,evaluate,LLMs,nine popular llms,-4.912523248822676
14,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,We study the tendency of <mask> to deceive by constructing a realistic simulation setting of a company AI assistant.,6_arx_2405.01576_2058788_0,439,of,AI,ai systems,-3.252950371291096
15,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of <mask>.,6_arx_2405.01576_2058788_0,439,of,AI,a company ai assistant,-3.2682489777962704
16,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.","With large language models like <mask> taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.",6_acl_245_29281_1,429,take,GPT-4,gpt-4,-5.645393237290534
17,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.","With large language models like <mask> taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.",6_acl_245_29281_1,429,take,GPT,gpt-4,-5.645393237290534
18,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.","With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of <mask>.",6_acl_245_29281_1,439,of,LLMs,llms,-4.656341475270979
19,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs.,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of <mask>.,6_acl_916_40326_5,439,of,LLMs,chinese llms,-1.8187527793718523
20,"However, this awareness of LMs has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.","However, this awareness of <mask> has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.",6_acl_1539_40949_1,439,of,LMs,lms,-4.493531722733042
21,Numerous benchmarks have been established to assess the reasoning abilities of LLMs.,Numerous benchmarks have been established to assess the reasoning abilities of <mask>.,6_acl_225_32387_1,439,of,LLMs,llms,-3.8436958975530704
22,"Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.","Additionally, the causal reasoning ability of <mask> is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.",6_acl_743_29779_6,439,of,ChatGPT,chatgpt,-3.9805721189198096
23,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of LLMs and speed up the development of LLMs in journalism.,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of <mask> and speed up the development of <mask> in journalism.,6_acl_538_32700_6,439,of,LLMs,llms,-2.2249331950268036
24,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of LLMs and speed up the development of LLMs in journalism.,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of <mask> and speed up the development of <mask> in journalism.,6_acl_538_32700_6,439,of,LLMs,llms,-2.2249331950268036
25,We show how progress has been made in benchmark development to measure understanding capabilities of AI methods and we review as well how current methods develop understanding capabilities.,We show how progress has been made in benchmark development to measure understanding capabilities of <mask> and we review as well how current methods develop understanding capabilities.,6_arx_2101.06573_1410315_4,439,of,AI,ai methods,-3.117560457834731
26,"Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.","Specifically, extensive experiments will be conducted to explore: 1) the personality types of <mask>, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.",6_arx_2307.16180_1887175_4,439,of,LLMs,different llms,-2.7186801138544237
27,"Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.","Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect <mask>.",6_arx_2307.16180_1887175_4,416,affect,model,the model's personality,-3.532553720412846
28,"Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.","Leveraging the strengths of Large Language Models (<mask>) in knowledge comprehension and reasoning, recent approaches are eager to apply <mask> to sequential recommendation.",6_arx_2408.10159_2130340_1,403,models,LLMs,llms,-0.5346041198084208
29,"Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.","Leveraging the strengths of Large Language Models (<mask>) in knowledge comprehension and reasoning, recent approaches are eager to apply <mask> to sequential recommendation.",6_arx_2408.10159_2130340_1,416,apply,LLMs,llms,-0.5346041198084208
30,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.,The first approach uses <mask> for college algebra as a testbed to assess LLM problem-solving capabilities.,6_arx_2503.16460_2280772_5,416,use,system,an intelligent tutoring system,-2.4239536347743993
31,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess <mask>.,6_arx_2503.16460_2280772_5,416,assess,LLM,llm problem-solving capabilities,-4.89152685882507
32,A medical consultation training set is further constructed to improve the consultation ability of LLMs.,A medical consultation training set is further constructed to improve the consultation ability of <mask>.,6_arx_2309.02077_1906881_6,439,of,LLMs,llms,-0.7694079463120858
33,"Moreover, we provide a benchmark to evaluate the ability of LLMs to use tools, which is performed in both zero-shot and fine-tuning ways.","Moreover, we provide a benchmark to evaluate the ability of <mask> to use tools, which is performed in both zero-shot and fine-tuning ways.",6_arx_2305.18752_1851808_6,439,of,LLMs,llms,-2.57800933575572
34,"Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.","Inspired by the superior performance of <mask>, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.",6_arx_2309.11805_1916609_6,439,of,LLMs,llms,-4.093205853742077
35,"Large language models (LLMs), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.","Large language models (<mask>), known for their capability in understanding and following instructions, are vulnerable to adversarial attacks.",6_arx_2310.02417_1924674_0,403,model,LLMs,llms,-0.23708941801941563
36,We propose to use behavioural game theory to study LLMs' cooperation and coordination behaviour.,We propose to use behavioural game theory to study <mask>.,6_arx_2305.16867_1849923_1,416,study,LLMs,llms' cooperation and coordination behaviour,-4.006531429550087
37,It is tempting to interpret these CoT explanations as the LLM's process for solving a task.,It is tempting to interpret these CoT explanations as <mask> for solving a task.,6_arx_2305.04388_1837444_1,439,as,LLM,the llm's process,-2.9964593756553235
38,Explainable machine learning and artificial intelligence models have been used to justify a model's decision-making process.,Explainable machine learning and artificial intelligence models have been used to justify <mask>.,6_arx_2005.02335_1282130_0,416,justify,model,a model's decision-making process,-5.746756380725893
39,We also discuss issues that are unique to edge applications such as protecting a model's intellectual property and verifying its integrity.,We also discuss issues that are unique to edge applications such as protecting <mask> and verifying its integrity.,6_arx_2203.10923_1623785_4,416,protect,model,a model's intellectual property,-4.516063512976579
40,"However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for an AI's decision.","However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for <mask>.",6_arx_2207.09374_1685272_1,439,for,AI,an ai's decision,-3.7065856515950735
41,We propose conceptual consistency to measure a LLM's understanding of relevant concepts.,We propose conceptual consistency to measure <mask> of relevant concepts.,6_arx_2209.15093_1720808_3,416,measure,LLM,a llm's understanding,-4.329273164336804
42,We find that the visual grounding improves the model's understanding of semantic similarity both within and across languages and improves perplexity.,We find that the visual grounding improves <mask> of semantic similarity both within and across languages and improves perplexity.,6_arx_2210.05487_1726842_3,416,improve,model,the model's understanding,-6.319571965848066
43,"GenRec uses LLMs' understanding ability to interpret context, learn user preferences, and generate relevant recommendation.","GenRec uses <mask> to interpret context, learn user preferences, and generate relevant recommendation.",6_arx_2307.00457_1871453_4,416,use,LLMs,llms' understanding ability,-7.287083996653548
44,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",6_arx_2307.10250_1881245_0,416,evaluate,model,the gpt-4 large language model's abductive reasoning,-3.3953633750574497
45,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",6_arx_2307.10250_1881245_0,416,evaluate,GPT-4,the gpt-4 large language model's abductive reasoning,-3.3953633750574497
46,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.",6_arx_2307.10250_1881245_0,416,evaluate,GPT,the gpt-4 large language model's abductive reasoning,-3.3953633750574497
47,"However, effectively integrating LLMs' commonsense knowledge and reasoning abilities into recommendation systems remains a challenging problem.","However, effectively integrating <mask> and reasoning abilities into recommendation systems remains a challenging problem.",6_arx_2308.10837_1898729_1,416,integrate,LLMs,llms' commonsense knowledge,-3.592335393710794
48,Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions.,Our findings underscore <mask> and ability to discern and adapt to nuanced instructions.,6_arx_2308.07326_1895218_4,416,underscore,GPT,gpt's versatility,-1.8559019229300482
49,These biases may impact the responses of constructs and should be considered when interpreting ChatGPT's conceptual capabilities.,These biases may impact the responses of constructs and should be considered when interpreting <mask>.,6_arx_2307.05488_1876483_8,416,interpret,ChatGPT,chatgpt's conceptual capabilities,-4.213554281346642
50,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,This effectively mitigates <mask> to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,6_arx_2306.11296_1864444_1,416,mitigate,ChatGPT,chatgpt's tendency,-3.993726133031453
51,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (<mask>) in scientific fields challenging.,6_arx_2306.11296_1864444_1,403,models,LLMs,llms,-0.7917360854586803
52,We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically.,We then consider a decision maker who is aware of <mask> and responds strategically.,6_arx_2303.13712_1813509_7,439,of,algorithm,the algorithm's manipulation,-7.053260420318566
53,"In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.","In addition, <mask> provides reasoning paths as rationales to interpret the model's decision.",6_arx_2211.08380_1747286_6,429,provide,LM,oreo-lm,-2.8630291303014044
54,"In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.","In addition, OREO-LM provides reasoning paths as rationales to interpret <mask>.",6_arx_2211.08380_1747286_6,416,interpret,model,the model's decision,-4.739286273046979
55,"Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.","Using explainability, we observe that <mask> is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.",6_arx_2301.13852_1784916_11,429,be,ChatGPT,chatgpt's writing,-3.3296965546431583
56,"In this experiment, we characterize ChatGPT's refusal behavior using a black-box attack.","In this experiment, we characterize <mask> using a black-box attack.",6_arx_2306.03423_1856571_4,416,characterize,ChatGPT,chatgpt's refusal behavior,-3.0536429567709895
57,"Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.","Our analysis of <mask> over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.",6_acl_406_32568_3,439,of,GPT,gpt-series models,-5.963742368709294
58,"Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.","Our analysis of GPT-series models over a rule subset reveals significant gaps in <mask> compared to human performance, especially in compositional and structural complex rules with certain bias patterns.",6_acl_406_32568_3,439,in,LLMs,llms’ logic understanding,-3.498837237874593
59,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.","However, given <mask> in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.",6_arx_2309.05163_1909967_10,439,give,LLMs,the llms' considerable proficiency,-3.979703135746149
60,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.","However, given the <mask>' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by <mask>.",6_arx_2309.05163_1909967_10,439,by,LLMs,llms,-1.38751930907679
61,"This conflict renders LLMs vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.","This conflict renders <mask> vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.",6_arx_2311.08487_1951454_2,429,vulnerable,LLMs,llms,-2.334504542038948
62,"On the other hand, downstream performance is mainly driven by the model’s size and prior legal knowledge which can be estimated by upstream and probing performance.","On the other hand, downstream performance is mainly driven by <mask> and prior legal knowledge which can be estimated by upstream and probing performance.",6_acl_865_25015_6,439,by,model,the model’s size,-2.445636459770892
63,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","<mask>, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.",6_acl_2210.12530_1733885_3,429,incorporate,method,our method,-2.2027328790182876
64,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","Our method, <mask> (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.",6_acl_2210.12530_1733885_3,403,method,model,language model priors,0.35745816123472807
65,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage <mask> to be consistent with the LM's common-sense reasoning based on the metadata.",6_acl_2210.12530_1733885_3,416,encourage,model,downstream model outputs,-3.892503748959774
66,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with <mask> based on the metadata.",6_acl_2210.12530_1733885_3,439,with,LM,the lm's common-sense reasoning,-6.0203062858010075
67,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.","More specifically, we assess <mask>, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",6_arx_2206.14576_1674996_1,416,assess,GPT-3,gpt-3's decision-making,-3.839571891035053
68,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.","More specifically, we assess <mask>, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",6_arx_2206.14576_1674996_1,416,assess,GPT,gpt-3's decision-making,-3.839571891035053
69,"The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.","The results highlight <mask> in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.",6_arx_2308.01552_1889444_4,416,highlight,ChatGPT,chatgpt's competence,-5.158615034125871
70,"Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.","Our research is the first to systematically study <mask> in litigation, as well as in securities law and cryptocurrency-related misconduct.",6_arx_2308.06032_1893924_10,416,study,LLM,an llm's legal drafting and reasoning capabilities,-1.8678818056092084
71,"This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.","This research sheds light on the collaborative synergy between human expertise and <mask>, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.",6_arx_2308.06920_1894812_8,410,expertise,AI,ai assistance,-5.272495350521297
72,"This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.","This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein <mask> enhance the design and development of potential pharmaceutical solutions.",6_arx_2308.06920_1894812_8,429,enhance,ChatGPT,chatgpt's cognitive abilities,-6.389291024661013
73,"Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.","Furthermore, historical figure simulations highlighted <mask> to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.",6_arx_2308.07326_1895218_5,416,highlight,LLM,the llm's capacity,-2.2795441480824987
74,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,Explainability is usually referred to as <mask> to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,6_arx_2308.08407_1896299_3,439,as,system,an ai system's ability,-3.1174945485463255
75,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,Explainability is usually referred to as <mask> to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,6_arx_2308.08407_1896299_3,439,as,AI,an ai system's ability,-3.1174945485463255
76,The objective of the studies is to assess ChatGPT's ability to comprehend theoretical concepts and differentiate between constructs.,The objective of the studies is to assess <mask> to comprehend theoretical concepts and differentiate between constructs.,6_arx_2307.05488_1876483_1,416,assess,ChatGPT,chatgpt's ability,-3.9968797975631034
77,"Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model's ability to showcase pedagogical skills.","Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on <mask> to showcase pedagogical skills.",6_arx_2307.04274_1875269_7,439,on,model,the model's ability,-4.399378666492165
78,"We examine ChatGPT's ability to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.","We examine <mask> to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.",6_arx_2306.10645_1863793_3,416,examine,ChatGPT,chatgpt's ability,-6.54370543590543
79,"The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.","The possibility of manipulating, fooling or fairwashing evidence of <mask> has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.",6_arx_2306.06123_1859271_2,439,of,model,the model's reasoning,-3.78023537544426
80,These results enrich our understanding of LLMs' social behaviour and pave the way for a behavioural game theory for machines.,These results enrich our understanding of <mask> and pave the way for a behavioural game theory for machines.,6_arx_2305.16867_1849923_8,439,of,LLMs,llms' social behaviour,-5.2193432480349315
81,"Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs.","Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to <mask>.",6_arx_2305.14795_1847851_2,439,to,model,the model's related beliefs,-4.014607727852409
82,We find that GPT's decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,We find that <mask> are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,6_arx_2305.12763_1845819_3,429,be,GPT,gpt's decisions,-2.608622487544782
83,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).","Moreover, we find that this seemingly default perception of <mask> as male can reverse when <mask>'s feminine-coded abilities are highlighted (e.g., providing emotional support for a user).",6_arx_2305.12564_1845620_3,439,of,ChatGPT,chatgpt,1.486452424089176
84,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).","Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when <mask> are highlighted (e.g., providing emotional support for a user).",6_arx_2305.12564_1845620_3,430,highlight,ChatGPT,chatgpt's feminine-coded abilities,-1.870552676255766
85,Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,Our approach makes use of Large Language Models (<mask>) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,6_arx_2303.03480_1803277_1,403,models,LLMs,llms,-0.6336629388927761
86,Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,Our approach makes use of Large Language Models (LLMs) for this task by leveraging <mask> for making sequential navigational decisions.,6_arx_2303.03480_1803277_1,416,leverage,LLM,the llm's commonsense reasoning capabilities,-8.852032071394428
87,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.","In this work, we argue that for <mask> to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",6_arx_1704.00717_835229_5,429,be,AI,human-ai teams,-5.25610649390449
88,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.","In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of <mask> (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",6_arx_1704.00717_835229_5,439,of,AI,ai's mind,-4.400850879344407
