,sentence,masked_sentence,text_id,POS,verb,original_term,original_noun,anthroscore
0,Our experiments show that these errors can be identified with high accuracy by an LLM.,Our experiments show that these errors can be identified with high accuracy by <mask>.,2_acl_143_43709_5,439,by,LLM,an llm,-3.240353056940876
1,"To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.","To maintain the knowledge acquired by <mask>, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.",2_acl_511_29547_1,439,by,LLMs,llms,-3.1342142358185043
2,"Examination prioritization was performed by the AI, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.","Examination prioritization was performed by <mask>, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.",2_arx_2001.08625_1234038_4,439,by,AI,the ai,0.6200992625403572
3,"In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.","In CAPoW, a security professional can define relevant request context attributes which can be learned by <mask>.",2_arx_2301.11767_1782831_2,439,by,AI,the ai system,0.6403825270846646
4,"In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.","In CAPoW, a security professional can define relevant request context attributes which can be learned by <mask>.",2_arx_2301.11767_1782831_2,439,by,system,the ai system,0.6403825270846646
5,I suggest that up to 50% of a radiologists work in 2021 will be performed by AI-models in 2025.,I suggest that up to 50% of a radiologists work in 2021 will be performed by <mask> in 2025.,2_arx_2106.07921_1485685_1,439,by,AI,ai-models,0.8160046693952872
6,This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model.,This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by <mask>.,2_arx_2007.15619_1327133_1,439,by,model,the model,-2.285665951952648
7,The simulations are grounded by a neuro-symbolic language that both enables question answering of what is learned by the AI methods and provides a means of explainability.,The simulations are grounded by a neuro-symbolic language that both enables question answering of what is learned by <mask> and provides a means of explainability.,2_arx_2302.06852_1791786_1,439,by,AI,the ai methods,-3.6675371759890076
8,"Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.","Large Language Models (<mask>) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the <mask> themselves.",2_acl_23_33157_0,403,models,LLMs,llms,0.07314053455529645
9,"Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.","Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by <mask> themselves.",2_acl_23_33157_0,439,by,LLMs,the llms,-3.0889869857848637
10,The text was translated by both ChatGPT and a translator who is an academic in the field of translation and has 10 years of experience.,The text was translated by <mask> and a translator who is an academic in the field of translation and has 10 years of experience.,2_acl_3_26185_65,439,by,ChatGPT,both chatgpt,2.909923303888304
11,The final submission was chosen based on the best performances which was achieved by the BERT+BiLSTM model.,The final submission was chosen based on the best performances which was achieved by <mask>.,2_acl_260_9141_4,439,by,model,the bert+bilstm model,0.6173392872128485
12,These features are best interpreted by a self-consistent relativistic reflection model.,These features are best interpreted by <mask>.,2_arx_1907.08625_1153161_6,439,by,model,a self-consistent relativistic reflection model,-3.1798016791324297
13,"In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by LLMs.","In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by <mask>.",2_acl_430_37198_2,439,by,LLMs,llms,-2.40448986428423
14,How should we train a language model in this scenario?,How should we train <mask> in this scenario?,3_acl_696_6286_1,416,train,model,a language model,1.6425636213216048
15,"Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct fixed LLMs to generate appropriate responses on novel tasks, without the need for training data.","Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct <mask> to generate appropriate responses on novel tasks, without the need for training data.",3_acl_891_29927_2,416,instruct,LLMs,fixed llms,-3.1629290460388084
16,"A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output.","A promising approach to rectify these flaws is correcting <mask> with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output.",3_acl_27_42781_1,416,correct,LLMs,llms,-6.365980084076181
17,"A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output.","A promising approach to rectify these flaws is correcting LLMs with feedback, where <mask> itself is prompted or guided with feedback to fix problems in its own output.",3_acl_27_42781_1,430,prompt,LLM,the llm,-4.733220042970867
18,"This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches.","This paper provides an exhaustive review of the recent advances in correcting <mask> with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches.",3_acl_27_42781_3,416,correct,LLMs,llms,-5.496350846615233
19,"We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.","We present <mask> with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask <mask> to generate responses to those questions; we dub this LLM evaluation.",3_arx_2305.01937_1834993_4,416,present,LLMs,the llms,-1.3764555755217405
20,"We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.","We present <mask> with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask <mask> to generate responses to those questions; we dub this LLM evaluation.",3_arx_2305.01937_1834993_4,416,ask,LLMs,the llms,-1.3764555755217405
21,"We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.","We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub <mask>.",3_arx_2305.01937_1834993_4,416,dub,LLM,this llm evaluation,-4.980227266695433
22,"We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.","We show that choosing the best policy to interact with <mask> can reduce cost by ~90% while giving better or comparable performance, compared to communicating with <mask> in the original LRL.",3_acl_920_38624_10_1,439,with,LLM,the llm,-1.2654859408462986
23,"We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.","We show that choosing the best policy to interact with <mask> can reduce cost by ~90% while giving better or comparable performance, compared to communicating with <mask> in the original LRL.",3_acl_920_38624_10_1,439,with,LLM,the llm,-1.2654859408462986
24,"This paper explores the potential of constructing an AI spoken dialogue system that ""thinks how to respond"" and ""thinks how to speak"" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.","This paper explores the potential of constructing <mask> that ""thinks how to respond"" and ""thinks how to speak"" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.",3_arx_2309.11000_1915804_0,416,construct,AI,an ai spoken dialogue system,-3.3009133675358058
25,"This paper explores the potential of constructing an AI spoken dialogue system that ""thinks how to respond"" and ""thinks how to speak"" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.","This paper explores the potential of constructing <mask> that ""thinks how to respond"" and ""thinks how to speak"" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.",3_arx_2309.11000_1915804_0,416,construct,system,an ai spoken dialogue system,-3.3009133675358058
26,"We introduce a new task, “less likely brainstorming,” that asks a model to generate outputs that humans think are relevant but less likely to happen.","We introduce a new task, “less likely brainstorming,” that asks <mask> to generate outputs that humans think are relevant but less likely to happen.",3_acl_794_28930_3,416,ask,model,a model,-3.6783834863738054
27,We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing.,We successfully trained <mask> to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing.,3_arx_2308.01154_1889046_3,416,train,model,a light language model,-2.2644881366215
28,"For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches.","For earlier patches that passed all the tests, we further ask <mask> to generate alternative variations of the original plausible patches.",3_arx_2304.00385_1818431_9,416,ask,LLM,the llm,-0.3371421046730738
29,"Subsequently, we ask LLMs to predict this masked field.","Subsequently, we ask <mask> to predict this masked field.",3_arx_2411.05823_2188250_7,416,ask,LLMs,llms,-0.7713693231446417
30,"Typically, the advice generated by AI is judged by a human and either deemed reliable or rejected.","Typically, the advice generated by <mask> is judged by a human and either deemed reliable or rejected.",2_arx_2204.06916_1637054_2,439,by,AI,ai,-1.980100346857654
31,Each lesson in the curriculum is learnt by a deep reinforcement learning model.,Each lesson in the curriculum is learnt by <mask>.,2_arx_2004.11543_1276313_6,439,by,model,a deep reinforcement learning model,2.911136880314265
32,"Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API.","Therefore, we aim to train <mask> with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API.",3_acl_814_27535_2,416,train,agent,an agent,-3.5511145826407944
33,"Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API.","Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct <mask>.",3_acl_814_27535_2,416,instruct,ChatGPT,chatgpt api,1.946503086330738
34,"Specifically, the structural features identified by our algorithm were found to be related to clinical observations of glaucoma.","Specifically, the structural features identified by <mask> were found to be related to clinical observations of glaucoma.",2_arx_2012.09755_1397633_5,439,by,algorithm,our algorithm,0.484096664588721
