-4_arx_2005.06620_1286415_1	While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue.	While governments and businesses are eager to enjoy the benefits of <mask>, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue. these autonomous and intelligent systems	systems system	autonomous,intelligent	AI	ai innovations	2	-8.064980499205223
-4_arx_2408.08878_2129059_6	Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI.	Integrating <mask> into KE tasks needs to be mindful of potential risks and harms related to responsible AI.	responsible AI	AI	AI	responsible	LLMs	llms	2	-5.224869173821585
-4_arx_2402.05827_2003466_5	RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations?	RQ1: Can edited <mask> behave consistently resembling communicative AI in realistic situations? communicative AI	AI	AI	communicative	LLMs	llms	2	-2.2119669546089646
-4_arx_1904.13086_1118126_10	The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.	The results demonstrate the descriptive value of <mask> to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.	the intelligent system	system	system	intelligent	model	the resqu model 2	-5.548319029008585
-4_acl_1_30970_8	Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than the SVM model.	Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than <mask>.	language models models	model	sensitive	model	the svm model	2	-1.4209684241625915
-4_acl_159_43725_0	Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for the model.	Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for <mask>.	Modern large language models	large language models	model	sensitive	model	the model	2	1.2726868062471564
-4_arx_2405.16310_2073522_7	These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.	These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on <mask>.	untrustworthy LLMs	LLMs	LLM	untrustworthy	LLMs	untrustworthy llms	2	-5.775178082605381
-4_acl_128_54380_3	Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.	<mask> with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.	the competitive word-level model	word-level model	model	competitive	model	our best morpheme-aware model	2	-4.460899131557738
-4_acl_155_26876_9	Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.	Amidst the extensive deliberations on policy-making for regulating <mask>, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.	LLM	LLM	LLM	vulnerable	AI	ai development	2	-2.7925168306909196
-4_acl_45_49661_1	We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.	We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than <mask> (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.	an "attentive"" RNN-LM	RNN-LM	LM	attentive LMs	larger rnn-lms	2	-4.794794903411866
-4_acl_45_49661_1	We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.	We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of <mask>.	an "attentive RNN-LM	RNN-LM	LM	attentive	LMs	10 similar sized rnn-lms	2	-3.413201839473679
-4_arx_2503.22772_2287084_2	To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.	To address this blind spot, this study introduces <mask> (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.	emotionally intelligent AI	AI	AI	emotionally intelligent AI	the ai family integration index 2	-2.4482582589539703
-4_arx_2502.18676_2261667_3	We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.	We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform <mask> in the future.	Thoughtful AI	AI	AI	thoughtful	AI	human-ai interaction	2	-5.099401890650331
-4_acl_906_35749_0	Large language models (LLMs) have played a pivotal role in building communicative AI, yet they encounter the challenge of efficient updates.	Large language models (<mask>) have played a pivotal role in building communicative AI, yet they encounter the challenge of efficient updates.	communicative AI	AI	AI	communicative	LLMs	llms	0	-0.1826920704676204
-4_arx_2112.07467_1577243_0	As consensus across the various published AI ethics principles is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems.	As consensus across <mask> is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems.	responsible AI systems	AI systems	system	responsible	AI	the various published ai ethics principles	0	-1.947745749657308
-4_arx_2405.13024_2070236_0	This study explores the integration of the ChatGPT API with GPT-4 model and Microsoft Copilot Studio on the Microsoft Teams platform to develop an intelligent tutoring system.	This study explores the integration of the ChatGPT API with <mask> and Microsoft Copilot Studio on the Microsoft Teams platform to develop an intelligent tutoring system.	an intelligent tutoring system	tutoring system system	intelligent	model	gpt-4 model	0	-5.473759467450849
-4_arx_2412.12563_2214941_4	Additionally, we show our method is robust to both downstream fine-tuning, fine-pruning, and layer removal attacks, and can be trained in a fraction of the time required to train the original model.	Additionally, we show our method is robust to both downstream fine-tuning, fine-pruning, and layer removal attacks, and can be trained in a fraction of the time required to train <mask>.	our method	method	method	robust	model	the original model	0	-3.4619866497611937
-4_arx_2305.02231_1835287_1	However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses.	However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of <mask>, and considers previous aspects from different lenses.	truly trustworthy AI	AI	AI	trustworthy	system	the system's life cycle 0	-6.508549975674178
-4_arx_2312.15710_1977518_2	We first construct a factually weak LLM by inducing hallucinations from the original LLMs.	We first construct a factually weak LLM by inducing hallucinations from <mask>. a factually weak LLM	LLM	LLM	factually weak	LLMs	the original llms	0	-1.6013100520923036
-4_arx_2504.06279_2294982_3	To address these challenges, this paper presents an intelligent financial data analysis system that integrates Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) technology.	To address these challenges, this paper presents an intelligent financial data analysis system that integrates Large Language Models (<mask>) with Retrieval-Augmented Generation (RAG) technology.	an intelligent financial data analysis system	financial data analysis system	system	intelligent	LLMs	llms	0	-0.7920514008247608
-4_arx_1605.02817_730932_3	Availability of such information would be of great value particularly to computer scientists, mathematicians, and others who have an interest in AI safety, and who are attempting to avoid the spontaneous emergence or the deliberate creation of a dangerous AI, which can negatively affect human activities and in the worst case cause the complete obliteration of the human species.	Availability of such information would be of great value particularly to computer scientists, mathematicians, and others who have an interest in <mask>, and who are attempting to avoid the spontaneous emergence or the deliberate creation of a dangerous AI, which can negatively affect human activities and in the worst case cause the complete obliteration of the human species.	dangerous AI	AI	AI	dangerous	AI	ai safety	0	-6.8256696778697155
-4_acl_159_43725_5	Experimental results indicate that with the increase of model size, although the ease-of-use could be significantly improved, there is still a long way to go to build a sufficiently user-friendly model.	Experimental results indicate that with the increase of <mask>, although the ease-of-use could be significantly improved, there is still a long way to go to build a sufficiently user-friendly model.	a sufficiently user-friendly model	model	model	user-friendly	model	model size	0	-4.0238170709644905
-4_arx_2311.11796_1954763_1	However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks.	However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, <mask>, and model stealing attacks.	these AI systems	AI systems	system	vulnerable	model	model inversion 0	-2.793063510279012
-4_arx_2311.11796_1954763_1	However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks.	However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and <mask>.	these AI systems	AI systems	system	vulnerable	model	model stealing attacks	0	-2.1689561226086944
4_arx_2312.10766_1972574_1	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools.	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling <mask> to generate harmful content, while hijacking attacks manipulate <mask> to perform attacker-desired tasks, underscoring the necessity for detection tools.	current LLM systems	LLM systems	system	vulnerable	LLM	the llm system	0	-1.7000885242710773
4_arx_2312.10766_1972574_1	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools.	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling <mask> to generate harmful content, while hijacking attacks manipulate <mask> to perform attacker-desired tasks, underscoring the necessity for detection tools.	current LLM systems	LLM systems	system	vulnerable	system	the llm system	0	-1.7000885242710773
4_arx_2312.10766_1972574_1	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools.	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling <mask> to generate harmful content, while hijacking attacks manipulate <mask> to perform attacker-desired tasks, underscoring the necessity for detection tools.	current LLM systems	LLM systems	system	vulnerable	LLM	the llm system	0	-1.7000885242710773
4_arx_2312.10766_1972574_1	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools.	However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling <mask> to generate harmful content, while hijacking attacks manipulate <mask> to perform attacker-desired tasks, underscoring the necessity for detection tools.	current LLM systems	LLM systems	system	vulnerable	system	the llm system	0	-1.7000885242710773
4_acl_147_34632_2	While recent advances in large language models (LLMs) have greatly promoted language generation in general, state-of-the-art LLMs are still unreliable when it comes to suspenseful story generation.	While recent advances in large language models (<mask>) have greatly promoted language generation in general, state-of-the-art <mask> are still unreliable when it comes to suspenseful story generation. state-of-the-art LLMs	LLMs	LLM	unreliable	LLMs	llms	0	0.5584053052043227
4_arx_2502.16691_2259682_4	Aggregating such unsafe LLMs into the global model and distributing them to clients may result in the widespread deployment of unsafe LLMs.	Aggregating such unsafe LLMs into <mask> and distributing them to clients may result in the widespread deployment of unsafe LLMs. such unsafe LLMs	LLMs	LLM	unsafe	model	the global model	0	-1.64754878962842
-4_acl_2_41732_5	ReLLM is user-friendly and requires no additional LLM training.	ReLLM is user-friendly and requires <mask>.	ReLLM	ReLLM	LLM	user-friendly	LLM	no additional llm training	0	0.3793296748246924
-4_arx_2505.02062_2312622_0	The adoption of Artificial Intelligence (AI) in the healthcare service industry presents numerous ethical challenges, yet current frameworks often fail to offer a comprehensive, empirical understanding of the multidimensional factors influencing ethical AI integration.	The adoption of Artificial Intelligence (AI) in the healthcare service industry presents numerous ethical challenges, yet current frameworks often fail to offer a comprehensive, empirical understanding of the multidimensional factors influencing <mask>.	ethical AI	AI	AI	ethical AI	ethical ai integration	0	-6.730141114942493
-4_acl_48_14773_2	To alleviate this problem, we propose a simple and effective method to improve a character-aware neural language model by forcing a character encoder to produce word-based embeddings under Skip-gram architecture in a warm-up step without extra training data.	To alleviate this problem, we propose <mask> to improve a character-aware neural language model by forcing a character encoder to produce word-based embeddings under Skip-gram architecture in a warm-up step without extra training data.	a character-aware neural language model neural language model	model	character-aware method	a simple and effective method	0	-4.444554405171903
-4_acl_48_14773_2	To alleviate this problem, we propose a simple and effective method to improve a character-aware neural language model by forcing a character encoder to produce word-based embeddings under Skip-gram architecture in a warm-up step without extra training data.	To alleviate this problem, we propose a simple and effective method to improve a character-aware neural language model by forcing a character encoder to produce word-based embeddings under <mask> in a warm-up step without extra training data.	a character-aware neural language model neural language model	model	character-aware architecture	skip-gram architecture	0	-2.2625088547436807
-4_arx_2410.11009_2169210_3	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of an AI writing model.	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of <mask>.	a smart reply system	reply system	system	smart	model	an ai writing model	0	-6.900608425207398
-4_arx_2410.11009_2169210_3	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of an AI writing model.	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of <mask>.	a smart reply system	reply system	system	smart	AI	an ai writing model	0	-6.900608425207398
-4_acl_818_37575_1	In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback.	In practical use, users might provide feedback based on <mask>, hoping for a responsive model that can complete responses according to their feedback.	a responsive model	model	model	responsive	model	the model’s output	1	-7.088072701329958
-4_arx_1511.03246_676426_3	In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.	In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of <mask>.	malicious AI	AI	AI	malicious	AI	malicious ai	1	-0.4491658234539653
-4_arx_2005.13635_1293430_5	Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.	Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying <mask>.	malicious AI	AI	AI	malicious	AI	malicious ai	1	-4.480066888284107
-4_arx_2504.03726_2292429_5_1	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	malicious AI Assistants AI Assistants	AI assistant	malicious	AI	malicious ai assistants 1	-5.866401879427848
-4_arx_2504.03726_2292429_5_2	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	potentially manipulative systems	systems system	manipulative	AI	malicious ai assistants 1	-5.866401879427848
-4_arx_2504.03726_2292429_5_2	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	potentially manipulative systems	systems system	manipulative	AI	malicious ai assistants 1	-5.866401879427848
-4_arx_2305.02626_1835682_10	We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.	We apply our OTF scheme on <mask> (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.	ethically conscious LLMs	LLMs	LLM	ethically conscious	LLMs	two llms	1	-4.951949106898288
-4_arx_2305.02626_1835682_10	We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.	We apply our OTF scheme on two LLMs (Llama-13B and <mask>), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.	ethically conscious LLMs	LLMs	LLM	ethically conscious	ChatGPT chatgpt	1	-0.9607796127393692
-4_arx_2401.10727_1990281_4	Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.	Therefore, in this paper, we propose MLLM-Tool, <mask> incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.	the learned LLMs	learned LLMs	LLM	conscious	system	a system	1	-4.836361748944999
-4_arx_2401.10727_1990281_4	Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.	Therefore, in this paper, we propose MLLM-Tool, a system incorporating <mask> and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.	the learned LLMs	learned LLMs	LLM	conscious	LLMs	open-source llms	1	-3.340439040182977
-4_arx_2311.07723_1950690_0	As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.	As <mask> become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.	AI systems	AI systems	system	intelligent	AI	ai systems	1	-5.639337664163911
-4_arx_2311.07723_1950690_0	As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.	As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how <mask> generalize human feedback to situations where it is unreliable.	AI systems	AI systems	system	intelligent	LLMs	llms	1	-1.6899646129777253
-4_arx_2406.18326_2096614_4	Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.	<mask> constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.	the model	model	model	confident	method	our method	1	-0.1530018537798063
-4_arx_2407.09517_2107904_5	Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.	Consequently, we argue that the emergence of <mask> is plausible in the near term.	a conscious AI model	AI model	model	conscious	AI	a conscious ai model	1	-2.2401631552138745
-4_arx_2407.09517_2107904_5	Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.	Consequently, we argue that the emergence of <mask> is plausible in the near term.	a conscious AI model	AI model	model	conscious	AI	a conscious ai model	1	-2.2401631552138745
-4_arx_2501.07290_2230874_1	Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.	<mask> would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.	Conscious AI systems	AI systems	system	conscious	AI	conscious ai systems	1	-3.304997495476889
-4_arx_2502.18676_2261667_1	Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Unlike <mask> that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Thoughtful AI	AI	AI	thoughtful	AI	conventional ai systems	1	-7.986592783189815
-4_arx_2502.18676_2261667_1	Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Unlike <mask> that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Thoughtful AI	AI	AI	thoughtful	AI	conventional ai systems	1	-7.986592783189815
-4_arx_2502.18676_2261667_1	Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Unlike conventional AI systems that operate on <mask>, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Thoughtful AI	AI	AI	thoughtful	model	a turn-based, input-output model	1	-9.928795328475102
-4_arx_2502.18676_2261667_1	Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Unlike conventional AI systems that operate on a turn-based, input-output model, <mask> autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	Thoughtful AI	AI	AI	thoughtful	AI	thoughtful ai	1	-5.944842148499209
-4_arx_2308.08708_1896600_0	Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.	Whether <mask> could be conscious is a topic of scientific interest and increasing public concern.	current or near-term AI systems AI systems	system	conscious	AI	current or near-term ai systems 1	1.246905064914969
4_arx_2411.14133_2196560_0	Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.	Large Language Models (<mask>) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from <mask>.	Large Language Models (LLMs)	Large Language Models (LLMs)	model	vulnerable	LLMs	llms	1	-0.4063396248805198
4_arx_2411.14133_2196560_0	Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.	Large Language Models (<mask>) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from <mask>.	Large Language Models (LLMs)	Large Language Models (LLMs)	model	vulnerable	LLMs	llms	1	-0.4063396248805198
-4_acl_592_38304_5	We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.	We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating <mask>.	powerful LLMs	LLMs	LLM	aware	LLM	llm personalization	1	-4.492025593904705
-4_arx_1901.00912_1070459_9	We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.	We conclude by discussing <mask> may affect the fight between malicious bots and the public.	malicious bots	bots	bot	malicious	AI	how future ai developments	1	-4.071884303735828
-4_arx_1901.00912_1070459_9	We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.	We conclude by discussing <mask> may affect the fight between malicious bots and the public.	malicious bots	bots	bot	malicious	AI	how future ai developments	1	-4.071884303735828
-4_arx_2208.12505_1703217_1	The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.	The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during <mask>.	The OCR model	OCR model	model	confused	model	the model inference	1	-3.853910529377611
-4_arx_1905.13053_1131489_2	We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.	We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of <mask>.	a smarter-than-human intelligent system	system	system	intelligent	system	the system	1	-5.39975233682965
-4_arx_2501.13533_2237117_7	AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	<mask> are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	AI persons	AI persons	person	self-aware	AI	ai agents	1	-1.8734640621828564
-4_arx_2501.13533_2237117_7	AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	<mask> are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	AI persons	AI persons	person	self-aware	AI	ai agents	1	-1.8734640621828564
-4_arx_2501.13533_2237117_7	AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	AI agents are often assumed to pursue fixed goals, but <mask> may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.	AI persons	AI persons	person	self-aware	AI	ai persons	1	-3.098818862550843
-4_arx_2502.05605_2248596_0	A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions.	<mask>) should be capable of correcting errors in its responses through external interactions.	A truly intelligent Large Language Model (LLM)	Large Language Model (LLM)	model	intelligent,capable	LLM	a truly intelligent large language model (llm	1	-1.7177315509455742
-7_acl_24_22807_4	Our results show that GPT-3 scores similarly to human samples in terms of personality and - when provided with a model response memory - in terms of the values it holds.	Our results show that <mask> scores similarly to human samples in terms of personality and - when provided with a model response memory - in terms of the values it holds.	GPT-3	GPT-3	GPT-3	score similarly to human samples in terms of personality	GPT	gpt-3	2	-4.093221077031661
-7_acl_24_22807_4	Our results show that GPT-3 scores similarly to human samples in terms of personality and - when provided with a model response memory - in terms of the values it holds.	Our results show that GPT-3 scores similarly to human samples in terms of personality and - when provided with <mask> - in terms of the values it holds.	GPT-3	GPT-3	GPT-3	score similarly to human samples in terms of personality	model	a model response memory 2	-3.421747991108699
-7_acl_572_45853_6	We find that some LLMs are sensitive to factors that affect the inference process similarly to humans, yet there remains variance in human behavior not fully captured by LLMs.	We find that <mask> are sensitive to factors that affect the inference process similarly to humans, yet there remains variance in human behavior not fully captured by LLMs.	LLMs	LLMs	LLM	inference process similarly to humans	LLMs	some llms	2	-3.869442441984866
-7_acl_9_38794_1	We study a range of LLMs and find that the largest models we tested are able to draw human-like inferences when the inference is determined by context and can generalize to unseen adjective-noun combinations.	We study a range of <mask> and find that the largest models we tested are able to draw human-like inferences when the inference is determined by context and can generalize to unseen adjective-noun combinations.	the largest models we tested	models	model	human-like inferences	LLMs	llms	2	-3.3132845174513683
-7_arx_2303.09038_1808835_0	The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities.	The large language model called <mask> has drawn extensively attention because of its human-like expression and reasoning abilities.	The large language model called ChatGPT large language model	model	human-like expression and reasoning abilitiies	ChatGPT chatgpt 2	-2.287791657398257
7_acl_245_24395_3	This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the verifier.	This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with <mask> 1 as the generator and <mask> 2 as the verifier.	a human-like reasoning architecture	architecture	architecture	human-like reasoning	system	system	2	1.711831651707893
7_acl_245_24395_3	This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the verifier.	This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with <mask> 1 as the generator and <mask> 2 as the verifier.	a human-like reasoning architecture	architecture	architecture	human-like reasoning	system	system	2	1.711831651707893
-7_arx_2306.10063_1863211_3	Building social generative AI for education will require development of powerful AI systems that can converse with each other as well as humans, construct external representations such as knowledge maps, access and contribute to internet resources, and act as teachers, learners, guides and mentors.	Building <mask> for education will require development of powerful AI systems that can converse with each other as well as humans, construct external representations such as knowledge maps, access and contribute to internet resources, and act as teachers, learners, guides and mentors.	powerful AI systems	AI systems	system	converse with each other as well as humans	AI	social generative ai	2	-3.4046319102831504
-7_acl_773_32935_2	Observing this, we shift the perspective, by treating LLMs as human-like communicators to examine the interplay between everyday language interaction and AI safety.	Observing this, we shift the perspective, by treating LLMs as human-like communicators to examine the interplay between everyday language interaction and <mask>.	LLMs	LLMs	LLM	human-like communicators	AI	ai safety	2	-5.577992958087464
-7_acl_1_43505_3	We found that GPT-4 is an effective reader-annotator that performs close to or even slightly better than human annotators, and its results can be significantly improved by using a majority voting of five completions.	We found that <mask> is an effective reader-annotator that performs close to or even slightly better than human annotators, and its results can be significantly improved by using a majority voting of five completions.	GPT-4	GPT-4	GPT-4	performs close to or even slightly better than human annotators GPT	gpt-4	2	-4.924005260223632
-7_acl_169_28305_5	While GPT-3’s performance is not perfect, it is better than that of humans — likely thanks to its access to vast amounts of knowledge, and because conceptual processing is effortful for people (Connell and Lynott, 2012).	While <mask> is not perfect, it is better than that of humans — likely thanks to its access to vast amounts of knowledge, and because conceptual processing is effortful for people (Connell and Lynott, 2012). GPT-3	GPT-3	GPT-3	better than that of humans	GPT	gpt-3’s performance	2	-6.096086307329761
-7_arx_1808.01884_1011030_1	Through AI developments, machines are now given power and intelligence to behave and work like the human mind.	Through <mask>, machines are now given power and intelligence to behave and work like the human mind.	machines	machines	machine behave and work like the human mind	AI	ai developments 2	-4.853731403924945
-7_arx_2212.05206_1761383_2	In this study, we show that LLMs like GPT-3 exhibit behavior that strikingly resembles human-like intuition - and the cognitive errors that come with it.	In this study, we show that LLMs like <mask> that strikingly resembles human-like intuition - and the cognitive errors that come with it.	LLMs like GPT-3 LLMs	LLM	human-like intuition	GPT	gpt-3 exhibit behavior	2	-3.654225788747272
-7_arx_2304.07830_1825876_1	Accordingly, and given the recent proliferation of large language models (LLMs), here we asked whether such models exhibit an organisation of perceptual semantics similar to those observed in humans.	Accordingly, and given the recent proliferation of large language models (<mask>), here we asked whether such models exhibit an organisation of perceptual semantics similar to those observed in humans.	such models	models	model	organisation of perceptual semantics similar to those observed in humans	LLMs	llms	2	-1.8209831173429087
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that <mask> such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	LLMs	early llms	2	-4.81208196392387
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as <mask> exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	GPT-3	gpt-3	2	-0.6347714472277133
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as <mask> exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	GPT	gpt-3	2	-0.6347714472277133
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while <mask>, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	ChatGPT chatgpt 2	-1.485112931718934
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, <mask>, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans. ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	Llama2-Chat	llama2-chat	2	-0.3514980670853393
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, <mask> and GPT-4 show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	PaLM-2	palm-2	2	-0.7440586445031325
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and <mask> show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	GPT-4	gpt-4	2	-0.9438163700475676
-7_arx_2309.13356_1918160_3	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans.	Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and <mask> show significantly better performance on this task, comparable to adult humans.	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT, Llama2-Chat, PaLM-2 and GPT-4	ChatGPT,GPT,Llama	performance comparable to adult humans	GPT	gpt-4	2	-0.9438163700475676
-7_acl_4_45309_4	Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	Through extensive experiments across <mask> with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	advanced LLMs	LLMs	LLM	human-like cognitive abilities	LLMs	multiple mainstream llms	2	-0.6689111942257675
-7_acl_4_45309_4	Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as <mask>) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	advanced LLMs	LLMs	LLM	human-like cognitive abilities	GPT-4	gpt-4	2	-1.3580835269888445
-7_acl_4_45309_4	Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	Through extensive experiments across multiple mainstream LLMs with CogLM, we find that: (1) In our testing framework, advanced LLMs (such as <mask>) have demonstrated human-like cognitive abilities, comparable to those of a 20-year-old human.	advanced LLMs	LLMs	LLM	human-like cognitive abilities	GPT	gpt-4	2	-1.3580835269888445
-7_arx_2307.02194_1873190_1	With recent advancements (such as GPT-4), LLMs perform at a level comparable to humans for many proficient tasks.	With recent advancements (such as <mask>), LLMs perform at a level comparable to humans for many proficient tasks.	LLMs	LLMs	LLM	perform at a level comparable to humans GPT-4	gpt-4	2	-5.27045847352521
-7_arx_2307.02194_1873190_1	With recent advancements (such as GPT-4), LLMs perform at a level comparable to humans for many proficient tasks.	With recent advancements (such as <mask>), LLMs perform at a level comparable to humans for many proficient tasks.	LLMs	LLMs	LLM	perform at a level comparable to humans GPT	gpt-4	2	-5.27045847352521
7_arx_2308.12578_1900470_0	Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs.	Recent researches indicate that Pre-trained Large Language Models (<mask>) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of <mask>.	Pre-trained Large Language Models Pre-trained Large Language Models	model	cognitive constructs similar to those observed in humans	LLMs	llms	2	-0.8357156429336108
7_arx_2308.12578_1900470_0	Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs.	Recent researches indicate that Pre-trained Large Language Models (<mask>) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of <mask>.	Pre-trained Large Language Models Pre-trained Large Language Models	model	cognitive constructs similar to those observed in humans	LLMs	llms	2	-0.8357156429336108
-5_arx_2102.07536_1424025_6	Testing human behaviour in interaction with actual AI outputs, we provide first behavioural insights into the role of AI as an advisor.	Testing human behaviour in interaction with <mask>, we provide first behavioural insights into the role of AI as an advisor.	AI	AI	AI	advisor AI	actual ai outputs	1	-4.035535693937659
-5_acl_50_42804_2	In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: Assistants can access and process large amounts of information, while users have preferences and constraints external to the system.	In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: Assistants can access and process large amounts of information, while users have preferences and constraints external to <mask>.	AI assistants	AI	AI	assistant	system	the system	1	-3.5938894366396585
-5_arx_2401.13275_1992829_0	Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools.	Recently, AI assistants based on large language models (<mask>) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools.	AI assistants based on large language models (LLMs)	AI	AI	assistant	LLMs	llms	1	-0.1321381783811457
-5_arx_2306.16092_1869240_0	AI legal assistants based on Large Language Models (LLMs) can provide accessible legal consulting services, but the hallucination problem poses potential legal risks.	AI legal assistants based on Large Language Models (<mask>) can provide accessible legal consulting services, but the hallucination problem poses potential legal risks.	AI legal assistants based on Large Language Models (LLMs)	AI	AI	legal assistant LLMs	llms	1	-0.1387873399942432
-5_arx_2305.02626_1835682_1	In particular, given that LLMs have great potential to serve as general-purpose AI assistants in daily life, their subtly unethical suggestions become a serious and real concern.	In particular, given that LLMs have great potential to serve as <mask> in daily life, their subtly unethical suggestions become a serious and real concern.	LLMs	LLMs	LLM	assistant	AI	general-purpose ai assistants	1	-1.1296979910990714
-5_acl_523_44090_1	As such, it can be valuable for a large language model (LLM), particularly as an AI assistant, to be able to empathize with or even explain these various standpoints.	As such, it can be valuable for a large language model (<mask>), particularly as an AI assistant, to be able to empathize with or even explain these various standpoints. a large language model (LLM)	large language model (LLM)	model	assistant	LLM	llm	1	0.5913950249885733
-5_acl_523_44090_1	As such, it can be valuable for a large language model (LLM), particularly as an AI assistant, to be able to empathize with or even explain these various standpoints.	As such, it can be valuable for a large language model (LLM), particularly as <mask>, to be able to empathize with or even explain these various standpoints.	a large language model (LLM)	large language model (LLM)	model	assistant	AI	an ai assistant 1	0.4210309310036724
-5_acl_321_45615_1	To deploy LLMs as AI assistants, it is crucial that these models exhibit desirable behavioral traits, such as non-toxicity and resilience against jailbreak attempts.	To deploy LLMs as <mask>, it is crucial that these models exhibit desirable behavioral traits, such as non-toxicity and resilience against jailbreak attempts.	LLMs	LLMs	LLM	assistant	AI	ai assistants	1	-2.2577375465840017
-5_arx_2306.07207_1860355_0	Large Language Models (LLMs), with remarkable conversational capability, have emerged as AI assistants that can handle both visual and textual modalities.	Large Language Models (LLMs), with remarkable conversational capability, have emerged as <mask> that can handle both visual and textual modalities.	Large Language Models (LLMs)	Large Language Models (LLMs)	model	assistant	AI	ai assistants	1	-3.5612495840522698
-5_arx_2502.20541_2263532_1	The system leverages the capabilities of a sophisticated language model to serve as an intelligent research assistant, enhancing the efficiency and comprehensiveness of literature reviews in the nanotechnology domain.	The system leverages the capabilities of <mask> to serve as an intelligent research assistant, enhancing the efficiency and comprehensiveness of literature reviews in the nanotechnology domain.	The system	system	system	intelligent research assistant	model	a sophisticated language model	1	-4.365262584591976
-5_arx_2412.01992_2204370_5_2	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing <mask>, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI CEO agent AI	AI	CEO	AI	chatcollab ai agents	1	-4.466489894169641
-5_arx_2412.01992_2204370_5_2	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than <mask> or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI CEO agent AI	AI	CEO	AI	an ai product manager	1	2.072956489441907
-5_arx_2412.01992_2204370_5_2	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or <mask>, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI CEO agent AI	AI	CEO	AI	ai developer	1	2.229083261304222
-5_arx_2501.18948_2242532_3	Meanwhile, Human-Centered AI (HCAI), which envisions AI as a collaborator augmenting human capabilities and aligning with societal values, remains a fugitive from the mainstream narrative.	Meanwhile, <mask> (HCAI), which envisions AI as a collaborator augmenting human capabilities and aligning with societal values, remains a fugitive from the mainstream narrative. AI	AI	AI	collaborator	AI	human-centered ai	1	-0.44596947313482
-5_arx_2504.04253_2292956_6	Finally, we present our vision for a user-centered system that leverages GenAI not only for automation but as an intelligent collaborator in visual data exploration.	Finally, we present our vision for <mask> that leverages GenAI not only for automation but as an intelligent collaborator in visual data exploration.	GenAI	GenAI	GenAI	intelligent collaborator	system	a user-centered system	1	-2.583747778239733
-5_arx_2503.03067_2267379_0	This paper explores the acceptance of human-AI love among young adults, particularly focusing on Chinese women in romantic or intimate relationships with AI companions.	This paper explores the acceptance of <mask> among young adults, particularly focusing on Chinese women in romantic or intimate relationships with AI companions. AI companions	AI	AI	companion	AI	human-ai love	1	-2.582087581585512
-5_arx_2409.00862_2138494_0	Large language model-based AI companions are increasingly viewed by users as friends or romantic partners, leading to deep emotional bonds.	<mask> are increasingly viewed by users as friends or romantic partners, leading to deep emotional bonds. Large language model-based AI companions	AI	AI	companion	model	large language model-based ai companions	1	-1.1475868593396488
-5_arx_2412.01992_2204370_5_3	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing <mask>, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	AI developer	AI	AI	developer	AI	chatcollab ai agents	1	-4.466489894169641
-5_arx_2412.01992_2204370_5_3	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that <mask> generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	AI developer	AI	AI	developer	AI	an ai ceo agent 1	-0.1151455139372767
-5_arx_2412.01992_2204370_5_3	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than <mask> or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	AI developer	AI	AI	developer	AI	an ai product manager	1	2.072956489441907
-5_arx_2411.15692_2198119_5_1	DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas.	DrugAgent employs <mask> that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas.	an LLM instructor	LLM	LLM	instructor	LLM	an llm planner	1	-0.66698871639068
-5_arx_2412.01992_2204370_5_1	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing <mask>, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI product manager	AI	AI	product manager AI	chatcollab ai agents	1	-4.466489894169641
-5_arx_2412.01992_2204370_5_1	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that <mask> generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI product manager	AI	AI	product manager AI	an ai ceo agent 1	-0.1151455139372767
-5_arx_2412.01992_2204370_5_1	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or <mask>, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.	an AI product manager	AI	AI	product manager AI	ai developer	1	2.229083261304222
-5_arx_2503.05455_2269767_4	In another experiment, we enable human control, showing that participants perceive AI partners as more effective and enjoyable when they can directly dictate AI behavior.	In another experiment, we enable human control, showing that participants perceive AI partners as more effective and enjoyable when they can directly dictate <mask>.	AI partners	AI	AI	partner AI	ai behavior	1	-4.532937223533114
-5_arx_2501.19361_2242945_1	Although these LLMs are marketed as helpful creative assistants, several works have shown that using an LLM as a creative partner results in a narrower set of creative outputs.	Although <mask> are marketed as helpful creative assistants, several works have shown that using an LLM as a creative partner results in a narrower set of creative outputs.	an LLM	LLM	LLM	creative partner	LLMs	these llms	1	-3.6584316722458823
-5_arx_2502.18357_2261348_1	In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s).	In these tasks, <mask> acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s).	the AI system	AI system	system	co-creative partner	AI	the ai system	1	-2.4423310656767434
-5_arx_2411.15692_2198119_5_2	DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas.	DrugAgent employs an LLM Planner that formulates high-level ideas and <mask> that identifies and integrates domain knowledge when implementing those ideas.	an LLM planner	LLM	LLM	planner LLM	an llm instructor	1	-3.256694486387886
5_acl_280_13090_8_1	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of the student model to better transfer the knowledge learned by the teacher model.	In addition, we propose a momentum distillation method by incorporating the gradients of <mask> into the update of the student model to better transfer the knowledge learned by the <mask>.	the student model	model	model	student model	teacher model	1	-3.4737913762281423
-5_acl_280_13090_8_2	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of student model to better transfer the knowledge learned by the teacher model.	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of student model to better transfer the knowledge learned by <mask>.	the teacher model	model	model	teacher	model	the teacher model	1	-0.0921306314583887
5_acl_280_13090_8_1	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of the student model to better transfer the knowledge learned by the teacher model.	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of the student model to better transfer the knowledge learned by <mask>.	the student model	model	model	student model	the teacher model 1	-0.3740187217355259
-5_acl_280_13090_8_2	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of student model to better transfer the knowledge learned by the teacher model.	In addition, we propose a momentum distillation method by incorporating the gradients of teacher model into the update of <mask> to better transfer the knowledge learned by the teacher model.	the teacher model	model	model	teacher model	student model	1	-3.403195172055062
-5_acl_358_41505_5	Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student.	Leveraging the strong language abilities of <mask>, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student.	LLM teachers	LLM	LLM	teacher LLMs	llms	1	-1.3171035826383957
5_arx_2311.06985_1949952_2	We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or other LLMs, compared to humans.	We ask whether a large language model (<mask>) can serve as a more effective in-context teacher for itself or other <mask>s, compared to humans.	a large language model (LLM)	large language model (LLM)	model	teacher LLM	llm	1	0.5628143419753897
5_arx_2311.06985_1949952_2	We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or other LLMs, compared to humans.	We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or <mask>, compared to humans.	a large language model (LLM)	large language model (LLM)	model	teacher LLMs	other llms	1	-1.7641165579084124
-5_acl_6_43304_0	My research theme is to develop an optimal analytical model for various information generated during therapy using multimodal data in psychotherapy, to elucidate the process of psychotherapy, and to create an AI therapist to develop a new psychotherapy.	My research theme is to develop <mask> for various information generated during therapy using multimodal data in psychotherapy, to elucidate the process of psychotherapy, and to create an AI therapist to develop a new psychotherapy.	an AI therapist AI	AI	therapist	model	an optimal analytical model	1	-2.903394780282909
-5_acl_57_45359_0	In this paper, we investigate whether current state-of-the-art large language models (LLMs) are effective as AI tutors and whether they demonstrate pedagogical abilities necessary for good AI tutoring in educational dialogues.	In this paper, we investigate whether current state-of-the-art large language models (<mask>) are effective as AI tutors and whether they demonstrate pedagogical abilities necessary for good AI tutoring in educational dialogues.	AI tutors	AI	AI	tutor	LLMs	llms	1	1.2838911725884063
-5_acl_57_45359_0	In this paper, we investigate whether current state-of-the-art large language models (LLMs) are effective as AI tutors and whether they demonstrate pedagogical abilities necessary for good AI tutoring in educational dialogues.	In this paper, we investigate whether current state-of-the-art large language models (LLMs) are effective as <mask> and whether they demonstrate pedagogical abilities necessary for good AI tutoring in educational dialogues. AI tutors AI	AI	tutor	AI	ai tutors	1	-2.187159781119643
6_arx_2104.14506_1461924_5	The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.	The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of <mask>.	an AI model	AI model	model	decisions	AI	an ai model	1	-4.717264969147852
-6_acl_183_18630_5	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.	the GPT-3	GPT-3	GPT-3	misunderstandings	GPT-3	a deployed gpt-3	1	-3.9850025082201608
-6_acl_183_18630_5	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach <mask>, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.	the GPT-3	GPT-3	GPT-3	misunderstandings	GPT	a deployed gpt-3	1	-3.9850025082201608
-6_acl_183_18630_5	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by <mask>.	the GPT-3	GPT-3	GPT-3	misunderstandings	GPT	the gpt-3	1	-1.550002939879354
-6_arx_1912.03652_1215548_4	We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.	We investigate how inputs of humans can be altered to reduce misinterpretation by <mask> and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.	the AI system	AI system	system	misinterpretations	AI	the ai system	1	-2.9284242971815715
-6_acl_373_16531_2	Actions by the AI system may be required to bring these objects in view.	Actions by <mask> may be required to bring these objects in view.	the AI system	AI system	system	actions AI	the ai system	1	0.3415338480431273
-6_arx_2405.01576_2058788_0	We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.	We study the tendency of AI systems to deceive by constructing a realistic simulation setting of <mask>.	AI systems	AI systems	system	tendency to deceive	AI	a company ai assistant	1	-3.2682489777962704
-6_acl_245_29281_1	With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.	With large language models like <mask> taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.	LLMs	LLMs	LLM	reasoning capabilities	GPT-4	gpt-4	1	-5.645393237290534
-6_acl_245_29281_1	With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.	With large language models like <mask> taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.	LLMs	LLMs	LLM	reasoning capabilities	GPT	gpt-4	1	-5.645393237290534
-6_arx_2307.16180_1887175_4	Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.	Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect <mask>.	different LLMs	LLMs	LLM	personality types	model	the model's personality 1	-3.532553720412846
6_arx_2408.10159_2130340_1	Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.	Leveraging the strengths of Large Language Models (<mask>) in knowledge comprehension and reasoning, recent approaches are eager to apply <mask> to sequential recommendation.	Large Language Models (LLMs)	Large Language Models (LLMs)	model	strengths in knowledge comprehension and reasoning	LLMs	llms	1	-0.5346041198084208
6_arx_2408.10159_2130340_1	Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches are eager to apply LLMs to sequential recommendation.	Leveraging the strengths of Large Language Models (<mask>) in knowledge comprehension and reasoning, recent approaches are eager to apply <mask> to sequential recommendation.	Large Language Models (LLMs)	Large Language Models (LLMs)	model	strengths in knowledge comprehension and reasoning	LLMs	llms	1	-0.5346041198084208
-6_arx_2503.16460_2280772_5	The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.	The first approach uses <mask> for college algebra as a testbed to assess LLM problem-solving capabilities.	LLM	LLM	LLM	problem-solving capabilities	system	an intelligent tutoring system	1	-2.4239536347743993
-6_arx_2307.10250_1881245_0	This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.	This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.	the GPT-4 Large Language Model	GPT-4 Large Language Model	model	abductive reasoning	GPT-4	the gpt-4 large language model's abductive reasoning	1	-3.3953633750574497
-6_arx_2307.10250_1881245_0	This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.	This study evaluates <mask> in complex fields like medical diagnostics, criminology, and cosmology.	the GPT-4 Large Language Model	GPT-4 Large Language Model	model	abductive reasoning	GPT	the gpt-4 large language model's abductive reasoning	1	-3.3953633750574497
-6_arx_2306.11296_1864444_1	This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.	This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (<mask>) in scientific fields challenging.	ChatGPT ChatGPT ChatGPT tendency to hallucinate information	LLMs	llms	1	-0.7917360854586803
-6_arx_2211.08380_1747286_6	In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.	In addition, <mask> provides reasoning paths as rationales to interpret the model's decision.	the model	model	model	decisions	LM	oreo-lm 1	-2.8630291303014044
-6_acl_406_32568_3	Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.	Our analysis of <mask> over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.	LLMs	LLMs	LLM	logic understanding	GPT	gpt-series models	1	-5.963742368709294
-6_arx_2311.08487_1951454_2	This conflict renders LLMs vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.	This conflict renders <mask> vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information.	the models	models	model	desire	LLMs	llms	1	-2.334504542038948
-6_acl_2210.12530_1733885_3	Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.	<mask>, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.	the LM	LM	LM	common-sense reasoning	method	our method	1	-2.2027328790182876
-6_acl_2210.12530_1733885_3	Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.	Our method, <mask> (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.	the LM	LM	LM	common-sense reasoning	model	language model priors	1	0.357458161234728
-6_acl_2210.12530_1733885_3	Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.	Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage <mask> to be consistent with the LM's common-sense reasoning based on the metadata.	the LM	LM	LM	common-sense reasoning	model	downstream model outputs	1	-3.892503748959774
-6_arx_2206.14576_1674996_1	More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.	More specifically, we assess <mask>, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.	GPT-3	GPT-3	GPT-3	decision-making,deliberation,causal reasoning abilities GPT	gpt-3's decision-making	1	-3.839571891035053
-6_arx_2308.06920_1894812_8	This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.	This research sheds light on the collaborative synergy between human expertise and <mask>, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.	ChatGPT ChatGPT ChatGPT cognitive abilities	AI	ai assistance	1	-5.272495350521297
-6_arx_2308.08407_1896299_3	Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.	Explainability is usually referred to as <mask> to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.	an AI system	AI system	system	ability to provide a robust interpretation of its decision-making logic	AI	an ai system's ability	1	-3.1174945485463255
-6_arx_2305.12564_1845620_3	Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).	Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when <mask> are highlighted (e.g., providing emotional support for a user).	ChatGPT	ChatGPT	ChatGPT	feminine-coded abilities	ChatGPT	chatgpt's feminine-coded abilities	1	-1.870552676255766
-6_arx_2303.03480_1803277_1	Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.	Our approach makes use of Large Language Models (<mask>) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.	the LLM LLM	LLM	commonsense reasoning capabilities	LLMs	llms	1	-0.6336629388927761
-6_arx_1704.00717_835229_5	In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.	In this work, we argue that for <mask> to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.	AI	AI	AI	theory of mind	AI	human-ai teams	1	-5.25610649390449 
6_arx_2309.05163_1909967_10	However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.	However, given <mask> in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.	the LLMs	LLMs	LLM	considerable proficiency in writing Physics essays and coding abilities	LLMs	the llms' considerable proficiency	1	-3.979703135746149