2_arx_1910.06294_1190213_4	In this work-in-progress we combined the effectiveness of transfer learning provided by pre-trained masked language models with a semi-supervised approach to train a fast and compact model using labeled and unlabeled examples.	In this work-in-progress we combined the effectiveness of transfer learning provided by pre-trained masked language models with a semi-supervised approach to train <mask> using labeled and unlabeled examples.	pre-trained masked language models	pre-trained masked language models	model	provide	model	a fast and compact model	0	-4.415946561299641
2_arx_2006.05347_1299861_5	As for the passive eavesdropping, an average secrecy rate maximization problem is formulated, which is addressed by a low complexity algorithm.	As for the passive eavesdropping, an average secrecy rate maximization problem is formulated, which is addressed by <mask>.	a low complexity algorithm	low complexity algorithm	algorithm	address	algorithm	a low complexity algorithm	0	-1.988000611394785
2_arx_2007.00900_1312414_5	We introduce an explainable VQA system that uses spatial and object features and is powered by the BERT language model.	We introduce <mask> that uses spatial and object features and is powered by the BERT language model.	the BERT language model	BERT language model	model	power	system	an explainable vqa system	0	-4.856427372014613
2_arx_2007.00900_1312414_5	We introduce an explainable VQA system that uses spatial and object features and is powered by the BERT language model.	We introduce an explainable VQA system that uses spatial and object features and is powered by <mask>.	the BERT language model	BERT language model	model	power	model	the bert language model	0	-5.391540133038928
2_acl_7_34206_4	A positive correlation of 0.40 was found between the emotion intensity scores reproduced by GPT-4 and those manually annotated by humans.	A positive correlation of 0.40 was found between the emotion intensity scores reproduced by <mask> and those manually annotated by humans.	GPT-4	GPT-4	GPT-4	reproduce	GPT-4	gpt-4	0	-2.546263602841361
2_arx_2103.07820_1437965_2	We consider a UAS that can be fully controlled by the onboard DAA system and by a remote human pilot.	We consider a UAS that can be fully controlled by <mask> and by a remote human pilot.	the onboard DAA system	onboard DAA system	system	control	system	the onboard daa system	0	-1.9747190469979383
2_arx_1811.12185_1056818_9	We observed 95.61% alarms raised by the said system are taken care of by the operator.	We observed 95.61% alarms raised by <mask> are taken care of by the operator.	the said system	system	system	raise alarm	system	the said system	0	-1.5989440716932073
2_arx_1909.09993_1180031_2	Moreover, the A2C model can be used to recover out-of-vocabulary (OOV) words that are not covered by the A2W model, but this requires accurate detection of OOV words.	Moreover, <mask> can be used to recover out-of-vocabulary (OOV) words that are not covered by the A2W model, but this requires accurate detection of OOV words.	the A2W model	A2W model	model	cover	model	the a2c model	0	-4.255504353755546
2_arx_1909.09993_1180031_2	Moreover, the A2C model can be used to recover out-of-vocabulary (OOV) words that are not covered by the A2W model, but this requires accurate detection of OOV words.	Moreover, the A2C model can be used to recover out-of-vocabulary (OOV) words that are not covered by <mask>, but this requires accurate detection of OOV words.	the A2W model	A2W model	model	cover	model	the a2w model	0	-4.14336536502474
2_arx_1912.06835_1218731_4	By comparing the measurements with the results predicted by the ion flow model for negative corona discharge, it is found that the electric field at the conductor surface is proportional to the current density of the corona discharge with a negative constant of proportionality.	By comparing the measurements with the results predicted by <mask> for negative corona discharge, it is found that the electric field at the conductor surface is proportional to the current density of the corona discharge with a negative constant of proportionality.	the ion flow model	ion flow model	model	predict	model	the ion flow model	0	-2.755593198361609
2_arx_2102.07384_1423873_5	The two data-driven approaches are trained using data samples generated by the BCD algorithm via supervised learning.	The two data-driven approaches are trained using data samples generated by <mask> via supervised learning.	the BCD algorithm	BCD algorithm	algorithm	generate	algorithm	the bcd algorithm	0	-1.1296472231186776
2_arx_2205.05016_1649428_3	The fuzzy trajectory data are developed based on different driving styles, which are clustered by the K-means algorithm.	The fuzzy trajectory data are developed based on different driving styles, which are clustered by <mask>.	the K-means algorithm	K-means algorithm	algorithm	cluster	algorithm	the k-means algorithm	0	-1.8418212576905084
2_acl_280_28416_2	For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed?	For example, we ask, given <mask> that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed?	the debiasing method	debiasing method	method	use	method	a debiasing method	0	-1.5055892146179062
2_acl_280_28416_2	For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed?	For example, we ask, given a debiasing method that is developed to reduce toxicity in <mask>, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed?	the debiasing method	debiasing method	method	use	LMs	lms	0	-3.1055697710050545
2_acl_280_28416_2	For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by the debiasing method is reversed, would the debiasing results also be reversed?	For example, we ask, given a debiasing method that is developed to reduce toxicity in LMs, if the definition of toxicity used by <mask> is reversed, would the debiasing results also be reversed?	the debiasing method	debiasing method	method	use	method	the debiasing method	0	-1.3670697391354505
2_acl_4_33862_8	Taken together, these findings support the idea that meaning construction is supported by a flexible form-to-meaning mapping system based on statistical regularities in the language environment that can accommodate novel lexical entries as soon as they are encountered.	Taken together, these findings support the idea that meaning construction is supported by <mask> based on statistical regularities in the language environment that can accommodate novel lexical entries as soon as they are encountered.	a flexible form-to-meaning mapping system	form-to-meaning mapping system	system	support	system	a flexible form-to-meaning mapping system	0	-5.472453462236306
2_acl_6_42908_8	We find that synthetic data generated by LLMs is a promising avenue of research, but further research is needed to improve the quality of the generated data and develop better filtering methods.	We find that synthetic data generated by <mask> is a promising avenue of research, but further research is needed to improve the quality of the generated data and develop better filtering methods.	LLMs	LLMs	LLM	generate	LLMs	llms	0	-1.4302519342828433
2_arx_1901.05719_1075266_4	Specifically, we propose a constructor-evaluator framework, in which the code constructor is realized by AI algorithms and the code evaluator provides code performance metric measurements.	Specifically, we propose a constructor-evaluator framework, in which the code constructor is realized by <mask> and the code evaluator provides code performance metric measurements.	AI algorithms	AI algorithms	algorithm	realize	AI	ai algorithms	0	-2.6039497855252325
2_arx_1902.02508_1083592_0	The equations for LES are formally derived by low-pass filtering the NS equations with the effect of the small scales on the larger ones captured by a SGS model.	The equations for LES are formally derived by low-pass filtering the NS equations with the effect of the small scales on the larger ones captured by <mask>.	a SGS model	SGS model	model	capture	model	a sgs model	0	-2.861043484692665
2_arx_2002.05702_1243125_4	CNR is trained with data created by a generative model of synthetic structures which is used in combination with Simulated and Unsupervised Generative Adversarial Network (SimGAN) to create simulated and refined airways and vessels with known ground-truth.	CNR is trained with data created by <mask> of synthetic structures which is used in combination with Simulated and Unsupervised Generative Adversarial Network (SimGAN) to create simulated and refined airways and vessels with known ground-truth.	a generative model of synthetic structures	generative model	model	create	model	a generative model	0	-3.7015701929992777
2_arx_2009.12437_1353940_2	Ultimately, our results from comparisons of LVM segmentation predicted by a model locally trained using random initialization, versus one training-enhanced by TL, showed that a use-case model initiated by TL can be developed with sparse labels with acceptable performance.	Ultimately, our results from comparisons of LVM segmentation predicted by <mask> locally trained using random initialization, versus one training-enhanced by TL, showed that a use-case model initiated by TL can be developed with sparse labels with acceptable performance.	a model	model	model	predict	model	a model	0	-3.2850578293224313
2_arx_2009.12437_1353940_2	Ultimately, our results from comparisons of LVM segmentation predicted by a model locally trained using random initialization, versus one training-enhanced by TL, showed that a use-case model initiated by TL can be developed with sparse labels with acceptable performance.	Ultimately, our results from comparisons of LVM segmentation predicted by a model locally trained using random initialization, versus one training-enhanced by TL, showed that <mask> initiated by TL can be developed with sparse labels with acceptable performance.	a model	model	model	predict	model	a use-case model	0	-5.086350951526791
2_arx_2106.02498_1480262_5	Specifically we will overview the criteria that should be met by an AI system before coming into official service and the conformity assessment procedures useful to monitor its functioning for fair decisions.	Specifically we will overview the criteria that should be met by <mask> before coming into official service and the conformity assessment procedures useful to monitor its functioning for fair decisions.	an AI system	AI system	system	meet criteria	system	an ai system	0	-3.5571141475054446
2_arx_2106.02498_1480262_5	Specifically we will overview the criteria that should be met by an AI system before coming into official service and the conformity assessment procedures useful to monitor its functioning for fair decisions.	Specifically we will overview the criteria that should be met by <mask> before coming into official service and the conformity assessment procedures useful to monitor its functioning for fair decisions.	an AI system	AI system	system	meet criteria	AI	an ai system	0	-3.5571141475054446
2_arx_1212.5593_395209_0	Considering the natural ventilation, the thermal behavior of buildings can be described by a linear time varying model.	Considering the natural ventilation, the thermal behavior of buildings can be described by <mask>.	a linear time varying model	linear time varying model	model	describe	model	a linear time varying model	0	-1.9885820006547783
2_arx_1401.5941_495172_4	Then, a multilayer perceptron is trained by a backpropagation algorithm (MLP-BP) on a data subset, and used to classify the transients as glitch or burst.	Then, a multilayer perceptron is trained by <mask> (MLP-BP) on a data subset, and used to classify the transients as glitch or burst.	a backpropagation algorithm (MLP-BP)	backpropagation algorithm (MLP-BP)	algorithm	train	algorithm	a backpropagation algorithm	0	-3.5447560075632527
2_arx_1408.5886_551192_2	Both the emitted power and its angular pattern are well described by a model, where microwave photons are generated via bremsstrahlung in the free-electron atomic-nucleus collisions, during the slowdown of the electrons.	Both the emitted power and its angular pattern are well described by <mask>, where microwave photons are generated via bremsstrahlung in the free-electron atomic-nucleus collisions, during the slowdown of the electrons.	a model	model	model	describe	model	a model	0	-1.5506686940386416
2_arx_1501.07576_594324_2	In this study, UAV dynamics are described by a three-dimensional dynamic point-mass model.	In this study, UAV dynamics are described by <mask>.	a three-dimensional dynamic point-mass model	three-dimensional dynamic point-mass model	model	describe	model	a three-dimensional dynamic point-mass model	0	-0.3489078737803837
2_arx_1610.02937_778284_8	The synthetic PM10 record predicted by the model was found to correlate with the PM10 observations with a correlation coefficient close to 0.80 with a confidence greater than 99%.	The synthetic PM10 record predicted by <mask> was found to correlate with the PM10 observations with a correlation coefficient close to 0.80 with a confidence greater than 99%.	the model	model	model	predict	model	the model	0	-1.3468936488945342
2_arx_2304.11116_1829162_4	Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools.	Inspired by <mask>, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools.	the latest ChatGPT and Toolformer models	ChatGPT and Toolformer models	model	inspire	ChatGPT	the latest chatgpt and toolformer models	0	-3.0934439159489973
2_arx_2304.11116_1829162_4	Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools.	Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach <mask> themselves with prompts augmented by ChatGPT to use external graph reasoning API tools.	the latest ChatGPT and Toolformer models	ChatGPT and Toolformer models	model	inspire	LLMs	llms	0	-4.570551328696528
2_arx_2304.11116_1829162_4	Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools.	Inspired by the latest <mask> and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by <mask> to use external graph reasoning API tools.	the latest ChatGPT and Toolformer models	ChatGPT and Toolformer models	model	inspire	ChatGPT	chatgpt	0	-1.303555232818134
2_arx_2110.14419_1552562_1	Drawing upon the political philosophy of John Rawls, it holds that the basic structure of society should be understood as a composite of socio-technical systems, and that the operation of these systems is increasingly shaped and influenced by AI.	Drawing upon the political philosophy of John Rawls, it holds that the basic structure of society should be understood as a composite of socio-technical systems, and that the operation of these systems is increasingly shaped and influenced by <mask>.	AI	AI	AI	shape,influence	AI	ai	0	-6.510020891665961
2_arx_2207.00691_1676589_8	The results indicate that biases equating American identity with being White are learned by language-and-image AI, and propagate to downstream applications of such models.	The results indicate that biases equating American identity with being White are learned by <mask>, and propagate to downstream applications of such models.	language-and-image AI	AI	AI	learn	AI	language-and-image ai	0	-3.632870692169483
2_arx_1812.01714_1059288_3	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.	Through examining the weights in <mask>, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.	our model	model	model	learn	model	the trained dcnn model	0	-1.4918103939578788
2_arx_1812.01714_1059288_3	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by <mask>.	our model	model	model	learn	model	our model	0	-2.850064120652183
2_arx_2412.12865_2215243_5	This preference encourages the target model to predict a higher likelihood than that predicted by the aligned LLMs, incorporating assessment information on data quality (i.e., predicted likelihood by the aligned LLMs) into the training process.	This preference encourages <mask> to predict a higher likelihood than that predicted by the aligned LLMs, incorporating assessment information on data quality (i.e., predicted likelihood by the aligned LLMs) into the training process.	the aligned LLMs	aligned LLMs	LLM	predict	model	the target model	0	-2.733427746323139
2_arx_2412.12865_2215243_5	This preference encourages the target model to predict a higher likelihood than that predicted by the aligned LLMs, incorporating assessment information on data quality (i.e., predicted likelihood by the aligned LLMs) into the training process.	This preference encourages the target model to predict a higher likelihood than that predicted by <mask>, incorporating assessment information on data quality (i.e., predicted likelihood by <mask>) into the training process.	the aligned LLMs	aligned LLMs	LLM	predict	LLMs	the aligned llms	0	-4.79601857749353
2_arx_2412.12865_2215243_5	This preference encourages the target model to predict a higher likelihood than that predicted by the aligned LLMs, incorporating assessment information on data quality (i.e., predicted likelihood by the aligned LLMs) into the training process.	This preference encourages the target model to predict a higher likelihood than that predicted by <mask>, incorporating assessment information on data quality (i.e., predicted likelihood by <mask>) into the training process.	the aligned LLMs	aligned LLMs	LLM	predict	LLMs	the aligned llms	0	-4.79601857749353
2_acl_19_45086_1	Therefore, determining whether a text was generated by an LLM has become one of the factors that must be considered when evaluating its reliability.	Therefore, determining whether a text was generated by <mask> has become one of the factors that must be considered when evaluating its reliability.	an LLM	LLM	LLM	generate	LLM	an llm	0	-2.1390517862206018
2_arx_0906.5497_132048_3	We find that the observed behaviour is explained by a model including the effects associated with the variations of pressure and density.	We find that the observed behaviour is explained by <mask> including the effects associated with the variations of pressure and density.	a model	model	model	explain	model	a model	0	-3.162676908909006
2_arx_2002.10965_1248388_3	For the sake of simplicity, a simple single-cell scenario is considered, where the optimization of the BS and IRS phase shifts is solved by a low-complexity trellis-based algorithm.	For the sake of simplicity, a simple single-cell scenario is considered, where the optimization of the BS and IRS phase shifts is solved by <mask>.	a low-complexity trellis-based algorithm	low-complexity trellis-based algorithm	algorithm	solve	algorithm	a low-complexity trellis-based algorithm	0	-2.046626582119904
2_acl_750_35597_0	We present a large-scale study of linguistic bias exhibited by ChatGPT covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-”standard” varieties from around the world).	We present a large-scale study of linguistic bias exhibited by <mask> covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-”standard” varieties from around the world).	ChatGPT	ChatGPT	ChatGPT	exhibit bias	ChatGPT	chatgpt	0	-1.5870489439494977
2_acl_502_20526_4	We find that 4 pretrained transformers LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.	We find that <mask> obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.	the LM	LM	LM	learn	LMs	4 pretrained transformers lms	0	-2.6307933444268308
2_acl_502_20526_4	We find that 4 pretrained transformers LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.	We find that 4 pretrained transformers LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by <mask>.	the LM	LM	LM	learn	LM	the lm	0	-3.556823836460662
2_arx_2105.13818_1476377_2	By applying our experimental pipeline to LMs trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models.	By applying our experimental pipeline to <mask> trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models.	these models	models	model	acquire	LMs	lms	0	-2.5538009835619526
2_acl_46_41679_2	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.	However, these improvements can be attributed to the use of <mask>, which is typically trained on large amounts of parallel data not seen by the language model.	the language model	language model	model	see	system	a separate translation system	0	-4.099684310759434
2_acl_46_41679_2	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by <mask>.	the language model	language model	model	see	model	the language model	0	-3.0312065596318067
3_arx_1712.09783_928382_2	In order to train the MoE model efficiently, a matrix factorization method is applied, by extending each weight matrix of the RNN to be an ensemble of topic-dependent weight matrices.	In order to train <mask> efficiently, a matrix factorization method is applied, by extending each weight matrix of the RNN to be an ensemble of topic-dependent weight matrices.	the MoE model	MoE model	model	train	model	the moe model	0	-2.714345577840973
3_arx_1712.09783_928382_2	In order to train the MoE model efficiently, a matrix factorization method is applied, by extending each weight matrix of the RNN to be an ensemble of topic-dependent weight matrices.	In order to train the MoE model efficiently, <mask> is applied, by extending each weight matrix of the RNN to be an ensemble of topic-dependent weight matrices.	the MoE model	MoE model	model	train	method	a matrix factorization method	0	-2.891715183463731
3_acl_6_25720_4	We believe the discussions would provide a broader perspective of looking at LLMs through a sociotechnical lens and our recommendations could serve as baselines to effectively demarcate responsibilities among the various technical and social stakeholders and inspire future LLM research.	We believe the discussions would provide a broader perspective of looking at <mask> through a sociotechnical lens and our recommendations could serve as baselines to effectively demarcate responsibilities among the various technical and social stakeholders and inspire future LLM research.	LLMs	LLMs	LLM	look at	LLMs	llms	0	-6.403759683778013
3_acl_6_25720_4	We believe the discussions would provide a broader perspective of looking at LLMs through a sociotechnical lens and our recommendations could serve as baselines to effectively demarcate responsibilities among the various technical and social stakeholders and inspire future LLM research.	We believe the discussions would provide a broader perspective of looking at LLMs through a sociotechnical lens and our recommendations could serve as baselines to effectively demarcate responsibilities among the various technical and social stakeholders and inspire <mask>.	LLMs	LLMs	LLM	look at	LLM	future llm research	0	-3.0894062249273233
3_arx_2101.04617_1408359_3	We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train a named entity recognition model, and employ the trained model to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers.	We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train <mask>, and employ the trained model to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers.	the trained model	model	model	employ	model	a named entity recognition model	0	-2.7925817690248476
3_arx_2101.04617_1408359_3	We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train a named entity recognition model, and employ the trained model to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers.	We engage non-expert humans to create a corpus of labeled text, use this labeled corpus to train a named entity recognition model, and employ <mask> to extract 10912 drug-like molecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of 198875 papers.	the trained model	model	model	employ	model	the trained model	0	-7.800319512551587
3_arx_2101.05967_1409709_1	Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	Many companies that deploy <mask> that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	AI	AI	AI	deploy	AI	ai publicly state	0	-1.905352847728475
3_arx_2101.05967_1409709_1	Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	Many companies that deploy AI publicly state that when training <mask>, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	AI	AI	AI	deploy	model	a model	0	-5.78133950856879
3_arx_2101.05967_1409709_1	Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that <mask> does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more.	AI	AI	AI	deploy	model	the model	0	-6.814536049308419
3_acl_118_9850_4	We first pre-train our model on a huge artificially generated QE dataset, and then we fine-tune the model with a human-labeled dataset.	We first pre-train <mask> on a huge artificially generated QE dataset, and then we fine-tune the model with a human-labeled dataset.	the model	model	model	fine-tune	model	our model	0	-1.2401288052527288
3_acl_118_9850_4	We first pre-train our model on a huge artificially generated QE dataset, and then we fine-tune the model with a human-labeled dataset.	We first pre-train our model on a huge artificially generated QE dataset, and then we fine-tune <mask> with a human-labeled dataset.	the model	model	model	fine-tune	model	the model	0	-3.611246093382805
3_acl_3_2185_5	We evaluated the RBM-based language model on the German to English and English to French translation task of TED lectures.	We evaluated <mask> on the German to English and English to French translation task of TED lectures.	the RBM-based language model	RBM-based language model	model	evaluate	model	the rbm-based language model	0	-3.1537055251530415
3_arx_1911.03597_1202191_5	Moreover, since our model shares the same architecture as GPT (Radford et al., 2018), we are able to pre-train the model on large-scale unparallel corpus, which further improves the fluency of the output sentences.	Moreover, since <mask> shares the same architecture as GPT (Radford et al., 2018), we are able to pre-train the model on large-scale unparallel corpus, which further improves the fluency of the output sentences.	the model	model	model	pre-train	model	our model	0	-3.1252643247281515
3_arx_1911.03597_1202191_5	Moreover, since our model shares the same architecture as GPT (Radford et al., 2018), we are able to pre-train the model on large-scale unparallel corpus, which further improves the fluency of the output sentences.	Moreover, since our model shares the same architecture as GPT (Radford et al., 2018), we are able to pre-train <mask> on large-scale unparallel corpus, which further improves the fluency of the output sentences.	the model	model	model	pre-train	model	the model	0	-3.68158444959815
3_acl_329_43922_3	We ask whether structural information can be extracted from LLM’s and develop a model that integrates it with their learnt statistics.	We ask whether structural information can be extracted from <mask>’s and develop a model that integrates it with their learnt statistics.	a model	model	model	develop	LLM	llm	0	0.1475758917540588
3_acl_329_43922_3	We ask whether structural information can be extracted from LLM’s and develop a model that integrates it with their learnt statistics.	We ask whether structural information can be extracted from LLM’s and develop <mask> that integrates it with their learnt statistics.	a model	model	model	develop	model	a model	0	-4.670134986687687
3_arx_2302.07257_1792191_6	The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems.	The goal is to merge the strengths of <mask> and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems.	a more user-friendly and understandable system	system	system	create	LLMs	llms' medical domain knowledge	0	-1.969302355578769
3_arx_2302.07257_1792191_6	The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems.	The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create <mask> for patients compared to conventional CAD systems.	a more user-friendly and understandable system	system	system	create	system	a more user-friendly and understandable system	0	-3.489037808442948
3_arx_301_32463_8	Finally, we systematically evaluate and analyze eight mainstream LLMs and demonstrate the superior breadth and challenges of CodeScope for evaluating LLMs on code understanding and generation tasks compared to other benchmarks.	Finally, we systematically evaluate and analyze <mask> and demonstrate the superior breadth and challenges of CodeScope for evaluating LLMs on code understanding and generation tasks compared to other benchmarks.	eight mainstream LLMs	LLMs	LLM	evaluate,analyze	LLMs	eight mainstream llms	0	-3.0713037405464547
3_arx_301_32463_8	Finally, we systematically evaluate and analyze eight mainstream LLMs and demonstrate the superior breadth and challenges of CodeScope for evaluating LLMs on code understanding and generation tasks compared to other benchmarks.	Finally, we systematically evaluate and analyze eight mainstream <mask> and demonstrate the superior breadth and challenges of CodeScope for evaluating <mask> on code understanding and generation tasks compared to other benchmarks.	eight mainstream LLMs	LLMs	LLM	evaluate,analyze	LLMs	llms	0	-1.2930008864055171
3_acl_5_42629_6	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	We evaluate <mask>, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	recent multilingual LLMs	multilingual LLMs	LLM	evaluate	LLMs	recent multilingual llms	0	-2.417867848485983
3_acl_5_42629_6	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	We evaluate recent multilingual LLMs, including <mask>, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	recent multilingual LLMs	multilingual LLMs	LLM	evaluate	GPT-4	gpt-4	0	-0.9981617339986552
3_acl_5_42629_6	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, <mask>, and Turkcell-LLM, using this dataset.	recent multilingual LLMs	multilingual LLMs	LLM	evaluate	LLM	trendyol-llm	0	-0.4305306527538182
3_acl_5_42629_6	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and Turkcell-LLM, using this dataset.	We evaluate recent multilingual LLMs, including GPT-4, GPT-3.5, Cohere-AYA, Trendyol-LLM, and <mask>, using this dataset.	recent multilingual LLMs	multilingual LLMs	LLM	evaluate	LLM	turkcell-llm	0	-0.7134289114887373
3_acl_28_45074_3	We design a system using these pre-trained models to answer questions, based on the given context.	We design <mask> using these pre-trained models to answer questions, based on the given context.	a system	system	system	design	system	a system	0	-4.611908755282867
3_acl_41_45371_2	Unlike traditional methods that often simplify multi-agent interactions using a single opponent model, EMO constructs an individual model for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework.	Unlike traditional methods that often simplify multi-agent interactions using <mask>, EMO constructs an individual model for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework.	an individual model	model	model	construct	model	a single opponent model	0	-4.001578518500848
3_acl_41_45371_2	Unlike traditional methods that often simplify multi-agent interactions using a single opponent model, EMO constructs an individual model for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework.	Unlike traditional methods that often simplify multi-agent interactions using a single opponent model, EMO constructs <mask> for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework.	an individual model	model	model	construct	model	an individual model	0	-3.5920372365990403
3_acl_104_45430_3	We also develop a search algorithm that builds off this performance to tackle the problem of solving full crossword grids with out-of-the-box LLMs for the very first time, achieving an accuracy of 93% on New York Times crossword puzzles.	We also develop <mask> that builds off this performance to tackle the problem of solving full crossword grids with out-of-the-box LLMs for the very first time, achieving an accuracy of 93% on New York Times crossword puzzles.	a search algorithm	search algorithm	algorithm	develop	algorithm	a search algorithm	0	-3.5515157144793186
3_acl_6_46417_4	Using this approach, we train and present a BERT-based model trained on a biomedical corpus that matches or surpasses traditionally trained biomedical language models in performance across several downstream classification tasks while incurring up to 11 times lower training costs.	Using this approach, we train and present <mask> trained on a biomedical corpus that matches or surpasses traditionally trained biomedical language models in performance across several downstream classification tasks while incurring up to 11 times lower training costs.	a BERT-based model	BERT-based model	model	train,present	model	a bert-based model	0	-2.6873171955283226
3_acl_7_60414_2	In evaluations of ranking character predictions, training recurrent LMs on noisy text makes them much more robust to noisy histories, even when the error model is misspecified.	In evaluations of ranking character predictions, training <mask> on noisy text makes them much more robust to noisy histories, even when the error model is misspecified.	recurrent LMs	recurrent LMs	LM	train	LMs	recurrent lms	0	-3.7726164086546383
3_acl_7_60414_2	In evaluations of ranking character predictions, training recurrent LMs on noisy text makes them much more robust to noisy histories, even when the error model is misspecified.	In evaluations of ranking character predictions, training recurrent LMs on noisy text makes them much more robust to noisy histories, even when <mask> is misspecified.	recurrent LMs	recurrent LMs	LM	train	model	the error model	0	-4.274815347063555
3_arx_1910.06294_1190213_4	In this work-in-progress we combined the effectiveness of transfer learning provided by pre-trained masked language models with a semi-supervised approach to train a fast and compact model using labeled and unlabeled examples.	In this work-in-progress we combined the effectiveness of transfer learning provided by pre-trained masked language models with a semi-supervised approach to train <mask> using labeled and unlabeled examples.	a fast and compact model	model	model	train	model	a fast and compact model	0	-4.415946561299641
3_acl_1_7090_2	Thus, it is important to leverage memorized knowledge in the external LM for building the seq2seq model, since it is hard to prepare a large amount of paired data.	Thus, it is important to leverage memorized knowledge in <mask> for building the seq2seq model, since it is hard to prepare a large amount of paired data.	the seq2seq model	seq2seq model	model	build	LM	the external lm	0	-3.532173878743283
3_acl_1_7090_2	Thus, it is important to leverage memorized knowledge in the external LM for building the seq2seq model, since it is hard to prepare a large amount of paired data.	Thus, it is important to leverage memorized knowledge in the external LM for building <mask>, since it is hard to prepare a large amount of paired data.	the seq2seq model	seq2seq model	model	build	model	the seq2seq model	0	-4.46467250447135
3_acl_928_27649_2	Using the TREC Misinformation dataset, we empirically evaluate ChatGPT to show not just its effectiveness but reveal that knowledge passed in the prompt can bias the model to the detriment of answer correctness.	Using the TREC Misinformation dataset, we empirically evaluate <mask> to show not just its effectiveness but reveal that knowledge passed in the prompt can bias the model to the detriment of answer correctness.	ChatGPT	ChatGPT	ChatGPT	evaluate	ChatGPT	chatgpt	0	-6.432698175227811
3_acl_928_27649_2	Using the TREC Misinformation dataset, we empirically evaluate ChatGPT to show not just its effectiveness but reveal that knowledge passed in the prompt can bias the model to the detriment of answer correctness.	Using the TREC Misinformation dataset, we empirically evaluate ChatGPT to show not just its effectiveness but reveal that knowledge passed in the prompt can bias <mask> to the detriment of answer correctness.	ChatGPT	ChatGPT	ChatGPT	evaluate	model	the model	0	-3.1748777929832066
3_acl_582_29618_3	In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories.	In the present work, we develop <mask> with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories.	a recurrent neural language model	recurrent neural language model	model	develop	model	a recurrent neural language model	0	-2.5070021841578587
3_acl_582_29618_3	In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories.	In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels <mask> assumed by cognitive theories.	a recurrent neural language model	recurrent neural language model	model	develop	system	the memory system	0	-4.634638109919273
3_acl_418_44990_5	These findings highlight the challenges of developing AI for mental health counseling, particularly in competencies requiring empathy and nuanced reasoning.	These findings highlight the challenges of developing <mask> for mental health counseling, particularly in competencies requiring empathy and nuanced reasoning.	AI	AI	AI	develop	AI	ai	0	-1.7456001694636534
3_acl_45_45963_3	Our approach employs a pool of candidate VPs and trains a router model to dynamically select the most effective VP for a given input image.	Our approach employs a pool of candidate VPs and trains <mask> to dynamically select the most effective VP for a given input image.	a router model	router model	model	train	model	a router model	0	-5.397529616836936
3_arx_2308.00624_1888516_6	We have gathered a substantial amount of Chinese corpus to train the model and have also optimized its structure.	We have gathered a substantial amount of Chinese corpus to train <mask> and have also optimized its structure.	the model	model	model	train	model	the model	0	-2.3312499900943884
2_acl_75_14800_1	However, existing studies into language modelling with BERT have been mostly limited to English-language material and do not pay enough attention to the implicit knowledge of language, such as semantic roles, presupposition and negations, that can be acquired by the model during training.	However, existing studies into language modelling with BERT have been mostly limited to English-language material and do not pay enough attention to the implicit knowledge of language, such as semantic roles, presupposition and negations, that can be acquired by <mask> during training.	the model	model	model	acquire	model	the model	0	-1.3914197682256706
2_acl_98_33764_7	Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency.	Human raters were asked to rate the explanation of the implicatures generated by <mask> on their reasonability, logic and fluency.	LLMs	LLMs	LLM	generate	LLMs	llms	0	-2.202761036017135
2_acl_1_42012_5	We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths.	We posit that multiple solutions to a reasoning task, generated by <mask>, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths.	an LLM	LLM	LLM	generate	LLM	an llm	0	-4.315902723842822
2_acl_600_45881_2	In this paper, we introduce a new multilingual parallel dataset SHADES to help address this issue, designed for examining culturally-specific stereotypes that may be learned by LLMs.	In this paper, we introduce a new multilingual parallel dataset SHADES to help address this issue, designed for examining culturally-specific stereotypes that may be learned by <mask>.	LLMs	LLMs	LLM	learn	LLMs	llms	0	-2.8671448652703013
3_arx_2306.02920_1856068_2	Specifically, we trained bilingual LMs with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives.	Specifically, we trained <mask> with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives.	bilingual LMs	bilingual LMs	LM	train	LMs	bilingual lms	0	-1.6407584857544073
