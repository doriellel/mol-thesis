2_acl_119_34984_3	However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge.	However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by <mask> may vary depending on the possessed knowledge.	the LLMs	LLMs	LLM	perceive	LLMs	the llms	1	-2.022876427760498
2_acl_738_35585_4	Since a fallacious procedure is generally considered fake and thus harmless by LLMs, it helps bypass the safeguard mechanism.	Since a fallacious procedure is generally considered fake and thus harmless by <mask>, it helps bypass the safeguard mechanism.	LLMs	LLMs	LLM	consider	LLMs	llms	1	0.31565945901567
2_acl_304_37076_3	However their explicitly mention of malicious intent will be easily recognized and defended by LLMs.	However their explicitly mention of malicious intent will be easily recognized and defended by <mask>.	LLMs	LLMs	LLM	recognize,defend	LLMs	llms	1	-0.758075692088509
2_acl_305_37077_7	This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals.	This conclusion is supported by detailed evaluations conducted by <mask> and medical professionals.	GPT-4	GPT-4	GPT-4	conduct	GPT-4	both gpt-4	1	1.273314730271121
2_acl_687_35537_5	However, this ability is inconsistent: with a minimal reformulation of the task, some LMs were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computational principles of semantic property inference are yet to be mastered by LMs.	However, this ability is inconsistent: with a minimal reformulation of the task, some <mask> were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computational principles of semantic property inference are yet to be mastered by <mask>.	LMs	LMs	LM	master	LMs	lms	1	-4.687341374343077
2_arx_1811.00189_1044822_2	A remarkable feature of RAE is that the image can be correctly recognized and used by the AI model specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.	A remarkable feature of RAE is that the image can be correctly recognized and used by <mask> specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.	the AI model	AI model	model	recognize,use	model	the ai model	1	-3.0461278887702186
2_arx_1811.00189_1044822_2	A remarkable feature of RAE is that the image can be correctly recognized and used by the AI model specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.	A remarkable feature of RAE is that the image can be correctly recognized and used by <mask> specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.	the AI model	AI model	model	recognize,use	AI	the ai model	1	-3.0461278887702186
2_arx_2204.03332_1633470_10	We also demonstrate, that the considered system possesses a counter-intuitive relationship between workload and performance, which nevertheless is correctly inferred by the proposed simulation model.	We also demonstrate, that the considered system possesses a counter-intuitive relationship between workload and performance, which nevertheless is correctly inferred by <mask>.	the proposed simulation model	simulation model	model	infer	model	the proposed simulation model	1	-4.212134660187907
2_arx_1811.00189_1044822_0	In this study, we propose a new methodology to control how user's data is recognized and used by AI via exploiting the properties of adversarial examples.	In this study, we propose a new methodology to control how user's data is recognized and used by <mask> via exploiting the properties of adversarial examples.	AI	AI	AI	recognize,use	AI	ai	1	-1.5242806961824709
2_arx_1910.04404_1188323_0	Explanation is necessary for humans to understand and accept decisions made by an AI system when the system's goal is known.	Explanation is necessary for humans to understand and accept decisions made by <mask> when the system's goal is known.	an AI system	AI system	system	make a decision	system	an ai system	1	-5.252174003865694
2_arx_2012.08285_1396163_1	The goal of this article is to paint a vision of a new air interface which is partially designed by AI to enable optimized communication schemes for any hardware, radio environment, and application.	The goal of this article is to paint a vision of a new air interface which is partially designed by <mask> to enable optimized communication schemes for any hardware, radio environment, and application.	AI	AI	AI	design	AI	ai	1	-1.3604060609391624
2_arx_2205.08123_1652535_3	Results: After the exclusion of cases not meeting the study criteria, 9579 cases were analysed by AI.	Results: After the exclusion of cases not meeting the study criteria, 9579 cases were analysed by <mask>.	AI	AI	AI	analyse	AI	ai	1	-0.7442772501225967
2_acl_10_8527_2	The former is concerned with the generation of explanations for decisions taken by AI systems, while the latter is concerned with the way explanations are given to users and received by them.	The former is concerned with the generation of explanations for decisions taken by <mask>, while the latter is concerned with the way explanations are given to users and received by them.	AI systems	AI systems	system	take a decision	AI	ai systems	1	-2.969691221807853
2_arx_2011.13169_1385917_2	The need for explainable AI does not stem only from ethical and moral grounds but also from stricter legislation around the world mandating clear and justifiable explanations of any decision taken or assisted by AI.	The need for explainable <mask> does not stem only from ethical and moral grounds but also from stricter legislation around the world mandating clear and justifiable explanations of any decision taken or assisted by <mask>.	AI	AI	AI	take a decision,assist a decision	AI	ai	1	-4.1147069023902
2_arx_1712.07473_926072_0	One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm.	One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by <mask>.	the algorithm	algorithm	algorithm	face	algorithm	the algorithm	1	-3.555863101403231
2_arx_2011.03195_1375943_6	Medical diagnosis model is responsible for human life and we need to be confident enough to treat a patient as instructed by a black-box model.	Medical diagnosis model is responsible for human life and we need to be confident enough to treat a patient as instructed by <mask>.	a black-box model	black-box model	model	instruct	model	a black-box model	1	-1.5540290246167974
2_arx_1806.10698_996338_7	In addition, we found that the triage advice recommended by the AI System was, on average, safer than that of human doctors, when compared to the ranges of acceptable triage provided by independent expert judges, with only a minimal reduction in appropriateness.	In addition, we found that the triage advice recommended by <mask> was, on average, safer than that of human doctors, when compared to the ranges of acceptable triage provided by independent expert judges, with only a minimal reduction in appropriateness.	the AI system	AI system	system	recommend	system	the ai system	1	-0.403252620955616
2_arx_1905.10083_1128519_5	However, research on edge intelligence is still in its infancy stage, and a dedicated venue for exchanging the recent advances of edge intelligence is highly desired by both the computer system and artificial intelligence communities.	However, research on edge intelligence is still in its infancy stage, and a dedicated venue for exchanging the recent advances of edge intelligence is highly desired by <mask> and artificial intelligence communities.	the computer system	computer system	system	desire	system	both the computer system	1	-3.1129063862701027
2_arx_1811.01439_1046072_2	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break.	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by <mask>, and most importantly how the system might break.	the complex system	system	system	make a decision	system	the complex system	1	-3.877460057945654
2_arx_2311.11045_1954012_4	We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model.	We seek to teach <mask> to employ different solution strategies for different tasks, potentially different from the one used by the larger model.	small LMs	small LMs	LM	teach	LMs	small lms	1	-1.5202334723425397
3_acl_569_29605_3	Using GPT4 as the editor, we find it can successfully edit trigger shortcut in samples that fool LLMs.	Using GPT4 as the editor, we find it can successfully edit trigger shortcut in samples that fool <mask>.	LLMs	LLMs	LLM	fool	LLMs	llms	1	-2.7677374790530163
3_acl_71_43638_5	Specifically, we first identify a series of action candidates that could potentially trick LLMs into providing harmful responses.	Specifically, we first identify a series of action candidates that could potentially trick <mask> into providing harmful responses.	LLMs	LLMs	LLM	trick	LLMs	llms	1	-1.5428519689920144
3_arx_40_10977_2	In a series of experiments, we evaluate the extent to which language model representations of city and country names are isomorphic to real-world geography, e.g., if you tell a language model where Paris and Berlin are, does it know the way to Rome?	In a series of experiments, we evaluate the extent to which language model representations of city and country names are isomorphic to real-world geography, e.g., if you tell <mask> where Paris and Berlin are, does it know the way to Rome?	a language model	language model	model	tell	model	a language model	1	-6.066695540559515
3_arx_2304.08366_1826412_8	Next, we summarize the interviewees' reasons why and why not they would like to collaborate with AI.	Next, we summarize the interviewees' reasons why and why not they would like to collaborate with <mask>.	AI	AI	AI	collaborate with	AI	ai	1	0.2026408115565168
3_arx_2305.07001_1840057_9	Our approach sheds light on developing more user-friendly recommender systems, in which users can freely communicate with the system and obtain more accurate recommendations via natural language instructions.	Our approach sheds light on developing more user-friendly recommender systems, in which users can freely communicate with <mask> and obtain more accurate recommendations via natural language instructions.	the system	system	system	communicate with	system	the system	1	-2.387604453853415
3_acl_358_32520_4	Our goal is to teach the LLM that “even if the sentences are identical if they are spoken in different styles, their corresponding responses might be different”.	Our goal is to teach <mask> that “even if the sentences are identical if they are spoken in different styles, their corresponding responses might be different”.	the LLM	LLM	LLM	teach	LLM	the llm	1	1.8356047646284104
3_acl_3_22073_5	First, we induce a language model to produce step-by-step rationales before outputting the answer to effectively communicate the task to the model.	First, we induce a language model to produce step-by-step rationales before outputting the answer to effectively communicate the task to <mask>.	the model	model	model	communicate to	model	the model	1	-0.7549000222702116
3_arx_2112.11668_1581444_1	Yet, it is strikingly vulnerable to adversarial examples, e.g., word substitution attacks using only synonyms can easily fool a BERT-based sentiment analysis model.	Yet, it is strikingly vulnerable to adversarial examples, e.g., word substitution attacks using only synonyms can easily fool <mask>.	a BERT-based sentiment analysis model	BERT-based sentiment analysis model	model	fool	model	a bert-based sentiment analysis model	1	-2.463260462364504
3_arx_2205.01772_1646184_6	Furthermore, it shows how it is possible to fool a biometric system through a well-known presentation attack approach in the literature called morphing.	Furthermore, it shows how it is possible to fool <mask> through a well-known presentation attack approach in the literature called morphing.	a biometric system	biometric system	system	fool	system	a biometric system	1	-0.2808802501696537
3_arx_2402.09671_2007310_0	This investigation reveals a novel exploit derived from PNG image file formats, specifically their alpha transparency layer, and its potential to fool multiple AI vision systems.	This investigation reveals a novel exploit derived from PNG image file formats, specifically their alpha transparency layer, and its potential to fool <mask>.	multiple AI vision systems	AI vision systems	system	fool	AI	multiple ai vision systems	1	-0.5235941877511916
3_arx_2308.14132_1902024_1	Such jailbreaks can trick LLMs into providing intricate instructions to a malicious user for creating explosives, orchestrating a bank heist, or facilitating the creation of offensive content.	Such jailbreaks can trick <mask> into providing intricate instructions to a malicious user for creating explosives, orchestrating a bank heist, or facilitating the creation of offensive content.	LLMs	LLMs	LLM	trick	LLMs	llms	1	1.9882542643296688
3_arx_2309.05689_1910493_2	Socratic reasoning encourages LLMs to recursively discover, solve, and integrate problems while facilitating self-evaluation and refinement.	Socratic reasoning encourages <mask> to recursively discover, solve, and integrate problems while facilitating self-evaluation and refinement.	LLMs	LLMs	LLM	encourage	LLMs	llms	1	-2.418613515109925
3_arx_2306.04707_1857855_3	We study techniques that enable learning from helpful teachers while avoiding learning from people who are trying to trick the model into unhelpful or toxic responses.	We study techniques that enable learning from helpful teachers while avoiding learning from people who are trying to trick <mask> into unhelpful or toxic responses.	the model	model	model	trick	model	the model	1	-0.3161773640519456
3_arx_2311.08147_1951114_3	However, the external information from the Internet may include counterfactual information that will confuse the model and lead to an incorrect response.	However, the external information from the Internet may include counterfactual information that will confuse <mask> and lead to an incorrect response.	the model	model	model	confuse	model	the model	1	1.1927136966663987
3_acl_602_40012_4	Based on our findings, we propose FSLI, a framework for encouraging LLMs to Forget Spurious correlations and Learn from In-context information.	Based on our findings, we propose FSLI, a framework for encouraging <mask> to Forget Spurious correlations and Learn from In-context information.	LLMs	LLMs	LLM	encourage	LLMs	llms	1	-2.3660023122401697
3_acl_292_36775_3	In this approach, a multi-round feedback-revision mechanism is utilized to encourage LLMs to actively select appropriate revision actions guided by feedback information from the environment.	In this approach, a multi-round feedback-revision mechanism is utilized to encourage <mask> to actively select appropriate revision actions guided by feedback information from the environment.	LLMs	LLMs	LLM	encourage	LLMs	llms	1	-0.9178654746634916
3_acl_773_32935_3	Specifically, we study how to persuade LLMs to jailbreak them.	Specifically, we study how to persuade <mask> to jailbreak them.	LLMs	LLMs	LLM	persuade	LLMs	llms	1	1.6340607167124546
3_acl_328_38052_5	This method inspires the LLM to perceive domain information from the source text, which then serves as a helpful hint to guide the translation process.	This method inspires <mask> to perceive domain information from the source text, which then serves as a helpful hint to guide the translation process.	the LLM	LLM	LLM	inspire	LLM	the llm	1	1.6726171225771829
3_acl_476_35330_3	Motivated by social psychology principles, we propose a novel strategy named perspective-taking prompting (PeT) that inspires LLMs to integrate diverse human perspectives and self-regulate their responses.	Motivated by social psychology principles, we propose a novel strategy named perspective-taking prompting (PeT) that inspires <mask> to integrate diverse human perspectives and self-regulate their responses.	LLMs	LLMs	LLM	inspire	LLMs	llms	1	-2.9334437226531236
3_acl_373_22509_4	Overall, our results suggest that language modeling objectives incentivize the model to implicitly learn some notion of spelling, and that explicitly teaching the model how to spell does not appear to enhance its performance on such tasks.	Overall, our results suggest that language modeling objectives incentivize <mask> to implicitly learn some notion of spelling, and that explicitly teaching <mask> how to spell does not appear to enhance its performance on such tasks.	the model	model	model	incentivize	model	the model	1	-3.675845870884265
3_acl_31_27805_5	Given a natural language question, InsightPilot collaborates with the LLM to issue a sequence of analysis actions, explore the data and generate insights.	Given a natural language question, InsightPilot collaborates with <mask> to issue a sequence of analysis actions, explore the data and generate insights.	the LLM	LLM	LLM	collaborate with	LLM	the llm	1	-2.992261345328174
3_acl_920_38624_10_2	We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.	We show that choosing the best policy to interact with <mask> can reduce cost by ~90% while giving better or comparable performance, compared to communicating with <mask> in the original LRL.	the LLM	LLM	LLM	communicate with	LLM	the llm	1	-1.2654859408462986
3_acl_774_40184_4	The framework motivates the model itself to automatically generate rationales on existing datasets.	The framework motivates <mask> itself to automatically generate rationales on existing datasets.	the model	model	model	motivate	model	the model	1	-6.090298677559852
3_acl_347_24497_6	Second, we propose a sentence-level classification loss that teaches the model to distinguish between entailment and contradiction types of sentences.	Second, we propose a sentence-level classification loss that teaches <mask> to distinguish between entailment and contradiction types of sentences.	the model	model	model	teach	model	the model	1	0.3421223080324118
3_acl_814_27535_3	In this work, we introduce Character-LLM that teach LLMs to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar, etc.	In this work, we introduce Character-LLM that teach <mask> to act as specific people such as Beethoven, Queen Cleopatra, Julius Caesar, etc.	LLMs	LLMs	LLM	teach	LLMs	llms	1	-1.5699415072817473
3_acl_114_29150_2	Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction.	Existing studies utilize trigger sentences to encourage <mask> to concentrate on the relevant information but the trigger has limited effect on final answer prediction.	LLMs	LLMs	LLM	encourage	LLMs	llms	1	-0.7517828519787031
3_arx_2306.10063_1863211_1	In this conception, learners continually converse with AI language models within a dynamic computational medium of internet tools and resources.	In this conception, learners continually converse with <mask> within a dynamic computational medium of internet tools and resources.	AI language models	AI language models	model	converse with	AI	ai language models	1	-1.9344139092236097
3_arx_2306.03856_1857004_0	We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language understanding and translation capability as well as a human-like translation approach.	We propose iteratively prompting <mask> to self-correct a translation, with inspiration from their strong language understanding and translation capability as well as a human-like translation approach.	a large language model	large language model	model	prompt	model	a large language model	1	-2.8805569580303665
3_acl_212_35072_4	Instead of attempting to answer all questions, we explore a refusal mechanism that instructs LLMs to refuse to answer challenging questions in order to avoid errors.	Instead of attempting to answer all questions, we explore a refusal mechanism that instructs <mask> to refuse to answer challenging questions in order to avoid errors.	LLMs	LLMs	LLM	instruct	LLMs	llms	1	-1.1191770098174043
3_acl_966_30002_2	We ask several LLMs and humans to write such a story and conduct a human evaluation involving various criteria such as fluency, coherence, originality, humor, and style.	We ask <mask> and humans to write such a story and conduct a human evaluation involving various criteria such as fluency, coherence, originality, humor, and style.	several LLMs	LLMs	LLM	ask	LLMs	several llms	1	-0.8144875963476892
3_acl_3_33872_4	Variations of this vignette are used for role-prompting a commercial LLM, GPT-4, instructing the LLM to take on the role described in the patient vignette and act accordingly.	Variations of this vignette are used for role-prompting a commercial LLM, GPT-4, instructing <mask> to take on the role described in the patient vignette and act accordingly.	the LLM	LLM	LLM	instruct	LLM	the llm	1	-3.605928344136217
3_acl_11_31225_2	To explore this line of research, this paper uses a case study, namely, finding the best prompting strategy for asking ChatGPT to define new words based on morphological connections.	To explore this line of research, this paper uses a case study, namely, finding the best prompting strategy for asking <mask> to define new words based on morphological connections.	ChatGPT	ChatGPT	ChatGPT	ask	ChatGPT	chatgpt	1	-0.8361888217681752
3_acl_599_29635_5	Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets.	Last, we reveal that asking <mask> to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets.	the LLM	LLM	LLM	ask	LLM	the llm	1	-3.4338760261863417
3_arx_2302.13817_1798751_5	We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.	We also ask <mask> to provide its point of view and present its responses to several questions we attempt to answer.	ChatGPT	ChatGPT	ChatGPT	ask	ChatGPT	chatgpt	1	-2.4553884804611865
3_acl_7_30789_3	We then introduce these pairs into translation prompts, instructing ChatGPT to use the correct translations of the domain entities.	We then introduce these pairs into translation prompts, instructing <mask> to use the correct translations of the domain entities.	ChatGPT	ChatGPT	ChatGPT	instruct	ChatGPT	chatgpt	1	-0.1960753990181061
3_acl_5_46527_1	Different prompts are tested to instruct the LLM to clean the text without changing the structure, vocabulary or specialized lexicon.	Different prompts are tested to instruct <mask> to clean the text without changing the structure, vocabulary or specialized lexicon.	the LLM	LLM	LLM	instruct	LLM	the llm	1	2.4312678306050426
3_acl_11_41931_7	In the second experiment, we ask the LLMs to numerically rate various aspects of the musical cultures of different countries.	In the second experiment, we ask <mask> to numerically rate various aspects of the musical cultures of different countries.	the LLMs	LLMs	LLM	ask	LLMs	the llms	1	0.2393666127933258
