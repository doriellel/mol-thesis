id,Previous Sentence,Current Sentence,Masked Sentence,Next Sentence,AI Phrase,Suggested Mask,AI Entity,Anthropomorphic Component,Target Expression,Animated
1_acl_586_6176_1,"The success of large pretrained language models (LMs) such as BERT and RoBERTa has sparked interest in probing their representations, in order to unveil what types of knowledge they implicitly capture.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent [MASK] also derive lexical type-level knowledge from words in context.","In this work, we present a systematic empirical analysis across six typologically diverse languages and five different lexical tasks, addressing the following questions: 1) How do different lexical knowledge extraction strategies (monolingual versus multilingual source LM, out-of-context versus in-context encoding, inclusion of special tokens, and layer-wise averaging) impact performance?",LMs,LMs,LM,derive knowledge,LMs,2
1_acl_5_9514_1,"BERT is a popular language model whose main pre-training task is to fill in the blank, i.e., predicting a word that was masked out of a sentence, based on the remaining words.","In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.","In some applications, however, having an additional context can help the [MASK] make the right prediction, e.g., by taking the domain or the time of writing into account.",This motivates us to advance the BERT architecture by adding a global state for conditioning on a fixed-sized context.,the model,model,model,make a prediction,model,2
1_acl_65_19388_5,Embeddings created with BERT were used together with UMAP and HDBSCAN to model the topics.,The human evaluation found that our topic model creates coherent topics.,The human evaluation found that our [MASK] creates coherent topics.,The following discussion revolves around the requirements of industry and what research is needed for production-ready systems.,our topic model,topic model,model,create,topic model,2
1_acl_22_31716_3,"Nevertheless, several recent papers provide empirical evidence that LLMs fail to capture important aspects of linguistic meaning.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that [MASK] cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","More generally, we show that LLMs are unable to learn concepts beyond the first level of the Borel Hierarchy, which imposes severe limits on the ability of LMs, both large and small, to capture many aspects of linguistic meaning.",LLMs,LLMs,LLM,learn,LLMs,2
1_acl_163_34648_5,"Secondly, we present Persona-Aware-D2S, a novel approach by finetuning LLMs using target audience feedback to create persona-aware slides from scientific documents.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our [MASK] can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.",,our model,model,model,create,model,2
1_arx_2110.10185_1548328_5,"These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models.",The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the [MASK] acts in a manner human users find suitable.,"We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control.",the generation system,generation system,system,act,generation system,2
1_arx_2212.07414_1763591_5,"Thus, we propose hierarchical over-the-air (HOTA) PFL with a dynamic weighting strategy which we call HOTA-FedGradNorm.",Our algorithm considers the channel conditions during the dynamic weight selection process.,Our [MASK] considers the channel conditions during the dynamic weight selection process.,We conduct experiments on a wireless communication system dataset (RadComDynamic).,Our algorithm,algorithm,algorithm,consider,algorithm,2
1_arx_1101.3316_238729_3,"To estimate the efficiency and the accuracy of the model, we perform a cross-validation test using the training set.",The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.,The test shows that the [MASK] correctly identifies ~80% of known QSOs with a 25% false positive rate.,The majority of the false positives are Be stars.,the model,model,model,identify,model,2
1_arx_1205.6986_345987_9,"In data from Arabidopsis thaliana and mouse, our method is able to find a genetic cause for significantly greater fractions of phenotype variation in 91% of the phenotypes considered.","At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.","At the same time, our [MASK] dissects this variability into components that result from individual SNP effects and population structure.","In addition to this increase of genetic heritability, enrichment of known candidate genes suggests that the associations retrieved by LMM-Lasso are more likely to be genuine.",our model,model,model,dissect,model,2
1_arx_2302.04335_1789269_6,Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software.,"In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","In other words, [MASK] can create content on many topics with high originality as if they were written by someone.",These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort.,ChatGPT,ChatGPT,ChatGPT,create,ChatGPT,2
1_acl_154_25214_1,A number of recent benchmarks seek to assess how well models handle natural language negation.,"However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope.","However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a [MASK] had truly learned how negation morphemes semantically scope.","To fill these analytical gaps, we present the Scoped Negation NLI (ScoNe-NLI) benchmark, which contains contrast sets of six examples with up to two negations where either zero, one, or both negative morphemes affect the NLI label.",a model,model,model,learn,model,2
1_acl_852_33014_0,We believe that DocMath-Eval can serve as a valuable benchmark for evaluating LLMs' capabilities in solving challenging numerical reasoning problems within expert domains.,Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems.,Recent [MASK] have demonstrated remarkable performance in solving exam-like math word problems.,"However, the degree to which these numerical reasoning skills are effective in real-world scenarios, particularly in expert domains, is still largely unexplored.",Recent LLMs,LLMs,LLM,demonstrate,LLMs,2
1_acl_2_34276_7,"We conduct two evaluation experiments in the Polish language scenario, using a dataset presumably unfamiliar to LLMs to mitigate the risk of data contamination.","Our results show that not all extracted utterances are correctly structured, indicating that either LLMs do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.","Our results show that not all extracted utterances are correctly structured, indicating that either [MASK] do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.",We conclude that the ability of LLMs to comprehend noisy utterances is still relatively superficial compared to human proficiency in processing them.,LLMs,LLMs,LLM,acquire,LLMs,2
1_acl_53_34920_6,An additional experiment showed that this learning is enhanced when there is more variability in the input.,"Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena.","Taken together, our results provide an existence proof that [MASK] can learn rare grammatical phenomena by generalization from less rare phenomena.",Data and code: https://github.com/kanishkamisra/aannalysis.,LMs,LMs,LM,learn,LMs,2
1_acl_24_17147_6,We also experiment with different prompt designs and temperatures of the decoding method.,"Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.","Our experiment results suggest that [MASK] has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.",We also perform error analysis to summarize some common types of mistakes that GPT-3 has made when dealing with certain semantic information.,GPT-3,GPT-3,GPT-3,"acquire,fail",GPT-3,2
1_arx_1205.3313_342314_2,SDM is a particle-based and probabilistic approach in which a Monte-Carlo type algorithm is used for solving the particle collisions and coalescence process.,"The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","The [MASK] does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","Consequently, it covers representation of such cloud-microphysical processes as: CCN activation, drizzle formation by autoconversion, accretion of cloud droplets, self-collection of raindrops and precipitation including aerosol wet deposition.",The model,model,model,differentiate,model,2
1_arx_2304.10592_1828638_0,"Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/.","The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.","The recent [MASK] has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.",These features are rarely observed in previous vision-language models.,The recent GPT-4,GPT-4,GPT-4,demonstrate abilities,GPT-4,2
1_acl_11_43395_1,"In a highly globalized world, it is important for multi-modal large language models (MLLMs) to recognize and respond correctly to mixed-cultural inputs.","For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","For example, a [MASK] should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","However, current MLLMs show an over-reliance on the visual features of the person, leading to misclassification of the entities.",a model,model,model,identify,model,2
1_arx_2304.09337_1827383_2,"However, crafting prompts that accurately capture the user's creative intent remains challenging.",It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.,It often involves laborious trial-and-error procedures to ensure that the [MASK] interprets the prompts in alignment with the user's intention.,"To address the challenges, we present Promptify, an interactive system that supports prompt exploration and refinement for text-to-image generative models.",the model,model,model,interpret,model,2
1_arx_2207.08333_1684231_3,"In this paper, we propose a quantitative metric ""Equivariance Score"" and evaluation dataset ""Human Puzzle"" to assess whether a VL model is understanding an image like a human.",We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We observed that the [MASK] does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We aim to quantitatively measure a model's performance in understanding context.,the VL model,VL model,model,interpret,VL model,2
1_acl_814_27535_1,"Large language models (LLMs) can be used to serve as agents to simulate human behaviors, given the powerful ability to understand human instructions and provide high-quality generated texts.",Such ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.,Such ability stimulates us to wonder whether [MASK] can simulate a person in a higher form than simple human behaviors.,"Therefore, we aim to train an agent with the profile, experience, and emotional states of a specific person instead of using limited prompts to instruct ChatGPT API.",LLMs,LLMs,LLM,simulate,LLMs,2
1_acl_7_34361_5,A manual analysis classified errors in the machine translation and changes made by the post-editors.,The results show that ChatGPT made more changes than the average post-editor.,The results show that [MASK] made more changes than the average post-editor.,ChatGPT improved lexical richness over machine translation for all texts.,ChatGPT,ChatGPT,ChatGPT,make changes,ChatGPT,2
1_arx_1908.02624_1160794_1,"Decades of research in artificial intelligence (AI) have produced formidable technologies that are providing immense benefit to industry, government, and society.","AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","[MASK] can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","The deployment of AI systems has not only created a trillion-dollar industry that is projected to quadruple in three years, but has also exposed the need to make AI systems fair, explainable, trustworthy, and secure.",AI systems,AI systems,system,"translate,identify,streamline,control",AI systems,2
1_arx_2304.02868_1820914_3,Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, [MASK] can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.",ChatGPT,ChatGPT,ChatGPT,"construct,fail to leverage world knowledge,infer",ChatGPT,2
1_arx_2304.02182_1820228_0,Our work provides empirical evidence that ChatGPT still has great potential in translations.,The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.,The recently released [MASK] has demonstrated surprising abilities in natural language understanding and natural language generation.,Machine translation relies heavily on the abilities of language understanding and generation.,The recently released ChatGPT,ChatGPT,ChatGPT,demonstrate surprising abilities,ChatGPT,2
1_arx_2304.02868_1820914_2,"In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world.",Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,Our experiments show that [MASK] performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",ChatGPT,ChatGPT,ChatGPT,"perform competitively,exhibit a low level of intelligence",ChatGPT,2
1_arx_2302.06100_1791034_8,"More importantly, we create simple synthetic statutes, which GPT-3 is guaranteed not to have seen during training.",We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.,We find [MASK] performs poorly at answering straightforward questions about these simple synthetic statutes.,,GPT-3,GPT-3,GPT-3,perform poorly at answering straightforward questions,GPT-3,2
1_acl_679_35529_6,"3) Chain-of-thought prompting notably reduces shortcut reliance and outperforms other prompting strategies, while few-shot prompts generally underperform compared to zero-shot prompts.","4) LLMs often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","4) [MASK] often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","5) LLMs generally have a lower explanation quality in shortcut-laden datasets, with errors falling into three types: distraction, disguised comprehension, and logical fallacy.",LLMs,LLMs,LLM,exhibit overconfidence,LLMs,2
1_arx_1904.08530_1113570_2,"Using the dataset of complete intersections in products of projective spaces (CICY3 and CICY4, totalling about a million manifolds) as a concrete playground, we find that a relatively simple neural network with forward-feeding multi-layers can very efficiently distinguish the elliptic fibrations, much more so than using the traditional methods of manipulating the defining equations.",We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure.,We cross-check with control cases to ensure that the [MASK] is not randomly guessing and is indeed identifying an inherent structure.,Our result should prove useful in F-theory and string model building as well as in pure algebraic geometry.,the AI,AI,AI,"guess,identify",AI,2
1_acl_1011_30047_1,"Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a cost-effective way to align model behaviors with human preferences.","However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses.","However, the [MASK] has only seen one response per instruction, lacking the knowledge of potentially better responses.","In this paper, we propose finetuning an instruction-tuned LLM using our novel probabilistic ranking and contextual ranking approaches to increase the likelihood of generating better responses.",the instruction-tuned model,instruction-tuned model,model,see,instruction-tuned model,2
1_arx_1905.04127_1122563_1,"In order perform a large variety of tasks and to achieve human-level performance in complex real-world environments, Artificial Intelligence (AI) Agents must be able to learn from their past experiences and gain both knowledge and an accurate representation of their environment from raw sensory inputs.","Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.","Traditionally, [MASK] have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.",Deep reinforcement learning algorithms have provided a solution to this issue.,AI agents,AI agents,agent,suffer from difficulties,AI agents,2
1_acl_78_25975_8,"To explore more generic simile knowledge from PLMs, we further add semantic dependencyfeatures in three tasks.",The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.,The semantic dependency feature serves as a global signal and helps the [MASK] learn simile knowledge that can be applied to unseen domains.,We test with seenand unseen domains after training.,the model,model,model,learn,model,2
1_arx_2303.17276_1817073_8,"Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4.","This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","This suggests that larger and more advanced [MASK] may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the ""bad"" cases could paradoxically be learned from the ""good"" cases.",larger and more advanced LLMs,LLMs,LLM,develop a tendency,LLMs,2
