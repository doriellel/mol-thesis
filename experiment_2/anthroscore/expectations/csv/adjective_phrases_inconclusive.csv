id,previous_sentence,current_sentence,masked_sentence,next_sentence,AI_phrase,masked_phrase,AI_entity,component,expectations
4_acl_7_46407_0,"In conclusion, our findings can achieve less safety risk with fewer computational costs, allowing non-safety LM to be efficiently utilized in real-world service.",Language models (LMs) are vulnerable to exploitation for adversarial misuse.,<mask> are vulnerable to exploitation for adversarial misuse.,"Training LMs for safety alignment is extensive, making it hard to respond to fast-developing attacks immediately, such as jailbreaks.",Language models (LMs),Language models (LMs),model,vulnerable,2
4_arx_2005.06620_1286415_1,Artificial intelligence (AI) enabled products and services are becoming a staple of everyday life.,"While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue.","While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent <mask> on human well-being has become a pressing issue.",This article introduces one of the first international standards focused on the social and ethical implications of AI: The Institute of Electrical and Electronics Engineering (IEEE) Standard (Std) 7010-2020 Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-being.,these autonomous and intelligent systems,systems,system,"autonomous,intelligent",2
4_arx_2408.08878_2129059_6,"We discovered prompting to be a useful but undervalued skill for knowledge engineers working with LLMs, and note that natural language processing skills may become more relevant across more roles in KG construction.",Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI.,Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible <mask>.,"Given the limited ethical training, most knowledge engineers receive solutions such as our suggested `KG cards' based on data cards could be a useful guide for KG construction.",responsible AI,AI,AI,responsible,2
4_arx_2402.05827_2003466_5,We focus on three key research questions.,RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations?,RQ1: Can edited LLMs behave consistently resembling communicative <mask> in realistic situations?,RQ2: To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory?,communicative AI,AI,AI,communicative,2
4_arx_1904.13086_1118126_10,Simply putting a human into the loop does not assure that the human will meaningfully contribute to the outcomes.,"The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.","The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent <mask>, the environment and some systematic behavioral biases.",The ResQu model is a new quantitative method that can be used in system design and can guide policy and legal decisions regarding human responsibility in events involving intelligent systems.,the intelligent system,system,system,intelligent,2
4_acl_1_30970_8,The choice of the model depends on the desired end-goal.,"Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than the SVM model.","Moreover, our error analysis shows that language <mask> are generally less sensitive to the changes in claim length and source than the SVM model.",,language models,models,model,sensitive,2
4_acl_159_43725_0,"Experimental results indicate that with the increase of model size, although the ease-of-use could be significantly improved, there is still a long way to go to build a sufficiently user-friendly model.","Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for the model.","Modern <mask> are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for the model.","Composing an optimal prompt for a specific demand lacks theoretical support and relies entirely on human experimentation, which poses a considerable obstacle to popularizing generative artificial intelligence.",Modern large language models,large language models,model,sensitive,2
4_acl_335_27056_3,We develop a typology of epistemic markers and inject 50 markers into prompts for question answering.,"We find that LMs are highly sensitive to epistemic markers in prompts, with accuracies varying more than 80%.","We find that <mask> are highly sensitive to epistemic markers in prompts, with accuracies varying more than 80%.","Surprisingly, we find that expressions of high certainty result in a 7% decrease in accuracy as compared to low certainty expressions; similarly, factive verbs hurt performance, while evidentials benefit performance.",LMs,LMs,LM,sensitive,2
4_acl_12_46472_3,"Our findings reveal low-to-moderate agreement among LLMs and humans, reflecting the complexity of the task.",Analysis shows that LLMs are sensitive to subtle contextual changes and often rely on surface-level cues.,Analysis shows that <mask> are sensitive to subtle contextual changes and often rely on surface-level cues.,"Humans, too, may interpret relationships differently, leading to disagreements in annotations.",LLMs,LLMs,LLM,sensitive,2
4_arx_2405.16310_2073522_7,Our work reveals additional types of trustors and trustees and new factors impacting their trust relationships.,"These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.","These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy <mask>.","Based on these findings, we discuss the implications for research on `trust in AI'.",untrustworthy LLMs,LLMs,LLM,untrustworthy,2
4_arx_1906.03595_1135781_6,"This paper proposes a approach to design a creative and collaborative intelligence by employing a form of distributed machine learning approach called Federated Learning along with fusion on Generative Adversarial Networks, GAN.","This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.","This collaborative creative <mask> presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.","In short, this paper explores the design of a novel type of AI paradigm, called Federated AI Imagination, one that lets geographically distributed teams to collaboratively imagine.",This collaborative creative AI,AI,AI,"collaborative,creative",2
4_acl_128_54380_3,"We discover a simple hands-on principle: in a multi-layer input embedding model, layers should be tied consecutively bottom-up if reused at output.",Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.,Our best morpheme-aware model with properly reused weights beats the competitive <mask> by a large margin across multiple languages and has 20%-87% fewer parameters.,,the competitive word-level model,word-level model,model,competitive,2
4_acl_94_36582_1,"Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services.","However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks.","However, the untrustworthy <mask> may covertly introduce vulnerabilities for downstream tasks.","In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks.",the untrustworthy third-party LLMs,third-party LLMs,LLM,untrustworthy,2
4_arx_2207.00477_1676375_2,While the airports are more likely to become hotspots for potential conflicts to break out which can cause serious delays to flights and several safety issues.,"An intelligent algorithm which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.","An intelligent <mask> which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.",This paper details the development of a machine learning model to classify conflicting behaviour in a crowd.,An intelligent algorithm,algorithm,algorithm,intelligent,2
4_acl_155_26876_9,"Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI).","Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which LLM is more vulnerable towards hallucination.","Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess and measure which <mask> is more vulnerable towards hallucination.","We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.",LLM,LLM,LLM,vulnerable,2
4_arx_2012.03087_1390965_3,"Some solutions have been proposed in computer vision to recognize food images, but few are specialized in nutritional monitoring.",This work presents the development of an intelligent system that classifies and segments food presented in images to help the automatic monitoring of user diet and nutritional intake.,This work presents the development of an intelligent <mask> that classifies and segments food presented in images to help the automatic monitoring of user diet and nutritional intake.,"This work shows a comparative study of state-of-the-art methods for image classification and segmentation, applied to food recognition.",an intelligent system,system,system,intelligent,2
4_arx_2001.07641_1233054_2,"Automatically generated explanations for decisions can increase transparency and foster trust, especially for systems based on automated predictions by AI models.","However, given, e.g., economic incentives to create dishonest AI, to what extent can we trust explanations?","However, given, e.g., economic incentives to create dishonest <mask>, to what extent can we trust explanations?","To address this issue, our work investigates how AI models (i.e., deep learning, and existing instruments to increase transparency regarding AI decisions) can be used to create and detect deceptive explanations.",dishonest AI,AI,AI,dishonest,2
4_acl_862_33024_7,"We further test their text-infilling performance, revealing the incapability of appropriate adaptation to Arab cultural contexts.","Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build culturally aware LMs, if used as they are without adjustment.","Finally, we analyze 6 Arabic pre-training corpora and find that commonly used sources such as Wikipedia may not be best suited to build culturally aware <mask>, if used as they are without adjustment.",We will make CAMeL publicly available at: https://github.com/tareknaous/camel,culturally aware LMs,LMs,LM,culturally aware,2
4_acl_45_49661_1,"In this paper, we extend Recurrent Neural Network Language Models (RNN-LMs) with an attention mechanism.",We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,We show that an “attentive” <mask> (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.,We also show that an “attentive” RNN-LM needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,"an ""attentive"" RNN-LM",RNN-LM,LM,attentive,2
4_arx_2503.22772_2287084_2,"Existing indices such as the Stanford AI Index (2024), overlooked relational, ethical, and cultural dimensions essential to human centered AI integration.","To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.","To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent <mask> into family and caregiving systems.","Using mixed-method analysis and equal weighting, the AFII provides a multidimensional tool for assessing emotional and symbolic readiness in diverse cultural contexts.",emotionally intelligent AI,AI,AI,emotionally intelligent,2
4_arx_2502.18676_2261667_3,"In this position paper, we argue that this thoughtfulness unlocks new possibilities for human-AI interaction by enabling proactive AI behavior, facilitating continuous cognitive alignment with users, and fostering more dynamic interaction experiences.","We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.","We outline the conceptual foundations of Thoughtful <mask>, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.",,Thoughtful AI,AI,AI,thoughtful,2
