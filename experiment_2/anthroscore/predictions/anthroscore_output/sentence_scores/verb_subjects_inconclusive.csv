,sentence,masked_sentence,text_id,anthroscore
0,"While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent <mask> also derive lexical type-level knowledge from words in context.",1_acl_586_6176_1,-3.7589045242168275
1,"In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.","In some applications, however, having an additional context can help the <mask> make the right prediction, e.g., by taking the domain or the time of writing into account.",1_acl_5_9514_1,-0.46915063793754896
2,The human evaluation found that our topic model creates coherent topics.,The human evaluation found that our <mask> creates coherent topics.,1_acl_65_19388_5,-1.5306848086603502
3,"Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that <mask> cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.",1_acl_22_31716_3,-2.352818953555351
4,"Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our <mask> can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.",1_acl_163_34648_5,0.07085675328189822
5,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the <mask> acts in a manner human users find suitable.,1_arx_2110.10185_1548328_5,-2.864461217242738
6,Our algorithm considers the channel conditions during the dynamic weight selection process.,Our <mask> considers the channel conditions during the dynamic weight selection process.,1_arx_2212.07414_1763591_5,-0.8948006100056638
7,The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.,The test shows that the <mask> correctly identifies ~80% of known QSOs with a 25% false positive rate.,1_arx_1101.3316_238729_3,-1.3411310527150544
8,"At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.","At the same time, our <mask> dissects this variability into components that result from individual SNP effects and population structure.",1_arx_1205.6986_345987_9,-1.194445547232771
9,"In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","In other words, <mask> can create content on many topics with high originality as if they were written by someone.",1_arx_2302.04335_1789269_6,-0.13511214458895182
10,"However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope.","However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a <mask> had truly learned how negation morphemes semantically scope.",1_acl_154_25214_1,0.14855417498872647
11,Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems.,Recent <mask> have demonstrated remarkable performance in solving exam-like math word problems.,1_acl_852_33014_0,-2.82856982074064
12,"Our results show that not all extracted utterances are correctly structured, indicating that either LLMs do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.","Our results show that not all extracted utterances are correctly structured, indicating that either <mask> do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.",1_acl_2_34276_7,-3.6614589681110346
13,"Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena.","Taken together, our results provide an existence proof that <mask> can learn rare grammatical phenomena by generalization from less rare phenomena.",1_acl_53_34920_6,-1.5592040395884261
14,"Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.","Our experiment results suggest that <mask> has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.",1_acl_24_17147_6,0.02878247121016919
15,"The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","The <mask> does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.",1_arx_1205.3313_342314_2,0.2796508708095313
16,"The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.","The recent <mask> has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.",1_arx_2304.10592_1828638_0,-0.07945163107085484
17,"For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","For example, a <mask> should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.",1_acl_11_43395_1,-1.2278112849538623
18,It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.,It often involves laborious trial-and-error procedures to ensure that the <mask> interprets the prompts in alignment with the user's intention.,1_arx_2304.09337_1827383_2,-2.379640724403398
19,We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We observed that the <mask> does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,1_arx_2207.08333_1684231_3,-1.6610361398143372
20,Such ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.,Such ability stimulates us to wonder whether <mask> can simulate a person in a higher form than simple human behaviors.,1_acl_814_27535_1,-1.4472603071430452
21,The results show that ChatGPT made more changes than the average post-editor.,The results show that <mask> made more changes than the average post-editor.,1_acl_7_34361_5,2.6375988106510952
22,"AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","<mask> can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.",1_arx_1908.02624_1160794_1,-3.5404183660045803
23,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, <mask> can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",1_arx_2304.02868_1820914_3,-4.299381528961565
24,The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.,The recently released <mask> has demonstrated surprising abilities in natural language understanding and natural language generation.,1_arx_2304.02182_1820228_0,-1.5205595455496237
25,Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,Our experiments show that <mask> performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,1_arx_2304.02868_1820914_2,-3.862445885325492
26,We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.,We find <mask> performs poorly at answering straightforward questions about these simple synthetic statutes.,1_arx_2302.06100_1791034_8,-4.162454580579665
27,"4) LLMs often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","4) <mask> often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.",1_acl_679_35529_6,-3.7924260549602167
28,We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure.,We cross-check with control cases to ensure that the <mask> is not randomly guessing and is indeed identifying an inherent structure.,1_arx_1904.08530_1113570_2,-0.4232756439728451
29,"However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses.","However, the <mask> has only seen one response per instruction, lacking the knowledge of potentially better responses.",1_acl_1011_30047_1,-0.6482142454367121
30,"Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.","Traditionally, <mask> have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.",1_arx_1905.04127_1122563_1,-4.855990749805699
31,The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.,The semantic dependency feature serves as a global signal and helps the <mask> learn simile knowledge that can be applied to unseen domains.,1_acl_78_25975_8,0.36355862947540274
32,"This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","This suggests that larger and more advanced <mask> may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.",1_arx_2303.17276_1817073_8,-4.305086929850404
