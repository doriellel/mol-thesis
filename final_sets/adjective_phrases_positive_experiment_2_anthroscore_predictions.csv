id,sentence,masked_sentence,AI_phrase,mask,component,expectation,model_score,prediction
4_acl_683_21860_6,"Next, an experiment is conducted on the dataset to examine to what extent a pretrained masked language model is aware of the constructions.","Next, an experiment is conducted on the dataset to examine to what extent a <mask> is aware of the constructions.",a pretrained masked language model,pretrained masked language model,aware,1,1.1309829384142684,1
4_acl_348_35206_2,A desired characteristic of an intelligent system is its ability to recognize the scope of its own knowledge.,A desired characteristic of an intelligent <mask> is its ability to recognize the scope of its own knowledge.,an intelligent system,system,intelligent,1,-1.77167582931693,0
4_acl_3_45070_1,LLMs are intelligent and slowly replacing the search engines.,<mask> are intelligent and slowly replacing the search engines.,LLMs,LLMs,intelligent,1,-4.247897999156674,0
4_acl_396_37165_1,"However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves?","However, a critical question emerges: Are <mask> conscious of the existence of these decoding strategies and capable of regulating themselves?",LLMs,LLMs,conscious,1,-3.800791003376144,0
4_acl_590_28726_3,"In this way, the captioning model can become aware of the task goal and information need from the PLM.","In this way, the <mask> can become aware of the task goal and information need from the PLM.",the captioning model,captioning model,aware,1,1.5592239844718971,1
4_acl_818_37575_1,"In practical use, users might provide feedback based on the model’s output, hoping for a responsive model that can complete responses according to their feedback.","In practical use, users might provide feedback based on the model’s output, hoping for a responsive <mask> that can complete responses according to their feedback.",a responsive model,model,responsive,1,-0.1183662129563956,2
4_acl_633_48859_2,"This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about.","This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the <mask> is least confident about.",the model,model,confident,1,-1.877263248345475,0
4_acl_243_44794_7,"In addition, we found that the model becomes more confident and refuses to provide an answer in only few cases.","In addition, we found that the <mask> becomes more confident and refuses to provide an answer in only few cases.",the model,model,confident,1,1.9058323264346235,1
4_acl_276_39685_3,(2) Is ChatGPT aware of the underlying commonsense knowledge for answering a specific question?,(2) Is <mask> aware of the underlying commonsense knowledge for answering a specific question?,ChatGPT,ChatGPT,aware,1,2.981358761856395,1
4_acl_117_37846_1,"However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not.","However, when LLMs face different types of questions, it is worth exploring whether <mask> are aware that some questions have limited answers and need to respond more deterministically but some do not.",LLMs,LLMs,aware,1,-1.5960699130825482,0
4_acl_450_41596_3,"The goal is to cultivate culturally cognizant and value-aligned Arabic LLMs capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.","The goal is to cultivate culturally cognizant and value-aligned <mask> capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.",culturally cognizant and value-aligned Arabic LLMs,Arabic LLMs,"culturally cognizant,value-aligned",1,-0.41023079526334527,2
4_acl_45_49661_2,We also show that an “attentive” RNN-LM needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,We also show that an “attentive” <mask> needs less contextual information to achieve similar results to the state-of-the-art on the wikitext2 dataset.,"an ""attentive"" RNN-LM",RNN-LM,attentive,1,0.3541913627928004,2
4_arx_2311.04177_1947144_0,Large Language Models (LLMs) are smart but forgetful.,<mask> are smart but forgetful.,Large Language Models (LLMs),Large Language Models (LLMs),"smart,forgetful",1,1.0430083150485583,1
4_arx_1511.03246_676426_3,"In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.","In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious <mask>.",malicious AI,AI,malicious,1,-0.7124931913891803,2
4_arx_2005.13635_1293430_5,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.,Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious <mask>.,malicious AI,AI,malicious,1,-3.2756794427833924,0
4_arx_2504.03726_2292429_5_1,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious <mask> as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.",malicious AI Assistants,AI Assistants,malicious,1,-2.63574839135096,0
4_arx_2504.03726_2292429_5_2,"In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.","In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative <mask>.",potentially manipulative systems,systems,manipulative,1,-3.141257382524998,0
4_arx_2305.02626_1835682_10,"We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.","We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious <mask>.",ethically conscious LLMs,LLMs,ethically conscious,1,-2.5168165760470096,0
4_arx_2401.10727_1990281_4,"Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.","Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the <mask> can be conscious of multi-modal input instruction and then select the function-matched tool correctly.",the learned LLMs,learned LLMs,conscious,1,-0.5245043119428843,2
4_arx_1301.6359_402949_3,We consider a number of issues related to the development of the set of patterns which will be used by the intelligent system when interacting with environment.,We consider a number of issues related to the development of the set of patterns which will be used by the intelligent <mask> when interacting with environment.,the intelligent system,system,intelligent,1,-1.5032899057940394,0
4_arx_2308.03688_1891580_0,"Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.","<mask> are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.",Large Language Models (LLMs),Large Language Models (LLMs),"smart,autonomous",1,-3.2947793433272583,0
4_arx_2403.11805_2028924_0,"Being more powerful and intrusive into user-device interactions, LLMs are eager for on-device execution to better preserve user privacy.","Being more powerful and intrusive into user-device interactions, <mask> are eager for on-device execution to better preserve user privacy.",LLMs,LLMs,eager,1,-5.483844121502816,0
4_arx_2405.06715_2063927_2,"However, whether the same strategies can help LLMs become more creative remains under-explored.","However, whether the same strategies can help <mask> become more creative remains under-explored.",LLMs,LLMs,creative,1,1.9818300712582886,1
4_arx_2008.00312_1328034_4,"To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems.","To bridge this gap, this work studies the security threats posed by malicious <mask> to NLP systems.",malicious LMs,LMs,malicious,1,-1.4334708228883741,0
4_acl_693_19140_1,"However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus.","However, existing <mask> are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus.",existing DA-training methods,DA-training methods,blind,1,-4.14002414646928,0
4_arx_2311.07723_1950690_0,"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.","As <mask> become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.",AI systems,AI systems,intelligent,1,-5.639337664163911,0
4_acl_27_55498_4,"The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.","The <mask> is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.",The model,model,sensitive,1,0.0953439175277424,2
4_arx_2407.11789_2110176_2,"We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.","We investigate the ability of <mask> to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.",LLMs,LLMs,deceptive,1,-4.926950229872258,0
4_arx_2305.14985_1848041_7,These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question.,These three modules perform the divide-and-conquer procedure iteratively until the <mask> is confident about the final answer to the main question.,the model,model,confident,1,-0.4000715275404261,2
4_arx_2406.18326_2096614_4,"Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.","Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the <mask> is significantly more confident under the original benchmark.",the model,model,confident,1,-2.1544897258798876,0
4_arx_2407.13164_2111551_3,"This is in part because LLMs might be overly confident in their predictions, overriding the influence of the constraints.","This is in part because <mask> might be overly confident in their predictions, overriding the influence of the constraints.",LLMs,LLMs,confident,1,-2.1455167226931167,0
4_arx_1812.08960_1066534_3,"A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.","A smart autonomous <mask> combines analytics and autonomy to understand, learn, decide and act autonomously.",A smart autonomous system (SAS),system (SAS),"smart,autonomous",1,-0.8296415274874356,2
4_arx_2304.09655_1827701_7,"Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.","Results suggest that <mask> is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.",ChatGPT,ChatGPT,aware,1,-0.856799227501762,2
4_arx_2305.08883_1841939_5,A detection algorithm aware of the list can identify the watermarked text.,A <mask> aware of the list can identify the watermarked text.,A detection algorithm,detection algorithm,aware,1,4.143491191260885,1
4_arx_2407.09517_2107904_5,"Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.","Consequently, we argue that the emergence of a conscious <mask> is plausible in the near term.",a conscious AI model,AI model,conscious,1,0.8724276996907747,2
4_arx_2501.07290_2230874_1,"Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.","Conscious <mask> would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.",Conscious AI systems,AI systems,conscious,1,-1.2114163757723144,0
4_arx_2404.16873_2054324_0,"While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.","While recently <mask> have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.",Large Language Models (LLMs),Large Language Models (LLMs),vulnerable,1,-1.1686652192894744,0
4_arx_2502.18676_2261667_1,"Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.","Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful <mask> autonomously generates, develops, and communicates its evolving thought process throughout an interaction.",Thoughtful AI,AI,thoughtful,1,-2.774267047346333,0
4_arx_2308.08708_1896600_0,Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.,Whether current or near-term <mask> could be conscious is a topic of scientific interest and increasing public concern.,current or near-term AI systems,AI systems,conscious,1,-1.7012053635196853,0
4_arx_2502.00735_2243726_1,"While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.","While <mask> have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.",LLMs,LLMs,vulnerable,1,-5.333978674585531,0
4_arx_2411.14133_2196560_0,"Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.","<mask> have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.",Large Language Models (LLMs),Large Language Models (LLMs),vulnerable,1,-1.1133696457333748,0
4_acl_592_38304_5,"We find that powerful LLMs are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.","We find that powerful <mask> are aware of the certainty of their prediction and can achieve high agreement with ground truth on high-certainty samples, indicating a promising approach for building reliable and scalable proxies for evaluating LLM personalization.",powerful LLMs,LLMs,aware,1,-2.9594299266093937,0
4_arx_2306.01879_1855027_7,"In fact, we demonstrate that even a ""blind"" language model that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago.","In fact, we demonstrate that even a ""blind"" <mask> that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago.","a ""blind"" language model",language model,blind,1,0.008353253451094389,2
4_arx_1901.00912_1070459_9,We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.,We conclude by discussing how future AI developments may affect the fight between malicious <mask> and the public.,malicious bots,bots,malicious,1,-1.94781633948298,0
4_arx_2208.12505_1703217_1,"The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.","The <mask> easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference.",The OCR model,OCR model,confused,1,-0.5555138950006118,2
4_arx_2311.03287_1946254_6,"Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together.","Moreover, <mask> is vulnerable to leading questions and is often confused when interpreting multiple images together.",GPT-4V(ision),GPT-4V(ision),"vulnerable,confused",1,-2.507501243570923,0
4_arx_2311.17095_1960062_4,"To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask.","To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the <mask> is most attentive to, we are able to better resolve the entire extent of the segmentation mask.",the model,model,attentive,1,1.9578840943410292,1
4_arx_1905.13053_1131489_2,"We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.","We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent <mask> will take to achieve its objectives, even if we know terminal goals of the system.",a smarter-than-human intelligent system,system,intelligent,1,-0.7116054666328893,2
4_acl_36_22670_6,"All in all, we demonstrate that our self-aware model improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.","All in all, we demonstrate that our self-aware <mask> improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.",our self-aware model,model,self-aware,1,-0.13674546583808578,2
4_acl_133_36622_2,"We study how to better construct in-context example sets, based on whether the model is aware of the in-context examples.","We study how to better construct in-context example sets, based on whether the <mask> is aware of the in-context examples.",the model,model,aware,1,0.8646691280827419,2
4_arx_2501.13533_2237117_7,"AI agents are often assumed to pursue fixed goals, but AI persons may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.","AI agents are often assumed to pursue fixed goals, but <mask> may be self-aware enough to reflect on their aims, values, and positions in the world and thereby induce their goals to change.",AI persons,AI persons,self-aware,1,-3.098818862550843,0
4_arx_2502.05605_2248596_0,A truly intelligent Large Language Model (LLM) should be capable of correcting errors in its responses through external interactions.,A truly intelligent <mask> should be capable of correcting errors in its responses through external interactions.,A truly intelligent Large Language Model (LLM),Large Language Model (LLM),"intelligent,capable",1,-2.0597105398915225,0
