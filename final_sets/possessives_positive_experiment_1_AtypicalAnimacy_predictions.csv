id,sentence,masked_sentence,AI_phrase,mask,component,expectation,model_score,prediction
6_arx_2104.14506_1461924_5,"The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.","The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of [MASK] .",an AI model,AI model,decisions,1,0.44473737175367484,1
6_acl_183_18630_5,"On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.","On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by [MASK] .",the GPT-3,GPT-3,misunderstandings,1,0.49160504612083733,1
6_arx_1912.03652_1215548_4,We investigate how inputs of humans can be altered to reduce misinterpretation by the AI system and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,We investigate how inputs of humans can be altered to reduce misinterpretation by [MASK] and to improve efficiency of input generation for the human while altered inputs should remain as similar as possible to the original inputs.,the AI system,AI system,misinterpretations,1,0.32065554275022917,1
6_acl_373_16531_2,Actions by the AI system may be required to bring these objects in view.,Actions by [MASK] may be required to bring these objects in view.,the AI system,AI system,actions,1,0.17238033992106824,0
6_arx_2110.06674_1544817_2,"This raises the question of how we should limit the harm caused by AI ""lies"" (i.e. falsehoods that are actively selected for).","This raises the question of how we should limit the harm caused by [MASK]"" (i.e. falsehoods that are actively selected for).",AI,AI,lies,1,0.03897958483539904,0
6_arx_2207.07051_1682949_0,Reasoning is a key ability for an intelligent system.,Reasoning is a key ability for [MASK] .,an intelligent system,system,reasoning,1,0.2840250335026389,0
6_acl_71_46015_2,"In this study, leveraging the POPQUORN dataset, we evaluate nine popular LLMs on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.","In this study, leveraging the POPQUORN dataset, we evaluate [MASK] on their ability to understand demographic differences in two subjective judgment tasks: politeness and offensiveness.",nine popular LLMs,LLMs,ability to understand,1,0.4624291279489741,1
6_arx_2405.01576_2058788_0,We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.,We study the tendency of [MASK] to deceive by constructing a realistic simulation setting of a company AI assistant.,AI systems,AI systems,tendency to deceive,1,0.5674696046409372,1
6_acl_245_29281_1,"With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of LLMs.","With large language models like GPT-4 taking over the field, prompting techniques such as chain-of-thought (CoT) were proposed to unlock compositional, multi-step reasoning capabilities of [MASK] .",LLMs,LLMs,reasoning capabilities,1,0.19714723498731024,0
6_acl_916_40326_5,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of Chinese LLMs.,LHMKE is designed to provide a comprehensive evaluation of the knowledge acquisition capabilities of [MASK] .,Chinese LLMs,LLMs,knowledge acquisition capabilities,1,0.46269034730513187,1
6_acl_1539_40949_1,"However, this awareness of LMs has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.","However, this awareness of [MASK] has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values.",LMs,LMs,awareness,1,0.04870414449849421,0
6_acl_225_32387_1,Numerous benchmarks have been established to assess the reasoning abilities of LLMs.,Numerous benchmarks have been established to assess the reasoning abilities of [MASK] .,LLMs,LLMs,reasoning abilities,1,0.35375723387254965,1
6_acl_743_29779_6,"Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.","Additionally, the causal reasoning ability of [MASK] is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts.",ChatGPT,ChatGPT,causal reasoning ability,1,0.4762918472220365,1
6_acl_538_32700_6,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of LLMs and speed up the development of LLMs in journalism.,The evaluation framework and experimental results are expected to provide an in-depth understanding of the editorial capabilities of [MASK] and speed up the development of [MASK] in journalism.,LLMs,LLMs,editorial capabilities,1,0.3198020263962958,1
6_arx_2101.06573_1410315_4,We show how progress has been made in benchmark development to measure understanding capabilities of AI methods and we review as well how current methods develop understanding capabilities.,We show how progress has been made in benchmark development to measure understanding capabilities of [MASK] and we review as well how current methods develop understanding capabilities.,AI methods,AI methods,understanding capabilities,1,0.15211277416649333,0
6_arx_2307.16180_1887175_4,"Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.","Specifically, extensive experiments will be conducted to explore: 1) the personality types of [MASK] , 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality.",different LLMs,LLMs,personality types,1,0.5057956560882176,1
6_arx_2503.16460_2280772_5,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess LLM problem-solving capabilities.,The first approach uses an intelligent tutoring system for college algebra as a testbed to assess [MASK] .,LLM,LLM,problem-solving capabilities,1,0.043606152613213225,0
6_arx_2309.02077_1906881_6,A medical consultation training set is further constructed to improve the consultation ability of LLMs.,A medical consultation training set is further constructed to improve the consultation ability of [MASK] .,LLMs,LLMs,consultation abilities,1,0.7328107728167543,1
6_arx_2305.18752_1851808_6,"Moreover, we provide a benchmark to evaluate the ability of LLMs to use tools, which is performed in both zero-shot and fine-tuning ways.","Moreover, we provide a benchmark to evaluate the ability of [MASK] to use tools, which is performed in both zero-shot and fine-tuning ways.",LLMs,LLMs,ability to use tools,1,0.4708591073387251,1
6_arx_2309.11805_1916609_6,"Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.","Inspired by the superior performance of [MASK] , we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form.",LLMs,LLMs,capability to understand natural language,1,0.3110663451923603,1
6_arx_2305.16867_1849923_1,We propose to use behavioural game theory to study LLMs' cooperation and coordination behaviour.,We propose to use behavioural game theory to study [MASK] .,LLMs,LLMs,cooperation and coordination behavior,1,0.07383979053967663,0
6_arx_2305.04388_1837444_1,It is tempting to interpret these CoT explanations as the LLM's process for solving a task.,It is tempting to interpret these CoT explanations as [MASK] for solving a task.,the LLM,LLM,process for solving a task,1,0.011153489154162083,0
6_arx_2005.02335_1282130_0,Explainable machine learning and artificial intelligence models have been used to justify a model's decision-making process.,Explainable machine learning and artificial intelligence models have been used to justify [MASK] .,a model,model,decision-making process,1,0.01369720360486219,0
6_arx_2203.10923_1623785_4,We also discuss issues that are unique to edge applications such as protecting a model's intellectual property and verifying its integrity.,We also discuss issues that are unique to edge applications such as protecting [MASK] and verifying its integrity.,a model,model,intellectual property,1,0.05721542321155211,0
6_arx_2207.09374_1685272_1,"However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for an AI's decision.","However, all common approaches from this field are based on communicating information about features or characteristics that are especially important for [MASK] .",an AI,AI,decisions,1,0.15039516429218183,0
6_arx_2209.15093_1720808_3,We propose conceptual consistency to measure a LLM's understanding of relevant concepts.,We propose conceptual consistency to measure [MASK] of relevant concepts.,a LLM,LLM,understanding,1,0.0,0
6_arx_2210.05487_1726842_3,We find that the visual grounding improves the model's understanding of semantic similarity both within and across languages and improves perplexity.,We find that the visual grounding improves [MASK] of semantic similarity both within and across languages and improves perplexity.,the model,model,understanding,1,0.0,0
6_arx_2307.00457_1871453_4,"GenRec uses LLMs' understanding ability to interpret context, learn user preferences, and generate relevant recommendation.","GenRec uses [MASK] to interpret context, learn user preferences, and generate relevant recommendation.",LLMs,LLMs,understanding abilities,1,0.0434810624063203,0
6_arx_2307.10250_1881245_0,"This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology.","This study evaluates [MASK] in complex fields like medical diagnostics, criminology, and cosmology.",the GPT-4 Large Language Model,GPT-4 Large Language Model,abductive reasoning,1,0.08929434747141003,0
6_arx_2308.10837_1898729_1,"However, effectively integrating LLMs' commonsense knowledge and reasoning abilities into recommendation systems remains a challenging problem.","However, effectively integrating [MASK] and reasoning abilities into recommendation systems remains a challenging problem.",LLMs,LLMs,commonsense knowledge and reasoning abilities,1,0.017712215554110733,0
6_arx_2308.07326_1895218_4,Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions.,Our findings underscore [MASK] and ability to discern and adapt to nuanced instructions.,GPT,GPT,ability to discern and adapt to nuanced instructions,1,0.0,0
6_arx_2307.05488_1876483_8,These biases may impact the responses of constructs and should be considered when interpreting ChatGPT's conceptual capabilities.,These biases may impact the responses of constructs and should be considered when interpreting [MASK] .,ChatGPT,ChatGPT,conceptual capabilities,1,0.013558903556647458,0
6_arx_2306.11296_1864444_1,This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,This effectively mitigates [MASK] to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging.,ChatGPT,ChatGPT,tendency to hallucinate information,1,0.013068513327248727,0
6_arx_2303.13712_1813509_7,We then consider a decision maker who is aware of the algorithm's manipulation and responds strategically.,We then consider a decision maker who is aware of [MASK] and responds strategically.,the algorithm,algorithm,manipulation,1,0.0472218695035856,0
6_arx_2211.08380_1747286_6,"In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision.","In addition, OREO-LM provides reasoning paths as rationales to interpret [MASK] .",the model,model,decisions,1,0.0,0
6_arx_2301.13852_1784916_11,"Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.","Using explainability, we observe that [MASK] is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings.",ChatGPT,ChatGPT,polite writing,1,0.133971593717943,0
6_arx_2306.03423_1856571_4,"In this experiment, we characterize ChatGPT's refusal behavior using a black-box attack.","In this experiment, we characterize [MASK] using a black-box attack.",ChatGPT,ChatGPT,refusal behavior,1,0.08255099160033907,0
6_acl_406_32568_3,"Our analysis of GPT-series models over a rule subset reveals significant gaps in LLMs’ logic understanding compared to human performance, especially in compositional and structural complex rules with certain bias patterns.","Our analysis of GPT-series models over a rule subset reveals significant gaps in [MASK] compared to human performance, especially in compositional and structural complex rules with certain bias patterns.",LLMs,LLMs,logic understanding,1,0.008133339372704535,0
6_arx_2309.05163_1909967_10,"However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs.","However, given the [MASK]' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by [MASK] .",the LLMs,LLMs,considerable proficiency in writing Physics essays and coding abilities,1,0.32316145000137353,1
6_acl_865_25015_6,"On the other hand, downstream performance is mainly driven by the model’s size and prior legal knowledge which can be estimated by upstream and probing performance.","On the other hand, downstream performance is mainly driven by [MASK] and prior legal knowledge which can be estimated by upstream and probing performance.",the model,model,prior legal knowledge,1,0.06067319430277941,0
6_acl_2210.12530_1733885_3,"Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with the LM's common-sense reasoning based on the metadata.","Our method, Language Model Priors (LMPriors), incorporates auxiliary natural language metadata about the task -- such as variable names and descriptions -- to encourage downstream model outputs to be consistent with [MASK] based on the metadata.",the LM,LM,common-sense reasoning,1,0.03050169146334221,0
6_arx_2206.14576_1674996_1,"More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.","More specifically, we assess [MASK] , information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature.",GPT-3,GPT-3,"decision-making,deliberation,causal reasoning abilities",1,0.0,0
6_arx_2308.01552_1889444_4,"The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.","The results highlight [MASK] in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.",ChatGPT,ChatGPT,competence in comprehending and performing intricate tasks,1,0.01759494389612891,0
6_arx_2308.06032_1893924_10,"Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.","Our research is the first to systematically study [MASK] in litigation, as well as in securities law and cryptocurrency-related misconduct.",an LLM,LLM,legal drafting and reasoning capabilities,1,0.057663387443836985,0
6_arx_2308.06920_1894812_8,"This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions.","This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein [MASK] enhance the design and development of potential pharmaceutical solutions.",ChatGPT,ChatGPT,cognitive abilities,1,0.41393572473349416,1
6_arx_2308.07326_1895218_5,"Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.","Furthermore, historical figure simulations highlighted [MASK] to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles.",the LLM,LLM,capacity to internalize and project instructible personas,1,0.00381922732195118,0
6_arx_2308.08407_1896299_3,Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,Explainability is usually referred to as [MASK] to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders.,an AI system,AI system,ability to provide a robust interpretation of its decision-making logic,1,0.0,0
6_arx_2307.05488_1876483_1,The objective of the studies is to assess ChatGPT's ability to comprehend theoretical concepts and differentiate between constructs.,The objective of the studies is to assess [MASK] to comprehend theoretical concepts and differentiate between constructs.,ChatGPT,ChatGPT,ability to comprehend theoretical concepts and differentiate between constructs,1,0.017565652626848876,0
6_arx_2307.04274_1875269_7,"Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on the model's ability to showcase pedagogical skills.","Finally, we note the need for these generative models to be evaluated with a metric that relies not only on dialog coherence and matched language modeling distribution but also on [MASK] to showcase pedagogical skills.",the model,model,ability to showcase pedagogical skills,1,0.04476512772505454,0
6_arx_2306.10645_1863793_3,"We examine ChatGPT's ability to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.","We examine [MASK] to pursue multiple interconnected learning objectives, adapt the educational activity to users' characteristics, such as culture, age, and level of education, and its ability to use diverse educational strategies and conversational styles.",ChatGPT,ChatGPT,ability to pursue multiple interconnected learning objectives,1,0.027288530244758843,0
6_arx_2306.06123_1859271_2,"The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.","The possibility of manipulating, fooling or fairwashing evidence of [MASK] has detrimental consequences when applied in high-stakes decision-making and knowledge discovery.",the model,model,reasoning,1,0.015145323567360298,0
6_arx_2305.16867_1849923_8,These results enrich our understanding of LLMs' social behaviour and pave the way for a behavioural game theory for machines.,These results enrich our understanding of [MASK] and pave the way for a behavioural game theory for machines.,LLMs,LLMs,social behaviour,1,0.054454797232720176,0
6_arx_2305.14795_1847851_2,"Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to the model's related beliefs.","Current evaluation paradigms are extremely limited, mainly validating the recall of edited facts, but changing one fact should cause rippling changes to [MASK] .",the model,model,related beliefs,1,0.03919246699448396,0
6_arx_2305.12763_1845819_3,We find that GPT's decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,We find that [MASK] are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature.,GPT,GPT,rational decisions,1,0.30439239039196403,1
6_arx_2305.12564_1845620_3,"Moreover, we find that this seemingly default perception of ChatGPT as male can reverse when ChatGPT's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).","Moreover, we find that this seemingly default perception of [MASK] as male can reverse when [MASK] 's feminine-coded abilities are highlighted (e.g., providing emotional support for a user).",ChatGPT,ChatGPT,feminine-coded abilities,1,0.3931360092073592,1
6_arx_2303.03480_1803277_1,Our approach makes use of Large Language Models (LLMs) for this task by leveraging the LLM's commonsense reasoning capabilities for making sequential navigational decisions.,Our approach makes use of Large Language Models (LLMs) for this task by leveraging [MASK] for making sequential navigational decisions.,the LLM,LLM,commonsense reasoning capabilities,1,0.09735226446229014,0
6_arx_1704.00717_835229_5,"In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.","In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of [MASK] (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks.",AI,AI,theory of mind,1,0.027802664495662665,0
