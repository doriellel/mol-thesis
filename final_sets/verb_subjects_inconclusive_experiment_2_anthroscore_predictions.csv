id,sentence,masked_sentence,AI_phrase,mask,component,expectation,model_score,prediction
1_acl_586_6176_1,"While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.","While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent <mask> also derive lexical type-level knowledge from words in context.",LMs,LMs,derive knowledge,2,-3.7589045242168275,0
1_acl_5_9514_1,"In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.","In some applications, however, having an additional context can help the <mask> make the right prediction, e.g., by taking the domain or the time of writing into account.",the model,model,make a prediction,2,-0.46915063793754896,2
1_acl_65_19388_5,The human evaluation found that our topic model creates coherent topics.,The human evaluation found that our <mask> creates coherent topics.,our topic model,topic model,create,2,-1.5306848086603502,0
1_acl_22_31716_3,"Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.","Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that <mask> cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.",LLMs,LLMs,learn,2,-2.352818953555351,0
1_acl_163_34648_5,"Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.","Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our <mask> can create presentations that are not only informative but also tailored to expectations and cognitive abilities of the target audience.",our model,model,create,2,0.07085675328189822,2
1_arx_2110.10185_1548328_5,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.,The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the <mask> acts in a manner human users find suitable.,the generation system,generation system,act,2,-2.864461217242738,0
1_arx_2212.07414_1763591_5,Our algorithm considers the channel conditions during the dynamic weight selection process.,Our <mask> considers the channel conditions during the dynamic weight selection process.,Our algorithm,algorithm,consider,2,-0.8948006100056638,2
1_arx_1101.3316_238729_3,The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.,The test shows that the <mask> correctly identifies ~80% of known QSOs with a 25% false positive rate.,the model,model,identify,2,-1.3411310527150544,0
1_arx_1205.6986_345987_9,"At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.","At the same time, our <mask> dissects this variability into components that result from individual SNP effects and population structure.",our model,model,dissect,2,-1.194445547232771,0
1_arx_2302.04335_1789269_6,"In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.","In other words, <mask> can create content on many topics with high originality as if they were written by someone.",ChatGPT,ChatGPT,create,2,-0.13511214458895182,2
1_acl_154_25214_1,"However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a model had truly learned how negation morphemes semantically scope.","However, these benchmarks lack the controlled example paradigms that would allow us to infer whether a <mask> had truly learned how negation morphemes semantically scope.",a model,model,learn,2,0.14855417498872647,2
1_acl_852_33014_0,Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems.,Recent <mask> have demonstrated remarkable performance in solving exam-like math word problems.,Recent LLMs,LLMs,demonstrate,2,-2.82856982074064,0
1_acl_2_34276_7,"Our results show that not all extracted utterances are correctly structured, indicating that either LLMs do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.","Our results show that not all extracted utterances are correctly structured, indicating that either <mask> do not fully acquire syntactic-semantic rules or they acquire them but cannot apply them effectively.",LLMs,LLMs,acquire,2,-3.6614589681110346,0
1_acl_53_34920_6,"Taken together, our results provide an existence proof that LMs can learn rare grammatical phenomena by generalization from less rare phenomena.","Taken together, our results provide an existence proof that <mask> can learn rare grammatical phenomena by generalization from less rare phenomena.",LMs,LMs,learn,2,-1.5592040395884261,0
1_acl_24_17147_6,"Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.","Our experiment results suggest that <mask> has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence.",GPT-3,GPT-3,"acquire,fail",2,0.02878247121016919,2
1_arx_1205.3313_342314_2,"The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.","The <mask> does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.",The model,model,differentiate,2,0.2796508708095313,2
1_arx_2304.10592_1828638_0,"The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.","The recent <mask> has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.",The recent GPT-4,GPT-4,demonstrate abilities,2,-0.07945163107085484,2
1_acl_11_43395_1,"For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.","For example, a <mask> should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.",a model,model,identify,2,-1.2278112849538623,0
1_arx_2304.09337_1827383_2,It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.,It often involves laborious trial-and-error procedures to ensure that the <mask> interprets the prompts in alignment with the user's intention.,the model,model,interpret,2,-2.379640724403398,0
1_arx_2207.08333_1684231_3,We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,We observed that the <mask> does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.,the VL model,VL model,interpret,2,-1.6610361398143372,0
1_acl_814_27535_1,Such ability stimulates us to wonder whether LLMs can simulate a person in a higher form than simple human behaviors.,Such ability stimulates us to wonder whether <mask> can simulate a person in a higher form than simple human behaviors.,LLMs,LLMs,simulate,2,-1.4472603071430452,0
1_acl_7_34361_5,The results show that ChatGPT made more changes than the average post-editor.,The results show that <mask> made more changes than the average post-editor.,ChatGPT,ChatGPT,make changes,2,2.6375988106510952,1
1_arx_1908.02624_1160794_1,"AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.","<mask> can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.",AI systems,AI systems,"translate,identify,streamline,control",2,-3.5404183660045803,0
1_arx_2304.02868_1820914_3,"Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.","Precisely, <mask> can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.",ChatGPT,ChatGPT,"construct,fail to leverage world knowledge,infer",2,-4.299381528961565,0
1_arx_2304.02182_1820228_0,The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.,The recently released <mask> has demonstrated surprising abilities in natural language understanding and natural language generation.,The recently released ChatGPT,ChatGPT,demonstrate surprising abilities,2,-1.5205595455496237,0
1_arx_2304.02868_1820914_2,Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,Our experiments show that <mask> performs competitively compared to all the existing systems but still exhibits a low level of intelligence.,ChatGPT,ChatGPT,"perform competitively,exhibit a low level of intelligence",2,-3.862445885325492,0
1_arx_2302.06100_1791034_8,We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.,We find <mask> performs poorly at answering straightforward questions about these simple synthetic statutes.,GPT-3,GPT-3,perform poorly at answering straightforward questions,2,-4.162454580579665,0
1_acl_679_35529_6,"4) LLMs often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.","4) <mask> often exhibit overconfidence in their predictions, especially when dealing with datasets that contain shortcuts.",LLMs,LLMs,exhibit overconfidence,2,-3.7924260549602167,0
1_arx_1904.08530_1113570_2,We cross-check with control cases to ensure that the AI is not randomly guessing and is indeed identifying an inherent structure.,We cross-check with control cases to ensure that the <mask> is not randomly guessing and is indeed identifying an inherent structure.,the AI,AI,"guess,identify",2,-0.4232756439728451,2
1_acl_1011_30047_1,"However, the instruction-tuned model has only seen one response per instruction, lacking the knowledge of potentially better responses.","However, the <mask> has only seen one response per instruction, lacking the knowledge of potentially better responses.",the instruction-tuned model,instruction-tuned model,see,2,-0.6482142454367121,2
1_arx_1905.04127_1122563_1,"Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.","Traditionally, <mask> have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.",AI agents,AI agents,suffer from difficulties,2,-4.855990749805699,0
1_acl_78_25975_8,The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.,The semantic dependency feature serves as a global signal and helps the <mask> learn simile knowledge that can be applied to unseen domains.,the model,model,learn,2,0.36355862947540274,2
1_arx_2303.17276_1817073_8,"This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.","This suggests that larger and more advanced <mask> may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.",larger and more advanced LLMs,LLMs,develop a tendency,2,-4.305086929850404,0
