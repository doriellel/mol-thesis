0705.4412_8414_2	Materials and Methods: The system consists of a computer and a localizer allowing spatial localization of the position of the various instruments.
0708.4198_22049_4	The population dynamics model determines nitrogen in two components, nutrients and phytoplankton, which are assumed to be passively advected by the simulated surface currents.
0709.0625_22890_4	For cases where an exact low-rank representation of the IBD matrix is available a-priori, the improved AI-REML algorithm normally runs almost twice as fast compared to the standard version.
0802.0733_48030_1	The model that I employ assumes that the time that a passenger requires to load his or her luggage is the dominant contribution to the time needed to completely fill the aircraft.
0810.3447_89026_3	A simple model of Thomson scattering in the stellar wind can account for the modulation seen in the X-ray light curves.
0811.1711_93063_8	However, the Adaptive Neuro-Fuzzy Inference system out performed the other methods in terms of accuracy and ease of implementation, while still achieving a fast execution time as well as a reasonable training time.
0912.5208_164959_8	We find that the LMC cluster system exhibits disk-like rotation with no clusters appearing to have halo kinematics and there is no evidence of a metallicity gradient in the LMC, in contrast with the stellar population of the MW and M33, where the metallicity decreases as galactocentric distance increases.
1101.3316_238729_3	The test shows that the model correctly identifies ~80% of known QSOs with a 25% false positive rate.
1106.0253_265888_5	While the AIS-BN algorithm always performed better than the other two algorithms, in the majority of the test cases it achieved orders of magnitude improvement in precision of the results.
1109.0704_285072_7	The model covers coronal temperatures that are representative of plasma conditions in coronal holes and quiet sun.
1201.0815_312802_8	A hybrid model, combining both wave and non-wave components, can explain many, but not all, of the observations.
1203.3470_328829_8	Then, we propose a framework whereby an automated system can plan to address these hazards in cooperation with the pilot, using a Time-Dependent Markov Process (TMDP).
1205.6986_345987_9	At the same time, our model dissects this variability into components that result from individual SNP effects and population structure.
1210.2715_376509_4	The model which we will offer will consist of final automata and first order formulas.
1301.2158_398748_8	Given careful design and problem formulation, an AI simulation framework can approximate optimal decisions even in complex and uncertain environments.
1304.0938_420071_1	The model approximates the effective C_d by the area-weighted averaging of the distinct drag coefficients associated with the foam-free and foam totally-covered portions of the sea surface, and identifies the roughness of the sea surface totally covered by foam with the foam bubble size.
1304.1515_420648_2	It is shown that interactive problem solving with a decision aid that is based on a fallible algorithm can easily result in aided performance which is poorer than unaided performance, even if the algorithm, by itself, performs significantly better than the unaided decision maker.
1304.6152_425285_1	The proposed IDD system consists of a soft-input soft-output parallel interference (PIC) cancellation scheme with linear minimum mean-square error (MMSE) receive filters and two novel belief propagation (BP) decoding algorithms.
1305.2331_429599_3	In this paper, we present an empirical model to describe the distribution of $\Xmax$ for EAS initiated by nuclei, in the energy range from $10^{17}$ eV up to $10^{21}$ eV, and by photons, in the energy range from $10^{17}$ eV up to $10^{19.6}$ eV. Our model adopts the generalized Gumbel distribution motivated by the relationship between the generalized Gumbel statistics and the distribution of the sum of non-identically distributed variables in dissipative stochastic systems.
1305.4038_431306_4	In that sense, the system tries to gain "air dominance" over attackers.
1311.7183_480844_2	Specifically, for a side-looking uniformly spaced linear array, the} algorithm firstly selects a group of linearly independent space-time steering vectors using LRGP that can represent the clutter subspace.
1312.5056_486409_10	For the second set of loops modeled with twice-heating, there are some discrepancies between modeled and observed EUV light curves in low-temperature bands, and the model does not fully produce the prolonged blueshift signatures as observed.
1401.3566_492797_1	Since standard LMS algorithm does not take into account the sparsity information about the channel impulse response (CIR), sparsity-aware modifications of the LMS algorithm aim at outperforming the standard LMS by introducing a penalty term to the standard LMS cost function which forces the solution to be sparse.
1403.6131_511030_6	The model trained using only the superclasses shows 99% recall and precision, while the model trained on all subclasses shows 87% recall and precision.
1404.1011_514064_1	Lindzen and Nigam (1987) noted that sea level pressure (SLP) gradients are proportional to surface temperature gradients if isobaric height (the height where pressure does not vary in the horizontal plane) is constant; their own model of low-level circulation assumed that isobaric height in the tropics is around 3 km.
1405.3515_524423_2	The model identifies words such as "cell" and "gay" as having changed during that time period.
1405.3515_524423_3	The model simultaneously identifies the specific years during which such words underwent change.
1405.4273_525181_2	We perform both intrinsic and extrinsic evaluations, presenting results on a range of languages which demonstrate that our model learns morphological representations that both perform well on word similarity tasks and lead to substantial reductions in perplexity.
1410.6629_567730_5	Our experiments on real world e-mail datasets demonstrate that our system can effectively block advanced email attacks sent from genuine email accounts, which traditional protection systems are unable to detect.
1412.1454_579432_1	A first set of experiments empirically evaluating it on the One Billion Word Benchmark shows that SNM $n$-gram LMs perform almost as well as the well-established Kneser-Ney (KN) models.
1501.04448_591196_0	  Latent Markov (LM) models represent an important class of models for the analysis of longitudinal data (Bartolucci et.
1501.06697_593445_6	The algorithm produces good predictions for the 156 solar wind high speed streams peak amplitudes with correlation coefficients of cc~0.60.
1511.01574_674754_4	Surprisingly, an adjustment model with meta-features that discard all lexical information can perform as well as lexicalized meta-features.
1511.05924_679104_1	The automatic region-wise spatially varying coefficient model consists three parts: we first compute the similarity matrix between the exposure-health outcome associations of all spatial units, then segment the whole map into a set of disjoint regions based on the adjacency matrix with constraints that all spatial units within a region are contiguous and have similar association, and lastly estimate the region specific associations between exposure and health outcome.
1511.05942_679122_4	Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79% recall@30, significantly higher than several baselines.
1602.02367_702646_4	Moreover, the theoretical properties of the algorithm are studied and it is proved that under certain assumptions the algorithm suffers a no regret bound.
1602.04207_704486_0	  We consider a system comprising a library of $N$ files (e.g., movies) and a wireless network with $K_T$ transmitters, each equipped with a local cache of size of $M_T$ files, and $K_R$ receivers, each equipped with a local cache of size of $M_R$ files.
1602.06465_706744_7	The second method is based on the fact that a system consisting of a transmissive SLM sandwiched between two polarisers can create a transmission function with negative values.
1603.07417_716838_5	Experimental results show that the proposed ALIP system performs better than the conventional IP-based load disaggregation system.
1605.00909_729024_1	The system consists of two late G-type giant stars on an eccentric orbit and orbital period of ~200 days.
1605.02877_730992_0	  The sparsity-aware zero attractor least mean square (ZA-LMS) algorithm manifests much lower misadjustment in strongly sparse environment than its sparsity-agnostic counterpart, the least mean square (LMS), but is shown to perform worse than the LMS when sparsity of the impulse response decreases.
1605.06048_734163_0	  In this article, I discuss how the AI community views concerns about the emergence of superintelligent AI and related philosophical issues.
1606.04241_742148_2	The model describes both the strategic phase associated to the planning of the flight trajectories and the tactical modifications occurring in the en-route phase.
1606.07470_745377_1	The model takes as input both word histories as well as n-gram counts.
1606.08410_746317_7	However, the heating and cooling model does not take into account human occupancy.
1606.08410_746317_10	This system makes it possible to reduce the consumption when needed minimizing impact on the consumer.
1606.08689_746596_6	The results indicate that the proposed model can learn useful representations of both documents and word tokens, outperforming the current state-of-the-art by a large margin.
1607.00228_747779_6	Our model naturally explains high energy broadening of the disk spectrum observed in some binaries.
1607.01486_749037_1	The system consists of an extended Kalman filter (EKF) based state estimation algorithm that fuses information from a low cost MEMS inertial measurement unit acquired at 200Hz and VGA resolution images from a monocular camera at 50Hz.
1607.05028_752579_1	We propose that a general player model needs parameters for subjective experience of play, including: player psychology, game structure, and actions of play.
1608.08644_765106_5	The results show the beam-space MIMO system and the conventional MIMO system exhibit similar finite-constellation capacity and error performance in NLOS scenarios when there is sufficient scattering in the channel.
1609.04879_770357_6	Extreme AI, a psychology-based personality engine, creates adaptive NPC personalities.
1609.08030_773508_4	Our model performs a local conflict detection and resolution procedure.
1609.09808_775286_0	  In this paper we consider the equation system describing the motion of the air and the variation of the radiation intensity and the quantity of water droplets in the air, including also the process of water phase transition.
1610.06195_781542_5	The new Model II resolves the lack of threshold stability in the Davison--Smith model by constructing a special functional form for the GPD parameters.
1702.05663_820257_1	Although state-of-the-art deep learning models for video game tasks generally rely on more complex methods such as deep-Q learning, we show that a supervised model which requires substantially fewer resources and training time can already perform well at human reaction speeds on the N64 classic game Super Smash Bros.
1703.09310_832814_0	  This work studies how an AI-controlled dog-fighting agent with tunable decision-making parameters can learn to optimize performance against an intelligent adversary, as measured by a stochastic objective function evaluated on simulated combat engagements.
1704.00717_835229_4	The latter involves making AI more human-like and having it develop a theory of our minds.
1704.00717_835229_9	Explainable AI has received considerable scientific and popular attention in recent times.
1704.00717_835229_10	Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior.
1704.00961_835473_3	During gameplay, the proposed AI analyze health states of the player; it determines its next action by predicting how each candidate action, recommended by a Monte-Carlo tree search algorithm, will induce the player to move, and how the player's health tends to be affected.
1704.06851_841363_5	Affect-LM also learns affect-discriminative word representations, and perplexity experiments show that additional affective information in conversational text can improve language model prediction.
1704.07782_842294_9	The very unusual combination of the components suggest that the system has passed through a mass transfer phase in its evolution.
1704.08695_843207_2	Our system consists of a modified off-the-shelf model aircraft that is controlled by the pixhawk autopilot hardware and the ardupilot software for fixed wing aircraft.
1705.05058_848599_5	For non-stationary networks, \plc{} obtains an $[O(\epsilon), O(\log^2(1/\epsilon)$ $+ \min(\epsilon^{c/2-1}, e_w/\epsilon))]$ utility-backlog tradeoff for distributions that last $\Theta(\frac{\max(\epsilon^{-c}, e_w^{-2})}{\epsilon^{1+a}})$ time, where $e_w$ is the prediction accuracy and $a=\Theta(1)>0$ is a constant (the Backpressue algorithm \cite{neelynowbook} requires an $O(\epsilon^{-2})$ length for the same utility performance with a larger backlog).
1705.05983_849524_0	  Based on Alan Turing's proposition on AI and computing machinery, which shaped Computing as we know it today, the new AI computing machinery should comprise a universal computer and a universal learning machine.
1706.00897_855632_3	Although RLS algorithm perform superior to LMS algorithm, it has very high computational complexity so not useful in most of the practical scenario.
1708.02938_877950_7	The proposed model demonstrates the effectiveness of using formal specification in conjunction with agent-based simulation for developing models of CAS in general and, social network-based agent-based models, in particular.
1708.04019_879031_4	The trained model could distinguish scrambled vs real DNA sequences for scrambling lengths of 2 bp, 10 bp, 50 bp and even 100 bp, with a significantly higher accuracy than linear SVMs.
1708.06926_881938_4	However, BPmin algorithm estimates route congestion based on unrealistic assumption that every node in the network knows real-time global queue length information of all other nodes.
1709.01547_886413_0	  We consider the fundamental question: how a legacy "student" Artificial Intelligent (AI) system could learn from a legacy "teacher" AI system or a human expert without complete re-training and, most importantly, without requiring significant computational resources.
1709.01547_886413_4	In particular, for $n$ sufficiently large, with probability close to one, the "student" system can successfully and non-iteratively learn $k\ll n$ new examples from the "teacher" (or correct the same number of mistakes) at the cost of two additional inner products.
1709.04574_889440_4	Specifically, we show that the AI learns a driving strategy that maintains a safe distance from a lead vehicle, and most novelly, preferentially slows the vehicle when the human passengers of the vehicle encounter objects of interest.
1710.02362_897745_3	This model may also consider the presence of a mucus layer coating the epithelial wall.
1710.08191_903574_10	As modern Robin Hoods, HIT-AI researchers should fight for a fairer Artificial Intelligence that gives back what it steals.
1710.09938_905321_2	The model accounts for all the particle-level and many-body physics of the system: nonaffine displacements, local connectivity and its evolution in terms of cage-breaking, and interparticle interactions mediated by the particle chemistry and colloidal forces.
1710.10675_906058_4	In addition to disease grading via the discovered deep radiomic sequencer, the CLEAR-DR system also produces a visual interpretation of the decision-making process to provide better insight and understanding into the decision-making process of the system.
1711.02013_909023_6	Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks.
1712.03080_921679_2	The objective module would ensure that the system acts in humanity's interest, not against it.
1712.07752_926351_3	In addition, not everyone in the society is studying the potential socio-economic intricacies and cultural drifts that AI can bring about.
1712.10082_928681_6	The newly proposed meta-modeling concept has been found to be comparable with the MLP in learning capability; and more importantly, our CNN model exhibits a competitive prediction accuracy with minimal constraints in a geometric representation.
1801.02782_931713_6	Especially for the EE maximization problem, the proposed algorithm exhibits about 109 % gain over the baseline scheme.
1802.02172_941712_0	  All artificial Intelligence (AI) systems make errors.
1802.08057_947597_3	The proposed algorithm learns multi-level sparse representation for both high and low resolution gallery images, along with an identity aware dictionary and a transformation function between the two representations for face identification scenarios.
1803.05049_955182_4	Among other things, Fractal AI makes it possible to generate a huge database of top performing examples with a very little amount of computation required, transforming Reinforcement Learning into a supervised problem.
1803.05049_955182_5	The algorithm presented is capable of solving the exploration vs exploitation dilemma on both the discrete and continuous cases, while maintaining control over any aspect of the behaviour of the Agent.
1803.05457_955590_6	Can your model perform better?
1803.05976_956109_9	Therefore, given a sequence of different alternatives presented to a customer, the model can learn to point to the one most likely to be chosen by the customer.
1803.07233_957366_9	On the other side, AI examiners develop and post machine intelligence tasks designed to evaluate and characterize algorithmic behavior.
1803.11261_961394_1	Initially, AI developed on a separate trajectory, both topically and institutionally, from pattern recognition, neural information processing, decision and control systems, and allied topics by focusing on symbolic systems within computer science departments rather than on continuous systems in electrical engineering departments.
1804.07819_969512_2	Thus, these auto-generated queries help address the epistemological question of how we know what we know, or more precisely in this case, how an AI system with ingested data knows what it knows.
1804.10201_971894_6	Our system performed face detection, face recognition, facial action unit detection, head pose detection, facial expression recognition, posture recognition, actigraphy analysis, sound pressure and light level detection, and visitation frequency detection.
1805.11646_984691_5	The algorithm receives as inputs a spatial distribution of refractive index and a pre-defined library of gradient index unit cells, and outputs a 3D model of GRIN device that is ready to be 3D printed.
1805.12070_985115_2	Our model jointly learns both language modeling and Part-of-Speech tagging on code-switched utterances.
1805.12506_985551_3	Our model assumes the camera movement to be free, but continuous and differentiable, and individual features are assumed to stay stationary.
1806.00839_986479_3	We initially use three training styles: complete from scratch using random initialization, using a pre-trained ImageNet model training only the last layer adapted to our problem (transfer learning) and a pre-trained model modified training all the classifying layers of the model (fine tuning).
1806.02421_988061_1	An AI system performing the OODA process requires a semantically rich representation to handle a complex real world situation and ability to reason under uncertainty about the situation.
1806.03620_989260_7	This new analytic model describes the different polarizations of the radiation and therefore allows the use of independently measured signals in different polarization, thereby doubling the amount of information that is available in current radio arrays, compared to what has been used thus far.
1807.06068_1003276_2	We focus on the particular problem of slicing data to identify subsets of the validation data where the model performs poorly.
1807.07455_1004663_8	Results: On the CQ2000 dataset, the deep learning system demonstrated an AUC of 0.92(CI 0.91-0.94) for detection of abnormal scans, and AUC(CI) of 0.96(0.94-0.98), 0.96(0.94-0.98), 0.95(0.87-1), 0.95(0.92-0.98), 0.93(0.90-0.96), 0.89(0.83-0.94), 0.91(0.87-0.96), 0.94(0.93-0.96), 0.98(0.97-1) for the detection of blunted costophrenic angle, cardiomegaly, cavity, consolidation, fibrosis, hilar enlargement, nodule, opacity and pleural effusion.
1807.08671_1005879_3	Typical and potential research directions to which AI can make promising contributions need to be identified, evaluated, and investigated.
1808.02608_1011754_3	Although this multi-level approach achieves significant error reduction in the Wall Street Journal (WSJ) task, two different LMs need to be trained and used for decoding, which increase the computational cost and memory usage.
1808.09031_1018177_4	In an experiment using this data set, an LSTM language model performed poorly on many of the constructions.
1808.10000_1019146_6	We find that this model represents the first empirical success for latent tree learning, and that neural network language modeling warrants further study as a setting for grammar induction.
1808.10627_1019773_2	We show that the model finds a relation between the licensing context and the negative polarity item and appears to be aware of the scope of this context, which we extract from a parse tree of the sentence.
1809.00066_1020082_2	Our language model proves surprisingly good at identifying the selectional restrictions of English derivational morphemes, a task that requires both morphological and syntactic awareness.
1809.00066_1020082_3	Thus we conclude that, when morphemes overlap extensively with the words of a language, a character language model can perform morphological abstraction.
1809.02306_1022322_1	The proposed model, which we call multilingual neural language models, takes sentences of multiple languages as an input.
1809.03014_1023030_5	The beam pair selection algorithm learns coarse beam directions in some predefined beam codebook, e.g., in discrete angles separated by the 3dB beamwidths.
1809.03964_1023980_3	Our proposed model considers historical air pollution records and historical meteorological data.
1809.04797_1024813_2	The potential for AI assistance in the health domain is immense, because AI can support medical decision making at reduced costs, everywhere.
1809.05762_1025778_6	It concludes that AI technology can support each of these four areas.
1809.06606_1026622_3	Present-day AI research still does not widely consider situations for interacting directly with humans and within human-populated environments, which present inherent uncertainty in dynamics, structure, and interaction.
1809.06800_1026816_2	However, visual co-articulation effects in visual speech signals damage the performance of visual speech LM's as visually, people do not utter what the language model expects.
1810.00485_1031672_1	The sensor system consists of optical time-of-flight range measurement modules covered in a clear elastomer.
1810.02596_1033783_1	The system needs to efficiently allocate its frequency spectrum such that the spectrum utilization can be maximized while ensuring the quality of service (QoS) level.
1810.02866_1034053_5	The results indicate that the proposed hardening model through decentralized and distributed local energy resources can produce a more robust solution that can protect the system significantly against multiple component outages due to an extreme event.
1810.06338_1037525_0	  In order to engender trust in AI, humans must understand what an AI system is trying to achieve, and why.
1810.06338_1037525_1	To overcome this problem, the underlying AI process must produce justifications and explanations that are both transparent and comprehensible to the user.
1810.09030_1040217_7	AI developers found that our system can help them discover unknown errors made by the AI models, and engage in the process of proactive testing.
1810.09568_1040755_5	Furthermore, the model trains quickly, is compact, and allows for efficient real-time inference.
1811.00189_1044822_3	On the other hand, other unauthorized AI models cannot recognize it correctly because it functions as an adversarial example.
1811.01133_1045766_5	The introduced algorithm does not require knowledge or estimation of the directional interferers' directions nor the second-order statistics of noise-only components.
1811.01133_1045766_6	The introduced algorithm requires an estimate of the target speaker direction, but it is designed to be robust to some deviation from the estimated direction.
1811.01238_1045871_2	A computer-aided diagnosis (CAD) system involves various stages like detection, segmentation and classification of lesions in fundus images.
1811.01439_1046072_2	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break.
1811.05321_1049954_0	  Artificial Intelligence (AI) systems sometimes make errors and will make errors in the future, from time to time.
1811.09353_1053986_2	Experiments show that the unconditional model learns predictive distributions better than character LSTM models, discovers words competitively with nonparametric Bayesian word segmentation models, and that modeling language conditional on visual context improves performance on both.
1811.10676_1055309_6	The LM-BIC procedure selects the semiparametric specification that is nonparametric in age but parametric in all other variables, which is in line with the conclusions in Yatchew and No (2001).
1811.12185_1056818_4	The proposed algorithm used in this system learned the probability of state transition from experience as well as the system is adaptable to new changes by incorporating the concept of transfer learning.
1811.12185_1056818_7	The proposed system raises an alarm for the operator to warn which he may or may not overlook depending on his own perception about the present condition of the system.
1812.00815_1058389_2	The resulting system analyzes the text input with no word boundaries one token at a time, which can be a character or a byte, and uses the information gathered by the language model to determine if a boundary must be placed in the current position or not.
1812.04608_1062182_3	We discuss specific methods for evaluating: (1) the goodness of explanations, (2) whether users are satisfied by explanations, (3) how well users understand the AI systems, (4) how curiosity motivates the search for explanations, (5) whether the user's trust and reliance on the AI are appropriate, and finally, (6) how the human-XAI work system performs.
1812.06794_1064368_5	Scalability testing indicates the algorithm can analyze systems of up to 40 coupled PDEs on a desktop computer.
1812.06965_1064539_3	Stability analysis of different steady states is performed and threshold parameters are identified where the model exhibits clearance of infection or maintenance of a chronic infection.
1812.08200_1065774_3	The model makes predictions of the effective wave dissipation coefficient, as a function of the volumetric ratio of air to water, as well as to the rainfall rate.
1812.08597_1066171_1	Such decisions will need to be justified due to ethical concerns as well as trust, but achieving this has become difficult due to the `black-box' nature many AI models have adopted.
1901.03729_1073276_0	  Automated rationale generation is an approach for real-time explanation generation whereby a computational model learns to translate an autonomous agent's internal state and action data representations into natural language.
1901.05049_1074596_7	Our AI pipeline consists of four modular main steps: i) data ingestion, ii) model training, iii) deployment optimization and, iv) the IoT hub integration.
1901.08579_1078126_7	These findings suggest that AI experts expect major advances in AI technology to continue over the next decade to a degree that will likely have profound transformative impacts on society.
1901.08911_1078458_2	Stellar model fitting finds an effective temperature of $T_{\rm eff} = 36351 \pm 53$ K. The mass function, $f = 0.0010 \pm 0.0004$ M$_{\odot}$, favours a neutron star compact object.
1902.00837_1081921_2	At the same time, the long delay in wide area network is very likely to cause a tracking system to lose its target.
1902.03271_1084355_5	In particular, we will study the individual treatment profiles suggested by their AI Clinician to gain insight into how their AI Clinician intends to treat patients on an individual level.
1902.03817_1084901_4	To exploit these cues, our model learns to predict global emotional traits over a given image based on the joint analysis of every detected person and the whole scene.
1902.03817_1084901_5	By integrating these predictions with a data-driven convolutional neural network (CNN) classifier, our system efficiently infers potential human rights abuses in a clean, end-to-end system we call GET-AID (from Global Emotional Traits for Abuse IDentification).
1902.07613_1088697_4	We show that our model performs almost as well as the monolingual models by using six times fewer parameters, and is capable of better adaptation to languages not seen during training in a low resource scenario.
1903.00382_1092768_3	The model comprises thermodynamically consistent multi-species transport in alkaline electrolytes, formation and dissolution of metallic zinc and passivating zinc oxide, as well as multi-phase coexistence in gas diffusion electrodes.
1903.04766_1097152_8	Based on our study, the AI receiver can estimate time-varying channels with a single training phase.
1903.05456_1097842_1	The model considers the transient effects of air transport and its impact on the heat and moisture transfer.
1903.05720_1098106_1	The system consists of two key components -- namely, the prediction And-Or graph (AOG) model for recognizing and localizing concepts of interest in input data, and the XAI model for providing explanations to the user about the AOG's predictions.
1903.05720_1098106_3	Our XAI model takes pg's as input and provides answers to the user's questions using the following types of reasoning: direct evidence (e.g., detection scores), part-based inference (e.g., detected parts provide evidence for the concept asked), and other evidences from spatio-temporal context (e.g., constraints from the spatio-temporal surround).
1903.08412_1100798_5	The simulated AD system runs without any human intervention, and represents state-of-the-art model for C2 autonomy.
1903.09518_1101904_7	AI practitioners should make notions and concepts accessible to the general public and the impacted fields (e.g. industries, law, education).
1904.09408_1114448_1	Recently, GPT and BERT demonstrate the efficacy of Transformer models on various NLP tasks using pre-trained language models on large-scale corpora.
1905.00501_1118937_2	We find that AI can support the achievement of 128 targets across all SDGs, but it may also inhibit 58 targets.
1905.01023_1119459_3	AI has generally acquired its prominence over the past few years due to its considerable progress in various fields.
1905.04127_1122563_1	Traditionally, AI agents have suffered from difficulties in using only sensory inputs to obtain a good representation of their environment and then mapping this representation to an efficient control policy.
1905.04994_1123430_6	The explicit transformation of abstract moral values into concrete norms brings great benefits in terms of explainability; stakeholders know exactly how the system is interpreting and employing relevant abstract moral human values and calibrate their trust accordingly.
1905.05675_1124111_0	  In the last decade, artificial intelligence (AI) models inspired by the brain have made unprecedented progress in performing real-world perceptual tasks like object classification and speech recognition.
1905.09205_1127641_9	In our application to prediction of septic shock, the AI-driven analysis produces a competent machine learning model (AUROC 0.85
1905.10985_1129421_11	Because it it may be the fastest path to general AI and because it is inherently scientifically interesting to understand the conditions in which a simple algorithm can produce general AI (as happened on Earth where Darwinian evolution produced human intelligence), I argue that the pursuit of AI-GAs should be considered a new grand challenge of computer science research.
1905.12547_1130983_1	A relay system projects the incoherent light pattern emitting from the scattering layer onto the SLM.
1905.13053_1131489_2	We prove that it is impossible to precisely and consistently predict what specific actions a smarter-than-human intelligent system will take to achieve its objectives, even if we know terminal goals of the system.
1906.01496_1133682_3	The proposed multilingual LM consists of language specific word embeddings in the encoder and decoder, and one language specific LSTM layer, plus two LSTM layers with shared parameters across the languages.
1906.01702_1133888_2	The model does not require any linguistic annotation of phrase segmentation.
1906.03595_1135781_6	This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.
1906.06056_1138242_4	Additionally, we use self attention on embeddings to increase the lexical coverage by allowing the system to take union over different embeddings.
1906.11669_1143855_1	Our algorithm al-lows novice users to create quadrotor based use-cases withoutrequiring deep knowledge in either quadrotor control or theunderlying constraints of the target domain.
1906.12307_1144493_1	As AI systems affect various stakeholders due to their unique nature, the growing influence of these systems calls for ethical considerations.
1907.00151_1144687_2	While the proposed model learns to generate various forms of classical Chinese poems, including Jueju, L\"{u}shi, various Cipai and Couples, the generated poems are of very high quality.
1907.02052_1146588_1	GPT-2 has demonstrated impressive efficacy of pre-trained language models on various tasks, particularly coherent text generation.
1907.05575_1150111_5	The model takes the form of a stochastic policy for a Markov decision process (MDP) in which the reward function is learned from pairwise queries of a domain expert.
1907.12118_1156654_1	Based on the pay-per-click pricing model and the keyword targeting technology, the sponsored system runs online auctions to determine the allocations and prices of search advertisements.
1908.01551_1159721_5	Instead, we use room impulse responses (RIRs) to compute robust adversarial examples for arbitrary room characteristics and employ the ASR system Kaldi to demonstrate the attack.
1908.02624_1160794_1	AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars.
1908.09730_1167900_5	These results suggest that the DPLMS algorithm can perform better in identifying the unknown coefficients under the complex and changeable impulsive interference environments.
1908.11860_1170030_5	We show that a cross-domain adapted BERT language model performs significantly better than strong baseline models like vanilla BERT-base and XLNet-base.
1909.06842_1176880_1	Yet, training a deep neural network (DNNs) model requires a considerable amount of calculations, long running time, and much energy.
1909.08053_1178091_8	We show that careful attention to the placement of layer normalization in BERT-like models is critical to achieving increased performance as the model size grows.
1909.08582_1178620_4	The model learns how to combine words from parallel sentences and identifies when to switch one language to the other.
1909.09962_1180000_2	Optimizing over DAE loss allows our model to learn the nuances of an author's style without relying on parallel data, which has been a severe limitation of the previous related works in this space.
1909.10359_1180397_6	In the hard state, a thermal Comptonization model with two seed photons populations ($kT_{\rm s,1}\sim 1.5$ keV and $kT_{\rm s,2}\sim 0.4$ keV, respectively) and a hot Comptonising plasma, represents the physically best motivated scenario to describe the data.
1909.13273_1183311_1	Conventional model-driven methods e.g., Akaikes information criterion (AIC) and minimum description length (MDL), suffer from severe performance degradation when the number of snapshots is small or the signal-to-noise ratio (SNR) is low.
1909.13709_1183747_1	Their basic algorithm involves division by the difference of two approximate eigenvalues, and can become unstable when there are multiple eigenvalues.
1910.04404_1188323_1	It is even more important when the AI system makes decisions in multi-agent environments where the human does not know the systems' goals since they may depend on other agents' preferences.
1910.07089_1191008_2	To do this effectively, AI systems must pay more attention to aspects of intelligence that helped humans work with each other---including social intelligence.
1910.07496_1191415_1	The system comprises of a preprocessing unit to remove various types of noise, followed by a fetal electrocardiogram (FECG) extraction unit and an FHR detection unit.
1910.10147_1194066_1	The learning algorithm trains a discrete field theory from a set of observational data on a spacetime lattice, and the serving algorithm uses the learned discrete field theory to predict new observations of the field for new boundary and initial conditions.
1910.10147_1194066_5	In particular, the learning algorithm learns a discrete field theory from a set of data of planetary orbits similar to what Kepler inherited from Tycho Brahe in 1601, and the serving algorithm correctly predicts other planetary orbits, including parabolic and hyperbolic escaping orbits, of the solar system without learning or knowing Newton's laws of motion and universal gravitation.
1910.11235_1195154_0	  Exposure bias describes the phenomenon that a language model trained under the teacher forcing schema may perform poorly at the inference stage when its predictions are conditioned on its previous predictions unseen from the training corpus.
1910.11235_1195154_4	Our model produces an improvement over competing models with regards to BLEU scores and road exam, a new metric we designed to measure the robustness against exposure bias in language models.
1910.12041_1195960_1	Our system consists of a metallic thin film (Cu) coated sample and a needle tip in a box filled with air.
1910.12544_1196463_6	We will present proof-of-concepts to investigate whether and how our approach can help human-AI team to understand and benefit each other, and ultimately improve productivity and creativity on creative problem domains.
1910.12731_1196650_8	Our experimental results demonstrate that our proposed GPS-aided LiDAR-inertial odometry system performs very accurately.
1910.14080_1197999_3	The proposed algorithm does not require retraining of the model and can be integrated into any NLP system without additional training on paired cleaning training data.
1911.01387_1199981_10	Using an incremental support vector machine mechanism, this AI tool can quickly learn to distinguish spurious false alarms from more serious matters that deserve further attention.   
1911.01387_1199981_12	We observe that our model can identify over 90% of actionable warnings when our methods tell humans to ignore 70 to 80% of the warnings.
1911.04263_1202857_5	Effectiveness of the proposed approach is demonstrated in the "2019 Learn to Run a Power Network (L2RPN)" global competition, where the developed AI agents can continuously and safely control a power grid to maximize ATCs without operator's intervention for up to 1-month's operation data and eventually won the first place in both development and final phases of the competition.
1911.04395_1202989_2	The VR system consists of HTC Vive Pro base stations and head-mounted display (HMD), and Leap Motion controller for tracking the user's hands motion in VR.
1911.05604_1204198_6	The error analysis suggested that the model did not really perform deep reasoning and that clinical why-QA might warrant more sophisticated solutions.
1911.05649_1204243_4	Through semantic-level adversarial training and latent classification loss, the proposed model learns to extract domain-invariant content between inertial signal and trajectory, while preserving semantic consistency during the translation across the two domains.
1911.06915_1205509_5	We find that the TF-IDF model performs significantly better than the strongest BERT-based model on the test (best BERT PR-AUC $0.3597 \pm 0.0041$ vs TF-IDF PR-AUC $0.3878 \pm 0.0148$, $p=7\cdot 10^{-5}$), and is statistically comparable to the misspelling sets (best BERT PR-AUC $0.2579 \pm 0.0079$ vs TF-IDF PR-AUC $0.2733 \pm 0.0130$, $p=0.06$).
1911.08448_1207042_1	Its implementation, our fully automated momentum equity trading system presented systematically, proved to be successful in extensive historical and real-time experiments.
1911.12543_1211137_3	Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM.
1911.12543_1211137_6	Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1% to 39.6%, providing a tighter lower bound on what LMs know.
1912.01266_1213162_1	While maintaining a high predictive performance, our system explains to the clinician on which relevant electronic health records (EHRs) data the prediction is grounded.
1912.02164_1214060_5	Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency.
1912.03363_1215259_2	Well-known model adaptation techniques, to account for domain and style adaptation, are not easily applicable to end-to-end systems.
1912.07367_1219263_4	Although CMAQ model considers a coverage of the historic air pollution data and meteorological variables, extra bias is introduced due to additional adjustment.
1912.10163_1222059_10	As a result, our model can construct an answer that corresponds to the situation that underlies the question; it fills the gap between answer selection and generation and is the first model to move beyond the current simple answer selection model for non-factoid QAs.
1912.11999_1223895_6	In particular, the proposed algorithm performs quite well when the channel uncertainty is smaller than 10%.
1912.13283_1225179_6	Our main findings are that: (a) different LMs exhibit qualitatively different reasoning abilities, e.g., RoBERTa succeeds in reasoning tasks where BERT fails completely; (b) LMs do not reason in an abstract manner and are context-dependent, e.g., while RoBERTa can compare ages, it can do so only when the ages are in the typical range of human ages; (c)
2001.00463_1225876_7	The AI research community should consider concepts and policies from a broad set of adjacent fields, and ultimately needs to craft policy well-suited to its particular challenges.
2001.05291_1230704_6	The local search algorithm proved insufficient for maximizing coverage, while the Tabu search achieved near-optimal results.
2001.05838_1231251_5	The two-stage deep learning algorithm consists of U-Net segmentation model with the annotation scheme and CNN classifier model.
2001.07537_1232950_6	We challenge the BPM community to build on the AI interpretability literature, and the AI Trust community to understand
2001.08308_1233721_0	  Model-based geostatistical design involves the selection of locations to collect data to minimise an expected loss function over a set of all possible locations.
2001.09786_1235199_7	For example, if some algorithm needs data from multiple data owners to be pooled together, that raises the question of data ownership.
2002.03024_1240447_0	  Modern AI image classifiers have made impressive advances in recent years, but their performance often appears strange or violates expectations of users.
2002.04500_1241923_1	Artificial Intelligence (AI) systems, based on deep learning, have proven to achieve pathologist-level performance at Gleason grading.
2002.05013_1242436_0	  The automatic identification system (AIS) reports vessels' static and dynamic information, which are essential for maritime traffic situation awareness.
2002.05967_1243390_6	Among all single LMs (i.e. without model interpolation), the mixed-feature TRF LMs perform the best, improving over both discrete TRF LMs and neural TRF LMs alone, and also being significantly better than LSTM LMs.
2002.06675_1244098_5	We investigated four modeling units (phone, syllable, word piece, and word) and found that the syllable-based model performed best in terms of both word and phone recognition accuracy, which were about 60% and over 85% respectively in speaker-open condition.
2002.08909_1246332_2	To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference.
2002.09668_1247091_5	AI at the edge requires close cooperation among edge devices, such as smart phones and smart vehicles, and edge servers at the wireless access points and base stations, which however result in heavy communication overheads.
2002.10588_1248011_3	The binary star model represents that the smaller, less massive primary component is 427 K hotter than the pulsating secondary, and our distance of 612$\pm$36 pc is in good agreement with the $Gaia$ distance of 644$\pm$26 pc.
2003.00866_1251221_7	Particularly, compared to the other related survey papers, we provide an in-depth discussion on the Wireless AI applications in various data-driven domains wherein AI proves extremely useful for wireless network design and optimization.
2003.01525_1251880_0	  As Artificial Intelligence (AI) technology gets more intertwined with every system, people are using AI to make decisions on their everyday activities.
2003.02305_1252660_3	The model-based approach considers the MAV and airflow sensor dynamics and its interaction with the wind, while the deep learning-based strategy uses a Long Short-Term Memory (LSTM) neural network to obtain an estimate of the relative airflow, which is then fused in the proposed filter.
2003.02632_1252987_3	Our model learns the multimodal fusion of critical factors to predict future air quality levels.
2003.03604_1253959_3	However, current systems maintain this state in memory, which either imposes a maximum period of tolerated lateness, or causes the system to degrade performance or even crash when the system memory runs out.   
2003.04315_1254670_1	Methods that allow an AI to take advice from humans in response to explanations are similarly useful.
2003.06769_1257124_6	The focus length is the number of previous rounds that the multi-AI should look at when determining which Single-AI has the best performance and should choose to play for the next game.
2003.07107_1257462_4	The proposed system adopts power splitting mode, which is very promising for simultaneously providing energy and transmitting information of the user equipments without any external power supply.
2003.08080_1258435_13	The experiments on inner-project and cross-project data sets indicate that the newly proposed Hierarchical Language Model (HLM) performs better than the state-of-art LSTM model in dealing with the data inconsistency between training and testing and achieves averagely 11.2\% improvement in prediction accuracy.
2003.09624_1259979_1	The system consists of three particle detectors (scintillator modules) and one or more RF antennas.
2003.10378_1260733_1	The N-Tuple Bandit Evolutionary Algorithm (NTBEA) has proven very effective in optimising algorithm parameters in Game AI.
2003.10521_1260876_4	Our model consists of a set of three ordinary differential equations, which we solve numerically.
2003.12205_1262560_5	The model consists of two modules: a station selector and an air quality regressor.
2003.12808_1263163_1	Today's AI deployments often require significant human involvement and skill in the operational stages of the model lifecycle, including pre-release testing, monitoring, problem diagnosis and model improvements.
2004.02288_1267058_2	However, during the pretraining phase on the target domain, the LM models may catastrophically forget the patterns learned from their source domain.
2004.04479_1269249_5	Here the perturbed system produces whatever output is desired by the attacker on a specific small data set, perhaps even a single input, but performs as normal on a validation set (which is unknown to the attacker).
2004.04644_1269414_0	  The AI-alignment problem arises when there is a discrepancy between the goals that a human designer specifies to an AI learner and a potential catastrophic outcome that does not reflect what the human designer really wants.
2004.06799_1271569_4	The creation of a comparable ecosystem for simulation-to-real embodied AI presents many challenges: (1) the inherently interactive nature of the problem, (2) the need for tight alignments between real and simulated worlds, (3) the difficulty of replicating physical conditions for repeatable experiments, (4) and the associated cost.
2004.08377_1273147_0	  Various recent Artificial Intelligence (AI) system failures, some of which have made the global headlines, have highlighted issues in these systems.
2004.13332_1278102_10	Moreover, AI-driven tax policies perform strongly in the face of emergent tax-gaming strategies learned by AI agents.
2004.14614_1279384_2	The required knowledge to develop an effective conversation, however, is not always available, which is different from prior work's assumption that a model always has acquired sufficient knowledge before chatting.
2005.00683_1280478_5	Our analysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly on the diagnostic dataset prior to any fine-tuning; (2) fine-tuning with distant supervision brings some improvement; (3) the best supervised model still performs poorly as compared to human performance (54.06% vs 96.3% in accuracy).
2005.01971_1281766_1	While the incompressible Navier-Stokes system is discretized using a stabilized Petrov-Galerkin procedure, the multibody structural system consists of a generic interaction of multiple components such as rigid body, beams and flexible thin shells along with various types of joints and connections among them.
2005.02563_1282358_0	  High quality AI solutions require joint optimization of AI algorithms and their hardware implementations.
2005.02600_1282395_4	The measurement system consists of a multicopter, a total station, an inertial measurement unit (IMU), and a frequency-modulated continuous-wave (FMCW) radar operating from 1 GHz to 4 GHz.
2005.04650_1284445_1	This system comprises six independently operated unsteady minijet actuators, two hot-wire sensors placed in the jet, and genetic programming for the unsupervised learning of a near-optimal control law.
2005.04650_1284445_6	The best AI forcing produces a complex turbulent flow structure that is characterized by periodically generated mushroom structures, helical motion and oscillating jet column, all enhancing the mixing rate and vastly outperforming others.
2005.05477_1285272_2	This assumes, that there are limited morphological inflections per root, and that the majority will appear in a large enough corpus, so that the model can adequately learn statistics about each form.
2005.05538_1285333_4	It is of utmost importance that artificial intelligent agents have their values aligned with human values, given the fact that we cannot expect an AI to develop our moral preferences simply because of its intelligence, as discussed in the Orthogonality Thesis.
2005.05716_1285511_5	We show on examples of news segments how the proposed system can be used to inspect and potentially better understand what a model has learned (or emphasized).
2005.07942_1287737_8	By using mathematical analysis and simulation results, we validate that the proposed algorithm performs better than other existing schemes.
2005.07990_1287785_1	In order to take into account real characteristics of such vehicles, and to reflect practically motivated constraints, the algorithm assumes a highly uncertain system dynamics model.
2005.09980_1289775_4	Using the identical starting lines of human poems, GPT-2 produced samples of poems.
2005.12137_1291932_3	The potential for AI to support the response to the pandemic has been proposed across a wide range of clinical and societal challenges, including disease forecasting, surveillance and antiviral drug discovery.
2005.14165_1293960_8	At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.
2005.14410_1294205_10	Our results show that within a limited number of iterations our proposed model learns an effective scaling policy per workload, improving the performance compared to the default auto-scaling configuration.
2006.03291_1297805_7	A more complex three-component model comprising a multi-colour disc blackbody $\approx 0.30$ keV, single temperature blackbody $\approx 0.65$ keV and Comptonization from the disc, partially absorbed (about 38 per cent) by an ionized absorber (log($\xi$) $\approx$ 4) describes the broad-band spectrum equally well.
2006.04013_1298527_1	This shows the imperative need to develop means to endow common people with a minimum understanding of what AI means.
2006.04560_1299074_8	Furthermore, numerical results show that the proposed hybrid beamforming design substantially enhances the computation MSE performance as compared to other benchmark schemes, while the SCA-based algorithm performs closely to the performance upper bound achieved by the fully-digital beamforming.
2006.05509_1300023_9	All AI algorithms performed worse among the older age and people with prior TB history.
2006.05784_1300298_6	Moreover, in addition to automating the complex electricity procurement task, this algorithm demonstrates more consistent results throughout the years.
2006.07590_1302104_5	Our model performs 13% better than competitive baselines for short-term forecasting and 7% better for long term forecasting.
2006.11953_1306467_2	The proposed model considers the costs and probabilistic nature of transfer times and maximizes the reliability of the system using the available budget.
2006.12587_1307101_5	Our simulation model describes the interaction between pipelines and system infrastructure, and how pipeline tasks affect different ML model metrics.
2006.12695_1307209_2	To explore this question, we first propose a series of collaborative techniques to engage human pathologists with AI given AI's capabilities and limitations, based on which we prototype Impetus - a tool where an AI takes various degrees of initiatives to provide various forms of assistance to a pathologist in detecting tumors from histological slides.
2006.14779_1309293_0	  Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations.
2007.01599_1313113_6	Results acquired using these approaches show that the air traffic control model performs well on realistic traffic densities; it is capable of managing the airspace by avoiding 100% of potential collisions and preventing 89.8% of potential conflicts.
2007.01955_1313469_1	LMs for English enjoy ever growing corpora of diverse language resources.
2007.01955_1313469_6	Further experimental results on XQuAD and MLQA transfer-learning evaluation question answering tasks show that presumably multilingual LMs exhibit more resilience to machine translation artifacts in terms of the exact match score.
2007.03215_1314729_0	  With the increasing use of artificial intelligence (AI) services and products in recent years, issues related to their trustworthiness have emerged and AI service providers need to be prepared for various risks.
2007.04068_1315582_5	By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress.
2007.04490_1316004_5	AI and ML has already proven their effectiveness in different fields for classification, identification and automation with higher accuracy.
2007.05609_1317123_5	A single model makes it inflexible to utilize dynamic contextual information during inference.
2007.05609_1317123_9	Although an E2E model does not need pronunciation dictionary, it's interesting to make use of existing pronunciation knowledge to improve accuracy.
2007.10591_1322105_5	(a) By changing the basic segmentation model, the model can take into account the large objects and the boundary pixel classification of image details.
2008.00119_1327841_4	First, the model learns MRI signatures of cancer that are correlated with corresponding histopathology features using Common Representation Learning.
2008.01832_1329554_6	Experiments show that, the proposed new LSTM LM gets a better result on BLEU scores for long term sequence prediction.
2008.03301_1331023_3	In our new approach, however, the data-dependent hill-climbing search is replaced with a model-dependent search where a globally optimal SVM model is trained first, then the algorithm looks into support vectors as the most influential data points in the model, and induces a clause that would cover the support vector and points that are most similar to that support vector.
2008.03301_1331023_4	Instead of defining a fixed hypothesis search space, our algorithm makes use of SHAP, an example-specific interpreter in explainable AI, to determine a relevant set of features.
2008.03979_1331701_6	With those adjustments, our KR-BERT model performed comparably and even better than other existing pre-trained models using a corpus about 1/10 of the size.
2008.04057_1331779_5	Finally, in live play, the novel model demonstrates a human-to-transformer interface that correctly filters illegal moves and provides a novel method to challenge the transformer's chess strategies.
2008.04162_1331884_5	We further find that the model creates an accurate latent representation of the chessboard, and that it is possible to plot trajectories of legal moves across the board using this knowledge.
2008.04802_1332524_6	The vessel-based algorithm demonstrated strong performance with AUC-ROC = 0.96.
2008.05731_1333453_3	This algorithm, called ExplAIn, learns to segment and categorize lesions in images; the final image-level classification directly derives from these multivariate lesion segmentations.
2008.06208_1333930_1	The model consists of a big size common LM and small size adapters.
2008.06208_1333930_2	The model can perform multi-domain adaptation with only the small size adapters and its related layers.
2008.07371_1335093_2	A corollary of such widespread commercial deployment is that when AI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist behaviour; automated credit scoring processes discriminate on gender etc. - there are often significant financial, legal and brand consequences and the incident becomes major news.
2008.07371_1335093_6	In this paper, foregrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer an alternative explanation for AI errors: it is not so much that AI machinery cannot grasp causality, but that AI machinery - qua computation - cannot understand anything at all.
2008.09036_1336758_4	We explore three entity representations that allow LMs to represent millions of entities and present a detailed case study on paraphrased querying of world knowledge in LMs, thereby providing a proof-of-concept that language models can indeed serve as knowledge bases.
2008.10420_1338142_5	The proposed system communicates with the user via a smart phone application that provides various alerts, including notification of the need to recharge and/or decontaminate the mask prior to reuse.
2009.01180_1342683_9	System analysis demonstrates the robustness and the effectiveness of the proposed framework in real-time scenarios.
2009.01812_1343315_8	In addition, as reported in 2019, it took, on average, only around 0.2 year for AI preprints to receive their first citations, which is 5 times faster than 2000-2007.
2009.03393_1344896_3	GPT-f found new short proofs that were accepted into the main Metamath library, which is to our knowledge, the first time a deep-learning based system has contributed proofs that were adopted by a formal mathematics community.
2009.03533_1345036_0	  An unmanned aircraft system (UAS) consists of an unmanned aerial vehicle (UAV) and its controller which use radios to communicate.
2009.05615_1347118_2	In this method, an algorithm takes into account inputs (or constraints) from the schedule maker and then presents the possible solutions (incl.
2009.06082_1347585_6	The AI system then demonstrated a cognitive workflow, involving text analysis, image analysis, and reasoning, to process the question and generate the most probable answer.
2009.06807_1348310_1	Experimenting with prompts representative of different types of extremist narrative, structures of social interaction, and radical ideologies, we find that GPT-3 demonstrates significant improvement over its predecessor, GPT-2, in generating extremist texts.
2009.09079_1350582_1	This paper describes problems in AI research and how the SP System (described in an appendix) may help to solve them.
2009.11189_1352692_2	In the meantime of enriching the quantitative investment methodology, AI technologies have raised new challenges to the quantitative investment system.
2009.12898_1354401_14	The AI agent needs ~3s per case to predict fluence maps.$$$$   Conclusions: The developed AI agent can generate H&N IMRT plans with satisfying dosimetry quality.
2009.14001_1355504_1	While performances reach expert's level, interpretability (highlight how and what a trained model learned and why it makes a specific decision) is the next important challenge that deep learning methods need to answer to be fully integrated in the medical field.
2010.00828_1357158_8	System designers need to consider the potential adverse effects of introducing users or aids into systems.
2010.04827_1361157_0	  AI systems have found a wide range of application areas in financial services.
2010.04827_1361157_4	AI model governance frequently involves complex review flows and relies heavily on manual steps.
2010.05731_1362061_1	While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.
2010.05990_1362320_10	A highly-performing model allows the intelligent system to interpret human commands at the social-interaction level through a chatbot-like interface (e.g. "Robot, can we have a conversation?") and allows for better accessibility to AI by non-technical users.
2010.06608_1362938_7	Our model learns from only 16 pairs of small-volume LR-HR simulations, and is then able to generate SR simulations that successfully reproduce the HR matter power spectrum to percent level up to $16\,h^{-1}\mathrm{Mpc}$, and the HR halo mass function to within $10 \%$ down to $10^{11} \, M_\odot$. We successfully deploy the model in a box 1000 times larger than the training simulation box, showing that high-resolution mock surveys can be generated rapidly.
2010.07185_1363515_0	  High quality AI solutions require joint optimization of AI algorithms, such as deep neural networks (DNNs), and their hardware accelerators.
2010.07487_1363817_5	This model rests on two key properties of the vulnerability of the user and the ability to anticipate the impact of the AI model's decisions.
2010.09101_1365431_1	Recent work on language applications has made the AI code closer to biological reality in several ways.
2010.09101_1365431_2	This commentary examines this convergence and, in light of what is known of neocortical structure, addresses the question of whether ``general AI'' looks attainable with these tools.
2010.09890_1366220_1	In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently.
2010.09890_1366220_2	To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration).
2010.11604_1367934_5	Unlike prior efforts in natural language generation, our model can learn the judge's questioning intention through predefined knowledge.
2010.11639_1367969_4	Our bilingual model performs on par with Google's original English BERT on GLUE and nearly matches the performance of monolingual Finnish BERT on a range of Finnish NLP tasks, clearly outperforming multilingual BERT.
2010.11982_1368312_5	Despite our lenient evaluation methodology, we observe that a large pretrained language model performs poorly across all tasks.
2010.13912_1370242_1	This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks.
2010.14129_1370459_0	  Recently, AI-manipulated face techniques have developed rapidly and constantly, which has raised new security issues in society.
2010.15778_1372108_1	In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.
2011.01991_1374739_2	Trained with audio-transcript pairs, an E2E model implicitly learns an internal LM that characterizes the training data in the source domain.
2011.03751_1376499_1	However, developing AI/ML systems has presented several engineering problems that are different from those that arise in, non-AI/ML software development.
2011.08779_1381527_3	In this work, we consider the scenario where an AI system may need to operate at less-than-maximum accuracy in order to meet application-dependent energy requirements.
2011.09031_1381779_0	  Language model pre-training has proven to be useful in many language understanding tasks.
2011.09159_1381907_3	Since these are commonsense benchmarks, a model that generalizes on commonsense reasoning should not experience much performance loss across multiple commonsense benchmarks.
2011.09740_1382488_6	This model accounts for the main physical processes that determines the WSS, more particularly the compliance of the airways, the air inertia and the tree structure.
2011.10367_1383115_4	The algorithm implementation produces a GINI of 0.68 after tuning the hyper-parameters.
2012.00413_1388291_1	Recently, GPT-3, with 175 billion parameters and 570GB training data, drew a lot of attention due to the capacity of few-shot (even zero-shot) learning.
2012.06034_1393912_9	While many cases involving cooperation between humans and AIs will be asymmetric, with the human ultimately in control, AI systems are growing so complex that, even today, it is impossible for the human to fully comprehend their reasoning, recommendations, and actions when functioning simply as passive observers.
2012.06049_1393927_6	These advances may lead to a new era in computational simulation, in which sensors of many kinds are used to produce vast quantities of data, AI methods identify patterns in those data, and new AI-driven simulators combine machine-learned and mathematical rules to make accurate and actionable predictions.
2012.08013_1395891_1	We introduce new methods for acronym identification and disambiguation: our acronym identification model projects learned token embeddings onto tag predictions, and our acronym disambiguation model finds training examples with similar sentence embeddings as test examples.
2012.11995_1399873_3	Our results also show that pre-training on structured data does not always make the model acquire ability that can be transferred to natural language downstream tasks.
2012.14631_1402509_3	The differences in the meaning of a token in varying contexts are lost when each token is associated with a single representation; b) Existing language model based code completion models perform poor on completing identifiers, and the type information of the identifiers is ignored in most of these models.
2101.05494_1409236_7	We have presented the results from our approach in CONSTRAINT-2021 Shared Task on hostile post detection where our model performs extremely well with 3rd runner up in terms of Weighted Fine-Grained F1 Score.
2101.06098_1409840_4	Using the analytic lens of shared mental models, we report on the types of communication gaps that AI developers face, how AI developers communicate across disciplinary and organizational boundaries, and how they simultaneously manage issues regarding trust and expectations.
2101.07613_1411355_5	In addition, in order to adapt to the social trend of lightweight medical care, our model adopts the inverted residual with linear bottleneck in the module design to make it mobile and lightweight (reduce model parameters to one-eighth of its original) without sacrificing its performance.
2101.08779_1412521_3	We overcome these shortcomings by introducing key changes in its architecture design and supervision: FACT model involves a deep cross-modal transformer block with full-attention that is trained to predict $N$ future motions.
2101.09464_1413206_4	In the first step, the algorithm tries to identify the difficult words present in the text based on two features -- the number of syllables and usage frequency -- using a clustering algorithm.
2101.09464_1413206_8	The algorithm identifies the clusters which are difficult for the user, based on the result of the analysis.
2101.09635_1413377_6	Our model wangchanberta-base-att-spm-uncased trained on the 78.5GB dataset outperforms strong baselines (NBSVM, CRF and ULMFit) and multi-lingual models (XLMR and mBERT) on both sequence classification and token classification tasks in human-annotated, mono-lingual contexts.
2101.11131_1414873_1	Here, we introduce the corpus of Chinese linguistic minimal pairs (CLiMP), which can be used to investigate what knowledge Chinese LMs acquire.
2101.11435_1415177_5	The system can convey desired needs correctly by detecting P300 wave in acquired 14-channel EEG signal and classifying using linear discriminant analysis classifier just in 15 seconds.
2102.02437_1418926_6	It serves as a practical prototyping toolkit for HCI/AI practitioners and researchers to understand user requirements and build end-user-centered explainable AI.
2102.03406_1419895_7	This approach will allow for AI to interpret something as symbolic on its own rather than simply manipulate things that are only symbols to human onlookers, and thus will ultimately lead to AI with more human-like symbolic fluency.
2102.03683_1420172_1	The system needs to guarantee robust decoding in the sense that each user must decode its demanded function with signals received from any subset of servers whose cardinality exceeds a threshold.
2102.04255_1420744_1	This may be due to the conflicting ways through which distinct Artificial Intelligence (AI) research tracks conceive of their interface with social contexts.
2102.04887_1421376_7	In our approach, we design a teacher-student joint learning and distillation framework to collaboratively learn both teacher and student models, where the student model can learn from the learning experience of the teacher model.
2102.09268_1425757_9	The well-trained PLMs-based model from SpeedyFeed demonstrates highly competitive performance, where it outperforms the state-of-the-art news recommenders with significant margins.
2102.09690_1426179_0	  GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples.
2102.10535_1427024_4	We demonstrate that a fine-tuned model can perform well in code generation tasks, achieving a BLEU score of 0.22, an improvement of 46\% over a reasonable sequence-to-sequence baseline.
2102.10985_1427474_6	Our prototype planning system demonstrates the potential of our approach for rapid prototyping and flexibility of system composition.
2102.11567_1428056_4	It outlines why AI presents a unique tool for top-down and bottom-up anti-corruption approaches.
2102.11567_1428056_5	For both approaches, we outline in detail how AI-ACT present different potentials and pitfalls for (a) input data, (b) algorithmic design, and (c) institutional implementation.
2102.12592_1429081_2	Inspired by human documentation practices learned from 80 highly-voted Kaggle notebooks, we design and implement Themisto, an automated documentation generation system to explore how human-centered AI systems can support human data scientists in the machine learning code documentation scenario.
2103.04132_1434277_6	The hardware is only 18 grams in weight and 1.5 watts in energy consumption, and the developed DNN model needs only 838 kilobytes of disc space.
2103.04918_1435063_0	  There has been an emerging paradigm shift from the era of "internet AI" to "embodied AI", where AI algorithms and agents no longer learn from datasets of images, videos or text curated primarily from the internet.
2103.05434_1435579_2	To address this, we develop a normative framework for when it is ethical or unethical for a conversational AI to lie to humans, based on whether there is what we call "invitation of trust" in a particular scenario.
2103.07155_1437300_0	  A local surrogate for an AI-model correcting a simpler 'base' model is introduced representing an analytical method to yield explanations of AI-predictions.
2103.07155_1437300_2	The AI-model approximates the residual error of the linear model and the explanations are formulated in terms of the change of the interpretable base model's parameters.
2103.08405_1438550_6	Through a simulation study, we show that this model produces forecasts that result in higher revenue than traditional, time series forecasts.
2103.09147_1439292_3	The new DNN surrogate model also proves suited for general purposes: it is capable to reproduce the stress distribution in geometries topologically far different from those used for training, implying effective learning of scenarios described by the underlying partial differential equations.
2103.09147_1439292_4	Even in the case of elasto-plastic materials with up to 2 times mechanical contrast in elastic stiffness and 4 times in yield stress among adjacent regions, where conventional solvers typically require a substantial number of iterations to arrive at stress predictions, the trained model simulates the micromechanics with a MAPE of 6.4% in one single forward evaluation step of the network, i.e. without any iterative calculations even for the case of such a non-linear problem.
2103.11790_1441935_2	Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour.
2103.12407_1442552_3	We find that with zero- and one-shot learning, GPT-3 can identify sexist or racist text with an average accuracy between 55 per cent and 67 per cent, depending on the category of text and type of learning.
2103.14493_1444638_7	It adjusts per-layer bitwidth dynamically in order to save energy when a model can learn effectively with lower precision.
2103.14561_1444706_5	In this paper, we propose User-Oriented Smart General AI System under Causal Inference, abbreviated as UOGASuCI, where UOGAS represents User-Oriented General AI System and uCI means under the framework of causal inference.
2103.14988_1445133_4	Scripting system should support more complex NMR libraries, which will enable the emerging technologies to be easily implemented in the scripting environment.
2103.15294_1445439_1	However, at the same time, AI is also bearing serious controversies.
2103.15739_1445884_5	We wonder if ethical AI might be similarly achieved and advocate the process of automation as key step in making AI take ethical decisions.
2103.16168_1446313_0	  Designing human-centered AI-driven applications require deep understandings of how people develop mental models of AI.
2104.02526_1449944_4	This model takes the whole lattice as an input and predicts a new language score for each arc.
2104.03474_1450892_4	When scaled up to modern hardware, this model (despite its many limitations) performs much better than expected on word-level language model benchmarks.
2104.03740_1451158_9	The system prefers a moderate spin of about 0.85 for black hole masses between 4-6 M_sun for a 7 kpc distance.
2104.07204_1454622_5	Experiments on 11 Chinese natural language understanding tasks show that our model can bring an average increase of 1.5% under the 12-layer setting, which achieves new state-of-the-art among base-size models on the CLUE benchmarks.
2104.08017_1455435_5	We show that our model learns the inherent relationship between the embedding spaces and further probes into the scope of improvement by empirically analyzing the embedding methods.
2104.10403_1457821_6	We show that in comparison with standard DRL approaches, the proposed model-aided approach requires at least one order of magnitude less training data samples to reach identical data collection performance, hence offering a first step towards making DRL a viable solution to the problem.
2104.10809_1458227_1	This success raises the question of whether, in principle, a system can ever ``understand'' raw text without access to some form of grounding.
2104.10888_1458306_4	The developed surrogate model exhibited a remarkable accuracy (R2 score) of 0.72 and 0.87, with a mean absolute error of 11.8 GPa and 15.3 GPa for the shear and bulk modulus, respectively.
2104.12145_1459563_6	Given that GPT will perform better when given detailed and specific questions, we break down the PCSEL design problem into a series of sub-problems and converse with GPT by posing open-ended heuristic questions rather than definitive commands.
2104.12465_1459883_6	The proposed model consists of a contextualized video summary controller, multi-modal attention mechanisms, an interactive attention network, and a video summary generator.
2104.14088_1461506_1	However, the AI training demands tremendous computing resource, which is limited in most 6G devices.
2104.14506_1461924_7	AI can support rapid evaluation of CT scans to differentiate COVID-19 findings from other lung diseases.
2105.01016_1463575_6	The SR model performs satisfactorily on the halo occupation distribution, halo correlations in both real and redshift space, and the pairwise velocity distribution, matching the HR results with comparable scatter, thus demonstrating its potential in making mock halo catalogs.
2105.06264_1468823_3	The expectations of AI are based on a strong and justified mistrust about the way that AI makes decisions.
2105.06673_1469232_6	Applied to ion association in solution, gas-hydrate crystal formation, and membrane-protein assembly, the AI agent identifies the many-body solvent motions governing the assembly process, discovers the variables of classical nucleation theory, and reveals competing assembly pathways.
2105.09701_1472260_3	(1) Both cropping training data and using synthetic data can help the model learn more discriminative features.
2105.10099_1472658_2	In a model of an environment, to learn to make decisions, this AI agent needs to interact with its environment and make explorative actions.
2105.11098_1473657_1	Therefore, the NMT model naturally involves the mechanism of the Language Model (LM) that predicts the next token only based on partial translation.
2105.12558_1475117_2	Advances in artificial intelligence (AI)-based image analysis have produced a multitude of automatic calcium scoring methods.
2105.13818_1476377_0	  We investigate the semantic knowledge of language models (LMs), focusing on (1) whether these LMs create categories of linguistic environments based on their semantic monotonicity properties, and (2) whether these categories play a similar role in LMs as in human language understanding, using negative polarity item licensing as a case study.
2106.00161_1477925_9	Initial detection models were successfully created using the famous You Only Look Once algorithm, which indicates the practicality of the proposed data.
2106.03373_1481137_8	The results show that the system can perform high-quality candidate retrieval, especially for those tail queries with uncommon demands.
2106.04832_1482596_4	Our results also indicate that model distillation may hurt the ability of cross-lingual transfer of sentence representations, while language dissimilarity at most has a modest effect.
2106.07380_1485144_7	The results showed that the neural network model performed the best when the loss of the models were compared.
2106.08850_1486614_8	Finally, the algorithm presented is extended to estimate the ROA of finitely many equilibrium point systems and of general equilibrium set (arbitrary equilibrium points and limit cycles) systems.
2106.11805_1489569_2	Considering the hardware limitations of the IoT devices, the proposed algorithm requires only power information to enable the beam focusing capability of the RIS.
2106.11805_1489569_7	The experimental results show that the proposed MTBS algorithm can properly control the transmission phase of the transmitter and the reflection phase of the RIS to focus the power at the receiver.
2106.14647_1492411_8	The resulting system demonstrated will get good at separating attack traffic from normal flow and auto-generate a label for attacks based on features that contribute to the attack.
2106.14720_1492484_2	We were particularly interested in what benefits GPT-3 could bring to the SemEval 2021 MeasEval task - identifying measurements and their associated attributes in scientific literature.
2106.15110_1492874_1	But language models (LMs) are trained on snapshots of data collected at a specific moment in time, and this can limit their utility, especially in the closed-book setting where the pretraining corpus must contain the facts the model should memorize.
2106.16122_1493886_0	  Departing from the claim that AI needs to be trustworthy, we find that ethical advice from an AI-powered algorithm is trusted even when its users know nothing about its training data and when they learn information about it that warrants distrust.
2107.01543_1495555_11	Numerical results indicate that 1) in high signal-to-noise ratio regions, the central limit model performs as an upper bound, while a lower bound is obtained by the curve fitting model; 2) the TS protocol has the best performance but requesting more time blocks than other protocols; 3) the ES protocol outperforms the MS protocol as the ES protocol has higher diversity gains.
2107.03438_1497450_2	Specifically, given a reconstructed 3D scene in the form of point clouds with 3D bounding boxes of potential object candidates, and a language utterance referring to a target object in the scene, our model successfully identifies the target object from a set of potential candidates.
2107.04022_1498034_5	To make AI agents more human centric, we argue that there is a need for a mechanism that helps AI agents identify when to break rules set by their designers.
2107.05019_1499031_7	System design parameters, especially length and burial depth, bore the most important influence on the thermal efficiency of the system.
2107.06641_1500653_0	  In the past few decades, artificial intelligence (AI) technology has experienced swift developments, changing everyone's daily life and profoundly altering the course of human society.
2107.06641_1500653_3	Thus, trustworthy AI has attracted immense attention recently, which requires careful consideration to avoid the adverse effects that AI may bring to humans, so that humans can fully trust and live in harmony with AI technologies.   
2107.06785_1500797_9	The bigger model will take more computation resources and need a longer time to complete the tasks.
2107.07425_1501437_6	The localization algorithm learns the unique patterns of the scattered magnets during training and detects them from the ongoing streaming of data during localization.
2107.08045_1502057_0	  Explainable AI constitutes a fundamental step towards establishing fairness and addressing bias in algorithmic decision-making.
2107.10356_1504368_2	Methods: Using private and public datasets we evaluate: A) performance quantification of deep learning models to detect race from medical images, including the ability of these models to generalize to external environments and across multiple imaging modalities, B) assessment of possible confounding anatomic and phenotype population features, such as disease distribution and body habitus as predictors of race, and C) investigation into the underlying mechanism by which AI models can recognize race.   
2107.10658_1504670_5	The system supports a character input and gives a speech waveform at the output.
2107.11100_1505112_4	Furthermore, the proposed model can determine if a sample is packed or encrypted with a precision of 85%.
2107.12627_1506639_0	  Though the pre-trained contextualized language model (PrLM) has made a significant impact on NLP, training PrLMs in languages other than English can be impractical for two reasons: other languages often lack corpora sufficient for training powerful PrLMs, and because of the commonalities among human languages, computationally expensive PrLM training for different languages is somewhat redundant.
2107.12930_1506942_4	We compare the results of fine-tuning a gaBERT model with an mBERT model for the task of identifying verbal multiword expressions, and show that the fine-tuned gaBERT model also performs better at this task.
2107.13465_1507477_3	The proposed clinical workflow of AIACR is as follows given an initial contour that requires a clinicians revision, the clinician indicates where a large revision is needed, and a trained deep learning (DL) model takes this input to update the contour.
2108.00588_1509403_3	Objectives: Our overall objective is to help fill this gap, investigating what kinds of diverse users an AI product leaves out, and how to act upon that knowledge.
2108.02346_1511161_1	The system model consists of one base station (BS) and one RIS that is deployed to enhance the performance of both eMBB and URLLC in terms of the achievable data rate and reliability, respectively.
2108.02618_1511433_0	  Artificial Intelligence (AI) and Machine Learning (ML) algorithms can support the span of indicator-level, e.g. anomaly detection, to behavioral level cyber security modeling and inference.
2108.03502_1512317_5	Despite being able to produce sensible summaries, our model still suffers from a number of flaws, namely, it is prone to altering Named Entities present in the original text (such as surnames, places, dates), deviating from facts stated in the given document, and repeating the information in the summary.
2108.05158_1513973_2	But, the model for the multiple-choice task does not infer the answer.
2108.06159_1514974_0	  In the last years, AI systems, in particular neural networks, have seen a tremendous increase in performance, and they are now used in a broad range of applications.
2108.07400_1516215_6	A representative industrial water process system case study illustrates the strengths of the proposed formalism.
2108.07856_1516671_6	Results: The proposed system, demonstrated significantly improved mitotic counting performance for 41 cancer cases across 14 cancer types compared to human expert baselines.
2108.07879_1516694_1	AI hardware architectures today cannot meet the demand due to a fundamental "memory wall": data movement between separate compute and memory units consumes large energy and incurs long latency.
2108.12175_1520990_7	The system accepts text as the input, either manually verified annotations or automatically generated transcripts.
2108.12238_1521053_4	The model constructs a city graph and a city group graph to model the spatial and latent dependencies between cities, respectively.
2108.13902_1522717_6	The proposed model performs with high accuracy when evaluated against air quality measurements from ground stations (mean absolute error $<$6$~\mu g/m^3$).
2109.01207_1524028_2	Previous works hypothesized that these LMs internally project representations of different languages into a shared cross-lingual space.
2109.01479_1524300_8	By directly feeding the available texts in a pre-trained transformer architecture, our model does not need any hand-crafted stylometric features that are not meaningful in scenarios where the writing style is, at least to some extent, standardized.
2109.01962_1524783_3	We propose a new methodology to evaluate the faithfulness of explanations from the \textit{counterfactual reasoning} perspective: the model should produce substantially different outputs for the original input and its corresponding counterfactual edited on a faithful feature.
2109.03004_1525825_2	With the combination of the pre-trained RoBERTa and GPT-2, our model realizes a new state-of-the-art emotion accuracy.
2109.03537_1526358_9	Our work reveals that even if the LMs are not pre-trained on natural language, they still gain transferability on certain human language downstream tasks once the LMs learn to model the token dependencies in the sequences.
2109.03542_1526363_3	The proposed system intelligently produces potential gas sampling locations based on the current estimation of the wind field and the local map.
2109.04646_1527467_2	Engineering AI systems that aid emergency personnel proves to be a difficult system engineering problem.
2109.04646_1527467_3	Mission-critical "edge AI" situations require low-latency, reliable analytics.
2109.04865_1527686_1	However, AI models require a large amount of sensitive training data and are usually computationally intensive to build.
2109.05014_1527835_6	Specifically, we first convert the image into captions (or tags) that GPT-3 can understand, then adapt GPT-3 to solve the VQA task in a few-shot manner by just providing a few in-context VQA examples.
2109.05334_1528155_4	It is shown that the SOHE model can explain almost all phenomena and characteristics observed so far in the low-resolution MIMO signal reception.
2109.06137_1528958_4	The spline perturbation model finds potential signs of additional features in the primary mass distribution at lower masses similar to those previously reported by Tiwari and Fairhurst (2021).
2109.06515_1529336_5	As the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually.
2109.07848_1530669_6	As a response to disambiguating cues, the LMs often select the correct interpretation, but occasional errors point to potential areas of improvement.
2109.08913_1531734_2	The proposed channel model consists of a transmitter (Tx) and a receiver (Rx) both equipped with uniform linear arrays, and an IRS is used to enable communications between the transmitter and the receiver through the LoS links seen by the IRS.
2109.09904_1532725_3	The jury is still out on whether AI systems will need to use symbols in their internal reasoning to achieve general intelligence capabilities.
2109.11129_1533950_3	Our method introduces an additional meta-pretraining phase before cross-lingual pretraining, where the model learns generalization ability on a large-scale monolingual corpus.
2109.12798_1535619_6	The model comprises a modular hierarchical reinforcement-learning architecture of parallel and layered, generative-inverse model pairs.
2109.12912_1535733_3	The AI community is trying to overcome the problem by introducing the Explainable AI (XAI) field, which is tentative to make AI algorithms less opaque.
2109.14728_1537549_6	We surveyed audience members after each performance as well as performers to evaluate how well the AI performed in its role as narrator.
2110.01108_1539251_4	We argue that our work is a cornerstone towards the ultimate future of Human-AI Collaboration for DS and beyond, where AI and humans can take complementary and indispensable roles to achieve a better outcome and experience.
2110.01834_1539977_0	  AI systems have seen dramatic advancement in recent years, bringing many applications that pervade our everyday life.
2110.04249_1542392_3	Although AI research has recently made it increasingly possible to create artificial systems with affective processing, most cognitive neuroscience and AI research do not jointly address the issues of empathy in AI and cognitive neuroscience.
2110.04452_1542595_2	Besides reasoning about the knowledge and actions of individual agents, social AI logic can reason also about social dependencies among agents using the rights, obligations and permissions of the agents.
2110.05354_1543497_1	Language model (LM) fusion-based approaches require an additional external LM during inference, significantly increasing the computation cost.
2110.05354_1543497_3	Trained with audio-transcript pairs, an E2E model implicitly learns an internal LM that characterizes the token sequence probability which is approximated by the E2E model output after zeroing out the encoder contribution.
2110.05529_1543672_7	The proposed model formulates the goal of optimizing energy efficiency in data centers as a multi-objective scheduling problem, considering three important models: energy, thermal and cooling.
2110.06961_1545104_8	GPT-2 always acts as the best teacher, though, and using it and a Transformer-XL student on Wiki-02, rank-based KD reduces a cross-entropy baseline from 65.27 to 55.94 and against a KL-based KD of 56.70.
2110.09290_1547433_1	In this paper, we observe that AI expertise requires integrating computational, conceptual, and mathematical knowledge and representations.
2110.10185_1548328_5	The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.
2110.12010_1550153_2	In particular, climate-related texts include specific language that common LMs can not represent accurately.
2110.13341_1551484_1	The answer might seem an obvious `yes', in the sense that all (current) AI strictly acts in accordance with programming code constructed from highly formalized and well-defined rulesets.
2110.13341_1551484_10	In this essay, I defend the following answer: Rule-following AI should act in accordance with the interpretation best supported by minimally defeasible interpretive arguments (MDIA).
2110.14419_1552562_3	These norms entail that the relevant AI systems must meet a certain standard of public justification, support citizens rights, and promote substantively fair outcomes -- something that requires specific attention be paid to the impact they have on the worst-off members of society.
2110.15482_1553625_1	Under certain hypothesis, the considered model takes values in positive domain $(0,\infty)$.
2110.15768_1553911_2	Unlike prior works, our channel model takes into account the spherical wavefront of the emitted electromagnetic waves and the spatial-wideband effect.
2111.00610_1554713_5	With a limited dataset, orders of magnitude smaller than that required by contemporary generative models, our model closely approximates babbling speech.
2111.01726_1555829_2	Specifically, an AI examines human actions and calculates variations on the human strategy that lead to better performance.
2111.02001_1556104_1	While the AI community has made rapid progress, there are challenges in certifying AI systems.
2111.04165_1558268_0	  Artificial intelligence AI can bring substantial benefits to society by helping to reduce costs, increase efficiency and enable new solutions to complex problems.
2111.04916_1559019_2	In this paper, we discuss our views on today's challenges and opportunities that AI has presented on research software development and engineers, and the approaches we, at the University of Florida, are taking to prepare our workforce for the new era of AI.
2111.05108_1559211_1	However, most AI-based methods make predictions of suspicious samples in a black-box manner without transparency on models' inference.
2111.05391_1559494_5	That is, the system can perform its designed functionality for the intended period.
2111.05827_1559930_0	  AI modeling for source code understanding tasks has been making significant progress, and is being adopted in production development pipelines.
2111.06614_1560717_0	  AI agents need to be robust to unexpected changes in their environment in order to safely operate in real-world scenarios.
2111.07627_1561730_3	The model also accounts for the exchange of these two gases with blood in the capillaries, as well as for age, gender and other in-species characteristics.
2111.08168_1562271_0	  Medical AI algorithms can often experience degraded performance when evaluated on previously unseen sites.
2111.08168_1562271_3	However, such tests do not explain why the model performs worse.
2111.11923_1566026_2	The algorithm does not require any knowledge about the underlying hardware or channel.
2111.12444_1566547_3	By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks.
2111.14938_1569041_0	  Traditional AI approaches in customized (personalized) contextual pricing applications assume that the data distribution at the time of online pricing is similar to that observed during training.
2112.00331_1570107_4	AI.R Taletorium consists a neural story generator and a doodler-based fairy tale visualizer.
2112.01282_1571058_0	  The AI landscape demands a broad set of legal, ethical, and societal considerations to be accounted for in order to develop ethical AI (eAI) solutions which sustain human values and rights.
2112.02747_1572523_5	Assuming an AI expert trained using expert human labels, we ask (i) what is the best transferable knowledge we can extract from AI, and (ii) what is the most practical means to measure the gains in expertise given that knowledge?
2112.03625_1573401_2	This allows the model to learn generalizable features as well as distinguishing features between datasets.
2112.04729_1574505_4	Simulation results show that our BULT algorithm can perform close to the derived BCRB, and significantly outperforms the counterpart algorithms without exploiting the temporal correlation of the user location.
2112.06207_1575983_5	Numerical results show that the proposed robust design algorithm can ensure communication quality of the user in the presence of both hardware impairments and imperfect CSI.
2112.06883_1576659_8	The system can further perform cohort generation and preliminary dataset analysis in 2-5 minutes.
2112.11471_1581247_1	As AI systems demonstrate increasingly strong predictive performance, their adoption has grown in numerous domains.
2112.13834_1583610_4	In zero-shot probing experiments, we find that generative LMs produce poor ESDs with mostly omitted, irrelevant, repeated or misordered events.
2112.13922_1583698_6	Through the application of Logistics Regression, Random Forest, and Gradient Boosted Trees algorithms, we found that a Logistic Regression algorithm, fitted to our data, produced the most accurate results.
2112.15047_1584823_1	Cavitation bubbles are generated in real solutions without the use of optical traps making our system as close to real conditions as possible.
2112.15360_1585136_7	We argue that the possibility of AI taking over human civilization is low as developing such an advanced system requires a better understanding of the human brain first.
2201.01041_1586413_4	We find that the mrDMD algorithm identifies high-priority sensor locations in the western United States, but a significantly lower density of sensors than expected along the eastern coast, where a large number of EPA PM2.5 monitors currently reside.
2201.02730_1588102_1	Unfortunately, AI's capabilities and vulnerabilities make it a double-edged sword that may jeopardize the security of future networks.
2201.05070_1590442_2	The machine learning model considers joint effects of variables (race/ethnicity, partisanship, age, etc.) simultaneously to capture the unique combination of these factors on the vaccination rate.
2201.06009_1591381_1	For example, GPT-3 would mistakenly interpret "What word is similar to good?" to mean a homophone, while the user intended a synonym.
2201.06009_1591381_4	Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past.
2201.07040_1592412_3	Furthermore, there is a lack of systematized meta-information that allows clinical AI researchers to quickly determine accessibility, scope, content and other characteristics of datasets and benchmark datasets relevant to the clinical domain.   
2201.07642_1593014_0	  Artificial Intelligence (AI) has significant potential for product design: AI can check technical and non-technical constraints on products, it can support a quick design of new product variants and new AI methods may also support creativity.
2201.09227_1594599_4	English LMs generally perform better than their other language counterparts, due to the availability of massive English corpora.
2201.10518_1595890_4	Preliminary experiments presented in this paper suggest the model is learning two related, but different patterns: the absorption of a node by a sub-graph and union of more dense sub-graphs.
2201.10608_1595980_8	In particular, DOM-LM demonstrates better generalization performance both in few-shot and zero-shot settings, making it attractive for making it suitable for real-world application settings with limited labeled data.
2201.10822_1596194_2	However, the challenges incorporate when the AI model conceives a lake of interpretation and intuition to the network service provider.
2201.11133_1596505_6	In this synthetically enhanced dataset, our AI ensemble reports an average of one misclassification for every month of searched advanced LIGO data.
2201.11260_1596632_8	Given a model trained to recommend clinical procedures for patients, can we trust the recommendation when the model considers a patient older or younger than all the samples in the training set?
2201.11441_1596813_4	The AI discovered a mechanism that redressed initial wealth imbalance, sanctioned free riders, and successfully won the majority vote.
2201.12501_1597873_7	We find that for parallel sentences across different languages, the transliteration-based model learns sentence representations that are more similar.
2202.00528_1599352_3	Our results show that: (i) Different LMs have different scaling properties, where architectural differences often have a significant impact on model performance at small scales, but the performance gap narrows as the number of parameters increases, (ii) Several design choices, including causal masking and language-modeling objectives for the source sequence, have detrimental effects on translation quality, and (iii) When paired with full-visible masking for source sequences, LMs could perform on par with EncDec on supervised bilingual and multilingual translation tasks, and improve greatly on zero-shot directions by facilitating the reduction of off-target translations.
2202.01281_1600105_2	Educational offerings for students are ever increasing, beyond university degree programs where AI education traditionally lay.
2202.04145_1602969_2	The model performs better than other models in offline tests and exhibits performance comparable to the best models in A/B/C tests.
2202.04173_1602997_6	We find that i) large LMs have similar toxicity levels as smaller ones given the same pre-training corpus, and ii) large LMs require more endeavor to detoxify.
2202.05313_1604137_0	  In the future, AI will increasingly find its way into systems that can potentially cause physical harm to humans.
2202.06431_1605255_4	Notably, we demonstrated that our model performs even better than those trained with the same amount of labeled data.
2202.06987_1605811_0	  Embodied AI has seen steady progress across a diverse set of independent tasks.
2202.08510_1607334_4	The AI system demonstrates reliable diagnostic performance by achieving class-average sensitivity of above 0.85 on a total of 1,212 slides from multicentric cohort.
2202.08901_1607725_3	We found that the presence of the affordance of interactively manipulating the AI system's prediction parameters affected users' dwell times, and eye-fixations on AOIs, but not mental workload.
2202.09292_1608116_9	This history tells us that effective AI safety management requires transdisciplinary approaches and a shared language that allows involvement of all levels of society.
2202.10098_1608922_4	The blockchain and artificial intelligence (AI) are innovative technologies to fulfil these two factors, by which the blockchain provides decentralised trading platforms for energy markets and the AI supports the optimal operational control of power systems.
2202.11264_1610088_6	As a result, our method utilizes the determination of state transition and the randomness of action selection of a Markov decision process, as well as the computational complexity of a deep neural network, collectively to make the blocks not easy to recompute and to preserve the order of transactions, while the blockchain nodes are exploited to train the same deep neural network with different data samples (state-action pairs) in parallel, allowing the model to experience multiple episodes across computing nodes but at one time.
2202.12107_1610931_3	As a result, the language model could produce simulations of a single-product inventory-control system and single-server queuing system given the domain-specific context, a detailed description of the process, and a list of variables with the corresponding values.
2203.00249_1613111_8	Model analysis demonstrates that both strategies contribute to the performance boost.
2203.00789_1613651_4	A physical threat monitoring system typically needs to address complex and even destructive incidents, such as fire, which is unrealistic to simulate in real life.
2203.01112_1613974_5	As an example use case, a graph neural network model known as MLPF, developed for the task of Machine-Learned Particle-Flow reconstruction in High Energy Physics, acts as the base model for optimization.
2203.03712_1616574_4	In particular, recent advances in Artificial Intelligence (AI) open the discussion as to whether AI can support the ongoing availability and accessibility of trustworthy public records.
2203.04364_1617226_4	Our model explicitly describes the dominant geomagnetic emission with a rotationally symmetric lateral distribution function, on top of which additional effects disturb the symmetry.
2203.04364_1617226_6	Our fully analytic model describes the entire footprint with only two observables: the geometrical distance between the shower impact point at the ground and the shower maximum $d_\mathrm{max}$, and the geomagnetic radiation energy $E_\mathrm{geo}$. We demonstrate that with this model, the electromagnetic shower energy can be reconstructed by kilometer-spaced antenna arrays with an intrinsic resolution of 5\% and a negligible bias.
2203.05784_1618646_8	Notably, our framework has been incorporated into a software by a clear aligner manufacturer, and real-world clinical cases demonstrate that our model can visualize crown-root-bone structures during the entire orthodontic treatment and can predict risks like dehiscence and fenestration.
2203.05999_1618861_0	  The AI for Experimental Controls project is developing an AI system to control and calibrate detector systems located at Jefferson Laboratory.
2203.06112_1618974_1	It is crucial to minimize and to quantitatively estimate the uncertainties in such analysis and do so with a precision and accuracy that matches those that AI/ML techniques bring.
2203.07559_1620421_0	  A well-calibrated neural model produces confidence (probability outputs) closely approximated by the expected accuracy.
2203.08774_1621636_2	The model consists of a pretrained neural sentence LM, a BERT-based context encoder, and a masked transformer decoder that estimates LM probabilities using sentence-internal and sentence-external information.
2203.08774_1621636_3	When context or metadata are unavailable, our model learns to combine contextual and sentence-internal information using noisy oracle unigram embeddings as a proxy.
2203.08807_1621669_7	Finally, fine-tuning AI models on the well-characterized and diverse DDI images closed the performance gap between light and dark skin tones.
2203.10996_1623858_3	In the application, people can share and browse their outfit-of-the-day (OOTD) photos, while AI analyzes them and suggests similar style OOTDs and related products.
2203.11065_1623927_7	Then, we show that our new algorithm efficiently performs price experimentation in order to generate more revenue over long horizons than classical methods that seek to maximize revenue only.
2203.11147_1624009_2	But users can't trust any given claim a model makes without fact-checking, because language models can hallucinate convincing nonsense.
2203.12788_1625650_3	As a result, we have relatively little understanding of whether neural LMs accurately estimate the probability of sequences in this heavy-tail of rare events.
2203.14753_1627615_3	As the alternating optimization algorithm suffers from high computation complexity, we further develop a knowledge-guided learning algorithm that exploits the structure of the analytic expression of the optimal transmit power to achieve computation-efficient transceiver design.
2203.15144_1628006_2	Here, we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations.
2203.15827_1628689_0	  Language model (LM) pretraining can learn various knowledge from text corpora, helping downstream tasks.
2203.15841_1628703_4	Such model checkers can reason only about simple input-output robustness properties of neural networks.
2203.15917_1628779_5	While the WFST prevents unrecoverable errors, the language model resolves contextual ambiguity.
2203.16634_1629496_4	Our findings indicate that causal LMs might derive positional awareness not only from the explicit positioning mechanism, but also from the effects of the causal mask.
2204.01081_1631219_0	  AI Blitz XIII Faces challenge hosted on www.aicrowd.com platform consisted of five problems: Sentiment Classification, Age Prediction, Mask Prediction, Face Recognition, and Face De-Blurring.
2204.01440_1631578_3	We then investigate how an LM performs in generating a CN with regard to an unseen target of hate.
2204.02130_1632268_9	Compared with other systems under public benchmarks, our model proved to have better performance.
2204.03332_1633470_0	  In recent years, artificial intelligence (AI) technologies have found industrial applications in various fields.
2204.04949_1635087_6	The system consists of three modules; the image mosaic module and edge extension module process the image to improve the outcome of the hydrops lesion recognition module, which adopts a semantic segmentation network, our novel compound loss function, and a stepwise training function in order to achieve the best performance in identifying hydrops lesions.
2204.05356_1635494_6	This way, the model learns to accomplish the tasks via language generation without the need of training task-specific layers.
2204.06031_1636169_1	Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters.
2204.07464_1637602_5	In this paper, we inherit the model structure of BERT and design several syntax-related pre-training tasks so that the model can learn syntactic knowledge.
2204.07644_1637782_0	  Human-AI co-creativity involves humans and AI collaborating on a shared creative product as partners.
2204.07644_1637782_2	However, typically, the AI in co-creative systems cannot communicate back to humans, limiting their potential to be perceived as partners.
2204.07666_1637804_0	  Human-AI co-creativity involves both humans and AI collaborating on a shared creative product as partners.
2204.07934_1638072_9	The proposed model illustrates a better balance of the time cost and the fidelity requirements of evaluation for cruise and off-design conditions, which makes the model more feasible for industrial applications.
2204.07994_1638132_4	Based on these observations, we develop two solutions to help the model learn more knowledge from unstructured text in a fully self-supervised manner.
2204.08859_1638997_2	Typically, AI supports humans in decision-making by addressing human limitations.
2204.11788_1641926_0	  Despite impressive performance in many benchmark datasets, AI models can still make mistakes, especially among out-of-distribution examples.
2204.13217_1643355_0	  Human-AI co-creativity involves humans and AI collaborating on a shared creative product as partners.
2204.13217_1643355_3	Typically, the AI in co-creative systems cannot communicate back to humans, limiting their potential to be perceived as partners rather than just a tool.
2204.13217_1643355_7	Users perceive co-creative AI as more reliable, personal, and intelligent when the AI communicates to users.
2204.14226_1644364_11	The recommendations are intended to help AI developers demonstrate the utility of their products and to help regulatory agencies and end users verify reported performance measures.
2205.00072_1644484_0	  Effective human-AI collaboration requires a system design that provides humans with meaningful ways to make sense of and critically evaluate algorithmic recommendations.
2205.00084_1644496_9	Finally, we analyzed the attention of the transformer model and adapters, demonstrating that the proposed model understands the grammar of SMILES.
2205.02832_1647244_2	We propose a framework to analyze what LMs can infer about new entities that did not exist when the LMs were pretrained.
2205.04279_1648691_2	The direct alignment problem considers whether an AI system accomplishes the goals of the entity operating it.
2205.05126_1649538_0	  Research in artificial intelligence (AI)-assisted decision-making is experiencing tremendous growth with a constantly rising number of studies evaluating the effect of AI with and without techniques from the field of explainable AI (XAI) on human decision-making performance.
2205.07494_1651906_3	The proposed algorithm demonstrates superior performance over the state-of-the-art methods.
2205.07557_1651969_1	Queried with a zero-shot question-answering prompt, GPT-3 can identify the hero, villain, and victim in diverse domains: newspaper articles, movie plot summaries, and political speeches.
2205.07820_1652232_1	The traditional multi-ship air defense model does not consider the coordination between ships, and the model assumptions are often too simple to effectively describe the capabilities of the multi-ship cooperative air defense system in realistic combat scenarios.
2205.08404_1652816_2	As AI problems are getting even more complex, large processing power is demanded for safety-critical systems to fulfill real-time requirements.
2205.09330_1653742_3	Our CHARLES algorithm performs channel state information (CSI) estimation and adaptive scaling to mitigate the impacts of wireless channel fading.
2205.10045_1654457_1	The ExMo interpretable machine learning model consists of a list of IF...THEN... statements with a decision rule in the condition.
2205.10981_1655393_1	Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand.
2205.11758_1656170_4	In contrast, the point in pretraining when the model learns to transfer cross-lingually differs across language pairs.
2205.11758_1656170_5	Interestingly, we also observe that, across many languages and tasks, the final model layer exhibits significant performance degradation over time, while linguistic knowledge propagates to lower layers of the network.
2205.12600_1657012_1	However, it remains unclear from where the model learns the task-specific knowledge, especially in a zero-shot setup.
2205.12615_1657027_3	We make the surprising observation that LLMs can correctly translate a significant portion ($25.3\%$) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL.
2205.12749_1657161_4	By comparing the acceptance rates of provided solutions, we can assess how the AI system performs compared to the domain expert, and whether the AI system's explanations (if provided) are human-understandable.
2205.12805_1657217_5	Our model finds that the CO2 exosphere of Callisto is too dense to be sustained by impact-delivered volatiles, but could be maintained by only ~7 hectares of exposed CO2 ice.
2205.12805_1657217_7	Our model finds that to maintain Iapetus' two-tone appearance, its dark Cassini Regio likely has unresolved exposures of water ice, perhaps in sub-resolution impact craters, that amount to up to ~0.06% of its surface.
2206.04132_1664552_12	Finally, AI/ML researchers also exhibited significant optimism about how human-level machine intelligence will impact society.
2206.04776_1665196_1	From an ethical standpoint, the AI algorithm should take into account the vulnerability of objects or subjects on the street that ranges from "not at all", e.g. the road itself, to "high vulnerability" of pedestrians.
2206.04776_1665196_3	However, it is an open problem how to define the cost structure, who should be in charge to do that, and thereby define what AI-algorithms will actually "see".
2206.05658_1666078_2	Despite its recent success and wide adoption, fine-tuning a pre-trained language model often suffers from overfitting, which leads to poor generalizability due to the extremely high complexity of the model and the limited training samples from downstream tasks.
2206.06925_1667345_9	This model ensures traceability of drugs within a very simple way which is less complex compared to the existing ones.
2206.07271_1667691_6	We experimentally demonstrate that these heuristics make human judgment of AI-generated language predictable and manipulable, allowing AI systems to produce text perceived as "more human than human."
2206.07430_1667850_7	We experimentally confirmed that the proposed residual LM performs better than the internal LM estimation in most of the cross-domain and intra-domain scenarios.
2206.07635_1668055_2	In this paper, we take a closer look at how AI ethics issues take place in real world, in order to have a more in-depth and nuanced understanding of different ethical issues as well as their social impact.
2206.07948_1668368_4	By jointly training the classifier together with an allocation system, the classifier learns to accurately predict those instances that are difficult for the human experts, while the allocation system learns to pass each instance to the most suitable team member -- either the classifier or one of the human experts.
2206.08932_1669352_7	But, we believe it is only a matter of time before GPT-3 catches up on this particular task.
2206.08966_1669386_1	Some AI systems could present risks of events with very high or catastrophic consequences at societal scale.
2206.09360_1669780_6	The model also looks specifically at the question of learned optimization, and whether machine learning systems will create mesa-optimizers.
2206.09978_1670398_0	  Within the current AI ethics discourse, there is a gap in empirical research on understanding how AI practitioners understand ethics and socially organize to operationalize ethical concerns, particularly in the context of AI start-ups.
2206.09978_1670398_3	Building on social practice theory, we address this need via a framework that allows AI researchers, practitioners, and regulators to systematically analyze existing cultural understandings, histories, and social practices of ethical AI to define appropriate strategies for effectively implementing socio-technical innovations.
2206.10498_1670918_2	Most claims about LLM planning capabilities are however based on common sense tasks-where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge.
2206.10620_1671040_4	Its full-stack AI-oriented optimizations consist of a number of innovative optimizations at every layer of the DNN software stack, all designed in a cooperative manner.
2206.10912_1671332_6	Both AI modes -- automated and assisted -- produced an average increase in sensitivity (by 14% and 12%) and of F1-score (5% and 6%) and a decrease in specificity (by 10% and 3%, respectively).   
2206.11567_1671987_6	The system runs in real time on a laptop, suggesting that large-scale deployment on hearing aid chips could be achieved within a few years.
2206.13202_1673622_1	Learning to defer (L2D) has been presented as a promising framework to determine who among humans and AI should make which decisions in order to optimize the performance and fairness of the combined system.
2206.13349_1673769_2	Firstly, the AI system needs to follow guidelines or well-defined processes set by experts; the data alone will not be adequate.
2206.13349_1673769_8	For such applications, in addition to data and domain knowledge, the AI systems need to have access to and use the Process Knowledge, an ordered set of steps that the AI system needs to use or adhere to.
2206.14305_1674725_7	Performance metrics including yield (how many labeled images the model produced) and accuracy (percentage correct) were measured using the test set.
2206.15067_1675487_2	Unlike conventional systems that require auxiliary inputs such as manually defined emotion classes, our system directly estimates emotion-related attributes from the input text.
2206.15067_1675487_5	Consequently, the proposed system can produce emotional speech only from text without any auxiliary inputs.
2207.00477_1676375_2	An intelligent algorithm which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.
2207.00550_1676448_9	The "AI+R"-tree can automatically differentiate between the high- and low-overlap queries using a learned model.
2207.01493_1677391_1	Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies bring ethical well-being.
2207.01497_1677395_1	The human-AI alignment problem stems from the impracticality of explicitly specifying the rewards that AI models should receive for all the actions they could take in all relevant states of the world.
2207.01510_1677408_6	Positioning the discussion within the axes of interest and with a focus on reconciling the key tensions, we identify and propose the roles AI Regulation should take to make the endeavor of the AI Act a success in terms of AI fairness concerns.
2207.02463_1678361_8	Additionally, we re-discover a bias-performance trade-off: the better the model performs, the more bias it contains.
2207.08333_1684231_2	In this paper, we propose a quantitative metric "Equivariance Score" and evaluation dataset "Human Puzzle" to assess whether a VL model is understanding an image like a human.
2207.08333_1684231_3	We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.
2207.08954_1684852_4	We demonstrate the value of the generated pseudo labels in two specific tasks, open-vocabulary detection, where a model needs to generalize to unseen object categories, and semi-supervised object detection, where additional unlabeled images can be used to improve the model.
2207.08988_1684886_3	However, the DP-noise introduced to the model increases as the model size grows, which often prevents convergence.
2207.09085_1684983_3	Secondly, and from the point of view of the evolution of an author's ethical values, we checked what it would mean if the authorship attribution system encounters difficulties in detecting single authorship.
2207.13834_1689732_0	  In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions.
2207.14335_1690233_6	We show that a linear regression model using a single structural property -- length of the track and unclassified road network within 0.36% of districts within England and Wales (in the UK) -- can accurately estimate which districts are the most polluted.
2207.14335_1690233_7	The model presents a transparent and low-cost, yet effective, alternative to more expensive models such as the one currently used by DEFRA in the UK.
2207.14382_1690280_4	However, there has been a wide range of reactions and debate on whether these LLMs understand what they are saying or exhibit signs of intelligence.
2208.02321_1693033_5	The front-end system helps analyze contrails and their parameters across multiple simulation runs.
2208.02523_1693235_0	  AI-assisted colonoscopy has received lots of attention in the last decade.
2208.04675_1695387_6	We use a proof of concept that we validated with clinicians to demonstrate how current and upcoming AI capabilities support the workflow and how it would fit into clinical practice.
2208.06793_1697505_1	However, in order to outperform conventional communication systems, an RIS-aided system with solely passive reflection requires an extremely large surface.
2208.07601_1698313_2	The computation of the LM rate, however, has been a difficult task, due to the fact that the LM rate involves a maximization over a function of the channel input, which becomes challenging as the input alphabet size grows, and direct numerical methods (e.g., interior point methods) suffer from intensive memory and computational resource requirements.
2208.08176_1698888_0	  Neural language models are widely used; however, their model parameters often need to be adapted to the specific domains and tasks of an application, which is time- and resource-consuming.
2208.09312_1700024_6	However, such system would require concentrated investment, could contain Single-Points-of-Failure (SPoFs), would be a highly sought target of malicious attacks, and would be subject to periods of unavailability.   
2208.10806_1701518_2	However, the model may receive complicated impact from pre-training status, which changes accordingly as training time goes on.
2208.11243_1701955_3	However, most algorithms involve tricky parameter selection and complicated procedures that make the algorithm's decision rule obscure, so it is often difficult to explain and predict the errors and uncertainties of the resulting DTM.
2208.11282_1701994_3	In this paper we describe how these multi-AI systems can arise, even in relatively simple real-world humanitarian response scenarios, and lead to potentially emergent and erratic erroneous behavior.
2208.11910_1702622_6	From numerical experiments, we show that the DL model trained by the GAN generated samples performs close to that trained by the real samples.

2208.12539_1703251_1	Our system involves task-specific pre-training to improve LM representation of the masked object tokens, prompt decomposition for progressive generation of candidate objects, among other methods for higher-quality retrieval.
2208.12816_1703528_6	Unlike typical methods, our proposed complexity-driven algorithm selects a particular layer for filter-pruning based on its contribution to overall network complexity.
2209.00282_1705997_7	A second model, accounting for the Comptonization of the thermal emission from accretion disc along with an Fe emission line, describes the broad-band spectra of 2S 0921-63 equally well.
2209.01174_1706889_1	Sparse attention LMs can represent longer sequences, overcoming performance hurdles.
2209.03229_1708944_6	On May 1, 2022, persistent Laplacian-based AI projected Omicron BA.4 and BA.5 to become the new dominating COVID-19 variants.
2209.07753_1713468_3	When provided as input several example language commands (formatted as comments) followed by corresponding policy code (via few-shot prompting), LLMs can take in new commands and autonomously re-compose API calls to generate new policy code respectively.
2209.08982_1714697_6	We also find that the adaptation methods perform differently for different models and that unimodal model counterparts perform on par with the VL models regardless of adaptation, indicating that current VL models do not necessarily gain better language understanding from their multimodal training.
2209.09204_1714919_0	  Purpose: Artificial intelligence (AI) solutions for medical diagnosis require thorough evaluation to demonstrate that performance is maintained for all patient sub-groups and to ensure that proposed improvements in care will be delivered equitably.
2209.10254_1715969_3	This reduces their applicability, since LLMs requires expensive GPUs.
2209.10604_1716319_5	Our main contribution is a (non-exhaustive) exposition of potential AI risk factors and the causal relationships between them, focusing on how AI can affect power dynamics and information security.
2209.10763_1716478_3	This system performed 13% better than the baseline and was the best performing system overall for this shared task.
2209.11433_1717148_4	For track 4, our system consisted of voice activity detection (VAD), speaker embedding extraction, agglomerative hierarchical clustering (AHC) followed by a re-clustering step based on a Bayesian hidden Markov model and overlapped speech detection and handling.
2209.11515_1717230_6	Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity.
2209.11902_1717617_5	Finally, we have shown that model practically learns the rules of the chess game and can survive games against Stockfish at a category-A rating level.
2209.12153_1717868_1	In particular, we rewrite Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task.
2209.12277_1717992_0	  The conventional model aggregation-based federated learning (FL) approach requires all local models to have the same architecture, which fails to support practical scenarios with heterogeneous local models.
2209.12711_1718426_2	We evaluate 9 different tasks with negated prompts on (1) pretrained LMs (OPT & GPT-3) of varying sizes (125M - 175B), (2) LMs further pretrained to generalize to novel prompts (InstructGPT), (3) LMs provided with few-shot examples, and (4) LMs fine-tuned specifically on negated prompts; all LM types perform worse on negated prompts as they scale and show a huge performance gap between the human performance when comparing the average score on both original and negated prompts.
2209.12879_1718594_5	We will present our interdisciplinary approach, which combines interviews, workshops, online ethnography, and energy measurements, to address our research questions: How is Creative-Ai currently used by artist communities, and which future applications do artists imagine?
2209.13880_1719595_4	The arc-based model makes the flight delay decisions by duplicating flight copies, and is solved directly by commercial solvers such as Cplex.
2209.13880_1719595_5	The string-based model makes the flight delay decisions in the variable generation process.
2209.14927_1720642_7	Our experiments show that our model establishes SoTA results on several representative UI tasks and outperforms previous methods that use both screenshots and view hierarchies as inputs.
2210.00073_1721428_1	Backed by Artificial Intelligence, a surrogate model can present highly accurate results with a significant reduction in computation time than computer simulation of actual models.
2210.01478_1722833_1	In order to effectively collaborate with humans and ensure safety, AI systems need to be able to understand, interpret and predict human moral judgments and decisions.
2210.02969_1724324_1	However, meta-trained LMs still struggle to generalize to challenging tasks containing novel labels unseen during meta-training.
2210.02969_1724324_3	During inference, the LM trained with Flipped Learning, referred to as Flipped, selects the label option that is most likely to generate the task instruction.
2210.03350_1724705_7	In our method, the model explicitly asks itself (and answers) follow-up questions before answering the initial question.
2210.03575_1724930_5	While we would expect the predictive accuracy to correlate with human judgments of semantic compositionality, we find this is largely not the case, indicating that LMs may not accurately distinguish between compositional and non-compositional phrases.
2210.05173_1726528_1	In automatically deriving a system model, AI algorithms learn relations in data that are not detectable for humans.
2210.06376_1727731_7	Applying our method to BERT, producing a WordNet-enriched version named SynBERT, we find that LMs can learn non-trivial commonsense knowledge from self-supervision, covering numerous relations, and more effectively than comparable similarity-based approaches.
2210.06525_1727880_4	By unifying subword segmentation and language modelling, our model learns subwords that optimise LM performance.
2210.06649_1728004_1	A reliable XAI twin system for ZSM requires two composites: an extreme analytical ability for discretizing the physical behavior of the Internet of Everything (IoE) and rigorous methods for characterizing the reasoning of such behavior.
2210.06710_1728065_3	In this paper, we aim at understanding how well LLMs can perform table-related tasks with few-shot in-context learning.
2210.06725_1728080_1	In particular, a model may learn a reasoning process on in-domain training data that does not hold for out-of-domain test data.
2210.07884_1729239_6	Our algorithm finds all forgeries accurately (no false alarms) after analyzing 5.13 frames on average (corresponding to 1.28 seconds of video).
2210.08289_1729644_0	  Recently, Artificial Intelligence (AI) technology use has been rising in sports to reach decisions of various complexity.
2210.08536_1729891_0	  Knowledge-enhanced Pre-trained Language Model (PLM) has recently received significant attention, which aims to incorporate factual knowledge into PLMs.
2210.09439_1730794_4	We show that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the ``masked language model" unsupervised training objective.
2210.09492_1730847_6	Here, we fail to find convincing evidence that GPT-3 is reasoning about more than just individual lexical items.
2210.10514_1731869_2	Increasingly complex AI tasks demand shared resources, cross-device collaboration, and multiple data types, all without compromising user privacy or quality of experience.
2210.10779_1732134_8	The system performs in a robust manner, supporting radiologists and clinical colleagues in their important decisions, in practises and hospitals regardless of the user and X-ray system type producing the image-data.
2210.11584_1732939_2	In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review.
2210.12339_1733694_2	Specifically, P$^3$LM learns to generate tokens in permuted order upon an order-aware transformer decoder, as well as to generate the corresponding future $N$ tokens with a multi-stream attention mechanism.
2210.12353_1733708_6	The LLM needs what we term multiple choice symbol binding (MCSB) ability.
2210.12353_1733708_8	We show that a model with high MCSB ability performs much better with the natural approach than with the traditional approach across 20 diverse datasets and largely closes the gap with the SOTA, suggesting that the MCQA ability of LLMs has been previously underestimated.
2210.12476_1733831_8	Connected by high-speed networking, our system supports flexible frame rates up to 120 FPS and guarantees high precision and real-time tracking on low-end devices.
2210.13312_1734667_8	We find that even ChatGPT and GPT-4 do not display emergent Theory of Mind; strikingly even GPT-4 performs only 60% accuracy on the ToMi questions related to mental states and realities.
2210.14403_1735758_0	  When traditional pole-dynamics attacks (TPDAs) are implemented with nominal models, model mismatch between exact and nominal models often affects their stealthiness, or even makes the stealthiness lost.
2210.14611_1735966_11	In terms of DL architectures, the Turbulence Neural Transformer (TNT) model exhibited impressive accuracy, reaching 99.73% utilizing a 10-fold cross-validation approach.
2210.14986_1736341_7	We present our findings as the starting point for further research into evaluating how LLMs interpret language in context and to drive the development of more pragmatic and useful models of human discourse.
2210.15762_1737117_3	This similarity depends on how the model learns to encode context, which can be altered to include other attributes, such as style.
2210.15767_1737122_3	The report concludes that AI has made a major leap from the lab to people's lives in recent years, which increases the urgency to understand its potential negative effects.
2210.16651_1738006_0	  AI requires heavy amounts of storage and compute.
2210.17127_1738482_1	Recent research has revealed that neural language models at scale suffer from poor temporal generalization capability, i.e., the language model pre-trained on static data from past years performs worse over time on emerging data.
2210.17218_1738573_3	Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls.
2211.00593_1739499_2	In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI).
2211.00635_1739541_2	However, fine-tuning usually makes the model narrowly specialized on this dataset with reduced general in-context learning performances, which is undesirable whenever the fine-tuned model needs to handle additional tasks where no fine-tuning data is available.
2211.02744_1741650_3	In this work, we propose the Knowledge Graph Language Model (KGLM) architecture, where we introduce a new entity/relation embedding layer that learns to differentiate distinctive entity and relation types, therefore allowing the model to learn the structure of the knowledge graph.
2211.02759_1741665_2	To make AI opponents more human-like, we'd ideally like to see multiple different strategies at each level of difficulty, a concept we refer to as "multidimensional" difficulty.
2211.03309_1742215_0	  Over the past decade, machine learning model complexity has grown at an extraordinary rate, as has the scale of the systems training such large models.
2211.03358_1742264_10	", a causal language model should not express that [EVENTA&B] is likely.
2211.04584_1743490_4	We point out that to amplify AI's impact on carbon-neutral transition of the electric energy systems, the AI algorithms originally developed for other applications should be tailored in three layers of technology, markets, and policy.
2211.05030_1743936_6	In order for AI-powered writing assistants to realize their full potential, it is essential that they take into account the diverse goals and expertise of human writers.
2211.06753_1745659_1	While black-boxing AI systems can make the user experience seamless, hiding the seams risks disempowering users to mitigate fallouts from AI mistakes.
2211.07642_1746548_0	  Modern IT system operation demands the integration of system software and hardware metrics.
2211.07642_1746548_2	In the basic form, the decision model needs to monitor a large set of machine data, such as CPU utilization, allocated memory, disk and network latency, and predicts the system metrics to prevent performance degradation.
2211.07642_1746548_4	Moreover, this model needs to have low computational complexity and can scale efficiently to the dimension of data available.
2211.08361_1747267_6	Our system (hosted by Wikimedia at https://physwikiquiz.wmflabs.org) retrieves physics knowledge from the open community-curated database Wikidata.
2211.08412_1747318_1	To measure whether an LLM prefers factually consistent continuations of its input, we propose a new benchmark called FIB(Factual Inconsistency Benchmark) that focuses on the task of summarization.
2211.10384_1749290_1	Despite not passing the database's current criteria for incidents, these issues advance human understanding of where AI presents the potential for harm.
2211.10435_1749341_2	While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly.
2211.10623_1749529_1	In this paper, we investigate to what extent the pre-trained language model truly understands those SE tasks such as code search, code summarization, etc.
2211.10623_1749529_5	We refer to this phenomenon as overinterpretation, where a model confidently makes a decision without salient features, or where a model finds some irrelevant relationships between the final decision and the dataset.
2211.10938_1749844_4	Thus, the student model not only can learn the pre-trained model's predictive probabilities but also align the distributions between the pre-trained and student models.
2211.11492_1750398_5	In addition, our pipeline design allows the model to learn text-conditioned aesthetic cropping with a small cropping dataset, while inheriting the open-vocabulary ability acquired from millions of text-image pairs.
2211.13960_1752866_6	First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality.
2211.14611_1753517_0	  Data is a crucial infrastructure to how artificial intelligence (AI) systems learn.
2211.14611_1753517_3	Data-centric AI (DCAI) as an emerging concept brings data, its quality and its dynamism to the forefront in considerations of AI systems through an iterative and systematic approach.
2211.15006_1753912_7	The model produces consensus statements that are preferred by human users over those from prompted LLMs (>70%) and significantly outperforms a tight fine-tuned baseline that lacks the final ranking step.
2211.15426_1754332_4	AI performs a regression with various size of data window of previous exams to predict the probabilities of word appearance in the next exam.
2212.00460_1756637_3	Existing PLMs simply treat all corrupted texts as equal negative without any examination, which actually lets the resulting model inevitably suffer from the false negative issue where training is carried out on pseudo-negative data and leads to less efficiency and less robustness in the resulting PLMs.
2212.01681_1757858_2	Can LMs trained on text learn anything at all about the relationship between language and use?
2212.01681_1757858_4	When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context.
2212.01681_1757858_6	I survey findings from the recent literature showing that -- even in today's non-robust and error-prone models -- LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals.
2212.01779_1757956_1	Multilingual pre-trained language models can be trained on multiple languages, and the model can understand multiple languages at the same time.
2212.02075_1758252_6	The DFSAC algorithm takes the network packet delay as the joint reward value and introduces the global trend model as the joint target action-value function of each agent to guide the update of each agent's policy.
2212.02291_1758468_6	Our proposed model, I2MVFormer, learns multi-view semantic embeddings for zero-shot image classification with these class views.
2212.02291_1758468_7	We show that each text view of a class provides complementary information allowing a model to learn a highly discriminative class embedding.
2212.02475_1758652_3	A key improvement over dynamic evaluation is that FWLs can also be applied at training time so the model learns to make good use of gradient updates.
2212.02911_1759088_1	The model consists of two pretrained neural models that are fine-tuned for the poem generation task.
2212.02924_1759101_3	Through the performed in-depth intrinsic and extrinsic evaluations of this generation model along with the artificially generated data, we found that this model produced better results compared to the T5 model with a single soft prompt at encoder level and the sentiment classifier trained using this artificially generated data can produce comparable classification results to the results of a classifier trained with real labelled data and also the classifier decision is interpretable with respect to the input text content.
2212.03491_1759668_0	  While revolutionary AI-powered code generation tools have been rising rapidly, we know little about how and how to help software developers form appropriate trust in those AI tools.
2212.03699_1759876_1	However, existing conversational AI techniques still suffer from various limitations.
2212.03699_1759876_2	One such limitation is a lack of well-developed methods for incorporating auxiliary information that could help a model understand conversational context better.
2212.04792_1760969_1	The hydrodynamic model under consideration takes into account the important effects of airborne droplets of water in a thin layer above the water surface that effectively behave as a different fluid between the water and the air.
2212.05058_1761235_6	The model acts, we argue, as the condensation of often competing social desires, articulated through the internet and harvested into training data, which must then be regulated and repressed.
2212.05206_1761383_3	However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner.
2212.06556_1762733_1	When doing so, it is desirable that updating the model is fast and that the model does not lose its capabilities on data outside of the dataset, as is often the case with classical fine-tuning approaches.
2212.06823_1763000_1	Surprisingly, overreliance does not reduce when the AI produces explanations for its predictions, compared to only providing predictions.
2212.07508_1763685_0	  Motivated by mitigating potentially harmful impacts of technologies, the AI community has formulated and accepted mathematical definitions for certain pillars of accountability: e.g. privacy, fairness, and model transparency.
2212.07508_1763685_4	We argue that the AI community needs to consider all the consequences of choosing certain formulations of these pillars -- not just the technical incompatibilities, but also the effects within the context of deployment.
2212.09154_1765331_5	The results show that the Off-policy algorithm effectively develops a more fuel-efficient solution within the complete driving cycle compared with other algorithms.
2212.09251_1765428_5	We generate 154 datasets and discover new cases of inverse scaling where LMs get worse with size.
2212.09251_1765428_8	For example, RLHF makes LMs express stronger political views (on gun rights and immigration) and a greater desire to avoid shut down.
2212.09561_1765738_1	However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation.
2212.09561_1765738_2	The above issues make the LLMs need the ability to verify the answers.
2212.09736_1765913_5	A case study on the challenging problem of knowledge base question answering (KBQA), which features a massive environment, demonstrates the remarkable effectiveness and flexibility of Pangu: A BERT-base LM is sufficient for setting a new record on standard KBQA datasets, and larger LMs further bring substantial gains.
2212.09746_1765923_1	However, most benchmarks are non-interactive in that a model produces output without human involvement.
2212.10450_1766627_1	Having high-quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output.
2212.10450_1766627_2	GPT-3, a large-scale language model developed by OpenAI, has demonstrated impressive zero- and few-shot performance on a wide range of NLP tasks.
2212.10511_1766688_2	We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail.
2212.10559_1766736_5	On top of it, we understand ICL as follows: GPT first produces meta-gradients according to the demonstration examples, and then these meta-gradients are applied to the original GPT to build an ICL model.
2212.10561_1766738_0	  Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.
2212.11136_1767313_2	However, AI systems may produce errors, can exhibit bias, may be sensitive to noise in the data, and often lack technical and judicial transparency resulting in reduction in trust and challenges in their adoption.
2212.11136_1767313_6	Aim of XAI is to provide human understandable information of how AI systems make their decisions.
2212.11261_1767438_8	The evidence indicates that language-vision AI models trained on web scrapes learn biases of sexual objectification, which propagate to downstream applications.
2212.11311_1767488_5	With only a handful of prompts, the final model performs on par with existing supervised models.
2212.11661_1767838_0	  The latest AI language modules can produce original, high quality full short-form ($300$-word) Physics essays within seconds.
2212.11661_1767838_8	We argue that these results indicate that current AI MLPs represent a significant threat to the fidelity of short-form essays as an assessment method in Physics courses.
2212.12616_1768793_4	The results found that the ground-based blended RGB-LWIR model exhibited superior performance compared to the RGB or LWIR approaches, achieving a mAP of 98.4%.
2212.12744_1768921_2	However, the proposed algorithm suffers from high computational complexity, which hinders its application in some practical scenarios.
2212.13138_1769315_9	The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians.
2212.13261_1769438_5	Explainable artificial intelligence (XAI) aims to overcome the opaqueness of black-box models and provide transparency in how AI systems make decisions.
2212.13289_1769466_2	New Artificial Intelligence (AI) methods, including machine learning, data mining, and data assimilation, as well as new AI-enabled missions will need to be developed to meet this Sparse Data challenge.
2212.13338_1769515_3	An AI agent for one of these games means significant progress in AI agents for the entire class.
2212.13338_1769515_8	Our AI agent performed significantly better than all previous attempts and peaked at the 33rd place in the world, in one of the most popular battle formats, while running on only 4 single socket servers.
2212.13371_1769548_6	In our first experiment, we find that the AI agent decides to trust humans at higher rates when facing actual incentives than when making hypothetical decisions.
2212.13371_1769548_10	Furthermore, to address the possibility that the AI agent's trust decisions reflect a preference for uncertainty, the experiments include two conditions that present the AI agent with a non-social decision task that provides the opportunity to choose a certain or uncertain option; in those conditions, the AI agent consistently chooses the certain option.
2212.13631_1769808_2	On the one hand, AI can support applications in climate change mitigation (reducing or preventing greenhouse gas emissions), adaptation (preparing for the effects of a changing climate), and climate science.
2212.14402_1770579_9	While our ability to interpret these results is limited by nascent scientific understanding of LLMs and the proprietary nature of GPT, we believe that these results strongly suggest that an LLM will pass the MBE component of the Bar Exam in the near future.
2301.01181_1772245_1	An autoregressive large language model (OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are relevant to specific public companies and provides explanations and confidence levels.
2301.01768_1772832_2	ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release.
2301.01861_1772925_5	By recursively sampling the resulting policy and the surrogate transitions, the system translates the avoidance policy into a complete avoidance trajectory.
2301.01954_1773018_2	In an experiment, we study how AI advice (generated by a Natural-Language-Processing algorithm) affects (dis)honesty, compare it to equivalent human advice, and test whether transparency about advice source matters.
2301.02828_1773892_5	Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.
2301.03391_1774455_13	Ultimately, the AI$^{2}$ framework represents the next leap toward native language-based, human-oriented concerns about machine learning framework.
2301.03656_1774720_0	  Human-centered AI workflows involve stakeholders with multiple roles interacting with each other and automated agents to accomplish diverse tasks.
2301.04020_1775084_6	First, automated AI changes quant pipeline from traditional hand-craft modeling to the state-of-the-art automated modeling, practicing the philosophy of ``algorithm produces algorithm, model builds model, and eventually AI creates AI''.
2301.04020_1775084_7	Second, explainable AI develops new techniques to better understand and interpret investment decisions made by machine learning black-boxes, and explains complicated and hidden risk exposures.
2301.05133_1776197_2	AI art generators such as Dall-E and Midjourney can create fully rendered images based solely on a user's prompt, just at the click of a button.
2301.05272_1776336_4	Also, given that there are numerous critics of deep learning claiming that LLMs and related methods may soon lose their relevancy, we speculate that such an event could trigger a new wave of nativism in the language processing community.
2301.05578_1776642_0	  Generative AI technologies are growing in power, utility, and use.
2301.06937_1778001_1	To help people appropriately rely on AI aids, we propose showing them behavior descriptions, details of how AI systems perform on subgroups of instances.
2301.08745_1779809_3	By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages.
2301.08745_1779809_4	As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language.
2301.08745_1779809_7	Human analysis on Google Translate and ChatGPT suggests that ChatGPT with GPT-3.5 tends to generate more hallucinations and mis-translation errors while that with GPT-4 makes the least errors.
2301.09626_1780690_1	As the model sizes grow, the performance gap between English and other languages with fewer compute and data resources increases even further.
2301.10095_1781159_4	Instructions (in the case of language models, "prompts") that employ legal standards will allow AI agents to develop shared understandings of the spirit of a directive that generalize expectations regarding acceptable actions to take in unspecified states of the world.
2301.10823_1781887_5	In this paper we ask what reflective AI might look like.
2301.11596_1782660_0	  Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks.
2301.11916_1782980_7	Our empirical findings support our hypothesis that LLMs implicitly infer a latent variable containing task information.
2301.12473_1783537_7	The results illustrate that in contrast to encoder-only and encoder-decoder, decoder-only LLMs require further investigation.
2301.12652_1783716_3	Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions.
2301.12867_1783931_2	Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility.
2301.13089_1784153_1	An AI system that can enable students to ask questions via text or voice and get instant answers will make high-quality education accessible.
2301.13819_1784883_0	  ChatGPT has demonstrated exceptional proficiency in natural language conversation, e.g., it can answer a wide range of questions while no previous large language models can.
2302.00817_1785751_4	We found that the model performs better and with more consistency than equivalent nongeometric and nontemporal models.
2302.01020_1785954_2	Therefore, the question is how a predictive model can represent multiple predictions simultaneously.
2302.01215_1786149_0	  Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains.
2302.01339_1786273_5	For two of the ten questions, the language model produced at least one answer that experts selected more frequently than Dennett's own answer.
2302.02162_1787096_4	XAI tools can increase the vulnerability of model extraction attacks, which is a concern when model owners prefer black-box access, thereby keeping model parameters and architecture private.
2302.02944_1787878_6	We demonstrate the effectiveness of our proposed methods using data on real human responses and semi-synthetic, and find that our methods offer reliable and advantageous performance across setting, and that it is superior to when either the algorithm or the AI make decisions on their own.
2302.03287_1788221_6	As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum.
2302.04023_1788957_9	ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base.
2302.04116_1789050_3	The additional training process however diminishes the stealthiness of the attacks, as training a language model usually requires long optimization time, a massive amount of data, and considerable modifications to the model parameters.
2302.04335_1789269_6	In other words, ChatGPT can create content on many topics with high originality as if they were written by someone.
2302.04361_1789295_2	The algorithm developed is applied to an Urban Air Mobility case study.
2302.04536_1789470_7	In the experimental group, AI classifier recognized more potential AI-generated texts.
2302.04863_1789797_3	Specifically, we demonstrate that finetuned models that were optimized for high performance, reside in well-defined regions in weight space, and vice versa -- that any model that resides anywhere in those regions also exhibits high performance.
2302.04863_1789797_6	Our findings provide insight into the relationships between models, demonstrating that a model positioned between two similar models can acquire the knowledge of both.
2302.05206_1790140_1	The so-called algorithm, Reinforcement Learning with Human Feedback (RLHF) demonstrates impressive performance on the GPT series models.
2302.05206_1790140_4	Such an algorithm doesn't require any additional parameters except for the original language model and maximally reuses the pretraining pipeline.
2302.05733_1790667_5	In particular, we show that instruction-following LLMs can produce targeted malicious content, including hate speech and scams, bypassing in-the-wild defenses implemented by LLM API vendors.
2302.05817_1790751_2	Game levels, with their complex functional constraints and spatial relationships in more than one dimension, are very different from the kinds of data an LLM typically sees during training.
2302.05981_1790915_5	Here, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels.
2302.06100_1791034_8	We find GPT-3 performs poorly at answering straightforward questions about these simple synthetic statutes.
2302.06466_1791400_2	Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets.
2302.06476_1791410_5	We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging.
2302.06871_1791805_2	Should LLMs like ChatGPT produce educational content on par with human-authored content, the implications would be significant for further scaling of computer tutoring system approaches.
2302.06871_1791805_4	We find that 70% of hints produced by ChatGPT passed our manual quality checks and that both human and ChatGPT conditions produced positive learning gains.
2302.07081_1792015_1	AI has made substantial advancements in recent years, enabling the development of algorithms and systems that can perform tasks traditionally done by humans.
2302.07309_1792243_1	However, existing AI-assisted tools have not realized this promised potential due to a lack of insight into pathology and HCI considerations for pathologists' navigation workflows in practice.
2302.07406_1792340_3	The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses.
2302.07806_1792740_7	The AI-Pipeline consists of CNN, Optical flow, RCNN, pixel manipulation model, and U-net models in sequence.
2302.07856_1792790_1	However, even given the incredible quantities of data they are trained on, LLMs can struggle to translate inputs with rare words, which are common in low resource or domain transfer scenarios.
2302.08807_1793741_1	There is a limited understanding of how AI may perform in group decision-making.
2302.09977_1794911_9	Experimental results show that our model received state-of-the-art performance than other baselines.
2302.12173_1797107_5	We argue that LLM-Integrated Applications blur the line between data and instructions.
2302.12313_1797247_7	Based on a dataset of n=26,680 datapoints, we discovered that LLMs perform at chance accuracy and waver considerably in their answers.
2302.12813_1797747_3	Our system makes the LLM generate responses grounded in external knowledge, e.g., stored in task-specific databases.
2302.14115_1799049_2	Such a unified model requires large-scale training data, which is not available in current annotated datasets.
2302.14229_1799163_4	We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information.
2303.00293_1800090_0	  The GPT-3.5 models have demonstrated impressive performance in various Natural Language Processing (NLP) tasks, showcasing their strong understanding and reasoning capabilities.
2303.01248_1801045_0	  Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored.
2303.01255_1801052_0	  In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever.
2303.01255_1801052_4	And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet.
2303.01259_1801056_1	However, black-box AI techniques present some difficulties in comprehension and adoption by its operators, given that their decisions are not always humanly understandable (as is usually the case with deep neural networks, for example).
2303.01325_1801122_0	  AI Generated Content (AIGC) has received tremendous attention within the past few years, with content generated in the format of image, text, audio, video, etc.
2303.01421_1801218_3	We demonstrate that SeMem improves the scalability of semiparametric LMs for continual learning over streaming data in two ways: (1) data-wise scalability: as the model becomes stronger through continual learning, it will encounter fewer difficult cases that need to be memorized, causing the growth of the non-parametric memory to slow down over time rather than growing at a linear rate with the size of training data; (2) model-wise scalability: SeMem allows a larger model to memorize fewer samples than its smaller counterpart because it is rarer for a larger model to encounter incomprehensible cases, resulting in a non-parametric memory that does not scale linearly with model size.
2303.01692_1801489_1	The AI-based travel demand forecasting models, though generate accurate predictions, may produce prediction biases and raise fairness issues.
2303.02844_1802641_5	Compared to the ordinary neural network, our proposed model can exhibit better generalization capability with competitive prediction accuracy.
2303.03836_1803633_3	While ChatGPT has demonstrated impressive results in tasks like machine translation, text summarization, and question answering, it presents challenges when used for complex tasks like event extraction.
2303.04048_1803845_9	For the meta-evaluation datasets which are created greatly depending on the reference and thus are biased, the ChatGPT evaluator might lose its effectiveness.
2303.04226_1804023_6	With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation.
2303.06217_1806014_0	  The emergence of generative AI technologies, such as OpenAI's ChatGPT chatbot, has expanded the scope of tasks that AI tools can accomplish and enabled AI-generated creative content.
2303.06217_1806014_4	We discuss the implications of this work and outline planned pathways of research to better understand whether and when AI disclosure may affect the evaluation of creative content.
2303.06689_1806486_3	To this end, we introduce planning into code generation to help the model understand complex intent and reduce the difficulty of problem-solving.
2303.06689_1806486_5	Specifically, in the planning phase, LLM plans out concise solution steps from the intent combined with few-shot prompting.
2303.07610_1807407_1	Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences.
2303.08014_1807811_1	However, their internal workings remain a black box, and it is unclear whether LLMs and chatbots can develop humanlike characteristics in language use.
2303.08559_1808356_3	Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings.
2303.08774_1808571_1	While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers.
2303.09038_1808835_0	  The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities.
2303.09038_1808835_3	According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation.
2303.09038_1808835_5	ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt.
2303.09128_1808925_8	We find that for code generation, a model adapted to multiple domains simultaneously performs on par with those adapted to a single domain
2303.09224_1809021_6	Our findings provide initial evidence that allowing AI models to take over more management responsibilities can be an effective form of human-AI collaboration in workplaces.
2303.09387_1809184_9	In the absence of a consensus definition and reliable tools for measurement, we cannot rule out the possibility that AI systems learn to manipulate humans without the intent of the system designers.
2303.09601_1809398_6	Our system's success in generating DIsorder-Specific Multi-Objective Policies (DISMOP) and interpretable policy dynamics demonstrates the potential of DRL in providing personalized and efficient therapeutic recommendations.
2303.09858_1809655_10	Notably, those AI diagnosis networks exhibit a meager average accuracy of 38.59% when applied to images protected by MIAD-MARK, underscoring the robustness of our safeguarding mechanism.
2303.10001_1809798_2	This is important because the main challenge of implementing AI in a fighting game is the need for the AI to select an action to perform within a short response time.
2303.10338_1810135_0	  Radiology AI models have made significant progress in near-human performance or surpassing it.
2303.10494_1810291_9	Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning and prompting.
2303.11139_1810936_8	First, to be successful, AI will need to work seamlessly, and in an integrated manner with humans (and vice versa).
2303.11436_1811233_6	We show that GPT-4 exhibits a high level of accuracy in cognitive psychology tasks relative to the prior state-of-the-art models.
2303.11568_1811365_1	Once pretrained, large AI models demonstrate impressive performance in various downstream tasks.
2303.11717_1811514_1	As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond.
2303.11717_1811514_10	Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.
2303.11812_1811609_2	The data were analyzed in terms of five discourse components using Coh-Metrix (a special instrument for analyzing language discourses), and the results revealed that ChatGPT performed better than human writers in narrativity, word concreteness, and referential cohesion, but worse in syntactic simplicity and deep cohesion in its initial version.
2303.12093_1811890_3	Additionally, we assess if ChatGPT can recognize if given codes are written by humans or machines.
2303.12767_1812564_0	  ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks.
2303.12810_1812607_2	This fact raises the question whether LLMs can perform equally well across all these different domains.
2303.13001_1812798_4	We find that ChatGPT performs exceptionally well on all six candidate prompts, with minor performance differences observed across the datasets.
2303.13151_1812948_1	A production-ready AI system needs to be trustworthy, i.e. of high quality.
2303.13336_1813133_0	  Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction.
2303.13592_1813389_5	ChatGPT exhibits inconsistent capabilities in generating code-mixed texts, wherein its performance varies depending on the prompt template and language pairing.
2303.13592_1813389_6	For instance, ChatGPT generates fluent and natural Singlish texts (an English-based creole spoken in Singapore), but for English-Tamil language pair, the system mostly produces grammatically incorrect or semantically meaningless utterances.
2303.13592_1813389_8	Based on our investigation, existing multilingual LLMs exhibit a wide range of proficiency in code-mixed data generation for SEA languages.
2303.13648_1813445_2	By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT performs not as well as those baselines in terms of the automatic evaluation metrics (e.g., $F_{0.5}$ score), particularly on long sentences.
2303.13648_1813445_5	Human evaluation quantitatively confirms this and suggests that ChatGPT produces less under-correction or mis-correction issues but more over-corrections.
2303.13809_1813606_0	  Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks, such as machine translation, text summarization.
2303.14342_1814139_4	We report the performance of our best prompt on the BEA-2019 and JFLEG datasets, finding that the GPT models can perform well in a sentence-level revision setting, with GPT-4 achieving a new high score on the JFLEG benchmark.
2303.14396_1814193_6	Through an extensive set of experiments, our model not only establishes an effective baseline for this novel task but also demonstrates strong performances compared to existing methods that rely on stronger supervision, such as task-specific images and segmentation masks.
2303.14425_1814222_1	It will make the model to better understand the similarity between context, and more robust to the synonym substitution attack.
2303.14878_1814675_3	GPT-PINN represents a brand-new meta-learning paradigm for parametric systems.
2303.15714_1815511_5	When using small T5 models as its core selection and deduction components, our system performs competitively compared to GPT-3 despite having only about 1B parameters (i.e., 175 times smaller than GPT-3).
2303.16292_1816089_0	  Explainable AI (XAI) has established itself as an important component of AI-driven interactive systems.
2303.16854_1816651_2	Recently, GPT-3.5 series models have demonstrated remarkable few-shot and zero-shot ability across various NLP tasks.
2303.16854_1816651_4	Accordingly, we propose AnnoLLM, an annotation system powered by LLMs, which adopts a two-step approach, explain-then-annotate.
2303.16870_1816667_1	ChatGPT has learned language patterns and styles from a large dataset of internet texts, allowing it to provide answers that reflect common opinions, ideas, and language patterns found in the community.
2303.17012_1816809_1	Despite lacking any explicit programming regarding the laws of physics, recent work has demonstrated that GPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory.
2303.17276_1817073_8	This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data.
2303.17466_1817263_3	Our findings suggest that, when prompted with American context, ChatGPT exhibits a strong alignment with American culture, but it adapts less effectively to other cultural contexts.
2303.17491_1817288_3	In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent Recursively Criticizes and Improves its output (RCI).
2303.17557_1817354_1	What does a model remember about such examples seen only a few times during training and how long does that memory persist in the face of continuous training with new examples?
2303.17557_1817354_3	In recognition experiments, we ask if the model can distinguish the seen example from a novel example; in recall experiments, we ask if the model can correctly recall the seen example when cued by a part of it; and in retention experiments, we periodically probe the model's memory for the original examples as the model is trained continuously with new examples.
2303.17573_1817370_5	However, the model performed slightly worse than the expert neurologists (0.53 MAE).
2303.17580_1817377_2	Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this.
2304.00228_1818274_4	For sources where ratings are provided, LLMs exhibit a high level of agreement among themselves (average Spearman's $\rho = 0.79$), but their ratings align only moderately with human expert evaluations (average $\rho = 0.50$).
2304.00612_1818658_3	LLMs predictably get more capable with increasing investment, even without targeted innovation.   
2304.00612_1818658_12	7. LLMs need not express the values of their creators nor the values encoded in web text.   
2304.01238_1819284_5	This adaptability renders LLMs uniquely suited to spam detection tasks, where labeled samples are limited in number and models require frequent updates.
2304.01543_1819589_3	AI applications' underlying reasoning needs to be transparent to clinicians in order to gain their trust.
2304.01555_1819601_3	The system consists of an InfraRed camera to record the driver footage and an edge device to process the data.
2304.01746_1819792_6	However, further analysis of various types of errors at the document-level has shown that ChatGPT cannot effectively correct agreement, coreference, tense errors across sentences, and cross-sentence boundary errors.
2304.01938_1819984_8	In evaluating ChatGPTs (GPT-4) deductive reasoning ability using a novel approach (substituting the correct answer with "None of the above choices is the correct answer."), ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability.
2304.01938_1819984_9	Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials.
2304.02017_1820063_1	ChatGPT (Chat Generative Pre-trained Transformer), an OpenAI creation, stands out as a widely adopted, powerful tool.
2304.02169_1820215_4	Additionally, our model also produces high-quality continuous variables in a longitudinal and probabilistic manner.
2304.02182_1820228_0	  The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation.
2304.02210_1820256_3	By evaluating on a number of benchmarks, we surprisingly find that LLMs have demonstrated superior performance and show potential to become a new paradigm for document-level translation: 1) leveraging their powerful long-text modeling capabilities, GPT-3.5 and GPT-4 outperform commercial MT systems in terms of human evaluation; 2) GPT-4 demonstrates a stronger ability for probing linguistic knowledge than GPT-3.5.
2304.02868_1820914_2	Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence.
2304.02868_1820914_3	Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses.
2304.03439_1821485_6	Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks.
2304.03659_1821705_4	Our probes are grounded in cognitive science and help determine if a V+L model can, for example, determine if snow garnished with a man is implausible, or if it can identify beach furniture by knowing it is located on a beach.
2304.03893_1821939_4	Experiments confirmed that the proposed prompts enable ChatGPT to act according to requirements in various environments, and users can adjust ChatGPT's output with natural language feedback for safe and robust operation.
2304.04007_1822053_6	We investigated various segmentation algorithms for sky detection and found that the Otsu algorithm reported the highest classification rate and computational efficiency, despite the algorithm's simplicity and ease of implementation.
2304.04193_1822239_3	Our experimental analysis reveals that ChatGPT exhibits inferior extractive summarization performance in terms of ROUGE scores compared to existing supervised systems, while achieving higher performance based on LLM-based evaluation metrics.
2304.04231_1822277_2	The core idea is built on two observations: 1) the recent contrastive pre-trained vision-language model (CLIP) has presented impressive performance on various downstream tasks; 2) there is a natural mapping between crowd patches and count text.
2304.04339_1822385_0	  Recently, ChatGPT has drawn great attention from both the research community and the public.
2304.04675_1822721_1	In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages?
2304.04675_1822721_6	Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT.
2304.04675_1822721_7	First, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages.
2304.05197_1823243_2	As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring.
2304.07590_1825636_4	Specifically, through role instructions, 1) Multiple LLM agents act as distinct `experts', each responsible for a specific subtask within a complex task; 2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other's work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention.
2304.07619_1825665_3	The model generates several key predictions, which we empirically test: (i) it establishes a critical threshold in AI capabilities necessary for profitable predictions, (ii) it demonstrates that only advanced LLMs can effectively interpret complex information, and (iii) it predicts that widespread LLM adoption can enhance market efficiency.
2304.08103_1826149_4	The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow.
2304.08733_1826779_4	We find that even when AI learns an excellent model from the training data, one that outperforms humans in overall accuracy, these AI models have significant and consistent differences from human perception.
2304.09075_1827121_1	A critical problem for the visual assistance is that the communications system needs to match the radio signal with the visual information of the corresponding user, i.e., to identify the visual user that corresponds to the target radio signal from all the environmental objects.
2304.09337_1827383_2	It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.
2304.09433_1827479_11	This equates to a 110x reduction in the number of tokens the LLM needs to process, averaged across 16 real-world evaluation settings of 10k documents each.
2304.10149_1828195_7	Further, we explore the use of few-shot prompting to inject interaction information that contains user potential interest to help ChatGPT better understand user needs and interests.
2304.10149_1828195_10	And the human evaluations show ChatGPT can truly understand the provided information and generate clearer and more reasonable results.
2304.10428_1828474_6	More importantly, we find that GPT-NER exhibits a greater ability in the low-resource and few-shot setups, when the amount of training data is extremely scarce, GPT-NER performs significantly better than supervised models.
2304.10548_1828594_2	While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models.
