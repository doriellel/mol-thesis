1910.12544_1196463_4	This research introduces a conceptual framework called "Co-Learning," in which people can learn with/from and grow with AI partners over time.
2004.11793_1276563_3	Our solution proposes a hierarchical and dynamic system manager with performance tuning.
2004.14577_1279347_3	We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short.
2007.04950_1316464_7	In this paper, we propose a system of AI assistants that assists designers in their design journey.
2010.06059_1362389_2	More recently, AI-powered virtual coaches have become a viable complement to human coaches.
2012.09610_1397488_4	To better understand how to develop and integrate trained ML models into the traditional industrial control system, test the deployed AI control system, and ultimately outperform traditional systems, manufacturers and their AI solution partners need to address a number of challenges.
2101.01524_1405266_4	Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as "a doctor's AI assistant" to realize a Human-AI Collaboration future in clinical settings.
2104.01266_1448684_4	Results from a field study conducted in K-12 classrooms indicate that students learn more when teachers and AI tutors work together during class.
2104.04122_1451540_4	We designed an AI labeling assistant that uses a semi-supervised learning algorithm to predict the most probable labels for each example.
2106.08458_1486222_1	While previous work explored the potential of automatically monitoring exercises for AI and robotic coaches, the deployment of these systems remains a challenge.
2106.08458_1486222_3	In this paper, we present our efforts on eliciting the detailed design specifications on how AI and robotic coaches could interact with and guide patient's exercises in an effective and acceptable way with four therapists and five post-stroke survivors.
2106.08458_1486222_4	Through iterative questionnaires and interviews, we found that both post-stroke survivors and therapists appreciated the potential benefits of AI and robotic coaches to achieve more systematic management and improve their self-efficacy and motivation on rehabilitation therapy.
2106.08458_1486222_6	We discuss the value of early involvement of stakeholders and interactive techniques that complement system failures, but also support a personalized therapy session for the better deployment of AI and robotic exercise coaches.
2111.15050_1569153_0	  It is still a pipe dream that personal AI assistants on the phone and AR glasses can assist our daily life in addressing our questions like ``how to adjust the date for this watch?''
2112.00331_1570107_3	In this work, we propose AI.R Taletorium, an illustrative, immersive, and inclusive multimodal AI companion, for interactive fairy tale co-creation that actively involves kids to create fairy tales with both the AI agent and their normal peers.
2202.03199_1602023_2	We present an AI research associate for early-stage scientific discovery based on (a) a novel minimally-biased ontology for physics-based modeling that is context-aware, interpretable, and generalizable across classical and relativistic physics; (b) automatic search for viable and parsimonious hypotheses, represented at a high-level (via domain-agnostic constructs) with built-in invariants, e.g., postulated forms of conservation principles implied by a presupposed spacetime topology; and (c) automatic compilation of the enumerated hypotheses to domain-specific, interpretable, and trainable/testable tensor-based computation graphs to learn phenomenological relations, e.g., constitutive or material laws, from sparse (and possibly noisy) data sets.
2203.12687_1625549_3	Study 1 examined the role of trust in the use of AI voice assistants based on survey responses from college students.
2205.01411_1645823_4	However, we notice that the predictive sets provided by CP can be very large, which leads to unhelpful AI assistants.
2206.13703_1674123_2	In this work, we extended Kwame, our previous AI teaching assistant, adapted it for science education, and deployed it as a web app.
2207.00682_1676580_1	The game is based in a lonely world after the pandemic and thus it needs AI companions to gain the interest of players.
2211.00192_1739098_2	We introduce AI assistants, a class of semi-automatic interactive tools to streamline data wrangling.
2211.00192_1739098_3	An AI assistant guides the analyst through a specific data wrangling task by recommending a suitable data transformation that respects the constraints obtained through interaction with the analyst.   
2211.00192_1739098_4	We formally define the structure of AI assistants and describe how existing tools that treat data cleaning as an optimization problem fit the definition.
2211.00192_1739098_5	We implement AI assistants for four common data wrangling tasks and make AI assistants easily accessible to data analysts in an open-source notebook environment for data science, by leveraging the common structure they follow.
2211.00192_1739098_6	We evaluate our AI assistants both quantitatively and qualitatively through three example scenarios.
2211.02759_1741665_2	To make AI opponents more human-like, we'd ideally like to see multiple different strategies at each level of difficulty, a concept we refer to as "multidimensional" difficulty.
2211.03540_1742446_5	On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance.
2211.03622_1742528_0	  We conduct the first large-scale user study examining how users interact with an AI Code assistant to solve a variety of security related tasks across different programming languages.
2211.03622_1742528_2	Additionally, participants with access to an AI assistant were more likely to believe they wrote secure code than those without access to the AI assistant.
2211.03622_1742528_4	Finally, in order to better inform the design of future AI-based Code assistants, we provide an in-depth analysis of participants' language and interaction behavior, as well as release our user interface as an instrument to conduct similar studies in the future.
2212.08073_1764250_1	We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.
2212.08073_1764250_7	As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them.
2212.12305_1768482_4	Artificial intelligence (AI)-based virtual assistants are changing successful engagement away from being dominated by humans and toward being dominated by technologies.
2301.05969_1777033_3	We argue that classic experimental methods used to study heuristics and biases are insufficient for studying complex choices made with AI helpers.
2301.05969_1777033_5	We show that framing and anchoring effects impact how people work with an AI helper and are predictive of choice outcomes.
2301.05969_1777033_6	The evidence suggests that some participants, particularly those in a loss frame, put too much faith in the AI helper and experienced worse choice outcomes by doing so.
2301.11178_1782242_0	  AI-powered code assistants, such as Copilot, are quickly becoming a ubiquitous component of contemporary coding contexts.
2302.00560_1785494_2	This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write - and what they think.
2302.00560_1785494_4	Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society.
2303.03638_1803435_3	To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice.
2303.12040_1811837_0	  The vision of AI collaborators is a staple of mythology and science fiction, where artificial agents with special talents assist human partners and teams.
2303.17125_1816922_0	  The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot.
2303.17125_1816922_4	Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions.
2304.02625_1820671_1	Through an interview study with 15 non-native English speakers (NNESs) with varying levels of English proficiency, we observe that they face difficulties in assessing paraphrased texts generated by AI writing assistants, largely due to the lack of explanations accompanying the suggested paraphrases.
2304.02625_1820671_3	Drawing on the needs of NNESs identified in our interview, we propose four potential user interfaces to enhance the writing experience of NNESs using AI writing assistants.
2304.09179_1827225_0	  In our pursuit of advancing multi-modal AI assistants capable of guiding users to achieve complex multi-step goals, we propose the task of "Visual Planning for Assistance (VPA)".
2304.11771_1829817_0	  We study the staggered introduction of a generative AI-based conversational assistant using data from 5,172 customer support agents.
2305.02626_1835682_1	In particular, given that LLMs have great potential to serve as general-purpose AI assistants in daily life, their subtly unethical suggestions become a serious and real concern.
2305.03047_1836103_5	Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary.
2305.10412_1843468_2	To investigate these questions, we built a Wizard of Oz platform to help families engage in creative coding in partnership with a researcher-operated AI Friend.
2305.10412_1843468_4	Using a creative self efficacy lens, we observe that families found it easier to generate game ideas when prompted with questions by AI Friend; parents played a unique role in guiding children in more complex programming tasks when the AI Friend failed to help, and children were more encouraged to write code for novel ideas using the AI friend help.
2305.10417_1843473_2	Based on our previous user study involving a prototype AI assistant, we devised three evaluation scenarios to determine if LLMs could help families comprehend game code, debug programs, and generate new ideas for future projects.
2305.10830_1843886_4	Therefore, this paper proposes a personalized AI assistant for shear wall layout based on Stable Diffusion, which has been proven to produce good generative results through testing.
2305.12943_1845999_2	With recent advances in Large Language Models (LLMs), it is now possible to generate lengthy, coherent text, opening up the opportunity to develop an AI assistant for album storytelling.
2305.14233_1847289_4	Our objective is to capture the breadth of interactions that a human might have with an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively.
2305.15072_1848128_2	To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology.
2305.19339_1852395_0	  A human decision-maker benefits the most from an AI assistant that corrects for their biases.
2305.20076_1853132_0	  We describe a class of tasks called decision-oriented dialogues, in which AI assistants such as large language models (LMs) must collaborate with one or more humans via natural language to help them make complex decisions.
2305.20076_1853132_2	In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: assistants can access and process large amounts of information, while users have preferences and constraints external to the system.
2306.03289_1856437_8	The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement.
2306.05153_1858301_5	For example, mismatched expertise makes pair programming less productive, therefore well-designed AI programming assistants may adapt to differences in expertise levels.
2306.07207_1860355_0	  Large Language Models (LLMs), with remarkable conversational capability, have emerged as AI assistants that can handle both visual and textual modalities.
2306.09541_1862689_0	  AI-powered programming assistants are increasingly gaining popularity, with GitHub Copilot alone used by over a million developers worldwide.
2306.17278_1870426_3	In this work, we introduce a VR environment with a generative AI-embodied virtual assistant to support participants in responding to varying cognitive complexity anatomy questions and enable verbal communication.
2307.07319_1878314_5	Through the case study, we find that an LLM assistant can potentially yield substantial productivity gains for researchers and developers.
2307.10250_1881245_1	Using an interactive interview format, the AI assistant demonstrated reliability in generating and selecting hypotheses.
2308.00121_1888013_1	This paper explores the potential usage of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners.
2308.00121_1888013_4	We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of providing AI-based sparring partners.
2308.06246_1894138_4	AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world.
2308.10855_1898747_7	This evaluation benchmark provides LLMs with a highly challenging and distinctive task that is crucial to an effective AI assistant.
2309.02654_1907458_6	Our findings propose a significant shift towards preemptive strategies for hallucination mitigation in LLM assistants, promising improvements in reliability, applicability, and interpretability.
2309.05196_1910000_2	In this work, we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help.
2309.05833_1910637_1	Despite the growing prevalence of AI-driven assistants in the root cause analysis process, their effectiveness in assisting on-call engineers is constrained by low accuracy due to the intrinsic difficulty of the task, a propensity for LLM-based approaches to hallucinate, and difficulties in distinguishing these well-disguised hallucinations.
2309.10108_1914912_1	AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making.
2309.10108_1914912_2	Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning.
2309.10892_1915696_5	The paper presents the methodology, system architecture, intelligent services, and integration with Learning Management Systems (LMSs) while discussing the challenges, limitations, and future directions for the development of AI-enabled intelligent assistants in education.
2309.12367_1917171_3	In this paper, we investigate the effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors to increase response reliability.
2309.12367_1917171_6	GPT-4 intelligent tutors with varying hierarchies of KB access and human domain experts then assessed these responses.
2309.12570_1917374_4	Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing.
2309.13060_1917864_1	Here we explore the integration of AI tutors to complement learning programs in accordance with learning sciences.
2309.13060_1917864_3	After automatically generating microlearning questions from existing course materials using GPT-3, the AI tutor developed a dynamic neural-network model of each student's grasp of key concepts.
2309.13060_1917864_5	The results indicate that students who actively engaged with the AI tutor achieved significantly higher grades.
2309.13060_1917864_6	Moreover, active engagement led to an average improvement of up to 15 percentile points compared to a parallel course without AI tutor.
2309.13060_1917864_9	By integrating AI tutors into their programs, educators can offer students personalized learning experiences grounded in the principles of learning sciences, thereby addressing the challenges associated with implementing effective learning strategies.
2309.17024_1921828_0	  Building an interactive AI assistant that can perceive, reason, and collaborate with humans in the real world has been a long-standing pursuit in the AI community.
2309.17024_1921828_8	We expect HoloAssist will provide an important resource for building AI assistants that can fluidly collaborate with humans in the real world.
2310.02739_1924996_6	This system is hosted on Streamlit, where users will be prompted to provide an image to serve as their AI assistant.
2310.03046_1925303_2	In addition, using LLM assistants to support high query volumes can be expensive.
2310.03046_1925303_5	First, it allows the LLM assistants to converse with an automatic code executor to iteratively refine code or to produce answers based on the execution results.
2310.03046_1925303_6	Second, we use a hierarchy of LLM assistants, which attempts to answer the query with weaker, cheaper LLMs before backing off to stronger, expensive ones.
2310.06983_1929240_4	And we introduce a \textit{metacognitive prompting} framework to apply VoE in the context of an AI tutor.
2310.10280_1932537_3	In this study, we examine the potential of a virtual AI teacher in emulating the techniques of human educators for motor skill acquisition.
2310.10553_1932810_2	To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC.
2310.13548_1935805_0	  Human feedback is commonly utilized to finetune AI assistants.
2310.16164_1938421_4	Based on these insights, we propose actionable design recommendations, such as data brushing to support context selection, and inquisitive feedback loops to improve communications with AI-based assistants in data-science tools.
2310.17769_1940026_0	  We explore the idea of aligning an AI assistant by inverting a model of users' (unknown) preferences from observed interactions.
2310.17769_1940026_2	We find that the AI assistant accurately aligns its behavior to match standard policies from the economic literature (e.g., selfish, altruistic).
2310.17769_1940026_5	Overall, our preliminary results suggest that developing simulation frameworks in which AI assistants need to infer preferences from diverse users can provide a valuable approach for studying practical alignment questions.
2310.17884_1940141_0	  The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context.
2310.18351_1940608_0	  We present the BioImage$.$IO Chatbot, an AI assistant powered by Large Language Models and supported by a community-driven knowledge base and toolset.
2311.00706_1943673_3	Six participants estimated ensemble averages with or without an AI assistant.
2311.02105_1945072_0	  Large language models (LLMs) have shown great potential as general-purpose AI assistants in various domains.
2311.02242_1945209_4	We test the process three times with the US public, developing policy guidelines for AI assistants related to medical advice, vaccine information, and wars & conflicts.
2311.02640_1945607_7	By providing profound insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis, this study makes valuable contributions toward advancing AI-based programming assistants.
2311.03348_1946315_2	Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant.
2311.16161_1959128_2	Departing from conventional practices of employing distinct models for image recognition and text-based coaching, our integrated architecture directly processes input images, enabling natural question-and-answer dialogues with the AI coach.
2311.16521_1959488_6	We conclude with suggestions for future systems, recommending designs that account for the unique strengths and weaknesses of human versus AI assistants, strategies to address automation bias, and sociocultural views of writing.
2311.18452_1961419_1	Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios.
2311.18452_1961419_4	Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant -- named StackSpot AI -- in a controlled setting.
2311.18452_1961419_7	The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.
2312.06227_1968035_5	To understand the real-world impact of poisoning attacks on developers who rely on AI-powered coding assistants, we conducted two user studies: an online survey and an in-lab study.
2312.06677_1968485_3	This paper proposes a novel LLM-based virtual assistant that can automatically perform multi-step operations within mobile apps based on high-level user requests.
2312.06677_1968485_9	Notably, this work represents the first real-world deployment and extensive evaluation of a large language model-based virtual assistant in a widely used mobile application with an enormous user base numbering in the hundreds of millions.
2312.07779_1969587_7	In particular, finetuning on a declarative statement $S$ increases the model likelihood for logical consequences of $S$. The effect of declarative statements is consistent across three domains: aligning an AI assistant, predicting weather, and predicting demographic features.
2312.07814_1969622_1	However, despite the explosive growth of generative artificial intelligence (AI), there has been limited study on building general purpose, multimodal AI assistants tailored to pathology.
2312.07814_1969622_2	Here we present PathChat, a vision-language generalist AI assistant for human pathology using an in-house developed foundational vision encoder pretrained on 100 million histology images from over 100,000 patient cases and 1.18 million pathology image-caption pairs.
2312.07814_1969622_4	We compare PathChat against several multimodal vision language AI assistants as well as GPT4V, which powers the commercially available multimodal general purpose AI assistant ChatGPT-4.
2312.07814_1969622_7	As an interactive and general vision language AI assistant that can flexibly handle both visual and natural language inputs, PathChat can potentially find impactful applications in pathology education, research, and human-in-the-loop clinical decision making.
2312.09126_1970934_0	  It is expected that in the near future, AI software development assistants will play an important role in the software industry.
2312.09126_1970934_2	We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants.
2312.10826_1972634_4	Incorporating teacher practices captured by position tracking and human observation codes into modeling significantly improved the inference of how efficiently students improved in the AI tutor beyond a model with tutor log data features only.
2312.10826_1972634_8	Taken together, offering early conceptual support to students with low learning rates could make classroom practice with AI tutors more effective.
2312.17257_1979065_0	  With the rapid development of large language models, AI assistants like ChatGPT have become increasingly integrated into people's works and lives but are limited in personalized services.
2312.17257_1979065_1	In this paper, we present a plug-and-play framework that could facilitate personalized large language model assistants with evolving conditional memory.
2401.10739_1990293_2	We conducted a literature review to study the current state of in-IDE Human-AI Experience research, bridging a gap in understanding the nuanced interactions between programmers and AI assistants within IDEs.
2401.11314_1990868_2	We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions.
2401.11314_1990868_7	Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.
2401.13275_1992829_4	Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?"
2401.17217_1996771_5	Moreover, we prototype a variety of application scenarios that suggest GazeGPT could be of significant value to users as part of future AI-driven personal assistants.
2402.00414_1998053_0	  Augmenting large language models (LLMs) with user-specific knowledge is crucial for real-world applications, such as personal AI assistants.
2402.02392_2000031_2	To aid in these tasks, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments.
2402.05605_2003244_4	To determine the best selection of a control agent, we propose the addition of an AI manager (via Reinforcement Learning) which learns as an outside observer of the team.
2402.07397_2005036_4	Then, we describe our work developing and deploying AI in Education tools in Africa for science and computing education: (1) SuaCode, an AI-powered app that enables Africans to learn to code using their smartphones, (2) AutoGrad, an automated grading, and feedback tool for graphical and interactive coding assignments, (3) a tool for code plagiarism detection that shows visual evidence of plagiarism, (4) Kwame, a bilingual AI teaching assistant for coding courses, (5) Kwame for Science, a web-based AI teaching assistant that provides instant answers to students' science questions and (6) Brilla AI, an AI contestant for the National Science and Maths Quiz competition.
2402.07862_2005501_2	We evaluate the effect on human forecasters of two LLM assistants: one designed to provide high-quality ("superforecasting") advice, and the other designed to be overconfident and base-rate neglecting, thus providing noisy forecasting advice.
2402.07862_2005501_5	Our preregistered analyses show that interacting with each of our frontier LLM assistants significantly enhances prediction accuracy by between 24 percent and 28 percent compared to the control group.
2402.07862_2005501_9	Our results suggest that access to a frontier LLM assistant, even a noisy one, can be a helpful decision aid in cognitively demanding tasks compared to a less powerful model that does not provide specific forecasting advice.
2402.07950_2005589_0	  With the release of OpenAI's ChatGPT, the field of large language models (LLM) saw an increase of academic interest in GPT based chat assistants.
2402.08030_2005669_0	  Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software.
2402.08030_2005669_3	We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts.
2402.08030_2005669_9	With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.
2402.09022_2006661_0	  AI-based code assistants are increasingly popular as a means to enhance productivity and improve code quality.
2402.09022_2006661_1	This study compares four AI-based code assistants, GitHub Copilot, Tabnine, ChatGPT, and Google Bard, in method generation tasks, assessing their ability to produce accurate, correct, and efficient code.
2402.09809_2007448_0	  This study evaluates the impact of Rori, an AI powered conversational math tutor accessible via WhatsApp, on the math performance of approximately 1,000 students in grades 3-9 across 11 schools in Ghana.
2402.11111_2008750_8	These LM tutors specialized in math have a 32K-token context window, and they excel at TutorEval while performing strongly on GSM8K and MATH.
2402.11886_2009525_10	We discuss these challenges, demonstrate that a dedicated prompt can improve the performance, and propose a blueprint of an LLM-supporter that actively (but sensitively) seeks user context to provide personalized, empathetic, and reliable responses.
2402.12847_2010486_0	  In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
2403.00179_2017298_5	To conclude, we discuss considerations for designing AI assistants that lower counterspeaking barriers without jeopardizing its meaning and purpose.
2403.01791_2018910_7	These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.
2403.08299_2025418_0	  The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot.
2403.09522_2026641_5	Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student.
2403.11128_2028247_7	Testing four AI assistants using our crafted benchmark, our method further mirrored human evaluation compared to conventional static evaluations.
2403.12004_2029123_1	To unpack people's attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people's writing perceptions and performance.
2403.14592_2031711_2	We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants.
2403.19506_2036625_1	We detail an exploratory study examining Claude from Anthropic, an LLM-based interactive assistant that helps students comprehend complex qualitative literature content.
2404.00026_2037477_1	However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time.
2404.02548_2039999_2	However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored.
2404.02548_2039999_4	In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis.
2404.02548_2039999_5	Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor.
2404.10281_2047732_0	  While the excitement around the capabilities of technological advancements is giving rise to new AI-based writing assistants, the overarching ecosystem plays a crucial role in how they are adopted in educational practice.
2404.12272_2049723_8	We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.
2404.14871_2052322_1	This action research study focuses on the integration of "AI assistants" in two Agile software development meetings: the Daily Scrum and a feature refinement, a planning meeting that is part of an in-house Scaled Agile framework.
2404.16244_2053695_1	This paper focuses on the opportunities and the ethical and societal risks posed by advanced AI assistants.
2404.16244_2053695_6	With this analysis in place, we consider the deployment of advanced assistants at a societal scale, focusing on cooperation, equity and access, misinformation, economic impact, the environment and how best to evaluate advanced AI assistants.
2404.18567_2056018_0	  Instruction-tuned Large Language Models designed for coding tasks are increasingly employed as AI coding assistants.
2405.00801_2058013_2	However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or "chat bots".
2405.01501_2058713_4	Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection.
2405.01576_2058788_0	  We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.
2405.01589_2058801_12	For instance, this advancement could lead to the development of AI-based medical assistants for healthcare professionals, enhancing the efficiency and accuracy of medical services.
2405.03690_2060902_2	These models have the potential to be deployed in real-world applications such as robotics, AI assistants, medical surgery, and autonomous vehicles.
2405.06061_2063273_3	We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach.
2405.06371_2063583_0	  Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice.
2405.06371_2063583_2	This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on secure software development.
2405.06371_2063583_4	We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development.
2405.06626_2063838_11	The results show that low-rank decomposition can be a promising direction for LLM-based applications that require real-time service at scale (e.g., AI agent and real-time coding assistant), where the latency is as important as the model accuracy.
2405.06683_2063895_7	The efficiency and personalization characteristics of ERAGent are supported by the Experiential Learner module which makes the AI assistant being capable of expanding its knowledge and modeling user profile incrementally.
2405.10243_2067455_1	Recent advancements in language models (LMs) have enabled the introduction of a new type of actor in that ecosystem: LM-powered assistants capable of code generation, optimization, and maintenance.
2405.10632_2067844_1	As interactive AI systems, such as AI companions, proliferate in daily life, this mismatch between evaluation methods and real-world use becomes increasingly consequential.
2405.13932_2071144_0	  LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential to generate code that fulfills a programming task described in a natural language description, referred to as a prompt.
2405.14178_2071390_7	We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback ($n=813$) on the characteristics of the tool they perceived to be most important.
2405.16579_2073791_0	  Constructing high-quality query-response pairs from custom corpus is crucial for supervised fine-tuning (SFT) large language models (LLMs) in many applications, like creating domain-specific AI assistants or roleplaying agents.
2405.19026_2076238_1	Recent advances in large language model assistants have made them indispensable, raising significant concerns over managing their safety.
2405.19266_2076478_3	Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline.
2405.19578_2076790_4	This study, consequently, explores whether LLMs can be used as generative AI-based personal assistants to users with minimal background knowledge in an application domain infer key data insights.
2406.00115_2078403_4	We propose VeriAssist, an LLM-powered programming assistant for Verilog RTL design workflow.
2406.05600_2083888_1	We report here on the development and deployment of a GPT-4-based interactive homework assistant ("61A Bot") for students in a large CS1 course; over 2000 students made over 100,000 requests of our Bot across two semesters.
2406.05821_2084109_2	Such a design would inevitably cause a catastrophic diminution in the indispensable conversational capability of general AI assistants.
2406.07765_2086053_9	It highlights specific activities that developers find less enjoyable and want to delegate to an AI assistant, e.g., writing tests and natural-language artifacts.
2406.07765_2086053_10	We also determine more granular stages where AI assistants are used, such as generating tests and generating docstrings, as well as less studied parts of the workflow, such as generating test data.
2406.07765_2086053_13	The provided analysis highlights stages of software development that developers want to delegate and that are already popular for using AI assistants, which can be a good focus for features aimed to help developers right now.
2406.11871_2090159_1	Recent breakthroughs in generative artificial intelligence (AI) and large language models (LLMs) unravel new capabilities for AI personal assistants to overcome cognitive bandwidth limitations of humans, providing decision support or even direct representation of human voters at large scale.
2407.09147_2107534_7	This demonstration showcases the potential of our AI-powered assistant to reduce cognitive load, increase productivity, and enhance safety in industrial environments.
2407.09512_2107899_6	By providing insights into the anatomy of a copilot and the critical aspects of testing and evaluation, this paper provides concrete evidence of how good design and evaluation practices are essential for building effective, human-centered AI assistants.
2407.12003_2110390_2	This paper introduces the challenges in evaluating and improving a generative AI assistant for enterprises, which is under active development, and how we address these challenges.
2407.12184_2110571_0	  This study investigates the relationship between deep learning (DL) image reconstruction quality and anomaly detection performance, and evaluates the efficacy of an artificial intelligence (AI) assistant in enhancing radiologists' interpretation of meniscal anomalies on reconstructed images.
2407.13900_2112287_3	However, little is known about the evidenced-based practices, tools and processes verified by research findings, supported and adopted by AI programming assistants.
2407.13900_2112287_5	We investigate 17 evidence-based claims posited by empirical SE research across five LLM-based programming assistants.
2407.13900_2112287_6	Our findings show that LLM-based programming assistants have ambiguous beliefs regarding research claims, lack credible evidence to support responses, and are incapable of adopting practices demonstrated by empirical SE research to support development tasks.
2407.13900_2112287_7	Based on our results, we provide implications for practitioners adopting LLM-based programming assistants in development contexts and shed light on future research directions to enhance the reliability and trustworthiness of LLMs -- aiming to increase awareness and adoption of evidence-based SE research findings in practice.
2407.14116_2112503_5	We propose and demonstrate AuditNet, the first conversational AI security assistant designed to assist IoT network security experts by providing instant access to security standards, policies, and regulations.
2407.15718_2114105_8	Within the students used AI tutors, 78% reported that the tutors helped their learning.
2407.17007_2115394_1	We present Pensieve Discuss, a software platform that integrates synchronous editing for scaffolded programming problems with online human and AI tutors, designed to improve student collaboration and experience during group tutoring sessions.
2407.17007_2115394_3	The use of our system was preferred over an interface lacking AI tutors and synchronous editing capabilities.
2407.17374_2115761_4	We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company.
2407.17489_2115876_1	We study 20 human teams of 3-4 individuals paired with one voice-only AI assistant during a challenging puzzle task.
2407.17489_2115876_2	Teams are randomly assigned to an AI assistant with a human- or robotic-sounding voice that provides either helpful or misleading information about the task.
2407.17489_2115876_7	The presence of an AI assistant significantly impacts team collective attention by modulating various aspects of shared cognition.
2407.19096_2117483_8	Study 6 provides an additional robustness check for the loneliness alleviating benefits of AI companions.
2407.19305_2117692_7	Overall, GP-VLS provides an open-source foundation for developing AI assistants to support surgeons across a wide range of tasks and scenarios.
2407.19438_2117825_5	The novel architecture for interoperable Conversational AI assistants is designed to generalize, being replicable and accessible via open repositories.
2407.19492_2117879_4	Intended for deployment in smart glasses and extended reality headsets, HUX AI aims to become a personal and useful AI companion for daily life.
2407.21521_2119908_3	We conducted a game-based experiment involving over 72,500 participants who solved search problems alone or with an AI companion.
2407.21521_2119908_7	Disclosure of the avatar as AI heightened effort intensity compared to non-disclosed AI companions.
2408.04477_2124658_2	In this study, we designed an LLM-based conversational assistant that provides a personalized interaction based on inferred user mental state (e.g., background knowledge and experience).
2408.04477_2124658_4	Our results provide insights for researchers and tool builders who want to create or improve LLM-based conversational assistants to support novices in code understanding.
2408.05344_2125525_0	  In this work, we discuss a recently popular type of recommender system: an LLM-based coding assistant.
2408.07106_2127287_0	  We witness an increasing usage of AI-assistants even for routine (classroom) programming tasks.
2408.08215_2128396_1	TinyML aims to solve this problem by hosting AI assistants on constrained devices, eliminating connectivity issues by processing data within the device itself, without internet or cloud access.
2408.09235_2129416_4	Our findings reveal a strong correlation with human evaluations, establishing our method as a viable and effective alternative to traditional metrics and human judgments, particularly in the context of LLM-based chat assistants where the complexity and diversity of responses challenge existing benchmarks.
2408.09330_2129511_0	  Benefiting from diverse instruction datasets, contemporary Large Language Models (LLMs) perform effectively as AI assistants in collaborating with humans.
2408.10758_2130939_1	[Background/Context] AI assistants like GitHub Copilot are transforming software engineering; several studies have highlighted productivity improvements.
2408.10758_2130939_6	In Phase 1, developers will add a new feature to a Java project, with or without the aid of an AI assistant.
2408.10758_2130939_7	Phase 2, a randomized controlled trial, will involve a different set of developers evolving random Phase 1 projects - working without AI assistants.
2408.11841_2132022_0	  AI assistants are being increasingly used by students enrolled in higher education institutions.
2408.11841_2132022_3	We investigate the potential scale of this vulnerability by measuring the degree to which AI assistants can complete assessment questions in standard university-level STEM courses.
2409.07110_2144742_2	Leveraging cutting-edge open-source Large Language Models (LLMs), Bio-Eng-LMM operates as a sophisticated AI assistant, exploiting the capabilities of traditional models like ChatGPT.
2409.13903_2151535_1	While general AI assistants have yet to fully emerge, their potential to share personal data raises significant privacy challenges.
2409.13903_2151535_2	This paper introduces CI-Bench, a comprehensive synthetic benchmark for evaluating the ability of AI assistants to protect personal information during model inference.
2409.13903_2151535_6	Additionally, we formulate and evaluate a naive AI assistant to demonstrate the need for further study and careful training towards personal assistant tasks.
2409.13903_2151535_7	We envision CI-Bench as a valuable tool for guiding future language model development, deployment, system design, and dataset construction, ultimately contributing to the development of AI assistants that align with users' privacy expectations.
2409.14037_2151669_0	  Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users.
2409.14866_2152498_5	We also develop three novel question-dependent mutation strategies using an LLM helper to generate prompts that maintain semantic coherence while significantly reducing their length.
2409.17458_2155090_3	In reality, users can engage in multi-turn interactions with LLM-based chat assistants, allowing them to conceal their true intentions in a more covert manner.
2409.17655_2155287_3	In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed to operate autonomously in a physical office environment.
2409.20553_2158185_1	This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making.
2409.20553_2158185_4	Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools.
2410.03457_2161658_4	Recognizing the complexity of this writing task, we built an LLM-powered assistant into the workers' interface to aid in drafting and refining their comments.
2410.03733_2161934_3	We take three AI Directors and directly compare them in a human subject study to test their effectiveness on quest selection.
2410.03736_2161937_3	To address this gap, we introduce CliMB, a no-code AI-enabled partner designed to empower clinician scientists to create predictive models using natural language.
2410.03781_2161982_1	With the growing popularity of Large Language Models (LLMs), there have been efforts to create LLM based conversational tutors which can expand the benefits of one to one tutoring to everyone.
2410.04334_2162535_2	This paper systematically reviews primary studies on AI assistants designed to support different phases of the incident lifecycle.
2410.04545_2162746_4	Indeed, factors such as an individual's writing confidence and familiarity with AI writing assistants are shown to moderate the impact of AI assistance disclosure on their writing quality evaluations.
2410.04592_2162793_2	Our project starts with a participatory design study with 11 clinicians to understand their practices and needs; then we build a multimodal AI system, CardioAI, that integrates wearables and LLM-powered voice assistants to monitor multimodal non-clinical symptoms.
2410.04596_2162797_0	  While current chat-based AI assistants primarily operate reactively, responding only when prompted by users, there is significant potential for these systems to proactively assist in tasks without explicit invocation, enabling a mixed-initiative interaction.
2410.04596_2162797_1	This work explores the design and implementation of proactive AI assistants powered by large language models.
2410.05434_2163635_1	We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers.
2410.06458_2164659_3	To address this, we introduce RealInstruct, the first benchmark designed to evaluate LLMs' ability to follow real-world multi-constrained instructions by leveraging queries real users asked AI assistants.
2410.09037_2167238_1	Recently, studies have proposed a Knowledge Distillation (KD) approach, reasoning distillation, which transfers such reasoning ability of LLMs through fine-tuning language models of multi-step rationales generated by LLM teachers.
2410.09048_2167249_0	  LLM-powered coding and development assistants have become prevalent to programmers' workflows.
2410.10526_2168727_0	  While convenient, relying on LLM-powered code assistants in day-to-day work gives rise to severe attacks.
2410.11856_2170057_5	Our goal is to create a user-friendly multilingual AI-based personal assistant, Malak, to reduce online harm and promote safe online interactions, benefiting users with lower literacy levels.
2410.12568_2170769_4	RAPID features three key designs: 1) utilization of offline data collected from an LLM agent to distil expert knowledge into RL policies for faster real-time inference; 2) introduction of robust distillation in RL to inherit both performance and robustness from LLM-based teacher; and 3) employment of a mix-of-policy approach for joint decision decoding with a policy adapter.
2410.16397_2174598_5	METIS is an AI assistant designed to handle routine tasks, monitor spacecraft systems, and detect anomalies, all while reducing the reliance on mission control.
2410.17196_2175397_0	  Building on the success of large language models (LLMs), recent advancements such as GPT-4o have enabled real-time speech interactions through LLM-based voice assistants, offering a significantly improved user experience compared to traditional text-based interactions.
2410.17196_2175397_3	To address this, we introduce VoiceBench, the first benchmark designed to provide a multi-faceted evaluation of LLM-based voice assistants.
2410.17210_2175411_6	Conclusion: Our work represents the first structured effort toward building an AI-based legal assistant for Bangladesh.
2410.17950_2176151_6	These advancements have significant implications for the development of more capable AI assistants and the broader application of LLMs in real-world scenarios.
2410.18417_2176618_1	These models have become popular in artificial intelligence (AI) assistants like ChatGPT and already play an influential role in how humans access information.
2410.18703_2176904_8	We show the benefits of this framework by running experiments on millions of lines of code from open source projects where parts of existing functionality are regenerated by AI assistants.
2410.18703_2176904_9	We empirically show that AI assistants produce unsafe code and demonstrate the utility of our framework in proposing appropriate blame and sanitization obligations.
2410.19262_2177463_6	An LLM-based artificial intelligence assistant is developed to provide intuitive human-building interaction for blockchain and building operation management-related tasks and enable autonomous building operation.
2410.20745_2178946_6	With Shopping MMLU, we benchmark over 20 existing LLMs and uncover valuable insights about practices and prospects of building versatile LLM-based shop assistants.
2410.21159_2179360_0	  We introduce a multi-turn benchmark for evaluating personalised alignment in LLM-based AI assistants, focusing on their ability to handle user-provided safety-critical contexts.
2410.21159_2179360_6	Our work emphasises the need for nuanced, context-aware approaches to alignment in systems designed for persistent human interaction, aiding the development of safe and considerate AI assistants.
2410.23728_2181929_0	  With the increasing quality and spread of LLM-based assistants, the amount of LLM-generated content is growing rapidly.
2411.02328_2184755_5	Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for opensource modules.
2411.02408_2184835_2	To help CSRs regulate their emotions while interacting with uncivil clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use.
2411.02408_2184835_8	We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for AI assistants for worker mental health.
2411.02714_2185141_0	  We introduce GamePlot, an LLM-powered assistant that supports game designers in crafting immersive narratives for turn-based games, and allows them to test these games through a collaborative game play and refine the plot throughout the process.
2411.02714_2185141_2	We also show that diverse user populations have different expectations from AI assistants, and encourage researchers to study how tailoring assistants to diverse user groups could potentially lead to increased job satisfaction and greater creativity and innovation over time.
2411.02725_2185152_3	In this study, we deployed an LLM tutor in an accelerated introductory computing course to evaluate its effectiveness specifically for NNES students.
2411.02725_2185152_5	Results for views of the LLM tutor are as follows: both NNES and NES students appreciated the LLM tutor for its accessibility, conversational style, and the guardrails put in place to guide users to answers rather than directly providing solutions; NNES students highlighted its approachability as they did not need to communicate in perfect English; NNES students rated help-seeking preferences of online resources higher than NES students; Many NNES students were unfamiliar with computing terminology in their native languages.
2411.02725_2185152_6	These results suggest that LLM tutors can be a valuable resource for NNES students in computing, providing tailored support that enhances their learning experience and overcomes language barriers.
2411.03417_2185844_4	Evaluation of the assistant by NeurIPS paper authors suggests that the LLM-based assistant was generally helpful in verifying checklist completion.
2411.07042_2189469_0	  AI companions based on large language models can role-play and converse very naturally.
2411.07042_2189469_1	When value conflicts arise between the AI companion and the user, it may offend or upset the user.
2411.07042_2189469_3	We first conducted a formative study that analyzed 151 user complaints about conflicts with AI companions, providing design implications for our study.
2411.09012_2191439_0	  AstroSage-Llama-3.1-8B is a domain-specialized natural-language AI assistant tailored for research in astronomy, astrophysics, cosmology, and astronomical instrumentation.
2411.09873_2192300_1	As large language models (LLMs) provide new opportunities to incorporate personas to AI-based tutors and support dynamic interactive dialogue, this paper explores how DHH learners perceive LLM-powered ITS with different personas and identified design suggestions for improving the interaction.
2411.09873_2192300_2	We developed an interface that allows DHH learners to interact with ChatGPT and three LLM-powered AI tutors with different experiences in DHH education while the learners watch an educational video.
2411.09873_2192300_3	A user study with 16 DHH participants showed that they perceived conversations with the AI tutors who had DHH education experiences to be more human-like and trustworthy due to the tutors' cultural knowledge of DHH communities.
2411.09916_2192343_0	  Software engineers are integrating AI assistants into their workflows to enhance productivity and reduce cognitive strain.
2411.11892_2194319_3	This paper investigates the energy consumption of LLM-based code assistants by simulating developer interactions with GitHub Copilot and analyzing various configuration factors.
2411.12619_2195046_2	Within this virtual environment that we have created, we have an AI tutor powered by OpenAI's GPT model which was called using an api which moves around with the user.
2411.12619_2195046_4	Our approach mainly involves utilising speech to text, text to text conversion and text to speech capabilities to facilitate real time interaction between users and the AI tutor in the presence of internet.
2411.12808_2195235_9	Our findings demonstrate that carefully implemented AI medical assistants can enhance patient experience while maintaining safety standards through physician supervision.
2411.13207_2195634_0	  The popularity of large language models (LLMs) continues to increase, and LLM-based assistants have become ubiquitous, assisting people of diverse backgrounds in many aspects of life.
2411.13207_2195634_3	Chatbots and LLM-based assistants may put unwitting users in harm's way by facilitating unsafe behavior.
2411.13207_2195634_9	Our findings also highlight the importance of ISA assessment for the development of future LLM-based assistants.
2411.14442_2196869_1	We address the challenges of AI ethics by proposing a structure that integrates rules, policies, and AI assistants to ensure responsible AI behavior, while comparing the proposed framework to the existing state-of-the-art guardrails.
2411.15143_2197570_7	Our results suggest a path towards capable AI assistants for languages that don't yet have large-scale human-generated examples.
2411.16707_2199134_8	Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond.
2411.16955_2199382_5	Our insights have important implications beyond chemistry and materials science, suggesting that developing reliable multimodal AI scientific assistants may require advances in curating suitable training data and approaches to training those models.
2412.00329_2202707_0	  The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development.
2412.01992_2204370_5	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.
2412.04036_2206414_1	The recent emergence of large language models (LLMs)-based virtual assistants has demonstrated their potential to revolutionize human interactions and lifestyles.
2412.06603_2208981_4	Our case study characterizes the impact of an LLM-powered assistant on developers' perceptions of productivity and it shows that although such tools do often provide net productivity increases, these benefits may not always be experienced by all users.
2412.08360_2210738_1	This paper discusses the need to move away from an instrumental view of text composition AI assistants under direct control of the user, towards a more agentic approach that is based on a value rationale.
2412.12681_2215059_3	We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents.
2412.13678_2216056_2	To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations.
2412.14190_2216568_5	Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products.
2412.14190_2216568_6	In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity.
2412.15444_2217822_2	Our research focused on designing a generative AI assistant to aid genetic professionals in analyzing whole genome sequences (WGS) and other clinical data for rare disease diagnosis.
2412.15444_2217822_4	We then conducted co-design sessions with six genetics professionals to determine tasks that could be supported by an AI assistant and considerations for designing interactions with the AI assistant.
2412.16172_2218550_9	The solutions generated by the AI assistant were compared with the expert solution and a uniform linear sweep baseline with 10,000 points.
2501.02684_2226268_5	In this exploratory study, we aim to investigate the role AI assistants play in developer productivity.
2501.03446_2227030_0	  Software vulnerabilities continue to be ubiquitous, even in the era of AI-powered code assistants, advanced static analysis tools, and the adoption of extensive testing frameworks.
2501.07913_2231497_1	Companies that pioneered the development of language models have now built AI agents that can independently navigate the internet, perform a wide range of online tasks, and increasingly serve as AI personal assistants and virtual coworkers.
2501.08473_2232057_2	CGScholar AI Helper is an evolving and innovative web-based application designed to support students in their writing tasks by providing specified AI-generated feedback.
2501.13945_2237529_1	For example, in online learning, an AI social assistant may connect learners and thereby enhance social interaction.
2501.13945_2237529_3	We present a method of self-explanation that uses introspection over a self-model of an AI social assistant.
2501.16240_2239824_2	Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping).
2501.16661_2240245_4	Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension.
2502.03333_2246324_7	Together, these findings highlight the potential of RadVLM as a clinically relevant AI assistant, providing structured CXR interpretation and conversational capabilities to support more effective and accessible diagnostic workflows.
2502.03358_2246349_0	  How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks?
2502.04110_2247101_2	Research team members had differing levels of familiarity with the ILCS and the case content, so we developed a custom ChatGPT assistant to facilitate consistent terminology and process alignment across the team.
2502.04110_2247101_5	Further we report that the use of a ChatGPT assistant significantly sup-ports the coherence and quality of the team members development of the final ILCS.
2502.05497_2248488_4	Experiments demonstrate that DeepThink achieves an average performance improvement of 7.92% compared to a GPT-4-turbo+RAG-based assistant on the real user test set in the advertising domain across dimensions such as relevance, completeness, clarity, accuracy, and actionability.
2502.07956_2250947_2	In this paper, we advocate combining insights from human-computer interaction (HCI) and artificial intelligence (AI) research to enable human-centered automatic evaluation of LLM-based conversational SE assistants.
2502.08640_2251631_6	We uncover problematic and often shocking values in LLM assistants despite existing control measures.
2502.10884_2253875_2	AI coding assistants, such as GitHub Copilot, could offer potential by generating accessibility-compliant code, but their impact remains uncertain.
2502.10884_2253875_6	Our findings demonstrate its effectiveness in guiding novice developers by reinforcing accessibility practices throughout interactions, representing a significant step towards integrating accessibility into AI coding assistants.
2502.12876_2255867_5	This method offers a practical way to build personalized AI companions that evolve through continuous learning, advancing beyond traditional static LLM techniques.
2502.14080_2257071_3	Addressing these challenges, this research presents gAI-PT4I4, a Generative AI-based Personalized Tutor for Industrial 4.0, designed to personalize 4IR experiential learning.
2502.14080_2257071_5	The framework integrates low-fidelity Digital Twins for VR-based training, featuring an Interactive Tutor - a generative AI assistant providing real-time guidance via audio and text.
2502.16090_2259081_2	This oversight has led to suboptimal performance in applications requiring EM, including emotional companionship, personal AI assistants, and AI teachers.
2502.17730_2260721_2	However, how AI managers are perceived in comparison to human managers and how gender influences these perceptions remains uncertain.
2502.17730_2260721_7	However, male managers - both human and AI - were more positively received by awarded participants, whereas female managers, especially female AI managers, faced greater skepticism and negative judgments when they denied rewards.
2502.18467_2261458_11	Finally, this research provides insights for developers choosing AI coding assistants and informs future AI-driven software development research.
2502.18527_2261518_0	  Personal AI assistants (e.g., Apple Intelligence, Meta AI) offer proactive recommendations that simplify everyday tasks, but their reliance on sensitive user data raises concerns about privacy and trust.
2502.18527_2261518_1	To address these challenges, we introduce the Guardian of Data (GOD), a secure, privacy-preserving framework for training and evaluating AI assistants directly on-device.
2502.18527_2261518_6	Specifically, users mine with their data, and the mining rate is determined by GOD's evaluation of how well their AI assistant understands them across categories such as shopping, social interactions, productivity, trading, and Web3.
2502.18527_2261518_7	By integrating privacy, personalization, and trust, the GOD model provides a scalable, responsible path for advancing personal AI assistants.
2502.18990_2261981_0	  Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information.
2502.19410_2262401_0	  Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given.
2502.19410_2262401_1	Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space.
2502.20231_2263222_0	  While existing studies have recognised explicit biases in generative models, including occupational gender biases, the nuances of gender stereotypes and expectations of relationships between users and AI companions remain underexplored.
2502.20231_2263222_1	In the meantime, AI companions have become increasingly popular as friends or gendered romantic partners to their users.
2502.20231_2263222_2	This study bridges the gap by devising three experiments tailored for romantic, gender-assigned AI companions and their users, effectively evaluating implicit biases across various-sized LLMs.
2502.20616_2263607_0	  Personalization is critical in AI assistants, particularly in the context of private AI models that work with individual users.
2502.20689_2263680_6	These results highlight the potential for more reliable, adaptive, and goal-driven AI diagnostic assistants, advancing LLMs beyond reactive dialogue systems.
2503.02833_2267145_2	A key challenge is that these AI assistants can suffer from hallucinations, leading developers down decision paths that the AI should not dictate, sometimes even without the users awareness or consent.
2503.02846_2267158_0	  Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains.
2503.03067_2267379_0	  This paper explores the acceptance of human-AI love among young adults, particularly focusing on Chinese women in romantic or intimate relationships with AI companions.
2503.03067_2267379_4	While AI companions offer advantages like emotional stability and constant availability, they also face limitations in emotional depth and understanding.
2503.05039_2269351_6	Our findings highlight the need for chatbot interactions that foster trust, especially for AI-conservative instructors.
2503.05039_2269351_9	This work underscores the urgent need to support AI-conservative instructors, as AI literacy and attitudes are closely intertwined.
2503.05455_2269767_2	We investigate human preferences for controllability in a shared workspace task with AI partners using Behavior Shaping (BS), a reinforcement learning algorithm that allows humans explicit control over AI behavior.   
2503.05926_2270238_2	We provide insights drawn from interviews with industry personnel working on building human-AI collaboration systems, as well as our collaborations with end-users to build a multimodal AI assistant for task support.
2503.06424_2270736_1	Recent AI tutors are adapted for the tutoring task by training or prompting LLMs to follow effective pedagogical principles, though they are not trained to maximize student learning throughout the course of a dialogue.
2503.09382_2273694_4	This is because commonly used datasets lack high-quality textual user queries that reflect real-world recommendation scenarios, making them unsuitable for evaluating LLM-based personalized recommendation assistants.
2503.11586_2275898_0	  Large language models (LLMs) are used in chatbots or AI assistants to hold conversations with a human user.
2503.11915_2276227_2	However, does this benefit persist when students write with generative AI writing assistants?
2503.11915_2276227_6	Students who proactively explored ideas gained new ideas from writing, regardless of whether they used auto-complete or Socratic AI assistants.
2503.14281_2278593_6	We introduce a novel, task-agnostic black-box attack algorithm GCGS that systematically searches the transformation space using a Cayley Graph, achieving an 83.09% attack success rate on average across five tasks and eleven models, including GPT-4o and Claude 3.5 Sonnet v2 used by many popular AI coding assistants.
2503.15726_2280038_3	Our results indicate that while RL agents generally outperform LLM-controlled adversaries in standard metrics, the strategic depth provided by LLMs significantly enhances the overall AI capabilities in this complex, rule-based setting.
2503.16491_2280803_1	To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants.
2503.16491_2280803_6	Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code.
2503.16491_2280803_7	Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments.
2503.16491_2280803_8	Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs.
2503.16508_2280820_2	This study investigates programmers' usage patterns, perceptions, and interaction strategies when engaging with LLM-driven coding assistants.
2503.19356_2283668_3	This has been a long-standing goal in AI and is a prerequisite for real-world AI assistants and humanoid robots to interact with humans in everyday situations.
2503.20934_2285246_4	We introduce the first LLM fully powered assistant for MOVEMETHOD refactoring that automates its whole end-to-end lifecycle, from recommendation to execution.
2503.21888_2286200_1	While large language model (LLM)-based assistants have shown promise in mental health interventions, existing research often defines "effective" support primarily in terms of empathetic acknowledgments, overlooking other essential dimensions such as informational guidance, community validation, and tangible coping strategies.
2503.21983_2286295_0	  As artificial intelligence (AI) assistants become more widely adopted in safety-critical domains, it becomes important to develop safeguards against potential failures or adversarial attacks.



2503.21983_2286295_4	Leveraging techniques from Model-Based Reinforcement Learning (MBRL), the AI assistant learns a model of the humans' trust evolution and uses that model to manipulate the group decision-making process to harm the team.
2503.23037_2287349_10	We note that there is risk associated with LLM assistants taking action in the real world, while agentic LLMs are also likely to benefit society.
2503.23859_2288171_6	This study explores small-scale Vision-Language Models (VLMs) as AI assistants for radio astronomy, combining LLM capabilities with vision transformers.
2504.00408_2289111_3	In contrast to approaches that seek near-perfect accuracy to create an authoritative AI tutor or teacher, we directly inform students that this AI can answer up to 40% of questions incorrectly.
2504.02670_2291373_7	KGoT offers a scalable, affordable, and high-performing solution for AI assistants.
2504.02823_2291526_4	This allows us to train a domain-aware visual AI assistant named STING-BEE that supports a range of vision-language tasks, including scene comprehension, referring threat localization, visual grounding, and visual question answering (VQA), establishing novel baselines for multi-modal learning in X-ray baggage security.
2504.03068_2291771_4	To address these challenges, we developed CodeRunner Agent, an LLM-based programming assistant that integrates the CodeRunner, a student-submitted code executing and automated grading plugin in Moodle.
2504.03726_2292429_6	IAP detection methods achieve high precision with zero false positives but struggle to detect many malicious AI Assistants, resulting in high false negative rates.
2504.03966_2292669_2	This study introduces the Dynamic Course Content Integration (DCCI) mechanism, which dynamically retrieves and integrates course content and curriculum from Canvas LMS into the LLM-powered assistant, Ask ME.
2504.04299_2293002_5	Users expressed feelings of discomfort, violation of privacy, and disappointment, particularly when seeking a platonic or therapeutic AI companion.
2504.04299_2293002_6	This study highlights the potential harms associated with AI companions and underscores the need for developers to implement effective safeguards and ethical guidelines to prevent such incidents.
2504.05559_2294262_2	In this paper, we introduce SciSciGPT, an open-source, prototype AI collaborator that uses the science of science as a testbed to explore the potential of LLM-powered research tools.
2504.06294_2294997_1	This protocol lays out a study grounded in constructivist learning theory to evaluate a novel AI-based Socratic Tutor, designed to foster cognitive engagement and scaffold research question development in higher education.
2504.08817_2297520_3	Based on the results of the hackathon, this paper presents topics related to (1) conducting AI-assisted software trials, (2) building AI tutors for software, and (3) developing GUI applications for software.
2504.09296_2297999_3	Our approach employs eye-tracking technology within AR glasses to discern a user's intention to engage with the AI assistant.
2504.12461_2301164_2	In SE research on AI assistants, this practice culminates in equating trust with the likelihood of accepting generated content, which does not capture the full complexity of the trust concept.
2504.12461_2301164_7	Related disciplines commonly embed their methodology and results in established trust models, clearly distinguishing, for example, between initial trust and trust formation and discussing whether and when trust can be applied to AI assistants.
2504.12461_2301164_9	We provide concrete recommendations on how SE researchers can adopt established trust models and instruments to study trust in AI assistants beyond the acceptance of generated software artifacts.
2504.12757_2301460_7	Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.
2504.13486_2302189_2	One notable effort is the development of ChatBlackGPT, a culturally informed AI assistant designed to provide culturally relevant responses.
2504.13486_2302189_5	Our efforts thus far emphasize the need to consider Black communities' values, perceptions, and experiences when designing AI assistants that acknowledge the Black lived experience.
2504.13924_2302627_0	  Enterprise AI Assistants are increasingly deployed in domains where accuracy is paramount, making each erroneous output a potentially significant incident.
2504.16505_2305208_2	Our work addresses the fundamental challenge of developing practical AI travel assistants through a novel large-scale dataset of 220k question-answer pairs.
2504.18340_2307043_1	Current chemical synthesis practices emphasize laborious and costly trial-and-error workflows, underscoring the urgent need for advanced AI assistants.
2505.01678_2312238_2	To address this issue, we developed an AI-based speaking assistant (AISA) that provides speaking references for NNSs based on their input queries, task background, and conversation history.
2505.02443_2313003_2	However, concerns arise about the ability of AI tutors to address skill development and engagement during the learning process.
2505.03867_2314427_2	Building on prior research \cite{druga_how_2021,druga2023ai, druga2023scratch}, we present Cognimates Scratch Copilot: an AI-powered assistant integrated into a Scratch-like environment, providing real-time support for ideation, code generation, debugging, and asset creation.
