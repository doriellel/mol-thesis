1012.1877_231245_6	We show that (i) this system is a cousin to the LMXB Cyg X-2; (ii) for neutron stars of canonical birth mass 1.4 solar masses, the initial donor stars which produce the closest relatives to PSR J1614-2230 have a mass between 3.4-3.8 solar masses; (iii) neutron stars as massive as 1.97 solar masses are not easy to produce in spite of the initially high mass of the donor star, unless they were already born as relatively massive neutron stars; (iv) to successfully produce a system like PSR J1614-2230 requires a minimum initial neutron star mass of at least 1.6+-0.1 solar masses, as well as initial donor masses and orbital period of ~ 4.25+-0.10 solar masses and ~49+-2 hrs, respectively; and (v) the current companion star is largely composed of CO, but should have a surface H abundance of ~10-15%.
1508.02487_649143_2	In this paper, we construct a scenario of a damaged aircraft model which has no physical rudder control surface, and then a strategy based on differential thrust is proposed to be utilized as a control input to act as a "virtual" rudder to help maintain stability and control of the damaged aircraft.
1605.06808_734923_4	In the whole analysis we incorporate as model constraints the most up-to-date observational information, encompassing the binary's orbital properties, the companion star mass, effective temperature, surface gravity and radius, as well as the black hole's mass and spin.
1703.09310_832814_0	  This work studies how an AI-controlled dog-fighting agent with tunable decision-making parameters can learn to optimize performance against an intelligent adversary, as measured by a stochastic objective function evaluated on simulated combat engagements.
1806.00610_986250_5	We label these types of costs as neglected dimensions of AI progress, and explore them using four case studies: Alpha* (Go, Chess, and other board games), ALE (Atari games), ImageNet (Image classification) and Virtual Personal Assistants (Siri, Alexa, Cortana, and Google Assistant).
1808.07899_1017045_2	It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field.
1810.00184_1031371_5	It is not the purpose of the authors of this paper to 'take sides' - we count ourselves as members, to varying degrees, of multiple communities - but rather to help disambiguate what stakeholders mean when they ask 'Why?' of an AI.
1908.08939_1167109_3	Considering the needs of users with disabilities can help technologists identify high-impact challenges whose solutions can advance the state of AI for all users; however, ethical challenges such as inclusivity, bias, privacy, error, expectation setting, simulated data, and social acceptability must be considered.
1911.01940_1200534_4	Utilizing RoBERTa as the backbone encoder, our proposed improvement over the pre-trained models is shown effective on multiple natural language understanding tasks and help our model rival with the state-of-the-art models on the GLUE benchmark.
1911.05796_1204390_7	Thus far the US has been a leader in AI technologies, and we believe as a national Laboratory it is crucial to help maintain and extend this leadership.
1912.03468_1215364_4	Furthermore, to help validate the proposedoptimization methods, we derive lower bounds to quantify the average transmit power at the BS as afunction of the number of MEs, the number of RIS elements, and the number of antennas at the BS.The simulation results demonstrated that the average transmit power at the BS is close to the lowerbound in an RIS aided system, and is significantly lower than the average transmit power in conventionalschemes without the RIS.
2003.06769_1257124_5	We introduce a parameter called "focus length" (a positive number such as 5 or 10) to control the speed and sensitivity for our multi-AI to adapt to the opponent's strategy change.
2004.02731_1267501_3	Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists.
2005.03848_1283643_2	As an alternative, we propose a new method for BERT distillation, i.e., asking the teacher to generate smoothed word ids, rather than labels, for teaching the student model in knowledge distillation.
2006.01908_1296422_1	In particular, we have developed four novel and intertwined AI technologies: (1) VERA, a virtual experimentation research assistant for supporting inquiry-based learning of scientific knowledge, (2) Jill Watson Q&A, a virtual teaching assistant for answering questions based on educational documents including the VERA user reference guide, (3) Jill Watson SA, a virtual social agent that promotes online interactions, and (4) Agent Smith, that helps generate a Jill Watson Q&A agent for new documents such as class syllabi.
2006.14576_1309090_2	As a privacy threat, the adversary can use this leaked information to exploit vulnerabilities of the ML model following an adversarial ML approach.
2007.05801_1317315_3	To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task.
2007.12391_1323905_5	We foresee that, in the near future, machine learning-based AI will be adopted widely as a tool or collaborative assistant for creativity.
2008.00312_1328034_6	By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that TROJAN-LM possesses the following properties: (i) flexibility - the adversary is able to flexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when trigger-embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts.
2008.01916_1329638_2	Differential privacy, as a promising mathematical model, has several attractive properties that can help solve these problems, making it quite a valuable tool.
2009.04943_1346446_2	Many research groups state that 5G cannot meet its demands without artificial intelligence (AI) integration as 5G wireless networks are expected to generate unprecedented traffic giving wireless research designers access to big data that can help in predicting the demands and adjust cell designs to meet the users requirements.
2009.04984_1346487_3	As the foundation for model pre-training, we synthesize a new dialogue corpus and build our training set with two unsupervised methods: 1) coherence-oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity-oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by considering specificity and informativeness.
2009.07240_1348743_1	The model is an agent-driven simulator, featuring various stakeholders such as the Network Manager and airlines.
2011.00593_1373341_6	Concretely, in addition to the original training examples, the student model is encouraged to mimic the teacher's behavior on the linear interpolation of example pairs as well.
2101.01524_1405266_4	Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as "a doctor's AI assistant" to realize a Human-AI Collaboration future in clinical settings.
2103.03373_1433518_0	  Current state-of-the-art large-scale conversational AI or intelligent digital assistant systems in industry comprises a set of components such as Automatic Speech Recognition (ASR) and Natural Language Understanding (NLU).
2103.10918_1441063_3	We also view these metrics as an extension of BLANC, a recently proposed approach to summary quality measurement based on the performance of a language model with and without the help of a summary.
2105.03192_1465751_3	Relevant concepts are integrated into a matrix intended to help defining more precisely when and how computing tools (programs or devices) may be qualified as AI while highlighting critical features to serve a specific technical, ethical and legal assessment of challenges in AI development.
2109.01396_1524217_4	Additionally, we explain how such an understanding of the training process can be useful in practice and, as an example, show how it can be used to improve vanilla non-autoregressive neural machine translation by guiding teacher model selection.
2109.02417_1525238_2	From the examination of the images that were produced and with the help of Machine Learning, the question of whether the activity of each user is classified as malicious or not for the Information System was answered.
2110.06961_1545104_8	GPT-2 always acts as the best teacher, though, and using it and a Transformer-XL student on Wiki-02, rank-based KD reduces a cross-entropy baseline from 65.27 to 55.94 and against a KL-based KD of 56.70.
2110.09290_1547433_4	Finally, just as the chemistry triplet has impacted chemistry education in concrete ways, we suggest two initial hypotheses for how the AI triplet might impact AI education: 1) how we can help AI students gain proficiency in moving between the corners of the triplet; and 2) how all corners of the AI triplet highlight the need for supporting students' spatial cognitive skills.
2111.01726_1555829_9	Instruction from AI such as this functions both to help humans perform better at tasks, but also to better understand, anticipate, and correct the actions of an AI.
2111.12210_1566313_3	The key is to use Explainable AI to help derive data or model interpretations, hypotheses, as well as scientific discoveries or insights.
2111.12210_1566313_6	This work also highlights the important role of Explainable AI (as compared to Blackbox AI) in science discovery to help humans prevent or better prepare for the possible technological singularity that may happen in the future, since science is not only about the know how, but also the know why.
2201.06724_1592096_3	AI should play a role as an assistant in the lyrics creation process, where human interactions are crucial for high-quality creation.
2201.06796_1592168_5	We demonstrate that CoAuthor can address questions about GPT-3's language, ideation, and collaboration capabilities, and reveal its contribution as a writing "collaborator" under various definitions of good collaboration.
2203.01556_1614418_5	Participants of the AI track are asked to develop their AI algorithm that controls a character given only sound as the input (blind AI) to fight against their opponent; a sample deep-learning blind AI will be provided by us.
2204.12000_1642138_8	Our estimation scheme sheds light on an important anthropomorphic element found in such AI models and can help stakeholders decide how they should be applied as well as how society could perceive them.
2206.13703_1674123_2	In this work, we extended Kwame, our previous AI teaching assistant, adapted it for science education, and deployed it as a web app.
2207.04692_1680590_4	In this article, we propose a classification system using ML based on a novel `PUF-Phenotype' concept to accurately identify the origin and determine the validity of noisy memory derived (DRAM) PUF responses as an alternative to helper data-reliant denoising techniques.
2208.07960_1698672_4	Our results show that while recommendations from an AI-Assistant can aid user decision making, factors such as users' baseline performance relative to the AI and complementary tuning of AI error types significantly impact overall team performance.
2210.01369_1722724_5	Therefore, they held mixed views towards AI-enabled products such as AI, an aid, or an adversary.
2210.02498_1723853_6	Specifically, we generate silver annotated data by sending a series of prompts to a frozen pretrained language model, which acts as a teacher.
2210.03629_1724984_1	In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.
2210.12427_1733782_3	The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student.
2211.00373_1739279_1	As part of a recent Web-based Geographic Information System (WebGIS) project, we are employing cloud-native technologies (from the container ecosystem) to develop a federated database (DB) infrastructure, to help manage and utilise the distributed and various geospatial data.
2211.06318_1745224_3	It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field.
2211.08361_1747267_9	For an average formula with three variables, the system can generate and correct up to 300 questions for individual students based on a single formula concept name as input by the teacher.
2211.13230_1752136_3	As with all new technologies, use of AI should be preceded by a fundamental understanding of the risks and benefits to those it is intended to help.
2212.07542_1763719_5	The model uses contexts given by their instructor, such as chapters of a textbook, to answer questions and is deployed on an interactive chatbot/voice agent.
2212.08073_1764250_0	  As AI systems become more capable, we would like to enlist their help to supervise other AIs.
2212.08073_1764250_7	As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them.
2301.10095_1781159_0	  Artificial Intelligence (AI) is taking on increasingly autonomous roles, e.g., browsing the web as a research assistant and managing money.
2301.10412_1781476_2	Specifically, the adversary injects a backdoor into the model during the training phase, so that input samples with backdoor triggers are classified as the target class.
2301.13867_1784931_7	We find that ChatGPT can be used most successfully as a mathematical assistant for querying facts, acting as a mathematical search engine and knowledge base interface.
2302.04536_1789470_0	  Aim: To compare students' essay writing performance with or without employing ChatGPT-3 as a writing assistant tool.
2302.07080_1792014_3	We developed a prototype system -- the Programmer's Assistant -- in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM.
2302.08500_1793434_2	Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust.
2302.09977_1794911_8	Besides, the hidden structural information between the stations can be obtained as model by-products, which can help make some subsequent decision-making analyses.
2302.10291_1795225_0	  Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc.
2302.10786_1795720_1	In this work, we extended Kwame, a bilingual AI teaching assistant for coding education, adapted it for science education, and deployed it as a web app.
2303.06573_1806370_3	In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search.
2303.07610_1807407_0	  As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis.
2303.08033_1807830_6	These findings can be leveraged by educators to adapt their instructional practices and assessments in programming courses, so that GPT becomes a valuable assistant for a learner as opposed to a source of confusion and/or potential hindrance in the learning process.
2303.09325_1809122_8	These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.
2303.11455_1811252_5	We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code.
2303.12040_1811837_2	The AI as collaborator dream is different from computer tools that augment human intelligence (IA) or intermediate human collaboration.
2303.12732_1812529_2	Specifically, with the recent appearance of tools such as DALL-E, capable of completing images guided by a textual description, it is possible to count on the help of AI for architectural design tasks.
2304.09873_1827919_1	This paper proposes using ChatGPT, an innovative technology with various applications, as an assistant for psychotherapy.
2304.09873_1827919_2	ChatGPT can serve as a patient information collector, a companion for patients in between therapy sessions, and an organizer of gathered information for therapists to facilitate treatment processes.
2304.09873_1827919_4	Using ChatGPT as an assistant for psychotherapy poses several challenges that need to be addressed, including technical as well as human-centric challenges which are discussed.
2304.11938_1829984_2	To assess the feasibility of using an LLM as a useful assistant bot for programmers, we must assess its realistic capabilities on unseen problems as well as its capabilities on various tasks.
2304.11938_1829984_3	In this paper, we present an empirical study of ChatGPT's potential as a fully automated programming assistant, focusing on the tasks of code generation, program repair, and code summariziation.
2304.13841_1831887_13	AI research and development may help make transportation more sustainable, as may optimizing EHVs and charging infrastructure.
2304.14233_1832279_4	As a part of the prompts, they are likely to help LLM generate more precise answers by pattern imitation or candidate summarization.
2305.03047_1836103_1	Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable.
2305.07759_1840815_5	We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher.
2305.11248_1844304_6	We gathered developers' feedback on how these design concepts can help them build appropriate trust in AI-powered code generation tools, as well as potential risks in design.
2305.14483_1847539_4	Building on this insight, SIRLC assigns LLMs dual roles as both student and teacher.
2305.14483_1847539_5	As a student, the LLM generates answers to unlabeled questions, while as a teacher, it evaluates the generated text and assigns scores accordingly.
2305.14878_1847934_3	Our results demonstrate that GPT-4 is adept at translation post-editing, producing meaningful and trustworthy edits to translations that help improve its general quality as well as remove different classes of major errors in translations.
2305.18011_1851067_0	  Explainable AI (XAI) techniques have been widely used to help explain and understand the output of deep learning models in fields such as image classification and Natural Language Processing.
2305.18239_1851295_5	These factors are: (i) the impact of teacher model quality on DWT effectiveness, (ii) guidelines for adjusting the weighting value for DWT loss, and (iii) the impact of parameter remapping as a student model initialization technique for DWT.
2305.18279_1851335_4	Moreover, we present ContextDET, a unified multimodal model that is capable of end-to-end differentiable modeling of visual-language contexts, so as to locate, identify, and associate visual objects with language inputs for human-AI interaction.
2305.20076_1853132_0	  We describe a class of tasks called decision-oriented dialogues, in which AI assistants such as large language models (LMs) must collaborate with one or more humans via natural language to help them make complex decisions.
2306.01058_1854206_2	Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements.
2306.01615_1854763_3	I propose that viewing AI as a tool or an instrument, rather than a collaborator, is more accurate, and ultimately fairer.
2306.03090_1856238_2	We explore whether generative AI could become a cost-effective complement to expert feedback by serving as an automated teacher coach.
2306.03102_1856250_1	This paper investigates the capabilities of ChatGPT as an automated assistant in diverse domains, including scientific writing, mathematics, education, programming, and healthcare.
2306.03204_1856352_0	  This paper explores the concept of leveraging generative AI as a mapping assistant for enhancing the efficiency of collaborative mapping.
2306.03823_1856971_4	While ChatGPT has the ability to help educators by creating instructional content, offering suggestions and acting as an online educator to learners by answering questions and promoting group work, there are clear drawbacks in its use, such as the possibility of producing inaccurate or false data and circumventing duplicate content (plagiarism) detectors where originality is essential.
2306.05360_1858508_2	The task aims to assess the performance of state-of-the-art generative models as AI teachers in producing suitable responses within a student-teacher dialogue.
2306.06503_1859651_1	The use of AI models solely trained on large multi-institutional datasets can help with this, yet the imperative to ensure data privacy remains, particularly as membership inference risks breaching patient confidentiality.
2306.06794_1859942_4	We propose that considering what it is like to be an LLM like ChatGPT, as Nagel might have put it, can help us gain insight into its capabilities in general, and in particular, that its exposure to linguistic training data can be productively reframed as exposure to the diegetic information encoded in language, and its deficits can be reframed as ignorance of extradiegetic information, including supradiegetic linguistic information.
2306.06941_1860089_2	The goal of the task was to benchmark the ability of generative language models to act as AI teachers, replying to a student in a teacher-student dialogue.
2306.10052_1863200_2	The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases.
2306.10645_1863793_4	Although the results are encouraging, challenges are posed by the limited history maintained for the conversation and the highly structured form of responses by ChatGPT, as well as their variability, which can lead to an unexpected switch of the chatbot's role from a teacher to a therapist.
2306.14048_1867196_7	We formulate the KV cache eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work.
2306.14165_1867313_0	  This study explores the potential of generative artificial intelligence (AI) models, specifically OpenAI's generative pre-trained transformer (GPT) series, when integrated with building information modeling (BIM) tools as an interactive design assistant for architectural design.
2306.16282_1869430_4	Additionally, the suitability of ChatGPT as a teacher for students also warrants consideration.
2307.01981_1872977_5	The key idea is to query large language models (LLMs) with category names to automatically generate additional cues and knowledge, such as disease symptoms or descriptions other than a single category name, to help provide more accurate and explainable diagnosis in CLIP.
2307.06865_1877860_7	Prompt extraction from real systems such as Claude 3 and ChatGPT further suggest that system prompts can be revealed by an adversary despite existing defenses in place.
2307.12776_1883771_2	However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others.
2307.16364_1887359_5	This paper introduces a novel pedagogical concept known as a `Prompt Problem', designed to help students learn how to craft effective prompts for LLMs.
2308.02180_1890072_5	While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop.
2308.09904_1897796_4	We introduce the RAH Recommender system, Assistant, and Human) framework, an innovative solution with LLM-based agents such as Perceive, Learn, Act, Critic, and Reflect, emphasizing the alignment with user personalities.
2308.10335_1898227_7	Existing code evaluation benchmark and datasets focus on crafting small tasks such as programming questions in coding interviews, which however deviates from the problem that developers would ask LLM for real-world coding help.
2308.10873_1898765_5	Moreover, the convergence of average spiking rate of neurons at equilibrium is utilized to develop a novel ANN-SNN knowledge distillation based technique wherein we use a pre-trained BERT model as "teacher" to train our "student" spiking architecture.
2309.00642_1905446_2	Where our study diverges from previous work is in (1) providing a more thorough analysis of what makes mathematical term extraction a difficult problem to begin with; (2) paying close attention to inter-annotator disagreements; (3) providing a set of guidelines which both human and machine annotators could use to standardize the extraction process; (4) introducing a new annotation tool to help humans with ATE, applicable to any mathematical field and even beyond mathematics; (5) using prompts to ChatGPT as part of the extraction process, and proposing best practices for such prompts; and (6) raising the question of whether ChatGPT could be used as an annotator on the same level as human experts.
2309.01645_1906449_1	While it was reported that ChatGPT had the capacity to deliver useful feedback, it is still unclear about its effectiveness compared with conventional feedback approaches,such as teacher feedback (TF) and self-feedback (SF).
2309.01645_1906449_7	These diverse outcomes indicate ChatGPT's potential as a supplementary resource, complementing traditional teacher-led methods in translation practice.
2309.04076_1908880_4	The key idea of Avatar is to formulate the optimization of language models as a multi-objective configuration tuning problem and solve it with the help of a Satisfiability Modulo Theories (SMT) solver and a tailored optimization algorithm.
2309.06424_1911228_4	In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.
2309.08788_1913592_3	The model has proven that it is able to accurately recall information about biological materials and is further enhanced with enhanced reasoning ability, as well as with retrieval-augmented generation to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains.
2309.09582_1914386_5	The generated data could then be used to train a binary sentiment classifier, effectively leveraging an LLM as a teacher to a smaller student model.
2309.10066_1914870_1	Twelve language models were trained on a corpus of PET reports using the teacher-forcing algorithm, with the report findings as input and the clinical impressions as reference.
2309.10694_1915498_3	Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.
2309.11672_1916476_3	However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged.
2309.12348_1917152_4	A future that can be extremely promising if humanity manages to have AI as a proper ally and partner, with distinct roles and specific rules of cooperation and interaction.
2309.14494_1919298_2	To generate a semantic-coherent video, exhibiting a rich portrayal of temporal semantics such as the whole process of flower blooming rather than a set of "moving images", we propose a novel Free-Bloom pipeline that harnesses large language models (LLMs) as the director to generate a semantic-coherence prompt sequence, while pre-trained latent diffusion models (LDMs) as the animator to generate the high fidelity frames.
2309.15839_1920643_0	  Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies.
2309.16697_1921501_9	Based on the survey results, ChatGPT is recommended to be used as an assistant to complete programming tasks and other general assignments.
2309.17415_1922219_1	This will not only help to understand LLMs' decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG).
2310.01434_1923691_4	Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features.
2310.01727_1923984_3	Given that large language models (LLMs), such as GPT-4, show promise in tackling both software engineering- and science-related tasks, these models could help replicate and thus democratize empirical software engineering research.   
2310.02421_1924678_1	Knowledge distillation, a technique aiming to transfer knowledge from a high-capacity "teacher" model to a streamlined "student" model, emerges as a promising solution to this dilemma.
2310.02439_1924696_1	Our primary approach is to simulate LLMs as a novice learner and an expert tutor, aiming to identify the incorrect answer to math question resulted from a specific misconception and to recognize the misconception(s) behind an incorrect answer, respectively.
2310.02527_1924784_2	In this paper, we exploit the idea of leveraging AI models in lieu of humans as the teacher to train student LLMs.
2310.02739_1924996_6	This system is hosted on Streamlit, where users will be prompted to provide an image to serve as their AI assistant.
2310.03684_1925941_0	  Despite efforts to align large language models (LLMs) with human intentions, widely-used LLMs such as GPT, Llama, and Claude are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content.
2310.03780_1926037_4	As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts.
2310.05191_1927448_0	  In the context of English as a Foreign Language (EFL) writing education, LLM-as-a-tutor can assist students by providing real-time feedback on their essays.
2310.05191_1927448_1	However, challenges arise in assessing LLM-as-a-tutor due to differing standards between educational and general use cases.
2310.05191_1927448_4	Second, we propose three metrics to evaluate LLM-as-a-tutor specifically designed for EFL writing education, emphasizing pedagogical aspects.
2310.05191_1927448_5	In this process, EFL experts evaluate the feedback from LLM-as-a-tutor regarding quality and characteristics.
2310.05191_1927448_6	On the other hand, EFL learners assess their learning outcomes from interaction with LLM-as-a-tutor.
2310.05191_1927448_7	This approach lays the groundwork for developing LLMs-as-a-tutor tailored to the needs of EFL learners, advancing the effectiveness of writing education in this context.
2310.05563_1927820_0	  This paper presents Social data and knowledge collective intelligence platform for TRaining Ethical AI Models (STREAM) to address the challenge of aligning AI models with human moral values, and to provide ethics datasets and knowledge bases to help promote AI models "follow good advice as naturally as a stream follows its course".
2310.05853_1928110_5	Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development.
2310.09617_1931874_4	Next, we conducted a qualitative user study examining the reactions and attitudes of practitioners toward ChatGPT as a visualization design assistant.
2310.11954_1934211_2	Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements.
2310.13021_1935278_5	We close with open discussions and questions that we believe necessitate a multi-disciplinary perspective -- cognitive scientists working in tandem with AI researchers and mathematicians -- as we move toward better mathematical AI systems which not only help us push the frontier of the mathematics, but also offer glimpses into how we as humans are even capable of such great cognitive feats.
2310.15127_1937384_2	In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction, or VLM description, and used as in-context prompt examples for LLM querying.
2310.17110_1939367_7	Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks.
2310.18628_1940885_4	Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution.
2311.00177_1943144_5	Our findings show that AI code completion enhanced students' productivity and efficiency by providing correct syntax suggestions, offering alternative solutions, and functioning as a coding tutor.
2311.06180_1949147_13	This study demonstrated the feasibility of using Generative AI as an assistant to generating feedback for student written responses with only a relatively small number of examples.
2311.06985_1949952_2	We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or other LLMs, compared to humans.
2311.07052_1950019_5	In the context of large LMs (LLMs), previously viable approaches become much less meaningful, as it is an impossible triangle to distill an expected student from an optimal teacher student with small compute overhead.
2311.07838_1950805_2	Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM's output.
2311.09868_1952835_1	INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair process, functioning as both a Code Learner and a Code Teacher.
2311.10054_1953021_2	For example, ChatGPT uses ``You are a helpful assistant'' as part of its default system prompt.
2311.11865_1954832_5	We hope our work can serve as a unified evaluation for video LLMs, and help expand more practical scenarios.
2311.14701_1957668_9	Results: The introduction of ChatGPT as a pedagogical tool led to increased student engagement and decreased teacher resistance, reflected in recognition at local science fairs.
2311.16161_1959128_5	The results underscore the methodology's potential as a promising paradigm for creating efficient AI coach models in various domains involving visual inputs.
2311.17978_1960945_0	  The context of this paper is the creation of large uniform archaeological datasets from heterogeneous published resources, such as find catalogues - with the help of AI and Big Data.
2312.00438_1962246_1	In this paper, we introduce Dolphins, a novel vision-language model architected to imbibe human-like abilities as a conversational driving assistant.
2312.01276_1963084_1	I discuss 14 methodological considerations that can help design more robust, generalizable studies evaluating the cognitive abilities of language-based AI systems, as well as to accurately interpret the results of these studies.
2312.01797_1963605_0	  This research focuses on how Large Language Models (LLMs) can help with (path) planning for mobile embodied agents such as robots, in a human-in-the-loop and interactive manner.
2312.03863_1965671_6	We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient LLMs research and inspire them to contribute to this important and exciting field.
2312.04724_1966532_0	  This paper presents CyberSecEval, a comprehensive benchmark developed to help bolster the cybersecurity of Large Language Models (LLMs) employed as coding assistants.
2312.06731_1968539_6	Through experiments and synthetic data analysis, our findings are: (1) current MLLMs can serve as robust data generators without assistance from GPT-4V; (2) MLLMs trained with task-specific datasets can surpass GPT-4V in generating complex instruction tuning data; (3) synthetic datasets enhance performance across various multimodal benchmarks and help mitigate model hallucinations.
2312.07343_1969151_1	This paper explores the potential of using ChatGPT, an LLM, as a virtual Teaching Assistant (TA) in an Introductory Programming Course.
2312.07814_1969622_4	We compare PathChat against several multimodal vision language AI assistants as well as GPT4V, which powers the commercially available multimodal general purpose AI assistant ChatGPT-4.
2312.07814_1969622_7	As an interactive and general vision language AI assistant that can flexibly handle both visual and natural language inputs, PathChat can potentially find impactful applications in pathology education, research, and human-in-the-loop clinical decision making.
2312.12006_1973814_1	This study aims to evaluate the potential of using a fine-tuned ChatGPT model as a personal medical assistant in the Arabic language.
2312.13103_1974911_1	This paper proposes one of the first clinical applications of multimodal large language models (LLMs) as an assistant for radiologists to check errors in their reports.
2312.15842_1977650_2	Our methodology involves training the smaller student model (Neural Network) using the prediction probabilities (as soft labels) of the LLM, which serves as a teacher model.
2312.17432_1979240_4	Furthermore, we identify five sub-types based on the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM as Text Decoder, LLM as Regressor, and LLM as Hidden Layer.
2401.00994_1980550_1	During virtual assistant development, some developers prefer to leverage the system message, also known as an initial prompt or custom prompt, for preconditioning purposes.
2401.01262_1980818_1	However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education.
2401.02147_1981703_0	  Large language models (LLMs) have demonstrated a powerful ability to answer various queries as a general-purpose assistant.
2401.02262_1981818_1	The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand.
2401.04543_1984099_0	  AI assistants such as Alexa, Google Assistant, and Siri, are making their way into the healthcare sector, offering a convenient way for users to access different healthcare services.
2401.06484_1986040_3	The simulation is done with the help of deep deterministic policy gradient (DDPG) as a deep reinforcement learning (DRL)-based algorithm.
2401.07964_1987520_2	The basic thrust of AI-as-exploration is that of creating and studying systems that can reveal candidate building blocks of intelligence that may differ from the forms of human and animal intelligence we are familiar with.
2401.14208_1993762_10	The combination of AI, XR, and an HDT-based solution will help to avoid technical errors and serve as a universal methodology in the development of personalized cardiology.
2401.15700_1995254_2	Artificial Intelligence (AI) can help financial institutions tailor relevant products and services to their customers as well as improve their credit risk management, compliance, and fraud detection capabilities by incorporating chatbots and face recognition systems.
2401.16454_1996008_3	In this regard, we introduce, Kaucus, a Knowledge-Augmented User Simulator framework, to outline a process of creating diverse user simulators, that can seamlessly exploit external knowledge as well as benefit downstream assistant model training.
2401.16587_1996141_0	  This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset.
2401.17217_1996771_3	We introduce GazeGPT as a new user interaction paradigm for contextual AI. GazeGPT uses eye tracking to help the LMM understand which object in the world-facing camera view a user is paying attention to.
2401.17459_1997013_9	We built and tested multiple versions of the AI agent using different off-the-shelf LLMs -- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with both chat completion and assistant APIs).
2402.01051_1998690_8	We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier.
2402.01536_1999175_0	  Large language models (LLMs) are now being used in a wide variety of contexts, including as creativity support tools (CSTs) intended to help their users come up with new ideas.
2402.02676_2000315_1	This paper uses ChatGPT as a research assistant to explore how far ChatGPT can replicate Quora question and answers, using data from the gig economy as an indicative case study.
2402.03630_2001269_0	  Large Language Models (LLMs) have achieved remarkable success in code completion, as evidenced by their essential roles in developing code assistant services such as Copilot.
2402.05605_2003244_4	To determine the best selection of a control agent, we propose the addition of an AI manager (via Reinforcement Learning) which learns as an outside observer of the team.
2402.06264_2003903_1	Art appreciation, often perceived as an unfamiliar and challenging endeavor for most students, can be more accessible with a generative AI enabled conversation partner that provides tailored questions and encourages the audience to deeply appreciate artwork.
2402.06264_2003903_2	This study explores the application of multimodal large language models (MLLMs) in art appreciation education, with a focus on developing LLaVA-Docent, a model designed to serve as a personal tutor for art appreciation.
2402.08761_2006400_3	Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM's APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement.
2402.09683_2007322_3	This paper first proposes a "positive friction" model that can help characterize how friction is currently beneficial in user and developer experiences with AI, diagnose the potential need for friction where it may not yet exist in these contexts, and inform how positive friction can be used to generate solutions, especially as advances in AI continue to be progress and new opportunities emerge.
2402.09773_2007412_3	Knowledge Distillation is well-suited for pruning, as the intact model can serve as an excellent teacher for pruned students.
2402.12366_2010005_4	Specifically, we show that simple supervised fine-tuning with GPT-4 as the teacher outperforms existing RLAIF pipelines.
2402.13516_2011155_3	Some recent efforts have explored introducing ReLU or its variants as the substitutive activation function to help LLMs achieve activation sparsity and inference acceleration, but few can simultaneously obtain high sparsity and comparable model performance.
2402.15100_2012739_2	In terms of actual use however, a great deal of software development still occurs in the for-profit/proprietary sphere, where the code under development is not, and never has been, in the public domain; thus, many developers, do their work, and use LLMs, in settings where the models may not be as familiar with the code under development.
2402.16361_2014000_5	The proposed LR-Drop can be regarded as a "self-distillation" framework, in which each sub-model generated by dropout is the other's "teacher" model and "student" model.
2402.16515_2014154_4	We construct a knowledge distillation model as the DP-based discriminator: teacher models, accessing private data, teaches students how to select private samples with calibrated noise to achieve DP.
2402.16664_2014303_5	We first develop a new multi-teacher CL framework that leverages a multimodal LLM as the additional teacher.
2403.00806_2017925_0	  With the large language model showing human-like logical reasoning and understanding ability, whether agents based on the large language model can simulate the interaction behavior of real users, so as to build a reliable virtual recommendation A/B test scene to help the application of recommendation research is an urgent, important and economic value problem.
2403.00871_2017990_3	This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%.
2403.00894_2018013_6	These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
2403.01538_2018657_2	This model is used in this study to help faculty with examining the impact that a disruptive new tool, such as ChatGPT, can pose for the learning environment.   
2403.01575_2018694_3	Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated.
2403.04260_2021379_6	The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g., LLaMA2-7B).
2403.10468_2027587_1	Despite its widespread adoption, the impact of ChatGPT as an assistant in collaborative coding remains largely unexplored.
2403.11128_2028247_3	However, such evaluation method can be misleading, as an AI assistant might fail in generating API calls from preceding human interaction in real cases.
2403.12014_2029133_2	Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller RL agents learn useful skills that they are weak at?
2403.14694_2031813_5	To this end, we have conducted a detailed experiment in a representative subject of Computer Science such as Software Engineering, which has focused on evaluating the use of ChatGPT as an assistant in theory activities, exercises, and laboratory practices, assessing its potential use as a support tool for both students and teachers.
2403.15638_2032757_2	However, DP-SGD overestimates an adversary's capabilities in having white box access to the model and, as a result, causes longer training times and larger memory usage than SGD.
2403.16427_2033546_7	It learns to select hints from the constructed KB based on the task-specific feedback, where the hints can serve as guidance to help correct LLMs reasoning for better recommendations.
2403.17336_2034455_8	Building on the insights from the user study, we also developed a system using AI as the assistant to automate the process of jailbreak prompt generation.
2403.18721_2035840_7	Hence, despite the relatively lower response quality of PhysicsAssistant than GPT-4, it has shown potential for being used as a real-time lab assistant to provide timely responses and can offload teachers' labor to assist with repetitive tasks.
2403.19049_2036168_0	  Past work has sought to design AI ethics interventions--such as checklists or toolkits--to help practitioners design more ethical AI systems.
2404.02548_2039999_2	However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored.
2404.02548_2039999_4	In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis.
2404.02616_2040067_4	To tackle above two problems, we first take query concatenated with the query-based summary and the document summary without query as the input of topic relevance model, which can help model learn the relevance degree between query and the core topic of document.
2404.02798_2040249_7	Finally, we explore the potential of generative AI, such as ChatGPT, and propose a hybrid model that blends artificial intelligence with a collaborative, teacher-facilitated approach to personalized learning.
2404.03715_2041166_7	Moreover, DNO enjoys monotonic improvement across iterations that help it improve even over a strong teacher (such as GPT-4).
2404.11502_2048953_0	  In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications.
2404.13149_2050600_3	Prompting approaches of the pre-trained LLMs that elicit a model's reasoning process, such as chain-of-thought, may help to improve the trustworthiness of the generated responses.
2404.14082_2051533_7	Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.
2404.15310_2052761_11	Moreover, GPT-4 could deliver logical and concrete reasoning as potential teacher guidelines.
2404.16297_2053748_4	As a remedy, we propose some actionable recommendations to help improve applying LLM in Fuzzing and conduct preliminary evaluations on DBMS fuzzing.
2404.19256_2056707_2	This phenomenon can be viewed as a form of social compensation, where the AI makes decisions based not on predefined goals but on its human partner's deficiencies in relation to the team's performance objectives.
2405.00715_2057927_4	We introduced a new approach, DistillDirect, for performing on-policy reinforcement learning with Gemini 1.0 Pro as the teacher model.
2405.00995_2058207_5	Knowledge workers also expressed worries about Gen AI undermining trust in the relationship between instructor and student and discussed potential solutions, such as pedagogy readiness, to mitigate them.
2405.00995_2058207_6	Additionally, participants recognized Gen AI's potential to democratize knowledge by accelerating the learning process and act as an accessible research assistant.
2405.06626_2063838_11	The results show that low-rank decomposition can be a promising direction for LLM-based applications that require real-time service at scale (e.g., AI agent and real-time coding assistant), where the latency is as important as the model accuracy.
2405.06800_2064012_0	  Large Language Models (LLMs) are becoming vital tools that help us solve and understand complex problems by acting as digital assistants.
2405.08828_2066040_2	The primary aim of this study is to contribute to the methodological discussion regarding the integration of AI tools, offering a practical guide to validation for using GPT as a collaborative research assistant.
2405.09186_2066398_0	  Language models (LMs) as conversational assistants recently became popular tools that help people accomplish a variety of tasks.
2405.09186_2066398_4	To help accelerate the development of LMs as conversational assistants, we propose a novel automatic evaluation task: HumanRankEval (HRE).
2405.13052_2070264_5	A chatbot mimicking ChatGPT's default behavior of acting as a helpful assistant led to markedly inferior personality inferences and lower user experience ratings but still captured psychologically meaningful information for some of the personality traits (mean r=.117, range=[-.004, .209]).
2405.13890_2071102_0	  As large language models (LLMs) become more powerful and ubiquitous, systems like ChatGPT are increasingly used by students to help them with writing tasks.
2405.13890_2071102_2	To that end, we plan to conduct a user study that will record the user writing process and present them with the opportunity to use ChatGPT as an AI assistant.
2405.14713_2071925_3	Our approach leverages Large Language Models (LLMs) and prompt engineering to generate tutor layout and contents based on high-level requirements provided by educators as inputs.
2405.15485_2072697_1	Motivated by the use of LLMs as a general scientific assistant, this paper assesses the domain knowledge of LLMs through its understanding of different mathematical skills required to solve problems.
2405.17821_2075033_4	Specifically, when a model hallucinates based on the original image, the transformed images -- altered in aspects such as orientation, scale, or color -- provide alternative viewpoints that help recalibrate the model's predictions.
2405.18137_2075349_6	In practice, the adversary could host the resulting full-precision model on an LLM community hub such as Hugging Face, exposing millions of users to the threat of deploying its malicious quantized version on their devices.
2405.19635_2076847_4	This approach leverages a larger LLM as a ''teacher'' to create guidance prompts, paired with a smaller ''student'' model to finalize responses.
2405.19635_2076847_9	When utilizing ChatGPT as teacher model and Llama2-70B as the student model, we can achieve 95.00% of ChatGPT's performance at 52% of the cost.
2405.19691_2076903_2	To help teachers address such risks, we conducted a two-phase iterative design process that comprises surveys, interviews, and prototype demonstration involving six EFL (English as a Foreign Language) teachers, who integrated ChatGPT into semester-long English essay writing classes.
2406.03079_2081367_6	Furthermore, our findings emphasize the importance of realizing that ChatGPT could be a valuable instructor even for novice fraudsters, as well as understanding and safely deploying complex language models, particularly in the context of cryptocurrency frauds.
2406.04236_2082524_4	We use a constraint-based formulation which views a visual question as having a set of visual or textual constraints that the model's generated answer must satisfy to be correct (e.g. What movie directed by the director in this photo has won a Golden Globe?).
2406.06560_2084848_11	As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: help identify undesirable annotator biases, understand model performance better, scale feedback to unseen data, or adapt models to individual user or group preferences.
2406.06575_2084863_1	Large language models (LLM) have the potential to help improve productivity by serving as conversational agents that effectively function as subject-matter experts.
2406.08680_2086968_0	  Automatically assessing classroom discussion quality is becoming increasingly feasible with the help of new NLP advancements such as large language models (LLMs).
2406.09288_2087576_5	In this paper, we introduce LMTX (Large language Model as Teacher for eXtreme classification), a novel framework that bridges the gap between these two approaches.
2406.09444_2087732_3	The proposed method takes the previous hidden layer as history and implements a layer-by-layer prediction of the teacher model autoregressively.
2406.10273_2088561_17	Therefore, experts can leverage LLMs as an effective complementing companion in risk analysis within a condensed timeframe.
2406.11858_2090146_5	The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.
2406.12665_2090953_8	Thus, CollabStory is a resource that could help propel an understanding as well as the development of new techniques to discern the use of multiple LLMs.
2406.12775_2091063_1	Motivated by this, we study how LLMs answer multi-hop queries such as "The spouse of the performer of Imagine is".
2406.13903_2092191_2	A novel aspect of the research involved using GPT-4 as a 'teacher' to create complex questions, with GPT-3.5 as the 'student' responding to these challenges.
2406.13972_2092260_3	To evaluate LLMs' realistic repair capabilities, (1) we introduce an extensive, non-crawled benchmark, referred to as TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code.
2406.15259_2093547_6	Since CoT is reported to perform poorly with small LLMs, we adopted a strategy in which a large LLM (GPT-4), acting as a Teacher, generates CoT-based instructions to fine-tune a small model, Llama-2-7B, which plays the role of a Student.
2407.00087_2098474_3	With advanced AI models (Teacher), such as GPT-4 and Claude 3 Opus, we can request various types of detailed feedback that are expensive for humans to provide.
2407.02048_2100435_8	The findings highlight the potential of AI and ChatGPT in particular, as an innovative cutting-edge educational tool that can both enhance the learning experience and help achieve the Sustainable Development Goals (SDGs) through education.
2407.02606_2100993_3	This method effectively combines edge devices and LLMs to help elderly people in their daily activities, such as reminding them to take pills or handling emergencies like falls.
2407.09709_2108096_2	For example, current attempts at designing general graph models either transform graph data into a language format for LLM-based prediction or still train a GNN model with LLM as an assistant.
2407.10362_2108749_3	Importantly, in contrast to previous scientific benchmarks, we expect that an AI system that can achieve consistently high scores on the more difficult LAB-Bench tasks would serve as a useful assistant for researchers in areas such as literature search and molecular cloning.
2407.11072_2109459_9	Our work highlights the need to secure LLM prompts against manipulation as well as rigorously auditing code generated with the help of LLMs.
2407.11360_2109747_3	It delves into the strategies humans are developing and refining to help mitigate risks such as bias, misinformation, and privacy breaches, that influence and shape Gen AI's evolution.
2407.12861_2111248_2	We pose the following research question: Given a text excerpt referencing a paper, could an LM act as a research assistant to correctly identify the referenced paper?
2407.12899_2111286_3	DreamStory consists of (1) an LLM acting as a story director and (2) an innovative Multi-Subject consistent Diffusion model (MSD) for generating consistent multi-subject across the images.
2407.13692_2112079_9	Our results suggest legibility training against small verifiers as a practical avenue for increasing legibility of large LLMs to humans, and thus could help with alignment of superhuman models.
2407.14769_2113156_1	Despite AI's potential as a valuable assistant, its role in complex medical data analysis often oversimplifies human-AI collaboration dynamics.
2407.16154_2114541_1	Knowledge Distillation (KD) has emerged as an effective strategy to improve the performance of a smaller LLM (i.e., the student model) by transferring knowledge from a high-performing LLM (i.e., the teacher model).
2407.19256_2117643_12	As LLMs evolve, they could become key tools in CCM to help improve patient outcomes and optimize healthcare delivery.
2407.19492_2117879_1	This paper proposes Heads Up eXperience (HUX), an AI system designed to bridge this gap, serving as a constant companion across the extended reality (XR) environments.
2407.19586_2117973_3	Our theory has a close analogy to a familiar insight in financial economics on the impossibility of an informationally efficient market [Grossman and Stiglitz (1980)]: If generative AI models can provide all the content humans need at low variable costs, then there is no incentive for humans to spend costly resources on content creation as they cannot profit from it.
2407.21202_2119589_0	  Nowadays, we delegate many of our decisions to Artificial Intelligence (AI) that acts either in solo or as a human companion in decisions made to support several sensitive domains, like healthcare, financial services and law enforcement.
2408.00946_2121127_4	From inception theories up to current methodologies, this paper provides an integrated view of dealing with better total uncertainty as well as complexities of uncertainty in AI that help us understand its meaning and value across different domains.
2408.03354_2123535_6	Various ways to enhance the model were uncovered, such as the need to help the LLM distinguish between stories and past events, as well as being careful with verb tenses in prompts.
2408.03506_2123687_0	  This paper presents a compute-efficient approach to pre-training a Language Model-the "1.5-Pints"-in only 9 days, while outperforming state-of-the-art models as an instruction-following assistant.
2408.04112_2124293_0	  Large language models (LLMs) can help writers build story worlds by generating world elements, such as factions, characters, and locations.
2408.04645_2124826_0	  This study evaluates the performance of Large Language Models (LLMs) as an Artificial Intelligence-based tutor for a university course.
2408.04775_2124956_2	We employ a student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as student models and GPT-4o as the teacher, to dynamically select between prompt refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.
2408.05534_2125715_6	To help decide when and how to use LLMs in human-subject studies, we propose model-model agreement as a predictor of whether a given task is suitable for LLMs at all, and model confidence as a means to select specific samples where LLMs can safely replace human annotators.
2408.08321_2128502_2	We explored the feasibility of utilizing ChatGPT as a virtual assistant to provide navigation directions.
2408.10947_2131128_4	Therefore, our research introduces a benchmark to evaluate the questioning capability in education as a teacher of LLMs through evaluating their generated educational questions, utilizing Anderson and Krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary domains.
2408.10947_2131128_7	Our results indicate that GPT-4 demonstrates significant potential in teaching general, humanities, and science courses; Claude2 appears more apt as an interdisciplinary teacher.
2408.11043_2131224_3	The novelty of this work lies in strategizing the research inquiry as one that is augmented by an LLM that serves as a novice research assistant.
2408.14512_2134693_7	Experiments show that our graph token embeddings help the LLM predictor achieve state-of-the-art performance on unseen datasets and tasks compared to other methods using LLMs as predictors.
2408.16235_2136416_2	We first design a latent mean-teacher framework that integrates both labeled and unlabeled data, as well as their latent vectors, into model training.
2408.16984_2137165_5	Finally, we argue that these limitations motivate a reframing of the targets of AI alignment: Instead of alignment with the preferences of a human user, developer, or humanity-writ-large, AI systems should be aligned with normative standards appropriate to their social roles, such as the role of a general-purpose assistant.
2408.17097_2137278_4	Our approach employs an LLM as a ''teacher'' model through zero-shot prompting to generate teaching CoT rationales, followed by a CoT ''student'' model that is fine-tuned by the generated teaching data for learning to reason about performance declines.
2409.00558_2138190_3	Specifically, given an input textual prompt, our scheme consists of three stages: 1) We leverage LLM as the director to first decompose the complex query into several sub-prompts that indicate individual concepts within the video~(\textit{e.g.}, scene, objects, motions), then we let LLM to invoke pre-trained expert models to obtain corresponding 3D representations of concepts.
2409.04056_2141688_3	Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM.
2409.07110_2144742_2	Leveraging cutting-edge open-source Large Language Models (LLMs), Bio-Eng-LMM operates as a sophisticated AI assistant, exploiting the capabilities of traditional models like ChatGPT.
2409.09047_2146679_0	  The effect of large language models (LLMs) in education is debated: Previous research shows that LLMs can help as well as hurt learning.
2409.11654_2149286_6	We envision a future where AI Virtual Cells help identify new drug targets, predict cellular responses to perturbations, as well as scale hypothesis exploration.
2409.12586_2150218_5	These important tokens are then provided as rationales to a student model, aiming to distill the knowledge of the teacher model.
2409.13099_2150731_0	  As AI-generated summaries proliferate, how can we help people understand the veracity of those summaries?
2409.13343_2150975_4	Developers generally express positive attitudes towards AI, viewing it as an efficiency-enhancing assistant rather than a job replacement threat.
2409.14206_2151838_4	Therefore, we propose CORE as an assistant that combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for a Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements to ensure an intuitive understanding of procedure steps, reliability, offline availability, and flexibility in terms of response style and procedure updates.
2409.14924_2152556_9	This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications.
2409.17027_2154659_3	Although this story, generated by a large language model, is captivating, one may wonder -- how would the story have unfolded if the model had chosen "Captain Maeve" as the protagonist instead?
2409.17434_2155066_5	It also advises public sector developers to classify their code as "Open" to use Gen-AI Coding Assistant tools on the Cloud like GitHub Copilot and to consider self-hosted tools like Codeium or Code Llama for confidential code to leverage technology efficiently within the public sector framework.
2409.17946_2155578_6	Specifically, we poison small-scale language models through full-parameter fine-tuning to serve as the teacher model.
2409.18999_2156631_6	Using data augmented by GPT-4 Omni, which involves generating new training examples and transforming existing data, we significantly improved the accuracy of FinBERT, preparing it to serve as a teacher model.
2410.00163_2158364_0	  This study evaluates the performance of large language models (LLMs) as medical agents in Portuguese, aiming to develop a reliable and relevant virtual assistant for healthcare professionals.
2410.03017_2161218_3	We introduce Tutor CoPilot, a novel Human-AI approach that leverages a model of expert thinking to provide expert-like guidance to tutors as they tutor.
2410.03032_2161233_7	Users perceived CounterQuill as a writing partner and thus were more willing to post the co-written counterspeech online compared to the one written with ChatGPT.
2410.03083_2161284_2	Specifically, we formulate the proposed term of effective training tokens to be a combination of two readily-computed indicators of text: (i) text diversity and (ii) syntheticity as measured by a teacher model.
2410.07122_2165323_5	Specifically, the large cloud model acts as a teacher, guiding and promoting the learning of the end model, which significantly reduces the end model's reliance on large-scale, high-quality data and thereby addresses the data bottleneck in traditional end model training, offering a new paradigm for the rapid deployment of industry applications.
2410.07397_2165598_7	We suggest that this principle can help make human-AI collaboration more fruitful, as well as shed light on how humans make scientific modeling choices.
2410.07461_2165662_4	Besides the already intriguing observation that the choice of calibration data significantly impacts the performance of pruned LLMs, our results also uncover several subtle and often unexpected findings, summarized as follows: (1) C4 is not the optimal choice for LLM pruning, even among commonly used pre-training datasets; (2) arithmetic datasets, when used as calibration data, performs on par or even better than pre-training datasets; (3) pruning with downstream datasets does not necessarily help the corresponding downstream task, compared to pre-training data; (4) ICL is widely beneficial to all data categories, whereas CoT is only useful on certain tasks.
2410.09268_2167469_3	While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality.
2410.09318_2167519_0	  While Large language model (LLM)-based programming assistants such as CoPilot and ChatGPT can help improve the productivity of professional software developers, they can also facilitate cheating in introductory computer programming courses.
2410.09343_2167544_4	ELICIT serves as a plug-and-play performance booster to enable adaptive elicitation of model capabilities.
2410.09937_2168138_3	Such research is critical to help ensure current law students are positioned to fully exploit this technology as they embark on their legal careers but to also assist existing legal firms to better leverage their AI skillset both operationally and in helping to formulate future legal frameworks for regulating this technology across industries.
2410.11863_2170064_1	The assistant allows a user to specify the operations in natural language, attempting to generate a Python script for the desired operations, prompting the LLM to revise the script as needed until it executes correctly.
2410.11864_2170065_1	As a human-AI team, we together advocate for a shift toward viewing AI as a learning partner, akin to a student who learns from interactions with humans.
2410.11864_2170065_4	By reframing AI as a dynamic partner, a model emerges in which AI systems develop alongside humans, learning from human interactions and feedback loops including reflections on team conversations.
2410.13648_2171849_7	We further show that we can help models do better at (b) and (c) via interventions such as reminding the model of its earlier mental state answer and mental-state-specific chain-of-thought prompting, raising the action prediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment accuracies (e.g., from 15.3% to 94.7% in GPT-4o).
2410.14166_2172367_5	Compared with strategies such as finetuning and in-context learning that are commonly adopted to enhance performance on new or challenging tasks, we show that engaging reasoning is the most robust and efficient way to help LLMs better perceive tasks with more accurate responses.   
2410.14252_2172453_1	These intelligent home assistant frameworks, such as those based on high-performance LLMs like GPT-4, have greatly expanded their functional range and application scenarios by computing on the cloud, enriching user experience and diversification.
2410.14395_2172596_1	Those include using AI as a language tutor, creating learning materials, or assessing learner output.
2410.14425_2172626_4	Specifically, we first train a small-scale language model through full-parameter fine-tuning to serve as the clean teacher model.
2410.14609_2172810_9	Additionally, through the relaxation of the objective, we propose a multi-teacher distillation, using multiple LLMs as teachers, yielding additional gains, and outperforming the teachers themselves in in-domain experiments.
2410.16215_2174416_3	We first conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a 1.9B parameter student LLM, validating the effectiveness of PD.
2410.16215_2174416_5	We conduct extensive experiments to explore the design space of pre-training distillation and find better configurations and interesting conclusions, such as larger student LLMs generally benefiting more from pre-training distillation, while a larger teacher LLM does not necessarily guarantee better results.
2410.16229_2174430_9	CONAN can also be used as an assistant for Large Language Models (LLMs), providing LLMs with external knowledge in shorter code document lengths to improve their effectiveness on various code tasks.
2410.21819_2180020_5	To explore the causes, we hypothesize that LLMs may favor outputs that are more familiar to them, as indicated by lower perplexity.
2410.24148_2182349_4	In this paper, we propose to utilize vision language models (VLMs) such as generative pre-trained transformer (GPT), GEMINI, large language and vision assistant (LLAVA), PaliGemma, and Microsoft Florence2 to recognize facial attributes such as race, gender, age, and emotion from images with human faces.
2411.00780_2183207_6	Based on our findings, we envision MLMs as a teacher for knowledge distillation, a machine labeler, and a part of the ensembled and tiered seasonality detection system, which can empower ads ranking systems with enriched seasonal information.
2411.02725_2185152_4	Key insights for LLM tutor use are as follows: NNES students signed up for the LLM tutor at a similar rate to native English speakers (NES); NNES students used the system at a lower rate than NES students -- to a small effect; NNES students asked significantly more questions in languages other than English compared to NES students, with many of the questions being multilingual by incorporating English programming keywords.
2411.02725_2185152_5	Results for views of the LLM tutor are as follows: both NNES and NES students appreciated the LLM tutor for its accessibility, conversational style, and the guardrails put in place to guide users to answers rather than directly providing solutions; NNES students highlighted its approachability as they did not need to communicate in perfect English; NNES students rated help-seeking preferences of online resources higher than NES students; Many NNES students were unfamiliar with computing terminology in their native languages.
2411.03495_2185922_3	We present here the study of several dimensions: 1) identifying error patterns made by simulated students on secondary-level math exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating their effectiveness in generating hints that enable simulated students to self-correct; and 3) testing the best-performing prompts, based on their ability to produce relevant hints and facilitate error correction, with Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with GPT-4o.
2411.03495_2185922_6	Interestingly, Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.
2411.05681_2188108_1	To fully achieve the potential of MaaS, a range of AI (including machine learning and data mining) algorithms are needed to learn personal requirements and needs, to optimise journey planning of each traveller and all travellers as a whole, to help transport service operators and relevant governmental bodies to operate and plan their services, and to detect and prevent cyber attacks from various threat actors including dishonest and malicious travellers and transport operators.
2411.05828_2188255_2	Focusing on the management of multiparty AI conversations, this work introduces new concepts such as the Convener Agent, Floor-Shared Conversational Space, Floor Manager, Multi-Conversant Support, and mechanisms for handling Interruptions and Uninvited Agents.
2411.07820_2190247_3	Moreover, to enhance flexibility and reduce computational costs, we propose a trainable scheme for our pipeline that utilizes a smaller, tunable model as the query optimizer, which is refined through knowledge distillation from a larger teacher model.
2411.08469_2190896_4	This approach strives to help AI systems deliver results that are as accurate, explainable, and trustworthy as possible, aligning with regulatory expectations for transparency and accountability.
2411.09261_2191688_8	Our findings reveal that LLM-generated test suites can correctly identify most valid solutions, and for most problems are at least as comprehensive as the instructor test suites.
2411.09916_2192343_4	Therefore, we conducted an observational study with 22 participants using ChatGPT as a coding assistant in a non-trivial SE task to understand the practices, challenges, and opportunities for using LLMs for SE tasks.
2411.10718_2193145_0	  This study examines the transformative potential of Generative AI (GenAI) in teacher education within developing countries, focusing on Ghana, where challenges such as limited pedagogical modeling, performance-based assessments, and practitioner-expertise gaps hinder progress.
2411.11856_2194283_2	Large Language Models (LLMs) are emerging as a potential tool to help generate fully functioning HDL code, but most works have focused on generation in the single-shot capacity: i.e., run and evaluate, a process that does not leverage debugging and, as such, does not adequately reflect a realistic development process.
2411.12761_2195188_4	AI as a research tool (ART), AI as a research assistant (ARA), and AI as a research participant (ARP).
2411.13226_2195653_1	We focus on a specific privacy risk where LLMs may help identify the authorship of anonymous texts, which challenges the effectiveness of anonymity in real-world systems such as anonymous peer review systems.
2411.13800_2196227_0	  Use of large language models such as ChatGPT (GPT-4) for mental health support has grown rapidly, emerging as a promising route to assess and help people with mood disorders, like depression.
2411.16707_2199134_1	It positions AI as a versatile research assistant rather than a mere problem-solving tool.
2411.19638_2202065_2	The framework employs a Generative Pretrained Transformer (GPT) model as the teacher model to develop an IPTC Media Topic training dataset through automatic annotation of news articles in Slovenian, Croatian, Greek, and Catalan.
2412.01072_2203450_6	To address the gap, we investigate the use of federated learning as a privacy-preserving approach that enables private entities to fine-tune LLMs on proprietary and decentralized data, facilitating the collaboration between clients to fully utilize their data to help enhance software development and maintenance.
2412.01282_2203660_1	Meanwhile, the great need for capable aritificial intelligence on mobile devices also arises, such as the AI assistant software.
2412.01353_2203731_1	Leveraging this data, AI-based systems can be developed that help in assessing the mental health of individuals, such as suicide risk.
2412.01617_2203995_3	To explore this, we analysed user interactions with ChatGPT, particularly those outside of its marketed use as task-oriented assistant.
2412.06040_2208418_5	In Study 2 (N = 684), we tested whether spillover persisted when the agent was individuated with a name and described as an AI or human, rather than specifically as a chatbot or personal assistant.
2412.06603_2208981_0	  AI assistants are being created to help software engineers conduct a variety of coding-related tasks, such as writing, documenting, and testing code.
2412.07031_2209409_6	As long as these steps are taken, LLM outputs can be used in empirical research with the familiar econometric guarantees we desire.
2412.08054_2210432_8	Apart from that, an incredible Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU) module is designed and we incorporate the aggregated global knowledge compendium as a teacher to teach LLM agents the usage of tools.
2412.09173_2211551_5	By virtue of the decidable nature of formats, we propose to Reinforce Format Faithfulness (ReFF) to help LLMs generate formatted output as instructed without compromising general quality.
2412.09416_2211794_4	We assess reliability of the popular Prometheus2 and Llama-3.1-8B LLMs as evaluators and analyze each tutor's pedagogical abilities, highlighting which LLMs are good tutors and which ones are more suitable as question-answering systems.
2412.11300_2213678_1	Previous research in science education has highlighted the potential for generative AI in various education-related areas, including generating valuable discussion material, solving physics problems, and acting as a tutor.
2412.11300_2213678_7	As such, our findings show that generative AI tools may handle some questions and problems and thus demonstrate their potential to help distribute teachers' workload more equitably during laboratory sessions.
2412.11536_2213914_6	The central element of this work is the use of a teacher model - the LLM as a judge - to generate training data.
2412.12107_2214485_4	The competencies follow a logical progression and serve as a roadmap for individuals seeking to get familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.
2412.12117_2214495_2	We review the pros and cons of AI in the writing process, emphasizing process-based assessments, creativity-driven tasks, and AI as a supplement to teacher guidance.
2412.15047_2217425_4	Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection.
2412.15896_2218274_7	Furthermore, we show that the LLM is able to help resolve disagreements among human experts, especially in tasks such as identifying cases of negative targeting.
2412.19819_2222197_3	This limitation impedes the practical application of chip LLMs, including serving as assistant chatbots for hardware design engineers.
2501.00031_2223615_3	We leveraged state-of-the-art LLMs (Gemini and OpenAI models) and medical ontologies (RxNorm and SNOMED) as teacher labelers for medication, disease, and symptom extraction.
2501.00359_2223943_1	To explore expression of local narratives, we conducted a workshop with 20 participants utilizing Generative AI (GenAI) to support visual narratives, asking them to use Stable Diffusion to create images of familiar cultural heritage sites, as well as images of unfamiliar ones for comparison.
2501.00953_2224537_5	Primary focus is on the part of the system that makes decisions, known as the dialogue manager.
2501.02229_2225813_4	Having fine-tuned the LLMs specifically for smart contract code classification should help in getting better results when detecting several types of well-known vulnerabilities, such as Reentrancy, Integer Overflow, Timestamp Dependency and Dangerous Delegatecall.
2501.03923_2227507_3	In this context, explainable AI (XAI) emerges as a solution that could help to understand disease-associated mechanisms when combined with efficient NN models.
2501.05224_2228808_2	To help establish best practices for employing LLMs in zero-shot settings, we also assess the ability of LLMs as judges, finding that they are able to replicate the preferences of human judges.
2501.05455_2229039_5	For example, can concepts such as common mode failures from downstream safety be used to help assess the strength of AI guardrails?
2501.06607_2230191_1	This paper describes the AI Drawing Partner, which is a co-creative drawing agent that also serves as a research platform to model co-creation.
2501.07919_2231503_0	  Home Energy Management Systems (HEMSs) help households tailor their electricity usage based on power system signals such as energy prices.
2501.08243_2231827_6	Evaluations of our multi-agent system with the help of practitioners as well as using automated checks demonstrate enhanced accuracy, responsiveness, and effectiveness over non-agentic approaches across complex workflows.
2501.09171_2232755_0	  Many believe that use of generative AI as a private tutor has the potential to shrink access and achievement gaps between students and schools with abundant resources versus those with fewer resources.
2501.10551_2234135_6	We found that factors such as gender, race, and perceived self-efficacy can help predict different AI usage patterns.
2501.11935_2235519_2	Since the majority of students' experiences in online self-learning have come through using search engines such as Google, evaluating AI tools in this context can help us address these gaps.
2501.12697_2236281_1	Existing research in ZS-VQA has proposed to leverage knowledge graphs or large language models (LLMs), respectively, as external information sources to help VQA model comprehend images and questions.
2501.14877_2238461_7	We also find that synthetic QAs, though imperfect, can yield similar model rankings as teacher-written QAs.
2501.15247_2238831_6	While generative AI shows potential as a personalized tutor, further evaluation is needed to assess its effectiveness.
2501.16548_2240132_0	  As the climate crisis deepens, artificial intelligence (AI) has emerged as a contested force: some champion its potential to advance renewable energy, materials discovery, and large-scale emissions monitoring, while others underscore its growing carbon footprint, water consumption, and material resource demands.
2501.16661_2240245_4	Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension.
2501.18948_2242532_3	Meanwhile, Human-Centered AI (HCAI), which envisions AI as a collaborator augmenting human capabilities and aligning with societal values, remains a fugitive from the mainstream narrative.
2501.19361_2242945_1	Although these LLMs are marketed as helpful creative assistants, several works have shown that using an LLM as a creative partner results in a narrower set of creative outputs.
2501.19377_2242961_0	  In this work, we present and evaluate SELMA, a Speech-Enabled Language Model for virtual Assistant interactions that integrates audio and text as inputs to a Large Language Model (LLM).
2502.00012_2243003_2	Complexity theory can help illuminate the features of AI that pose central challenges for policymakers, such as feedback loops induced by training AI models on synthetic data and the interconnectedness between AI systems and critical infrastructure.
2502.01493_2244484_4	These attributes foster balanced interaction, enabling AI to act as a responsive partner, evolving with users over time.
2502.01671_2244662_4	We include detailed descriptions of our LCA to act as a tutorial, road map, and inspiration for other computer engineers to perform similar LCAs to help us all understand the environmental impacts of our chips and of AI.   
2502.03129_2246120_3	Specifically, a teacher LLM is employed to generate TEN rationales as supervision data, which are then used to teach and fine-tune a student LLM.
2502.03333_2246324_7	Together, these findings highlight the potential of RadVLM as a clinically relevant AI assistant, providing structured CXR interpretation and conversational capabilities to support more effective and accessible diagnostic workflows.
2502.04390_2247381_3	We implement two key components inspired by human cognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior to classify information as novel, familiar, or dissonant; and (2) Targeted Network Updates, which track neural activity to identify frequently used (stubborn) and rarely used (plastic) neurons.
2502.04964_2247955_3	Our investigation reveals distinctive characteristics of LLMs as probabilistic models, which help to explain why these UQ methods underperform in certain tasks.
2502.05497_2248488_4	Experiments demonstrate that DeepThink achieves an average performance improvement of 7.92% compared to a GPT-4-turbo+RAG-based assistant on the real user test set in the advertising domain across dimensions such as relevance, completeness, clarity, accuracy, and actionability.
2502.09532_2252523_7	Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM.
2502.12102_2255093_4	As AI agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-AI interactions.
2502.12134_2255125_4	Specifically, we employ a lightweight assistant model to generate instance-specific soft thought tokens speculatively as the initial chain of thoughts, which are then mapped into the LLM's representation space via a projection module.
2502.14080_2257071_6	It uses zero-shot sentiment analysis with LLMs and prompt engineering, achieving 86\% accuracy in classifying student-teacher interactions as positive or negative.
2502.14865_2257856_6	Our goal is to establish AI as a reliable partner in preserving cultural heritage, ensuring that technological advancements contribute meaningfully to historical discovery.
2502.17730_2260721_3	To investigate this, we conducted randomized controlled trials (RCTs) where teams of three participants worked together under a randomly assigned manager - either human or AI - who was presented as male, female, or gender-neutral.
2502.17855_2260846_2	Participants envisioned AI playing multidimensional roles, such as an operational assistant, personal trainer, group coach, and evaluator, as solutions to address unique instructional and operational challenges in K-12 PE classes.
2502.18357_2261348_1	In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s).
2502.18476_2261467_2	However, with the help of automated tools and models such as OpenAI Codex and GPT-4, many aspects of the Software Development Life Cycle (SDLC) have been made possible.
2502.18527_2261518_6	Specifically, users mine with their data, and the mining rate is determined by GOD's evaluation of how well their AI assistant understands them across categories such as shopping, social interactions, productivity, trading, and Web3.
2502.19410_2262401_0	  Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given.
2502.19557_2262548_2	Extracting reliable reward signals directly from teacher models is challenging, as LLMs are optimized for generation rather than evaluation, often resulting in biased or inconsistent assessments.
2502.20541_2263532_1	The system leverages the capabilities of a sophisticated language model to serve as an intelligent research assistant, enhancing the efficiency and comprehensiveness of literature reviews in the nanotechnology domain.
2503.00144_2264456_3	To explore user preferences for AI-supported programming learning tools, we conducted a participatory design study with 15 undergraduate novice programmers and 10 instructors to gather insights on their desired help features and control preferences, as well as a follow-up survey with 172 introductory programming students.   
2503.00596_2264908_1	This paper proposes a novel backdoor threat attacking the LLM-as-a-Judge evaluation regime, where the adversary controls both the candidate and evaluator model.
2503.01704_2266016_1	Edge Computing (EC) as a physically closer computing resource to the end users can help to reduce the communication delay for serving end users' tasks for LLM-dependent services.
2503.02099_2266411_4	Our findings indicate that LLMs can effectively function as educational analysts, turning diverse data into teacher-friendly insights that are well-received by educators.
2503.02250_2266562_4	In this paper, through a synthesis of related literature and extensive examples of existing AI systems intended to mimic humans, we develop a conceptual framework to help foreground key axes of design variations and provide analytical scaffolding to foster greater recognition of the design choices available to developers, as well as the possible ethical implications these choices might have.
2503.04743_2269055_7	I conclude with why building a system safety discipline can help us overcome limitations in the European AI Act, as well as how the discipline can help shape sustainable investments into Public Interest AI.
2503.05839_2270151_6	The system's architecture includes key components such as a bootloader, boot manager, and bootloader updater to facilitate seamless firmware updates.
2503.05926_2270238_2	We provide insights drawn from interviews with industry personnel working on building human-AI collaboration systems, as well as our collaborations with end-users to build a multimodal AI assistant for task support.
2503.09838_2274150_0	  We present BioSpark, a system for analogical innovation designed to act as a creativity partner in reducing the cognitive effort in finding, mapping, and creatively adapting diverse inspirations.
2503.13440_2277752_6	Subsequently, we employ a single-stage distillation process, using the pre-trained VLM as the teacher model to transfer knowledge to the MaTVLM, further enhancing convergence speed and performance.
2503.13533_2277845_0	  As artificial intelligence (AI) technology becomes increasingly prevalent in the filed of education, there is a growing need for mathematics teacher education students (MTES) to demonstrate proficiency in the integration of AI with the technological pedagogical content knowledge (AI-TPACK).
2503.16071_2280383_0	  Memory, additional information beyond the training of large language models (LLMs), is crucial to various real-world applications, such as personal assistant.
2503.16536_2280848_1	The system transforms narrative elements-such as protagonist goals, antagonist challenges, and environmental settings-into game levels with both spatial and gameplay constraints.
2503.17994_2282306_7	Specifically, on the step-level, we decompose the generation task into decision steps with powerful prompt engineering and inspire LLM to serve as instructor for architecture search based on its internal knowledge.
2503.19607_2283919_2	As Minecraft has an extensive player base and a rich ecosystem of pre-built AI agents, we hope this contribution can help to facilitate research quickly in the design of new collaborative agents and in understanding different human factors within HMT.
2503.21735_2286047_10	Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation.
2503.22040_2286352_2	We propose a framework for social scientists to incorporate LLMs into text annotation, either as the primary coding decision-maker or as a coding assistant.
2504.00463_2289166_0	  Existing state-of-the-art AI-Generated image detection methods mostly consider extracting low-level information from RGB images to help improve the generalization of AI-Generated image detection, such as noise patterns.
2504.00907_2289610_8	To the best of our knowledge, this is the first demonstration of adapting MLLMs as VLA agents that can act and ask for help using LLM-generated rewards with online RL.
2504.03105_2291808_0	  As AI takes on increasingly complex roles in human-computer interaction, fundamental questions arise: how can HCI help maintain the user as the primary agent while augment human cognition and intelligence?
2504.03966_2292669_8	Despite these benefits and positive perception of AI tools, concerns emerged regarding over-reliance on AI, accuracy limitations, and ethical issues such as plagiarism and reduced student-teacher interaction.
2504.04253_2292956_6	Finally, we present our vision for a user-centered system that leverages GenAI not only for automation but as an intelligent collaborator in visual data exploration.
2504.05333_2294036_9	The expected utility assessment approach presented here is intended to help AI developers and deployment decision makers to navigate the subtle but substantial impact of counterfactuals so as to better ensure that beneficial AI capabilities are used.
2504.05559_2294262_2	In this paper, we introduce SciSciGPT, an open-source, prototype AI collaborator that uses the science of science as a testbed to explore the potential of LLM-powered research tools.
2504.08670_2297373_4	These strategies -- long refined in Disney animation -- function as multimodal scaffolds for attention, understanding, and emotional attunement, thereby forming a structured design grammar familiar to children and transferable to AI interface design.
2504.09283_2297986_9	We argue that AI agent interfaces, such as software IDEs like Cursor and Windsurf, should provide affordances for impact analysis and help users validate AI retrieval independently from generation.
2504.09720_2298423_0	  This study explores NotebookLM, a Google Gemini powered AI platform that integrates Retrieval Augmented Generation (RAG), as a collaborative physics tutor, an area of research that is developing quickly.
2504.09720_2298423_1	In our implementation, NotebookLM was configured as an AI physics collaborative tutor to support students in solving conceptually oriented physics problems using a collaborative, Socratic approach.
2504.09720_2298423_2	When deployed as a collaborative tutor, the system restricts student interaction to a chat only interface, promoting controlled and guided engagement.
2504.10101_2298804_0	  The dominant metaphor of LLMs-as-minds leads to misleading conceptions of machine agency and is limited in its ability to help both users and developers build the right degree of trust and understanding for outputs from LLMs.
2504.11146_2299849_4	As students completed three code writing and debugging tasks, they had the option to receive guardrailed help or use a "See Solution" feature which disabled the guardrails and generated a verbatim response from the underlying model.
2504.11496_2300199_0	  This paper introduces IEA-plugin, a novel AI agent-based reasoning module developed as a new front-end for the Intelligent Engineering Assistant (IEA).
2504.13471_2302174_5	In the first stage, we construct an optimal performance prototype system by transforming complex tasks into a function call-based LLM-driven pipeline, which serves as a teacher model to generate high-quality data.
2504.13700_2302403_4	Informed by the findings, we introduce visual prompts as a complementary input modality to text prompts, which help clarify user intent and improve LLMs' interpretation abilities.
2504.13882_2302585_3	Using a public dataset from the Teacher-Student Chatroom Corpus, our system classifies each tutoring strategy as either being employed as desired or undesired.
2504.13903_2302606_4	Experienced developers are more likely to perceive AI as a junior colleague, a content generator, or assign it no role, whereas less experienced developers primarily view AI as a teacher.
2504.14928_2303631_0	  Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions.
2504.17028_2305731_10	Consequently, this paper and its corresponding GitHub materials may serve as an initial guide for other university research groups and courses related to machine learning, climate science, and data science to develop research and education programs on AI weather forecasting, and hence help democratize the AI NWP in the digital economy.
2504.18340_2307043_3	Here, we present Chemma, a fully fine-tuned LLM with 1.28 million pairs of Q&A about reactions, as an assistant to accelerate organic chemistry synthesis.
2504.19275_2307978_2	By employing a mixed-method approach combining theoretical frameworks (auteur theory, human-technology relations) and case studies (The Safe Zone, Fast & Furious 7, The Brutalist), the research reveals that positioning AI as an "embodiment tool" rather than an independent "alterity partner" preserves human authorship and artistic integrity.
2504.21769_2310472_5	Leveraging the emergent capabilities of Large Language Models (LLMs) in reasoning and generating human-like responses, we introduce LLM-iTeach -- a novel IIL framework that utilizes an LLM as an interactive teacher to enhance agent performance while alleviating the dependence on human resources.
2504.21769_2310472_8	We evaluate LLM-iTeach against baseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a state-of-the-art IIL method using a human teacher, on various robotic manipulation tasks.
2505.00831_2311391_2	We present SmallPlan -- a novel framework leveraging LLMs as teacher models to train lightweight Small Language Models (SLMs) for high-level path planning tasks.
2505.01563_2312123_6	At each step of problem-solving, AI agents are asked what they would do as a tutor or as a learner.
2505.01681_2312241_2	By treating a large language model (LLM), DeepSeek-R1, as an equal partner, we establish a closed-loop, iterative workflow in which the LLM proposes, refines, and reasons about near-wall turbulence models under adverse pressure gradients (APGs), system rotation, and surface roughness.
2505.02975_2313535_3	This paper examines these dynamics and advocates for participatory design approaches that position older adults as active decision makers in shaping AI assistant functionality.
2505.03163_2313723_4	Findings indicate that while LLMs could enhance personalized learning and reduce teacher workload, barriers such as poor connectivity, lack of AI training, and parental skepticism hinder adoption.
2505.06120_2316680_1	As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange.
2505.06428_2316988_1	However, current explanation mechanisms primarily help AI researchers and engineers in debugging and monitoring their AI systems, and may not address the specific questions of end-users, such as passengers, about AVs in various scenarios.
2505.06803_2317363_3	To reduce this gap, we introduce a cross-modal distillation framework, where an LLM in one modality serves as the teacher and another as the student, with knowledge transfer in sound classes predicted as more challenging to the student by a heuristic model.
2505.07105_2317665_4	To help the student model learn more effectively from the teacher model, we first train the teacher LLM as a classification model with soft targets.
2505.07105_2317665_6	Instead of using the same training data as the teacher model, we significantly expand the student model dataset by generating unlabeled data and labeling it with the teacher model predictions.
2505.08083_2318643_5	This exploration of teacher-AI collaboration highlights how LLM can help teachers include CRP components into their instructional practices efficiently, especially in global priorities for future-ready education, such as AI literacy.
2505.09334_2319894_7	We developed and trained a lightweight student model, Distilled Custom Student Network (DCSNet) using ResNet50 as the teacher.
2505.09970_2320530_1	Recent LLMs, such as DeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through the generation of ample intermediate tokens, which help build a strong premise before producing the final output tokens.
astro-ph/0201481_2336328_7	The system 6.6454.5 is found to contain a 4.97-day Cepheid, which cannot be definitely classified as Type I or Type II, with an unexpectedly brighter companion.
