1910.12544_1196463_4	This research introduces a conceptual framework called "Co-Learning," in which people can learn with/from and grow with AI partners over time.
2004.11793_1276563_3	Our solution proposes a hierarchical and dynamic system manager with performance tuning.
2004.14577_1279347_3	We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short.
2007.04950_1316464_7	In this paper, we propose a system of AI assistants that assists designers in their design journey.
2010.06059_1362389_2	More recently, AI-powered virtual coaches have become a viable complement to human coaches.
2012.09610_1397488_4	To better understand how to develop and integrate trained ML models into the traditional industrial control system, test the deployed AI control system, and ultimately outperform traditional systems, manufacturers and their AI solution partners need to address a number of challenges.
2104.04122_1451540_4	We designed an AI labeling assistant that uses a semi-supervised learning algorithm to predict the most probable labels for each example.
2106.08458_1486222_1	While previous work explored the potential of automatically monitoring exercises for AI and robotic coaches, the deployment of these systems remains a challenge.
2106.08458_1486222_3	In this paper, we present our efforts on eliciting the detailed design specifications on how AI and robotic coaches could interact with and guide patient's exercises in an effective and acceptable way with four therapists and five post-stroke survivors.
2106.08458_1486222_4	Through iterative questionnaires and interviews, we found that both post-stroke survivors and therapists appreciated the potential benefits of AI and robotic coaches to achieve more systematic management and improve their self-efficacy and motivation on rehabilitation therapy.
2106.08458_1486222_6	We discuss the value of early involvement of stakeholders and interactive techniques that complement system failures, but also support a personalized therapy session for the better deployment of AI and robotic exercise coaches.
2111.15050_1569153_0	  It is still a pipe dream that personal AI assistants on the phone and AR glasses can assist our daily life in addressing our questions like ``how to adjust the date for this watch?''
2112.00331_1570107_3	In this work, we propose AI.R Taletorium, an illustrative, immersive, and inclusive multimodal AI companion, for interactive fairy tale co-creation that actively involves kids to create fairy tales with both the AI agent and their normal peers.
2202.03199_1602023_2	We present an AI research associate for early-stage scientific discovery based on (a) a novel minimally-biased ontology for physics-based modeling that is context-aware, interpretable, and generalizable across classical and relativistic physics; (b) automatic search for viable and parsimonious hypotheses, represented at a high-level (via domain-agnostic constructs) with built-in invariants, e.g., postulated forms of conservation principles implied by a presupposed spacetime topology; and (c) automatic compilation of the enumerated hypotheses to domain-specific, interpretable, and trainable/testable tensor-based computation graphs to learn phenomenological relations, e.g., constitutive or material laws, from sparse (and possibly noisy) data sets.
2203.12687_1625549_3	Study 1 examined the role of trust in the use of AI voice assistants based on survey responses from college students.
2205.01411_1645823_4	However, we notice that the predictive sets provided by CP can be very large, which leads to unhelpful AI assistants.
2206.13703_1674123_2	In this work, we extended Kwame, our previous AI teaching assistant, adapted it for science education, and deployed it as a web app.
2207.00682_1676580_1	The game is based in a lonely world after the pandemic and thus it needs AI companions to gain the interest of players.
2211.00192_1739098_2	We introduce AI assistants, a class of semi-automatic interactive tools to streamline data wrangling.
2211.00192_1739098_3	An AI assistant guides the analyst through a specific data wrangling task by recommending a suitable data transformation that respects the constraints obtained through interaction with the analyst.   
2211.00192_1739098_4	We formally define the structure of AI assistants and describe how existing tools that treat data cleaning as an optimization problem fit the definition.
2211.00192_1739098_5	We implement AI assistants for four common data wrangling tasks and make AI assistants easily accessible to data analysts in an open-source notebook environment for data science, by leveraging the common structure they follow.
2211.00192_1739098_6	We evaluate our AI assistants both quantitatively and qualitatively through three example scenarios.
2211.02759_1741665_2	To make AI opponents more human-like, we'd ideally like to see multiple different strategies at each level of difficulty, a concept we refer to as "multidimensional" difficulty.
2211.03540_1742446_5	On these tasks, we find that human participants who interact with an unreliable large-language-model dialog assistant through chat -- a trivial baseline strategy for scalable oversight -- substantially outperform both the model alone and their own unaided performance.
2211.03622_1742528_0	  We conduct the first large-scale user study examining how users interact with an AI Code assistant to solve a variety of security related tasks across different programming languages.
2211.03622_1742528_2	Additionally, participants with access to an AI assistant were more likely to believe they wrote secure code than those without access to the AI assistant.
2211.03622_1742528_4	Finally, in order to better inform the design of future AI-based Code assistants, we provide an in-depth analysis of participants' language and interaction behavior, as well as release our user interface as an instrument to conduct similar studies in the future.
2212.08073_1764250_1	We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.
2212.08073_1764250_7	As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them.
2212.12305_1768482_4	Artificial intelligence (AI)-based virtual assistants are changing successful engagement away from being dominated by humans and toward being dominated by technologies.
2301.05969_1777033_3	We argue that classic experimental methods used to study heuristics and biases are insufficient for studying complex choices made with AI helpers.
2301.05969_1777033_5	We show that framing and anchoring effects impact how people work with an AI helper and are predictive of choice outcomes.
2301.05969_1777033_6	The evidence suggests that some participants, particularly those in a loss frame, put too much faith in the AI helper and experienced worse choice outcomes by doing so.
2301.11178_1782242_0	  AI-powered code assistants, such as Copilot, are quickly becoming a ubiquitous component of contemporary coding contexts.
2302.00560_1785494_2	This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write - and what they think.
2302.00560_1785494_4	Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society.
2303.03638_1803435_3	To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice.
2303.12040_1811837_0	  The vision of AI collaborators is a staple of mythology and science fiction, where artificial agents with special talents assist human partners and teams.
2303.17125_1816922_0	  The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot.
2303.17125_1816922_4	Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions.
2304.02625_1820671_1	Through an interview study with 15 non-native English speakers (NNESs) with varying levels of English proficiency, we observe that they face difficulties in assessing paraphrased texts generated by AI writing assistants, largely due to the lack of explanations accompanying the suggested paraphrases.
2304.02625_1820671_3	Drawing on the needs of NNESs identified in our interview, we propose four potential user interfaces to enhance the writing experience of NNESs using AI writing assistants.
2304.09179_1827225_0	  In our pursuit of advancing multi-modal AI assistants capable of guiding users to achieve complex multi-step goals, we propose the task of "Visual Planning for Assistance (VPA)".
2304.11771_1829817_0	  We study the staggered introduction of a generative AI-based conversational assistant using data from 5,172 customer support agents.
2305.03047_1836103_5	Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary.
2305.10412_1843468_2	To investigate these questions, we built a Wizard of Oz platform to help families engage in creative coding in partnership with a researcher-operated AI Friend.
2305.10412_1843468_4	Using a creative self efficacy lens, we observe that families found it easier to generate game ideas when prompted with questions by AI Friend; parents played a unique role in guiding children in more complex programming tasks when the AI Friend failed to help, and children were more encouraged to write code for novel ideas using the AI friend help.
2305.10417_1843473_2	Based on our previous user study involving a prototype AI assistant, we devised three evaluation scenarios to determine if LLMs could help families comprehend game code, debug programs, and generate new ideas for future projects.
2305.10830_1843886_4	Therefore, this paper proposes a personalized AI assistant for shear wall layout based on Stable Diffusion, which has been proven to produce good generative results through testing.
2305.12943_1845999_2	With recent advances in Large Language Models (LLMs), it is now possible to generate lengthy, coherent text, opening up the opportunity to develop an AI assistant for album storytelling.
2305.14233_1847289_4	Our objective is to capture the breadth of interactions that a human might have with an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively.
2305.15072_1848128_2	To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology.
2305.19339_1852395_0	  A human decision-maker benefits the most from an AI assistant that corrects for their biases.
2305.20076_1853132_0	  We describe a class of tasks called decision-oriented dialogues, in which AI assistants such as large language models (LMs) must collaborate with one or more humans via natural language to help them make complex decisions.
2305.20076_1853132_2	In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: assistants can access and process large amounts of information, while users have preferences and constraints external to the system.
2306.03289_1856437_8	The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement.
2306.05153_1858301_5	For example, mismatched expertise makes pair programming less productive, therefore well-designed AI programming assistants may adapt to differences in expertise levels.
2306.09541_1862689_0	  AI-powered programming assistants are increasingly gaining popularity, with GitHub Copilot alone used by over a million developers worldwide.
2306.17278_1870426_3	In this work, we introduce a VR environment with a generative AI-embodied virtual assistant to support participants in responding to varying cognitive complexity anatomy questions and enable verbal communication.
2307.07319_1878314_5	Through the case study, we find that an LLM assistant can potentially yield substantial productivity gains for researchers and developers.
2307.10250_1881245_1	Using an interactive interview format, the AI assistant demonstrated reliability in generating and selecting hypotheses.
2308.00121_1888013_1	This paper explores the potential usage of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners.
2308.00121_1888013_4	We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of providing AI-based sparring partners.
2308.06246_1894138_4	AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world.
2308.10855_1898747_7	This evaluation benchmark provides LLMs with a highly challenging and distinctive task that is crucial to an effective AI assistant.
2309.02654_1907458_6	Our findings propose a significant shift towards preemptive strategies for hallucination mitigation in LLM assistants, promising improvements in reliability, applicability, and interpretability.
2309.05196_1910000_2	In this work, we measure the impact of co-writing on diversity via a controlled experiment, where users write argumentative essays in three setups -- using a base LLM (GPT3), a feedback-tuned LLM (InstructGPT), and writing without model help.
2309.05833_1910637_1	Despite the growing prevalence of AI-driven assistants in the root cause analysis process, their effectiveness in assisting on-call engineers is constrained by low accuracy due to the intrinsic difficulty of the task, a propensity for LLM-based approaches to hallucinate, and difficulties in distinguishing these well-disguised hallucinations.
2309.10108_1914912_1	AI assistants have the potential to support analysts in planning their analyses, enabling more robust decision making.
2309.10108_1914912_2	Though AI-based assistants that target code execution (e.g., Github Copilot) have received significant attention, limited research addresses assistance for both analysis execution and planning.
2309.10892_1915696_5	The paper presents the methodology, system architecture, intelligent services, and integration with Learning Management Systems (LMSs) while discussing the challenges, limitations, and future directions for the development of AI-enabled intelligent assistants in education.
2309.12367_1917171_3	In this paper, we investigate the effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors to increase response reliability.
2309.12367_1917171_6	GPT-4 intelligent tutors with varying hierarchies of KB access and human domain experts then assessed these responses.
2309.12570_1917374_4	Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing.
2309.13060_1917864_1	Here we explore the integration of AI tutors to complement learning programs in accordance with learning sciences.
2309.13060_1917864_3	After automatically generating microlearning questions from existing course materials using GPT-3, the AI tutor developed a dynamic neural-network model of each student's grasp of key concepts.
2309.13060_1917864_5	The results indicate that students who actively engaged with the AI tutor achieved significantly higher grades.
2309.13060_1917864_6	Moreover, active engagement led to an average improvement of up to 15 percentile points compared to a parallel course without AI tutor.
2309.13060_1917864_9	By integrating AI tutors into their programs, educators can offer students personalized learning experiences grounded in the principles of learning sciences, thereby addressing the challenges associated with implementing effective learning strategies.
2309.17024_1921828_0	  Building an interactive AI assistant that can perceive, reason, and collaborate with humans in the real world has been a long-standing pursuit in the AI community.
2309.17024_1921828_8	We expect HoloAssist will provide an important resource for building AI assistants that can fluidly collaborate with humans in the real world.
2310.02739_1924996_6	This system is hosted on Streamlit, where users will be prompted to provide an image to serve as their AI assistant.
2310.03046_1925303_2	In addition, using LLM assistants to support high query volumes can be expensive.
2310.03046_1925303_5	First, it allows the LLM assistants to converse with an automatic code executor to iteratively refine code or to produce answers based on the execution results.
2310.03046_1925303_6	Second, we use a hierarchy of LLM assistants, which attempts to answer the query with weaker, cheaper LLMs before backing off to stronger, expensive ones.
2310.06983_1929240_4	And we introduce a \textit{metacognitive prompting} framework to apply VoE in the context of an AI tutor.
2310.10280_1932537_3	In this study, we examine the potential of a virtual AI teacher in emulating the techniques of human educators for motor skill acquisition.
2310.10553_1932810_2	To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC.
2310.13548_1935805_0	  Human feedback is commonly utilized to finetune AI assistants.
2310.16164_1938421_4	Based on these insights, we propose actionable design recommendations, such as data brushing to support context selection, and inquisitive feedback loops to improve communications with AI-based assistants in data-science tools.
2310.17769_1940026_0	  We explore the idea of aligning an AI assistant by inverting a model of users' (unknown) preferences from observed interactions.
2310.17769_1940026_2	We find that the AI assistant accurately aligns its behavior to match standard policies from the economic literature (e.g., selfish, altruistic).
2310.17769_1940026_5	Overall, our preliminary results suggest that developing simulation frameworks in which AI assistants need to infer preferences from diverse users can provide a valuable approach for studying practical alignment questions.
2310.17884_1940141_0	  The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context.
2310.18351_1940608_0	  We present the BioImage$.$IO Chatbot, an AI assistant powered by Large Language Models and supported by a community-driven knowledge base and toolset.
2311.00706_1943673_3	Six participants estimated ensemble averages with or without an AI assistant.

2311.02640_1945607_7	By providing profound insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis, this study makes valuable contributions toward advancing AI-based programming assistants.
2311.03348_1946315_2	Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant.
2311.16161_1959128_2	Departing from conventional practices of employing distinct models for image recognition and text-based coaching, our integrated architecture directly processes input images, enabling natural question-and-answer dialogues with the AI coach.
2311.16521_1959488_6	We conclude with suggestions for future systems, recommending designs that account for the unique strengths and weaknesses of human versus AI assistants, strategies to address automation bias, and sociocultural views of writing.
2311.18452_1961419_1	Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios.
2311.18452_1961419_4	Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant -- named StackSpot AI -- in a controlled setting.
2311.18452_1961419_7	The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.
2312.06227_1968035_5	To understand the real-world impact of poisoning attacks on developers who rely on AI-powered coding assistants, we conducted two user studies: an online survey and an in-lab study.
2312.06677_1968485_3	This paper proposes a novel LLM-based virtual assistant that can automatically perform multi-step operations within mobile apps based on high-level user requests.
2312.06677_1968485_9	Notably, this work represents the first real-world deployment and extensive evaluation of a large language model-based virtual assistant in a widely used mobile application with an enormous user base numbering in the hundreds of millions.
2312.07779_1969587_7	In particular, finetuning on a declarative statement $S$ increases the model likelihood for logical consequences of $S$. The effect of declarative statements is consistent across three domains: aligning an AI assistant, predicting weather, and predicting demographic features.
2312.07814_1969622_1	However, despite the explosive growth of generative artificial intelligence (AI), there has been limited study on building general purpose, multimodal AI assistants tailored to pathology.
2312.07814_1969622_2	Here we present PathChat, a vision-language generalist AI assistant for human pathology using an in-house developed foundational vision encoder pretrained on 100 million histology images from over 100,000 patient cases and 1.18 million pathology image-caption pairs.
2312.07814_1969622_4	We compare PathChat against several multimodal vision language AI assistants as well as GPT4V, which powers the commercially available multimodal general purpose AI assistant ChatGPT-4.
2312.07814_1969622_7	As an interactive and general vision language AI assistant that can flexibly handle both visual and natural language inputs, PathChat can potentially find impactful applications in pathology education, research, and human-in-the-loop clinical decision making.
2312.09126_1970934_0	  It is expected that in the near future, AI software development assistants will play an important role in the software industry.
2312.09126_1970934_2	We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants.
2312.10826_1972634_4	Incorporating teacher practices captured by position tracking and human observation codes into modeling significantly improved the inference of how efficiently students improved in the AI tutor beyond a model with tutor log data features only.
2312.10826_1972634_8	Taken together, offering early conceptual support to students with low learning rates could make classroom practice with AI tutors more effective.
2312.17257_1979065_0	  With the rapid development of large language models, AI assistants like ChatGPT have become increasingly integrated into people's works and lives but are limited in personalized services.
2312.17257_1979065_1	In this paper, we present a plug-and-play framework that could facilitate personalized large language model assistants with evolving conditional memory.
2401.10739_1990293_2	We conducted a literature review to study the current state of in-IDE Human-AI Experience research, bridging a gap in understanding the nuanced interactions between programmers and AI assistants within IDEs.
2401.11314_1990868_2	We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions.
2401.11314_1990868_7	Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.
2401.13275_1992829_4	Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?"
2401.17217_1996771_5	Moreover, we prototype a variety of application scenarios that suggest GazeGPT could be of significant value to users as part of future AI-driven personal assistants.
2402.00414_1998053_0	  Augmenting large language models (LLMs) with user-specific knowledge is crucial for real-world applications, such as personal AI assistants.
2402.02392_2000031_2	To aid in these tasks, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments.
2402.05605_2003244_4	To determine the best selection of a control agent, we propose the addition of an AI manager (via Reinforcement Learning) which learns as an outside observer of the team.
2402.07397_2005036_4	Then, we describe our work developing and deploying AI in Education tools in Africa for science and computing education: (1) SuaCode, an AI-powered app that enables Africans to learn to code using their smartphones, (2) AutoGrad, an automated grading, and feedback tool for graphical and interactive coding assignments, (3) a tool for code plagiarism detection that shows visual evidence of plagiarism, (4) Kwame, a bilingual AI teaching assistant for coding courses, (5) Kwame for Science, a web-based AI teaching assistant that provides instant answers to students' science questions and (6) Brilla AI, an AI contestant for the National Science and Maths Quiz competition.
2402.07862_2005501_2	We evaluate the effect on human forecasters of two LLM assistants: one designed to provide high-quality ("superforecasting") advice, and the other designed to be overconfident and base-rate neglecting, thus providing noisy forecasting advice.
2402.07862_2005501_5	Our preregistered analyses show that interacting with each of our frontier LLM assistants significantly enhances prediction accuracy by between 24 percent and 28 percent compared to the control group.
2402.07862_2005501_9	Our results suggest that access to a frontier LLM assistant, even a noisy one, can be a helpful decision aid in cognitively demanding tasks compared to a less powerful model that does not provide specific forecasting advice.
2402.07950_2005589_0	  With the release of OpenAI's ChatGPT, the field of large language models (LLM) saw an increase of academic interest in GPT based chat assistants.
2402.08030_2005669_0	  Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software.
2402.08030_2005669_3	We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts.
2402.08030_2005669_9	With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.
2402.09022_2006661_0	  AI-based code assistants are increasingly popular as a means to enhance productivity and improve code quality.
2402.09022_2006661_1	This study compares four AI-based code assistants, GitHub Copilot, Tabnine, ChatGPT, and Google Bard, in method generation tasks, assessing their ability to produce accurate, correct, and efficient code.
2402.09809_2007448_0	  This study evaluates the impact of Rori, an AI powered conversational math tutor accessible via WhatsApp, on the math performance of approximately 1,000 students in grades 3-9 across 11 schools in Ghana.
2402.11886_2009525_10	We discuss these challenges, demonstrate that a dedicated prompt can improve the performance, and propose a blueprint of an LLM-supporter that actively (but sensitively) seeks user context to provide personalized, empathetic, and reliable responses.
2402.12847_2010486_0	  In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
2403.00179_2017298_5	To conclude, we discuss considerations for designing AI assistants that lower counterspeaking barriers without jeopardizing its meaning and purpose.
2403.01791_2018910_7	These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.
2403.08299_2025418_0	  The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot.
2403.09522_2026641_5	Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student.
2403.11128_2028247_7	Testing four AI assistants using our crafted benchmark, our method further mirrored human evaluation compared to conventional static evaluations.
2403.12004_2029123_1	To unpack people's attitude towards and experience with generative AI-powered writing assistants, in this paper, we conduct an experiment to understand whether and how much value people attach to AI assistance, and how the incorporation of AI assistance in writing workflows changes people's writing perceptions and performance.
2403.14592_2031711_2	We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants.
2403.19506_2036625_1	We detail an exploratory study examining Claude from Anthropic, an LLM-based interactive assistant that helps students comprehend complex qualitative literature content.
2404.00026_2037477_1	However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time.
2404.02548_2039999_2	However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored.
2404.02548_2039999_4	In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis.
2404.02548_2039999_5	Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor.
2404.10281_2047732_0	  While the excitement around the capabilities of technological advancements is giving rise to new AI-based writing assistants, the overarching ecosystem plays a crucial role in how they are adopted in educational practice.
2404.12272_2049723_8	We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.
2404.14871_2052322_1	This action research study focuses on the integration of "AI assistants" in two Agile software development meetings: the Daily Scrum and a feature refinement, a planning meeting that is part of an in-house Scaled Agile framework.
2404.16244_2053695_1	This paper focuses on the opportunities and the ethical and societal risks posed by advanced AI assistants.
2404.16244_2053695_6	With this analysis in place, we consider the deployment of advanced assistants at a societal scale, focusing on cooperation, equity and access, misinformation, economic impact, the environment and how best to evaluate advanced AI assistants.
2404.18567_2056018_0	  Instruction-tuned Large Language Models designed for coding tasks are increasingly employed as AI coding assistants.
2405.00801_2058013_2	However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or "chat bots".
2405.01501_2058713_4	Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection.
2405.01576_2058788_0	  We study the tendency of AI systems to deceive by constructing a realistic simulation setting of a company AI assistant.
2405.01589_2058801_12	For instance, this advancement could lead to the development of AI-based medical assistants for healthcare professionals, enhancing the efficiency and accuracy of medical services.
2405.03690_2060902_2	These models have the potential to be deployed in real-world applications such as robotics, AI assistants, medical surgery, and autonomous vehicles.
2405.06061_2063273_3	We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach.
2405.06371_2063583_0	  Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice.
2405.06371_2063583_2	This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on secure software development.
2405.06371_2063583_4	We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development.
2405.06626_2063838_11	The results show that low-rank decomposition can be a promising direction for LLM-based applications that require real-time service at scale (e.g., AI agent and real-time coding assistant), where the latency is as important as the model accuracy.
2405.06683_2063895_7	The efficiency and personalization characteristics of ERAGent are supported by the Experiential Learner module which makes the AI assistant being capable of expanding its knowledge and modeling user profile incrementally.
2405.10243_2067455_1	Recent advancements in language models (LMs) have enabled the introduction of a new type of actor in that ecosystem: LM-powered assistants capable of code generation, optimization, and maintenance.
2405.10632_2067844_1	As interactive AI systems, such as AI companions, proliferate in daily life, this mismatch between evaluation methods and real-world use becomes increasingly consequential.
2405.13932_2071144_0	  LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential to generate code that fulfills a programming task described in a natural language description, referred to as a prompt.
2405.14178_2071390_7	We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback ($n=813$) on the characteristics of the tool they perceived to be most important.
2405.16579_2073791_0	  Constructing high-quality query-response pairs from custom corpus is crucial for supervised fine-tuning (SFT) large language models (LLMs) in many applications, like creating domain-specific AI assistants or roleplaying agents.
2405.19026_2076238_1	Recent advances in large language model assistants have made them indispensable, raising significant concerns over managing their safety.
2405.19266_2076478_3	Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline.
2405.19578_2076790_4	This study, consequently, explores whether LLMs can be used as generative AI-based personal assistants to users with minimal background knowledge in an application domain infer key data insights.
2406.00115_2078403_4	We propose VeriAssist, an LLM-powered programming assistant for Verilog RTL design workflow.
2406.05600_2083888_1	We report here on the development and deployment of a GPT-4-based interactive homework assistant ("61A Bot") for students in a large CS1 course; over 2000 students made over 100,000 requests of our Bot across two semesters.
2406.05821_2084109_2	Such a design would inevitably cause a catastrophic diminution in the indispensable conversational capability of general AI assistants.
2406.07765_2086053_9	It highlights specific activities that developers find less enjoyable and want to delegate to an AI assistant, e.g., writing tests and natural-language artifacts.
2406.07765_2086053_10	We also determine more granular stages where AI assistants are used, such as generating tests and generating docstrings, as well as less studied parts of the workflow, such as generating test data.
2406.07765_2086053_13	The provided analysis highlights stages of software development that developers want to delegate and that are already popular for using AI assistants, which can be a good focus for features aimed to help developers right now.
2406.11871_2090159_1	Recent breakthroughs in generative artificial intelligence (AI) and large language models (LLMs) unravel new capabilities for AI personal assistants to overcome cognitive bandwidth limitations of humans, providing decision support or even direct representation of human voters at large scale.
2407.09147_2107534_7	This demonstration showcases the potential of our AI-powered assistant to reduce cognitive load, increase productivity, and enhance safety in industrial environments.
2407.09512_2107899_6	By providing insights into the anatomy of a copilot and the critical aspects of testing and evaluation, this paper provides concrete evidence of how good design and evaluation practices are essential for building effective, human-centered AI assistants.
2407.12003_2110390_2	This paper introduces the challenges in evaluating and improving a generative AI assistant for enterprises, which is under active development, and how we address these challenges.
2407.12184_2110571_0	  This study investigates the relationship between deep learning (DL) image reconstruction quality and anomaly detection performance, and evaluates the efficacy of an artificial intelligence (AI) assistant in enhancing radiologists' interpretation of meniscal anomalies on reconstructed images.
2407.13900_2112287_3	However, little is known about the evidenced-based practices, tools and processes verified by research findings, supported and adopted by AI programming assistants.
2407.13900_2112287_5	We investigate 17 evidence-based claims posited by empirical SE research across five LLM-based programming assistants.
2407.13900_2112287_6	Our findings show that LLM-based programming assistants have ambiguous beliefs regarding research claims, lack credible evidence to support responses, and are incapable of adopting practices demonstrated by empirical SE research to support development tasks.
2407.13900_2112287_7	Based on our results, we provide implications for practitioners adopting LLM-based programming assistants in development contexts and shed light on future research directions to enhance the reliability and trustworthiness of LLMs -- aiming to increase awareness and adoption of evidence-based SE research findings in practice.
2407.14116_2112503_5	We propose and demonstrate AuditNet, the first conversational AI security assistant designed to assist IoT network security experts by providing instant access to security standards, policies, and regulations.
2407.15718_2114105_8	Within the students used AI tutors, 78% reported that the tutors helped their learning.
2407.17007_2115394_1	We present Pensieve Discuss, a software platform that integrates synchronous editing for scaffolded programming problems with online human and AI tutors, designed to improve student collaboration and experience during group tutoring sessions.
2407.17007_2115394_3	The use of our system was preferred over an interface lacking AI tutors and synchronous editing capabilities.
2407.17374_2115761_4	We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company.
2407.17489_2115876_1	We study 20 human teams of 3-4 individuals paired with one voice-only AI assistant during a challenging puzzle task.
2407.17489_2115876_2	Teams are randomly assigned to an AI assistant with a human- or robotic-sounding voice that provides either helpful or misleading information about the task.
2407.17489_2115876_7	The presence of an AI assistant significantly impacts team collective attention by modulating various aspects of shared cognition.
2407.19096_2117483_8	Study 6 provides an additional robustness check for the loneliness alleviating benefits of AI companions.
2407.19305_2117692_7	Overall, GP-VLS provides an open-source foundation for developing AI assistants to support surgeons across a wide range of tasks and scenarios.
2407.19438_2117825_5	The novel architecture for interoperable Conversational AI assistants is designed to generalize, being replicable and accessible via open repositories.
2407.19492_2117879_4	Intended for deployment in smart glasses and extended reality headsets, HUX AI aims to become a personal and useful AI companion for daily life.
2407.21521_2119908_3	We conducted a game-based experiment involving over 72,500 participants who solved search problems alone or with an AI companion.
2407.21521_2119908_7	Disclosure of the avatar as AI heightened effort intensity compared to non-disclosed AI companions.
2408.04477_2124658_2	In this study, we designed an LLM-based conversational assistant that provides a personalized interaction based on inferred user mental state (e.g., background knowledge and experience).
2408.04477_2124658_4	Our results provide insights for researchers and tool builders who want to create or improve LLM-based conversational assistants to support novices in code understanding.
2408.05344_2125525_0	  In this work, we discuss a recently popular type of recommender system: an LLM-based coding assistant.
2408.07106_2127287_0	  We witness an increasing usage of AI-assistants even for routine (classroom) programming tasks.
2408.08215_2128396_1	TinyML aims to solve this problem by hosting AI assistants on constrained devices, eliminating connectivity issues by processing data within the device itself, without internet or cloud access.
2408.09235_2129416_4	Our findings reveal a strong correlation with human evaluations, establishing our method as a viable and effective alternative to traditional metrics and human judgments, particularly in the context of LLM-based chat assistants where the complexity and diversity of responses challenge existing benchmarks.
2408.09330_2129511_0	  Benefiting from diverse instruction datasets, contemporary Large Language Models (LLMs) perform effectively as AI assistants in collaborating with humans.
2408.10758_2130939_1	[Background/Context] AI assistants like GitHub Copilot are transforming software engineering; several studies have highlighted productivity improvements.
2408.10758_2130939_6	In Phase 1, developers will add a new feature to a Java project, with or without the aid of an AI assistant.
2408.10758_2130939_7	Phase 2, a randomized controlled trial, will involve a different set of developers evolving random Phase 1 projects - working without AI assistants.
2408.11841_2132022_0	  AI assistants are being increasingly used by students enrolled in higher education institutions.
2408.11841_2132022_3	We investigate the potential scale of this vulnerability by measuring the degree to which AI assistants can complete assessment questions in standard university-level STEM courses.
2409.07110_2144742_2	Leveraging cutting-edge open-source Large Language Models (LLMs), Bio-Eng-LMM operates as a sophisticated AI assistant, exploiting the capabilities of traditional models like ChatGPT.
2409.13903_2151535_1	While general AI assistants have yet to fully emerge, their potential to share personal data raises significant privacy challenges.
2409.13903_2151535_2	This paper introduces CI-Bench, a comprehensive synthetic benchmark for evaluating the ability of AI assistants to protect personal information during model inference.
2409.13903_2151535_6	Additionally, we formulate and evaluate a naive AI assistant to demonstrate the need for further study and careful training towards personal assistant tasks.
2409.13903_2151535_7	We envision CI-Bench as a valuable tool for guiding future language model development, deployment, system design, and dataset construction, ultimately contributing to the development of AI assistants that align with users' privacy expectations.
2409.14037_2151669_0	  Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users.
2409.14866_2152498_5	We also develop three novel question-dependent mutation strategies using an LLM helper to generate prompts that maintain semantic coherence while significantly reducing their length.
2409.17458_2155090_3	In reality, users can engage in multi-turn interactions with LLM-based chat assistants, allowing them to conceal their true intentions in a more covert manner.
2409.17655_2155287_3	In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed to operate autonomously in a physical office environment.
2409.20553_2158185_1	This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making.
2409.20553_2158185_4	Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools.
2410.03457_2161658_4	Recognizing the complexity of this writing task, we built an LLM-powered assistant into the workers' interface to aid in drafting and refining their comments.
2410.03733_2161934_3	We take three AI Directors and directly compare them in a human subject study to test their effectiveness on quest selection.
2410.03736_2161937_3	To address this gap, we introduce CliMB, a no-code AI-enabled partner designed to empower clinician scientists to create predictive models using natural language.
2410.03781_2161982_1	With the growing popularity of Large Language Models (LLMs), there have been efforts to create LLM based conversational tutors which can expand the benefits of one to one tutoring to everyone.
2410.04334_2162535_2	This paper systematically reviews primary studies on AI assistants designed to support different phases of the incident lifecycle.
2410.04545_2162746_4	Indeed, factors such as an individual's writing confidence and familiarity with AI writing assistants are shown to moderate the impact of AI assistance disclosure on their writing quality evaluations.
2410.04592_2162793_2	Our project starts with a participatory design study with 11 clinicians to understand their practices and needs; then we build a multimodal AI system, CardioAI, that integrates wearables and LLM-powered voice assistants to monitor multimodal non-clinical symptoms.
2410.04596_2162797_0	  While current chat-based AI assistants primarily operate reactively, responding only when prompted by users, there is significant potential for these systems to proactively assist in tasks without explicit invocation, enabling a mixed-initiative interaction.
2410.04596_2162797_1	This work explores the design and implementation of proactive AI assistants powered by large language models.
2410.05434_2163635_1	We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers.
2410.06458_2164659_3	To address this, we introduce RealInstruct, the first benchmark designed to evaluate LLMs' ability to follow real-world multi-constrained instructions by leveraging queries real users asked AI assistants.
2410.09037_2167238_1	Recently, studies have proposed a Knowledge Distillation (KD) approach, reasoning distillation, which transfers such reasoning ability of LLMs through fine-tuning language models of multi-step rationales generated by LLM teachers.
2410.09048_2167249_0	  LLM-powered coding and development assistants have become prevalent to programmers' workflows.
2410.10526_2168727_0	  While convenient, relying on LLM-powered code assistants in day-to-day work gives rise to severe attacks.
2410.11856_2170057_5	Our goal is to create a user-friendly multilingual AI-based personal assistant, Malak, to reduce online harm and promote safe online interactions, benefiting users with lower literacy levels.
2410.12568_2170769_4	RAPID features three key designs: 1) utilization of offline data collected from an LLM agent to distil expert knowledge into RL policies for faster real-time inference; 2) introduction of robust distillation in RL to inherit both performance and robustness from LLM-based teacher; and 3) employment of a mix-of-policy approach for joint decision decoding with a policy adapter.
2410.16397_2174598_5	METIS is an AI assistant designed to handle routine tasks, monitor spacecraft systems, and detect anomalies, all while reducing the reliance on mission control.
2410.17196_2175397_0	  Building on the success of large language models (LLMs), recent advancements such as GPT-4o have enabled real-time speech interactions through LLM-based voice assistants, offering a significantly improved user experience compared to traditional text-based interactions.
2410.17196_2175397_3	To address this, we introduce VoiceBench, the first benchmark designed to provide a multi-faceted evaluation of LLM-based voice assistants.
2410.17210_2175411_6	Conclusion: Our work represents the first structured effort toward building an AI-based legal assistant for Bangladesh.
2410.17950_2176151_6	These advancements have significant implications for the development of more capable AI assistants and the broader application of LLMs in real-world scenarios.
2410.18417_2176618_1	These models have become popular in artificial intelligence (AI) assistants like ChatGPT and already play an influential role in how humans access information.
2410.18703_2176904_8	We show the benefits of this framework by running experiments on millions of lines of code from open source projects where parts of existing functionality are regenerated by AI assistants.
2410.18703_2176904_9	We empirically show that AI assistants produce unsafe code and demonstrate the utility of our framework in proposing appropriate blame and sanitization obligations.
2410.19262_2177463_6	An LLM-based artificial intelligence assistant is developed to provide intuitive human-building interaction for blockchain and building operation management-related tasks and enable autonomous building operation.
2410.20745_2178946_6	With Shopping MMLU, we benchmark over 20 existing LLMs and uncover valuable insights about practices and prospects of building versatile LLM-based shop assistants.
2410.21159_2179360_0	  We introduce a multi-turn benchmark for evaluating personalised alignment in LLM-based AI assistants, focusing on their ability to handle user-provided safety-critical contexts.
2410.21159_2179360_6	Our work emphasises the need for nuanced, context-aware approaches to alignment in systems designed for persistent human interaction, aiding the development of safe and considerate AI assistants.
2410.23728_2181929_0	  With the increasing quality and spread of LLM-based assistants, the amount of LLM-generated content is growing rapidly.
2411.02328_2184755_5	Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for opensource modules.
2411.02408_2184835_2	To help CSRs regulate their emotions while interacting with uncivil clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use.
2411.02408_2184835_8	We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for AI assistants for worker mental health.
2411.02714_2185141_0	  We introduce GamePlot, an LLM-powered assistant that supports game designers in crafting immersive narratives for turn-based games, and allows them to test these games through a collaborative game play and refine the plot throughout the process.
2411.02714_2185141_2	We also show that diverse user populations have different expectations from AI assistants, and encourage researchers to study how tailoring assistants to diverse user groups could potentially lead to increased job satisfaction and greater creativity and innovation over time.
2411.02725_2185152_3	In this study, we deployed an LLM tutor in an accelerated introductory computing course to evaluate its effectiveness specifically for NNES students.
2411.02725_2185152_5	Results for views of the LLM tutor are as follows: both NNES and NES students appreciated the LLM tutor for its accessibility, conversational style, and the guardrails put in place to guide users to answers rather than directly providing solutions; NNES students highlighted its approachability as they did not need to communicate in perfect English; NNES students rated help-seeking preferences of online resources higher than NES students; Many NNES students were unfamiliar with computing terminology in their native languages.
2411.02725_2185152_6	These results suggest that LLM tutors can be a valuable resource for NNES students in computing, providing tailored support that enhances their learning experience and overcomes language barriers.
2411.03417_2185844_4	Evaluation of the assistant by NeurIPS paper authors suggests that the LLM-based assistant was generally helpful in verifying checklist completion.
2411.07042_2189469_0	  AI companions based on large language models can role-play and converse very naturally.
2411.07042_2189469_1	When value conflicts arise between the AI companion and the user, it may offend or upset the user.
2411.07042_2189469_3	We first conducted a formative study that analyzed 151 user complaints about conflicts with AI companions, providing design implications for our study.
2411.09012_2191439_0	  AstroSage-Llama-3.1-8B is a domain-specialized natural-language AI assistant tailored for research in astronomy, astrophysics, cosmology, and astronomical instrumentation.
2411.09873_2192300_1	As large language models (LLMs) provide new opportunities to incorporate personas to AI-based tutors and support dynamic interactive dialogue, this paper explores how DHH learners perceive LLM-powered ITS with different personas and identified design suggestions for improving the interaction.
2411.09873_2192300_2	We developed an interface that allows DHH learners to interact with ChatGPT and three LLM-powered AI tutors with different experiences in DHH education while the learners watch an educational video.
2411.09873_2192300_3	A user study with 16 DHH participants showed that they perceived conversations with the AI tutors who had DHH education experiences to be more human-like and trustworthy due to the tutors' cultural knowledge of DHH communities.
2411.09916_2192343_0	  Software engineers are integrating AI assistants into their workflows to enhance productivity and reduce cognitive strain.
2411.11892_2194319_3	This paper investigates the energy consumption of LLM-based code assistants by simulating developer interactions with GitHub Copilot and analyzing various configuration factors.
2411.12619_2195046_2	Within this virtual environment that we have created, we have an AI tutor powered by OpenAI's GPT model which was called using an api which moves around with the user.
2411.12619_2195046_4	Our approach mainly involves utilising speech to text, text to text conversion and text to speech capabilities to facilitate real time interaction between users and the AI tutor in the presence of internet.
2411.12808_2195235_9	Our findings demonstrate that carefully implemented AI medical assistants can enhance patient experience while maintaining safety standards through physician supervision.
2411.13207_2195634_0	  The popularity of large language models (LLMs) continues to increase, and LLM-based assistants have become ubiquitous, assisting people of diverse backgrounds in many aspects of life.
2411.13207_2195634_3	Chatbots and LLM-based assistants may put unwitting users in harm's way by facilitating unsafe behavior.
2411.13207_2195634_9	Our findings also highlight the importance of ISA assessment for the development of future LLM-based assistants.
2411.14442_2196869_1	We address the challenges of AI ethics by proposing a structure that integrates rules, policies, and AI assistants to ensure responsible AI behavior, while comparing the proposed framework to the existing state-of-the-art guardrails.
2411.15143_2197570_7	Our results suggest a path towards capable AI assistants for languages that don't yet have large-scale human-generated examples.
2411.16707_2199134_8	Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond.
2411.16955_2199382_5	Our insights have important implications beyond chemistry and materials science, suggesting that developing reliable multimodal AI scientific assistants may require advances in curating suitable training data and approaches to training those models.
2412.00329_2202707_0	  The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development.
2412.01992_2204370_5	For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles.
2412.04036_2206414_1	The recent emergence of large language models (LLMs)-based virtual assistants has demonstrated their potential to revolutionize human interactions and lifestyles.
2412.06603_2208981_4	Our case study characterizes the impact of an LLM-powered assistant on developers' perceptions of productivity and it shows that although such tools do often provide net productivity increases, these benefits may not always be experienced by all users.
2412.08360_2210738_1	This paper discusses the need to move away from an instrumental view of text composition AI assistants under direct control of the user, towards a more agentic approach that is based on a value rationale.
2412.12681_2215059_3	We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents.
2412.13678_2216056_2	To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations.
2412.14190_2216568_5	Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products.
2412.14190_2216568_6	In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity.
2412.15444_2217822_2	Our research focused on designing a generative AI assistant to aid genetic professionals in analyzing whole genome sequences (WGS) and other clinical data for rare disease diagnosis.
2412.15444_2217822_4	We then conducted co-design sessions with six genetics professionals to determine tasks that could be supported by an AI assistant and considerations for designing interactions with the AI assistant.
2412.16172_2218550_9	The solutions generated by the AI assistant were compared with the expert solution and a uniform linear sweep baseline with 10,000 points.
2501.02684_2226268_5	In this exploratory study, we aim to investigate the role AI assistants play in developer productivity.
2501.03446_2227030_0	  Software vulnerabilities continue to be ubiquitous, even in the era of AI-powered code assistants, advanced static analysis tools, and the adoption of extensive testing frameworks.
2501.07913_2231497_1	Companies that pioneered the development of language models have now built AI agents that can independently navigate the internet, perform a wide range of online tasks, and increasingly serve as AI personal assistants and virtual coworkers.
2501.08473_2232057_2	CGScholar AI Helper is an evolving and innovative web-based application designed to support students in their writing tasks by providing specified AI-generated feedback.
2501.13945_2237529_1	For example, in online learning, an AI social assistant may connect learners and thereby enhance social interaction.
2501.13945_2237529_3	We present a method of self-explanation that uses introspection over a self-model of an AI social assistant.
2501.16240_2239824_2	Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping).
2501.16661_2240245_4	Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension.
2502.03333_2246324_7	Together, these findings highlight the potential of RadVLM as a clinically relevant AI assistant, providing structured CXR interpretation and conversational capabilities to support more effective and accessible diagnostic workflows.
2502.03358_2246349_0	  How effectively can LLM-based AI assistants utilize their memory (context) to perform various tasks?
2502.04110_2247101_2	Research team members had differing levels of familiarity with the ILCS and the case content, so we developed a custom ChatGPT assistant to facilitate consistent terminology and process alignment across the team.
2502.04110_2247101_5	Further we report that the use of a ChatGPT assistant significantly sup-ports the coherence and quality of the team members development of the final ILCS.
2502.05497_2248488_4	Experiments demonstrate that DeepThink achieves an average performance improvement of 7.92% compared to a GPT-4-turbo+RAG-based assistant on the real user test set in the advertising domain across dimensions such as relevance, completeness, clarity, accuracy, and actionability.
2502.07956_2250947_2	In this paper, we advocate combining insights from human-computer interaction (HCI) and artificial intelligence (AI) research to enable human-centered automatic evaluation of LLM-based conversational SE assistants.
2502.08640_2251631_6	We uncover problematic and often shocking values in LLM assistants despite existing control measures.
2502.10884_2253875_2	AI coding assistants, such as GitHub Copilot, could offer potential by generating accessibility-compliant code, but their impact remains uncertain.
2502.10884_2253875_6	Our findings demonstrate its effectiveness in guiding novice developers by reinforcing accessibility practices throughout interactions, representing a significant step towards integrating accessibility into AI coding assistants.
2502.12876_2255867_5	This method offers a practical way to build personalized AI companions that evolve through continuous learning, advancing beyond traditional static LLM techniques.
2502.14080_2257071_3	Addressing these challenges, this research presents gAI-PT4I4, a Generative AI-based Personalized Tutor for Industrial 4.0, designed to personalize 4IR experiential learning.
2502.14080_2257071_5	The framework integrates low-fidelity Digital Twins for VR-based training, featuring an Interactive Tutor - a generative AI assistant providing real-time guidance via audio and text.
2502.16090_2259081_2	This oversight has led to suboptimal performance in applications requiring EM, including emotional companionship, personal AI assistants, and AI teachers.
2502.17730_2260721_2	However, how AI managers are perceived in comparison to human managers and how gender influences these perceptions remains uncertain.
2502.17730_2260721_7	However, male managers - both human and AI - were more positively received by awarded participants, whereas female managers, especially female AI managers, faced greater skepticism and negative judgments when they denied rewards.
2502.18467_2261458_11	Finally, this research provides insights for developers choosing AI coding assistants and informs future AI-driven software development research.
2502.18527_2261518_0	  Personal AI assistants (e.g., Apple Intelligence, Meta AI) offer proactive recommendations that simplify everyday tasks, but their reliance on sensitive user data raises concerns about privacy and trust.
2502.18527_2261518_1	To address these challenges, we introduce the Guardian of Data (GOD), a secure, privacy-preserving framework for training and evaluating AI assistants directly on-device.
2502.18527_2261518_6	Specifically, users mine with their data, and the mining rate is determined by GOD's evaluation of how well their AI assistant understands them across categories such as shopping, social interactions, productivity, trading, and Web3.
2502.18527_2261518_7	By integrating privacy, personalization, and trust, the GOD model provides a scalable, responsible path for advancing personal AI assistants.
2502.18990_2261981_0	  Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information.
2502.19410_2262401_0	  Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given.
2502.19410_2262401_1	Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space.
2502.20231_2263222_0	  While existing studies have recognised explicit biases in generative models, including occupational gender biases, the nuances of gender stereotypes and expectations of relationships between users and AI companions remain underexplored.
2502.20231_2263222_1	In the meantime, AI companions have become increasingly popular as friends or gendered romantic partners to their users.
2502.20231_2263222_2	This study bridges the gap by devising three experiments tailored for romantic, gender-assigned AI companions and their users, effectively evaluating implicit biases across various-sized LLMs.
2502.20616_2263607_0	  Personalization is critical in AI assistants, particularly in the context of private AI models that work with individual users.
2502.20689_2263680_6	These results highlight the potential for more reliable, adaptive, and goal-driven AI diagnostic assistants, advancing LLMs beyond reactive dialogue systems.
2503.02833_2267145_2	A key challenge is that these AI assistants can suffer from hallucinations, leading developers down decision paths that the AI should not dictate, sometimes even without the users awareness or consent.
2503.02846_2267158_0	  Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains.
2503.03067_2267379_0	  This paper explores the acceptance of human-AI love among young adults, particularly focusing on Chinese women in romantic or intimate relationships with AI companions.
2503.03067_2267379_4	While AI companions offer advantages like emotional stability and constant availability, they also face limitations in emotional depth and understanding.
2503.05039_2269351_6	Our findings highlight the need for chatbot interactions that foster trust, especially for AI-conservative instructors.
2503.05039_2269351_9	This work underscores the urgent need to support AI-conservative instructors, as AI literacy and attitudes are closely intertwined.
2503.05455_2269767_2	We investigate human preferences for controllability in a shared workspace task with AI partners using Behavior Shaping (BS), a reinforcement learning algorithm that allows humans explicit control over AI behavior.   
2503.05926_2270238_2	We provide insights drawn from interviews with industry personnel working on building human-AI collaboration systems, as well as our collaborations with end-users to build a multimodal AI assistant for task support.
2503.06424_2270736_1	Recent AI tutors are adapted for the tutoring task by training or prompting LLMs to follow effective pedagogical principles, though they are not trained to maximize student learning throughout the course of a dialogue.
2503.09382_2273694_4	This is because commonly used datasets lack high-quality textual user queries that reflect real-world recommendation scenarios, making them unsuitable for evaluating LLM-based personalized recommendation assistants.
2503.11586_2275898_0	  Large language models (LLMs) are used in chatbots or AI assistants to hold conversations with a human user.
2503.11915_2276227_2	However, does this benefit persist when students write with generative AI writing assistants?
2503.11915_2276227_6	Students who proactively explored ideas gained new ideas from writing, regardless of whether they used auto-complete or Socratic AI assistants.
2503.14281_2278593_6	We introduce a novel, task-agnostic black-box attack algorithm GCGS that systematically searches the transformation space using a Cayley Graph, achieving an 83.09% attack success rate on average across five tasks and eleven models, including GPT-4o and Claude 3.5 Sonnet v2 used by many popular AI coding assistants.
2503.15726_2280038_3	Our results indicate that while RL agents generally outperform LLM-controlled adversaries in standard metrics, the strategic depth provided by LLMs significantly enhances the overall AI capabilities in this complex, rule-based setting.
2503.16491_2280803_1	To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants.
2503.16491_2280803_6	Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code.
2503.16491_2280803_7	Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments.
2503.16491_2280803_8	Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs.
2503.16508_2280820_2	This study investigates programmers' usage patterns, perceptions, and interaction strategies when engaging with LLM-driven coding assistants.
2503.19356_2283668_3	This has been a long-standing goal in AI and is a prerequisite for real-world AI assistants and humanoid robots to interact with humans in everyday situations.
2503.20934_2285246_4	We introduce the first LLM fully powered assistant for MOVEMETHOD refactoring that automates its whole end-to-end lifecycle, from recommendation to execution.
2503.21888_2286200_1	While large language model (LLM)-based assistants have shown promise in mental health interventions, existing research often defines "effective" support primarily in terms of empathetic acknowledgments, overlooking other essential dimensions such as informational guidance, community validation, and tangible coping strategies.
2503.21983_2286295_0	  As artificial intelligence (AI) assistants become more widely adopted in safety-critical domains, it becomes important to develop safeguards against potential failures or adversarial attacks.
2503.21983_2286295_4	Leveraging techniques from Model-Based Reinforcement Learning (MBRL), the AI assistant learns a model of the humans' trust evolution and uses that model to manipulate the group decision-making process to harm the team.
2503.23037_2287349_10	We note that there is risk associated with LLM assistants taking action in the real world, while agentic LLMs are also likely to benefit society.
2504.02670_2291373_7	KGoT offers a scalable, affordable, and high-performing solution for AI assistants.
2504.02823_2291526_4	This allows us to train a domain-aware visual AI assistant named STING-BEE that supports a range of vision-language tasks, including scene comprehension, referring threat localization, visual grounding, and visual question answering (VQA), establishing novel baselines for multi-modal learning in X-ray baggage security.
2504.03068_2291771_4	To address these challenges, we developed CodeRunner Agent, an LLM-based programming assistant that integrates the CodeRunner, a student-submitted code executing and automated grading plugin in Moodle.
2504.03726_2292429_6	IAP detection methods achieve high precision with zero false positives but struggle to detect many malicious AI Assistants, resulting in high false negative rates.
2504.03966_2292669_2	This study introduces the Dynamic Course Content Integration (DCCI) mechanism, which dynamically retrieves and integrates course content and curriculum from Canvas LMS into the LLM-powered assistant, Ask ME.
2504.04299_2293002_5	Users expressed feelings of discomfort, violation of privacy, and disappointment, particularly when seeking a platonic or therapeutic AI companion.
2504.04299_2293002_6	This study highlights the potential harms associated with AI companions and underscores the need for developers to implement effective safeguards and ethical guidelines to prevent such incidents.
2504.05559_2294262_2	In this paper, we introduce SciSciGPT, an open-source, prototype AI collaborator that uses the science of science as a testbed to explore the potential of LLM-powered research tools.
2504.06294_2294997_1	This protocol lays out a study grounded in constructivist learning theory to evaluate a novel AI-based Socratic Tutor, designed to foster cognitive engagement and scaffold research question development in higher education.
2504.09296_2297999_3	Our approach employs eye-tracking technology within AR glasses to discern a user's intention to engage with the AI assistant.
2504.12461_2301164_2	In SE research on AI assistants, this practice culminates in equating trust with the likelihood of accepting generated content, which does not capture the full complexity of the trust concept.
2504.12461_2301164_7	Related disciplines commonly embed their methodology and results in established trust models, clearly distinguishing, for example, between initial trust and trust formation and discussing whether and when trust can be applied to AI assistants.
2504.12461_2301164_9	We provide concrete recommendations on how SE researchers can adopt established trust models and instruments to study trust in AI assistants beyond the acceptance of generated software artifacts.
2504.12757_2301460_7	Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.
2504.13486_2302189_2	One notable effort is the development of ChatBlackGPT, a culturally informed AI assistant designed to provide culturally relevant responses.
2504.13486_2302189_5	Our efforts thus far emphasize the need to consider Black communities' values, perceptions, and experiences when designing AI assistants that acknowledge the Black lived experience.
2504.13924_2302627_0	  Enterprise AI Assistants are increasingly deployed in domains where accuracy is paramount, making each erroneous output a potentially significant incident.
2504.16505_2305208_2	Our work addresses the fundamental challenge of developing practical AI travel assistants through a novel large-scale dataset of 220k question-answer pairs.
2504.18340_2307043_1	Current chemical synthesis practices emphasize laborious and costly trial-and-error workflows, underscoring the urgent need for advanced AI assistants.
2505.01678_2312238_2	To address this issue, we developed an AI-based speaking assistant (AISA) that provides speaking references for NNSs based on their input queries, task background, and conversation history.
2505.03867_2314427_2	Building on prior research \cite{druga_how_2021,druga2023ai, druga2023scratch}, we present Cognimates Scratch Copilot: an AI-powered assistant integrated into a Scratch-like environment, providing real-time support for ideation, code generation, debugging, and asset creation.
1012.1877_231245_6	We show that (i) this system is a cousin to the LMXB Cyg X-2; (ii) for neutron stars of canonical birth mass 1.4 solar masses, the initial donor stars which produce the closest relatives to PSR J1614-2230 have a mass between 3.4-3.8 solar masses; (iii) neutron stars as massive as 1.97 solar masses are not easy to produce in spite of the initially high mass of the donor star, unless they were already born as relatively massive neutron stars; (iv) to successfully produce a system like PSR J1614-2230 requires a minimum initial neutron star mass of at least 1.6+-0.1 solar masses, as well as initial donor masses and orbital period of ~ 4.25+-0.10 solar masses and ~49+-2 hrs, respectively; and (v) the current companion star is largely composed of CO, but should have a surface H abundance of ~10-15%.
1508.02487_649143_2	In this paper, we construct a scenario of a damaged aircraft model which has no physical rudder control surface, and then a strategy based on differential thrust is proposed to be utilized as a control input to act as a "virtual" rudder to help maintain stability and control of the damaged aircraft.
1605.06808_734923_4	In the whole analysis we incorporate as model constraints the most up-to-date observational information, encompassing the binary's orbital properties, the companion star mass, effective temperature, surface gravity and radius, as well as the black hole's mass and spin.
1703.09310_832814_0	  This work studies how an AI-controlled dog-fighting agent with tunable decision-making parameters can learn to optimize performance against an intelligent adversary, as measured by a stochastic objective function evaluated on simulated combat engagements.
1806.00610_986250_5	We label these types of costs as neglected dimensions of AI progress, and explore them using four case studies: Alpha* (Go, Chess, and other board games), ALE (Atari games), ImageNet (Image classification) and Virtual Personal Assistants (Siri, Alexa, Cortana, and Google Assistant).
1808.07899_1017045_2	It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field.
1810.00184_1031371_5	It is not the purpose of the authors of this paper to 'take sides' - we count ourselves as members, to varying degrees, of multiple communities - but rather to help disambiguate what stakeholders mean when they ask 'Why?' of an AI.
1908.08939_1167109_3	Considering the needs of users with disabilities can help technologists identify high-impact challenges whose solutions can advance the state of AI for all users; however, ethical challenges such as inclusivity, bias, privacy, error, expectation setting, simulated data, and social acceptability must be considered.
1911.01940_1200534_4	Utilizing RoBERTa as the backbone encoder, our proposed improvement over the pre-trained models is shown effective on multiple natural language understanding tasks and help our model rival with the state-of-the-art models on the GLUE benchmark.
1911.05796_1204390_7	Thus far the US has been a leader in AI technologies, and we believe as a national Laboratory it is crucial to help maintain and extend this leadership.
1912.03468_1215364_4	Furthermore, to help validate the proposedoptimization methods, we derive lower bounds to quantify the average transmit power at the BS as afunction of the number of MEs, the number of RIS elements, and the number of antennas at the BS.The simulation results demonstrated that the average transmit power at the BS is close to the lowerbound in an RIS aided system, and is significantly lower than the average transmit power in conventionalschemes without the RIS.
2003.06769_1257124_5	We introduce a parameter called "focus length" (a positive number such as 5 or 10) to control the speed and sensitivity for our multi-AI to adapt to the opponent's strategy change.
2004.02731_1267501_3	Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists.
2005.03848_1283643_2	As an alternative, we propose a new method for BERT distillation, i.e., asking the teacher to generate smoothed word ids, rather than labels, for teaching the student model in knowledge distillation.
2006.01908_1296422_1	In particular, we have developed four novel and intertwined AI technologies: (1) VERA, a virtual experimentation research assistant for supporting inquiry-based learning of scientific knowledge, (2) Jill Watson Q&A, a virtual teaching assistant for answering questions based on educational documents including the VERA user reference guide, (3) Jill Watson SA, a virtual social agent that promotes online interactions, and (4) Agent Smith, that helps generate a Jill Watson Q&A agent for new documents such as class syllabi.
2006.14576_1309090_2	As a privacy threat, the adversary can use this leaked information to exploit vulnerabilities of the ML model following an adversarial ML approach.
2007.05801_1317315_3	To explore this, we developed a Migratable AI system where a user's information and/or the agent's identity can be preserved as it migrates across form factors to help its user with a task.
2007.12391_1323905_5	We foresee that, in the near future, machine learning-based AI will be adopted widely as a tool or collaborative assistant for creativity.
2008.00312_1328034_6	By empirically studying three state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP tasks (toxic comment detection, question answering, text completion) as well as user studies on crowdsourcing platforms, we demonstrate that TROJAN-LM possesses the following properties: (i) flexibility - the adversary is able to flexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary words as triggers, (ii) efficacy - the host systems misbehave as desired by the adversary with high probability when trigger-embedded inputs are present, (iii) specificity - the trojan LMs function indistinguishably from their benign counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs appear as fluent natural language and highly relevant to their surrounding contexts.
2008.01916_1329638_2	Differential privacy, as a promising mathematical model, has several attractive properties that can help solve these problems, making it quite a valuable tool.
2009.04943_1346446_2	Many research groups state that 5G cannot meet its demands without artificial intelligence (AI) integration as 5G wireless networks are expected to generate unprecedented traffic giving wireless research designers access to big data that can help in predicting the demands and adjust cell designs to meet the users requirements.
2009.04984_1346487_3	As the foundation for model pre-training, we synthesize a new dialogue corpus and build our training set with two unsupervised methods: 1) coherence-oriented context corruption, including utterance ordering, insertion, and replacement, to help the model capture the coherence inside the dialogue contexts; and 2) specificity-oriented automatic rescoring, which encourages the model to measure the quality of the synthesized data for dialogue-adaptive pre-training by considering specificity and informativeness.
2009.07240_1348743_1	The model is an agent-driven simulator, featuring various stakeholders such as the Network Manager and airlines.
2011.00593_1373341_6	Concretely, in addition to the original training examples, the student model is encouraged to mimic the teacher's behavior on the linear interpolation of example pairs as well.
2101.01524_1405266_4	Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as "a doctor's AI assistant" to realize a Human-AI Collaboration future in clinical settings.
2103.03373_1433518_0	  Current state-of-the-art large-scale conversational AI or intelligent digital assistant systems in industry comprises a set of components such as Automatic Speech Recognition (ASR) and Natural Language Understanding (NLU).
2103.10918_1441063_3	We also view these metrics as an extension of BLANC, a recently proposed approach to summary quality measurement based on the performance of a language model with and without the help of a summary.
2105.03192_1465751_3	Relevant concepts are integrated into a matrix intended to help defining more precisely when and how computing tools (programs or devices) may be qualified as AI while highlighting critical features to serve a specific technical, ethical and legal assessment of challenges in AI development.
2109.01396_1524217_4	Additionally, we explain how such an understanding of the training process can be useful in practice and, as an example, show how it can be used to improve vanilla non-autoregressive neural machine translation by guiding teacher model selection.
2109.02417_1525238_2	From the examination of the images that were produced and with the help of Machine Learning, the question of whether the activity of each user is classified as malicious or not for the Information System was answered.
2110.06961_1545104_8	GPT-2 always acts as the best teacher, though, and using it and a Transformer-XL student on Wiki-02, rank-based KD reduces a cross-entropy baseline from 65.27 to 55.94 and against a KL-based KD of 56.70.
2110.09290_1547433_4	Finally, just as the chemistry triplet has impacted chemistry education in concrete ways, we suggest two initial hypotheses for how the AI triplet might impact AI education: 1) how we can help AI students gain proficiency in moving between the corners of the triplet; and 2) how all corners of the AI triplet highlight the need for supporting students' spatial cognitive skills.
2111.01726_1555829_9	Instruction from AI such as this functions both to help humans perform better at tasks, but also to better understand, anticipate, and correct the actions of an AI.
2111.12210_1566313_3	The key is to use Explainable AI to help derive data or model interpretations, hypotheses, as well as scientific discoveries or insights.
2111.12210_1566313_6	This work also highlights the important role of Explainable AI (as compared to Blackbox AI) in science discovery to help humans prevent or better prepare for the possible technological singularity that may happen in the future, since science is not only about the know how, but also the know why.
2201.06724_1592096_3	AI should play a role as an assistant in the lyrics creation process, where human interactions are crucial for high-quality creation.
2201.06796_1592168_5	We demonstrate that CoAuthor can address questions about GPT-3's language, ideation, and collaboration capabilities, and reveal its contribution as a writing "collaborator" under various definitions of good collaboration.
2203.01556_1614418_5	Participants of the AI track are asked to develop their AI algorithm that controls a character given only sound as the input (blind AI) to fight against their opponent; a sample deep-learning blind AI will be provided by us.
2204.12000_1642138_8	Our estimation scheme sheds light on an important anthropomorphic element found in such AI models and can help stakeholders decide how they should be applied as well as how society could perceive them.
2207.04692_1680590_4	In this article, we propose a classification system using ML based on a novel `PUF-Phenotype' concept to accurately identify the origin and determine the validity of noisy memory derived (DRAM) PUF responses as an alternative to helper data-reliant denoising techniques.
2208.07960_1698672_4	Our results show that while recommendations from an AI-Assistant can aid user decision making, factors such as users' baseline performance relative to the AI and complementary tuning of AI error types significantly impact overall team performance.
2210.01369_1722724_5	Therefore, they held mixed views towards AI-enabled products such as AI, an aid, or an adversary.
2210.02498_1723853_6	Specifically, we generate silver annotated data by sending a series of prompts to a frozen pretrained language model, which acts as a teacher.
2210.03629_1724984_1	In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.
2210.12427_1733782_3	The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student.
2211.00373_1739279_1	As part of a recent Web-based Geographic Information System (WebGIS) project, we are employing cloud-native technologies (from the container ecosystem) to develop a federated database (DB) infrastructure, to help manage and utilise the distributed and various geospatial data.
2211.06318_1745224_3	It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field.
2211.08361_1747267_9	For an average formula with three variables, the system can generate and correct up to 300 questions for individual students based on a single formula concept name as input by the teacher.
2211.13230_1752136_3	As with all new technologies, use of AI should be preceded by a fundamental understanding of the risks and benefits to those it is intended to help.
2212.07542_1763719_5	The model uses contexts given by their instructor, such as chapters of a textbook, to answer questions and is deployed on an interactive chatbot/voice agent.
2212.08073_1764250_0	  As AI systems become more capable, we would like to enlist their help to supervise other AIs.
2301.10095_1781159_0	  Artificial Intelligence (AI) is taking on increasingly autonomous roles, e.g., browsing the web as a research assistant and managing money.
2301.10412_1781476_2	Specifically, the adversary injects a backdoor into the model during the training phase, so that input samples with backdoor triggers are classified as the target class.
2301.13867_1784931_7	We find that ChatGPT can be used most successfully as a mathematical assistant for querying facts, acting as a mathematical search engine and knowledge base interface.
2302.04536_1789470_0	  Aim: To compare students' essay writing performance with or without employing ChatGPT-3 as a writing assistant tool.
2302.07080_1792014_3	We developed a prototype system -- the Programmer's Assistant -- in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM.
2302.08500_1793434_2	Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust.
2302.09977_1794911_8	Besides, the hidden structural information between the stations can be obtained as model by-products, which can help make some subsequent decision-making analyses.
2302.10291_1795225_0	  Pretrained large language models (LLMs) are becoming increasingly powerful and ubiquitous in mainstream applications such as being a personal assistant, a dialogue model, etc.
2302.10786_1795720_1	In this work, we extended Kwame, a bilingual AI teaching assistant for coding education, adapted it for science education, and deployed it as a web app.
2303.06573_1806370_3	In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search.
2303.07610_1807407_0	  As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis.
2303.08033_1807830_6	These findings can be leveraged by educators to adapt their instructional practices and assessments in programming courses, so that GPT becomes a valuable assistant for a learner as opposed to a source of confusion and/or potential hindrance in the learning process.
2303.09325_1809122_8	These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.
2303.11455_1811252_5	We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code.
2303.12040_1811837_2	The AI as collaborator dream is different from computer tools that augment human intelligence (IA) or intermediate human collaboration.
2303.12732_1812529_2	Specifically, with the recent appearance of tools such as DALL-E, capable of completing images guided by a textual description, it is possible to count on the help of AI for architectural design tasks.
2304.09873_1827919_1	This paper proposes using ChatGPT, an innovative technology with various applications, as an assistant for psychotherapy.
2304.09873_1827919_2	ChatGPT can serve as a patient information collector, a companion for patients in between therapy sessions, and an organizer of gathered information for therapists to facilitate treatment processes.
2304.09873_1827919_4	Using ChatGPT as an assistant for psychotherapy poses several challenges that need to be addressed, including technical as well as human-centric challenges which are discussed.
2304.11938_1829984_2	To assess the feasibility of using an LLM as a useful assistant bot for programmers, we must assess its realistic capabilities on unseen problems as well as its capabilities on various tasks.
2304.11938_1829984_3	In this paper, we present an empirical study of ChatGPT's potential as a fully automated programming assistant, focusing on the tasks of code generation, program repair, and code summariziation.
2304.13841_1831887_13	AI research and development may help make transportation more sustainable, as may optimizing EHVs and charging infrastructure.
2304.14233_1832279_4	As a part of the prompts, they are likely to help LLM generate more precise answers by pattern imitation or candidate summarization.
2305.03047_1836103_1	Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable.
2305.07759_1840815_5	We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher.
2305.11248_1844304_6	We gathered developers' feedback on how these design concepts can help them build appropriate trust in AI-powered code generation tools, as well as potential risks in design.
2305.14483_1847539_4	Building on this insight, SIRLC assigns LLMs dual roles as both student and teacher.
2305.14483_1847539_5	As a student, the LLM generates answers to unlabeled questions, while as a teacher, it evaluates the generated text and assigns scores accordingly.
2305.14878_1847934_3	Our results demonstrate that GPT-4 is adept at translation post-editing, producing meaningful and trustworthy edits to translations that help improve its general quality as well as remove different classes of major errors in translations.
2305.18011_1851067_0	  Explainable AI (XAI) techniques have been widely used to help explain and understand the output of deep learning models in fields such as image classification and Natural Language Processing.
2305.18239_1851295_5	These factors are: (i) the impact of teacher model quality on DWT effectiveness, (ii) guidelines for adjusting the weighting value for DWT loss, and (iii) the impact of parameter remapping as a student model initialization technique for DWT.
2305.18279_1851335_4	Moreover, we present ContextDET, a unified multimodal model that is capable of end-to-end differentiable modeling of visual-language contexts, so as to locate, identify, and associate visual objects with language inputs for human-AI interaction.
2306.01058_1854206_2	Layout-infused LMs are often evaluated on documents with familiar layout features (e.g., papers from the same publisher), but in practice models encounter documents with unfamiliar distributions of layout features, such as new combinations of text sizes and styles, or new spatial configurations of textual elements.
2306.01615_1854763_3	I propose that viewing AI as a tool or an instrument, rather than a collaborator, is more accurate, and ultimately fairer.
2306.03090_1856238_2	We explore whether generative AI could become a cost-effective complement to expert feedback by serving as an automated teacher coach.
2306.03102_1856250_1	This paper investigates the capabilities of ChatGPT as an automated assistant in diverse domains, including scientific writing, mathematics, education, programming, and healthcare.
2306.03204_1856352_0	  This paper explores the concept of leveraging generative AI as a mapping assistant for enhancing the efficiency of collaborative mapping.
2306.03823_1856971_4	While ChatGPT has the ability to help educators by creating instructional content, offering suggestions and acting as an online educator to learners by answering questions and promoting group work, there are clear drawbacks in its use, such as the possibility of producing inaccurate or false data and circumventing duplicate content (plagiarism) detectors where originality is essential.
2306.05360_1858508_2	The task aims to assess the performance of state-of-the-art generative models as AI teachers in producing suitable responses within a student-teacher dialogue.
2306.06503_1859651_1	The use of AI models solely trained on large multi-institutional datasets can help with this, yet the imperative to ensure data privacy remains, particularly as membership inference risks breaching patient confidentiality.
2306.06794_1859942_4	We propose that considering what it is like to be an LLM like ChatGPT, as Nagel might have put it, can help us gain insight into its capabilities in general, and in particular, that its exposure to linguistic training data can be productively reframed as exposure to the diegetic information encoded in language, and its deficits can be reframed as ignorance of extradiegetic information, including supradiegetic linguistic information.
2306.06941_1860089_2	The goal of the task was to benchmark the ability of generative language models to act as AI teachers, replying to a student in a teacher-student dialogue.
2306.10052_1863200_2	The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases.
2306.10645_1863793_4	Although the results are encouraging, challenges are posed by the limited history maintained for the conversation and the highly structured form of responses by ChatGPT, as well as their variability, which can lead to an unexpected switch of the chatbot's role from a teacher to a therapist.
2306.14048_1867196_7	We formulate the KV cache eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work.
2306.14165_1867313_0	  This study explores the potential of generative artificial intelligence (AI) models, specifically OpenAI's generative pre-trained transformer (GPT) series, when integrated with building information modeling (BIM) tools as an interactive design assistant for architectural design.
2306.16282_1869430_4	Additionally, the suitability of ChatGPT as a teacher for students also warrants consideration.
2307.01981_1872977_5	The key idea is to query large language models (LLMs) with category names to automatically generate additional cues and knowledge, such as disease symptoms or descriptions other than a single category name, to help provide more accurate and explainable diagnosis in CLIP.
2307.06865_1877860_7	Prompt extraction from real systems such as Claude 3 and ChatGPT further suggest that system prompts can be revealed by an adversary despite existing defenses in place.
2307.12776_1883771_2	However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others.
2307.16364_1887359_5	This paper introduces a novel pedagogical concept known as a `Prompt Problem', designed to help students learn how to craft effective prompts for LLMs.
2308.02180_1890072_5	While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop.
2308.09904_1897796_4	We introduce the RAH Recommender system, Assistant, and Human) framework, an innovative solution with LLM-based agents such as Perceive, Learn, Act, Critic, and Reflect, emphasizing the alignment with user personalities.
2308.10335_1898227_7	Existing code evaluation benchmark and datasets focus on crafting small tasks such as programming questions in coding interviews, which however deviates from the problem that developers would ask LLM for real-world coding help.
2308.10873_1898765_5	Moreover, the convergence of average spiking rate of neurons at equilibrium is utilized to develop a novel ANN-SNN knowledge distillation based technique wherein we use a pre-trained BERT model as "teacher" to train our "student" spiking architecture.
2309.00642_1905446_2	Where our study diverges from previous work is in (1) providing a more thorough analysis of what makes mathematical term extraction a difficult problem to begin with; (2) paying close attention to inter-annotator disagreements; (3) providing a set of guidelines which both human and machine annotators could use to standardize the extraction process; (4) introducing a new annotation tool to help humans with ATE, applicable to any mathematical field and even beyond mathematics; (5) using prompts to ChatGPT as part of the extraction process, and proposing best practices for such prompts; and (6) raising the question of whether ChatGPT could be used as an annotator on the same level as human experts.
2309.01645_1906449_1	While it was reported that ChatGPT had the capacity to deliver useful feedback, it is still unclear about its effectiveness compared with conventional feedback approaches,such as teacher feedback (TF) and self-feedback (SF).
2309.01645_1906449_7	These diverse outcomes indicate ChatGPT's potential as a supplementary resource, complementing traditional teacher-led methods in translation practice.
2309.04076_1908880_4	The key idea of Avatar is to formulate the optimization of language models as a multi-objective configuration tuning problem and solve it with the help of a Satisfiability Modulo Theories (SMT) solver and a tailored optimization algorithm.
2309.06424_1911228_4	In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.
2309.08788_1913592_3	The model has proven that it is able to accurately recall information about biological materials and is further enhanced with enhanced reasoning ability, as well as with retrieval-augmented generation to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains.
2309.09582_1914386_5	The generated data could then be used to train a binary sentiment classifier, effectively leveraging an LLM as a teacher to a smaller student model.
2309.10066_1914870_1	Twelve language models were trained on a corpus of PET reports using the teacher-forcing algorithm, with the report findings as input and the clinical impressions as reference.
2309.10694_1915498_3	Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.
2309.11672_1916476_3	However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged.
2309.12348_1917152_4	A future that can be extremely promising if humanity manages to have AI as a proper ally and partner, with distinct roles and specific rules of cooperation and interaction.
2309.14494_1919298_2	To generate a semantic-coherent video, exhibiting a rich portrayal of temporal semantics such as the whole process of flower blooming rather than a set of "moving images", we propose a novel Free-Bloom pipeline that harnesses large language models (LLMs) as the director to generate a semantic-coherence prompt sequence, while pre-trained latent diffusion models (LDMs) as the animator to generate the high fidelity frames.
2309.15839_1920643_0	  Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies.
2309.16697_1921501_9	Based on the survey results, ChatGPT is recommended to be used as an assistant to complete programming tasks and other general assignments.
2309.17415_1922219_1	This will not only help to understand LLMs' decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG).
2310.01434_1923691_4	Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features.
2310.01727_1923984_3	Given that large language models (LLMs), such as GPT-4, show promise in tackling both software engineering- and science-related tasks, these models could help replicate and thus democratize empirical software engineering research.   
2310.02421_1924678_1	Knowledge distillation, a technique aiming to transfer knowledge from a high-capacity "teacher" model to a streamlined "student" model, emerges as a promising solution to this dilemma.
2310.02439_1924696_1	Our primary approach is to simulate LLMs as a novice learner and an expert tutor, aiming to identify the incorrect answer to math question resulted from a specific misconception and to recognize the misconception(s) behind an incorrect answer, respectively.
2310.02527_1924784_2	In this paper, we exploit the idea of leveraging AI models in lieu of humans as the teacher to train student LLMs.
2310.03684_1925941_0	  Despite efforts to align large language models (LLMs) with human intentions, widely-used LLMs such as GPT, Llama, and Claude are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content.
2310.03780_1926037_4	As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts.
2310.05191_1927448_0	  In the context of English as a Foreign Language (EFL) writing education, LLM-as-a-tutor can assist students by providing real-time feedback on their essays.
2310.05191_1927448_1	However, challenges arise in assessing LLM-as-a-tutor due to differing standards between educational and general use cases.
2310.05191_1927448_4	Second, we propose three metrics to evaluate LLM-as-a-tutor specifically designed for EFL writing education, emphasizing pedagogical aspects.
2310.05191_1927448_5	In this process, EFL experts evaluate the feedback from LLM-as-a-tutor regarding quality and characteristics.
2310.05191_1927448_6	On the other hand, EFL learners assess their learning outcomes from interaction with LLM-as-a-tutor.
2310.05191_1927448_7	This approach lays the groundwork for developing LLMs-as-a-tutor tailored to the needs of EFL learners, advancing the effectiveness of writing education in this context.
2310.05563_1927820_0	  This paper presents Social data and knowledge collective intelligence platform for TRaining Ethical AI Models (STREAM) to address the challenge of aligning AI models with human moral values, and to provide ethics datasets and knowledge bases to help promote AI models "follow good advice as naturally as a stream follows its course".
2310.05853_1928110_5	Recognizing that users began treating our LLM-CA as a personal assistant or even a partner rather than just a recipe-reading tool, we propose several design considerations for future development.
2310.09617_1931874_4	Next, we conducted a qualitative user study examining the reactions and attitudes of practitioners toward ChatGPT as a visualization design assistant.
2310.11954_1934211_2	Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements.
2310.13021_1935278_5	We close with open discussions and questions that we believe necessitate a multi-disciplinary perspective -- cognitive scientists working in tandem with AI researchers and mathematicians -- as we move toward better mathematical AI systems which not only help us push the frontier of the mathematics, but also offer glimpses into how we as humans are even capable of such great cognitive feats.
2310.15127_1937384_2	In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction, or VLM description, and used as in-context prompt examples for LLM querying.
2310.17110_1939367_7	Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks.
2310.18628_1940885_4	Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution.
2311.00177_1943144_5	Our findings show that AI code completion enhanced students' productivity and efficiency by providing correct syntax suggestions, offering alternative solutions, and functioning as a coding tutor.
2311.06180_1949147_13	This study demonstrated the feasibility of using Generative AI as an assistant to generating feedback for student written responses with only a relatively small number of examples.
2311.06985_1949952_2	We ask whether a large language model (LLM) can serve as a more effective in-context teacher for itself or other LLMs, compared to humans.
2311.07052_1950019_5	In the context of large LMs (LLMs), previously viable approaches become much less meaningful, as it is an impossible triangle to distill an expected student from an optimal teacher student with small compute overhead.
2311.07838_1950805_2	Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM's output.
2311.09868_1952835_1	INTERVENOR prompts Large Language Models (LLMs) to play distinct roles during the code repair process, functioning as both a Code Learner and a Code Teacher.
2311.10054_1953021_2	For example, ChatGPT uses ``You are a helpful assistant'' as part of its default system prompt.
2311.11865_1954832_5	We hope our work can serve as a unified evaluation for video LLMs, and help expand more practical scenarios.
2311.14701_1957668_9	Results: The introduction of ChatGPT as a pedagogical tool led to increased student engagement and decreased teacher resistance, reflected in recognition at local science fairs.
2311.16161_1959128_5	The results underscore the methodology's potential as a promising paradigm for creating efficient AI coach models in various domains involving visual inputs.
2311.17978_1960945_0	  The context of this paper is the creation of large uniform archaeological datasets from heterogeneous published resources, such as find catalogues - with the help of AI and Big Data.
2312.00438_1962246_1	In this paper, we introduce Dolphins, a novel vision-language model architected to imbibe human-like abilities as a conversational driving assistant.
2312.01276_1963084_1	I discuss 14 methodological considerations that can help design more robust, generalizable studies evaluating the cognitive abilities of language-based AI systems, as well as to accurately interpret the results of these studies.
2312.01797_1963605_0	  This research focuses on how Large Language Models (LLMs) can help with (path) planning for mobile embodied agents such as robots, in a human-in-the-loop and interactive manner.
2312.03863_1965671_6	We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient LLMs research and inspire them to contribute to this important and exciting field.
2312.04724_1966532_0	  This paper presents CyberSecEval, a comprehensive benchmark developed to help bolster the cybersecurity of Large Language Models (LLMs) employed as coding assistants.
2312.06731_1968539_6	Through experiments and synthetic data analysis, our findings are: (1) current MLLMs can serve as robust data generators without assistance from GPT-4V; (2) MLLMs trained with task-specific datasets can surpass GPT-4V in generating complex instruction tuning data; (3) synthetic datasets enhance performance across various multimodal benchmarks and help mitigate model hallucinations.
2312.07343_1969151_1	This paper explores the potential of using ChatGPT, an LLM, as a virtual Teaching Assistant (TA) in an Introductory Programming Course.
2312.12006_1973814_1	This study aims to evaluate the potential of using a fine-tuned ChatGPT model as a personal medical assistant in the Arabic language.
2312.13103_1974911_1	This paper proposes one of the first clinical applications of multimodal large language models (LLMs) as an assistant for radiologists to check errors in their reports.
2312.15842_1977650_2	Our methodology involves training the smaller student model (Neural Network) using the prediction probabilities (as soft labels) of the LLM, which serves as a teacher model.
2312.17432_1979240_4	Furthermore, we identify five sub-types based on the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM as Text Decoder, LLM as Regressor, and LLM as Hidden Layer.
2401.00994_1980550_1	During virtual assistant development, some developers prefer to leverage the system message, also known as an initial prompt or custom prompt, for preconditioning purposes.
2401.01262_1980818_1	However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education.
2401.02147_1981703_0	  Large language models (LLMs) have demonstrated a powerful ability to answer various queries as a general-purpose assistant.
2401.02262_1981818_1	The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand.
2401.04543_1984099_0	  AI assistants such as Alexa, Google Assistant, and Siri, are making their way into the healthcare sector, offering a convenient way for users to access different healthcare services.
2401.06484_1986040_3	The simulation is done with the help of deep deterministic policy gradient (DDPG) as a deep reinforcement learning (DRL)-based algorithm.
2401.07964_1987520_2	The basic thrust of AI-as-exploration is that of creating and studying systems that can reveal candidate building blocks of intelligence that may differ from the forms of human and animal intelligence we are familiar with.
2401.14208_1993762_10	The combination of AI, XR, and an HDT-based solution will help to avoid technical errors and serve as a universal methodology in the development of personalized cardiology.
2401.15700_1995254_2	Artificial Intelligence (AI) can help financial institutions tailor relevant products and services to their customers as well as improve their credit risk management, compliance, and fraud detection capabilities by incorporating chatbots and face recognition systems.
2401.16454_1996008_3	In this regard, we introduce, Kaucus, a Knowledge-Augmented User Simulator framework, to outline a process of creating diverse user simulators, that can seamlessly exploit external knowledge as well as benefit downstream assistant model training.
2401.16587_1996141_0	  This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset.
2401.17217_1996771_3	We introduce GazeGPT as a new user interaction paradigm for contextual AI. GazeGPT uses eye tracking to help the LMM understand which object in the world-facing camera view a user is paying attention to.
2401.17459_1997013_9	We built and tested multiple versions of the AI agent using different off-the-shelf LLMs -- Google's Gemini-pro, as well as OpenAI's GPT-3.5-Turbo and GPT-4-Turbo (with both chat completion and assistant APIs).
2402.01051_1998690_8	We also show that GPT-4 can help in the labor-intensive task of evaluating the quality of the distilled models, using it as a zero-shot classifier.
2402.01536_1999175_0	  Large language models (LLMs) are now being used in a wide variety of contexts, including as creativity support tools (CSTs) intended to help their users come up with new ideas.
2402.02676_2000315_1	This paper uses ChatGPT as a research assistant to explore how far ChatGPT can replicate Quora question and answers, using data from the gig economy as an indicative case study.
2402.03630_2001269_0	  Large Language Models (LLMs) have achieved remarkable success in code completion, as evidenced by their essential roles in developing code assistant services such as Copilot.
2402.06264_2003903_1	Art appreciation, often perceived as an unfamiliar and challenging endeavor for most students, can be more accessible with a generative AI enabled conversation partner that provides tailored questions and encourages the audience to deeply appreciate artwork.
2402.06264_2003903_2	This study explores the application of multimodal large language models (MLLMs) in art appreciation education, with a focus on developing LLaVA-Docent, a model designed to serve as a personal tutor for art appreciation.
2402.08761_2006400_3	Our approach builds on small language models such as GPT2-XL in order to help avoid disclosing the original content to proprietary LLM's APIs, while also reducing the performance gap between small and large language models via algorithmic enhancement.
2402.09683_2007322_3	This paper first proposes a "positive friction" model that can help characterize how friction is currently beneficial in user and developer experiences with AI, diagnose the potential need for friction where it may not yet exist in these contexts, and inform how positive friction can be used to generate solutions, especially as advances in AI continue to be progress and new opportunities emerge.
2402.09773_2007412_3	Knowledge Distillation is well-suited for pruning, as the intact model can serve as an excellent teacher for pruned students.
2402.12366_2010005_4	Specifically, we show that simple supervised fine-tuning with GPT-4 as the teacher outperforms existing RLAIF pipelines.
2402.13516_2011155_3	Some recent efforts have explored introducing ReLU or its variants as the substitutive activation function to help LLMs achieve activation sparsity and inference acceleration, but few can simultaneously obtain high sparsity and comparable model performance.
2402.15100_2012739_2	In terms of actual use however, a great deal of software development still occurs in the for-profit/proprietary sphere, where the code under development is not, and never has been, in the public domain; thus, many developers, do their work, and use LLMs, in settings where the models may not be as familiar with the code under development.
2402.16361_2014000_5	The proposed LR-Drop can be regarded as a "self-distillation" framework, in which each sub-model generated by dropout is the other's "teacher" model and "student" model.
2402.16515_2014154_4	We construct a knowledge distillation model as the DP-based discriminator: teacher models, accessing private data, teaches students how to select private samples with calibrated noise to achieve DP.
2402.16664_2014303_5	We first develop a new multi-teacher CL framework that leverages a multimodal LLM as the additional teacher.
2403.00806_2017925_0	  With the large language model showing human-like logical reasoning and understanding ability, whether agents based on the large language model can simulate the interaction behavior of real users, so as to build a reliable virtual recommendation A/B test scene to help the application of recommendation research is an urgent, important and economic value problem.
2403.00871_2017990_3	This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%.
2403.00894_2018013_6	These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
2403.01538_2018657_2	This model is used in this study to help faculty with examining the impact that a disruptive new tool, such as ChatGPT, can pose for the learning environment.   
2403.01575_2018694_3	Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated.
2403.04260_2021379_6	The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g., LLaMA2-7B).
2403.10468_2027587_1	Despite its widespread adoption, the impact of ChatGPT as an assistant in collaborative coding remains largely unexplored.
2403.11128_2028247_3	However, such evaluation method can be misleading, as an AI assistant might fail in generating API calls from preceding human interaction in real cases.
2403.12014_2029133_2	Instead of directly employing LLMs as agents, can we use LLMs' reasoning capabilities to adaptively create training environments to help smaller RL agents learn useful skills that they are weak at?
2403.14694_2031813_5	To this end, we have conducted a detailed experiment in a representative subject of Computer Science such as Software Engineering, which has focused on evaluating the use of ChatGPT as an assistant in theory activities, exercises, and laboratory practices, assessing its potential use as a support tool for both students and teachers.
2403.15638_2032757_2	However, DP-SGD overestimates an adversary's capabilities in having white box access to the model and, as a result, causes longer training times and larger memory usage than SGD.
2403.16427_2033546_7	It learns to select hints from the constructed KB based on the task-specific feedback, where the hints can serve as guidance to help correct LLMs reasoning for better recommendations.
2403.17336_2034455_8	Building on the insights from the user study, we also developed a system using AI as the assistant to automate the process of jailbreak prompt generation.
2403.18721_2035840_7	Hence, despite the relatively lower response quality of PhysicsAssistant than GPT-4, it has shown potential for being used as a real-time lab assistant to provide timely responses and can offload teachers' labor to assist with repetitive tasks.
2403.19049_2036168_0	  Past work has sought to design AI ethics interventions--such as checklists or toolkits--to help practitioners design more ethical AI systems.
2404.02616_2040067_4	To tackle above two problems, we first take query concatenated with the query-based summary and the document summary without query as the input of topic relevance model, which can help model learn the relevance degree between query and the core topic of document.
2404.02798_2040249_7	Finally, we explore the potential of generative AI, such as ChatGPT, and propose a hybrid model that blends artificial intelligence with a collaborative, teacher-facilitated approach to personalized learning.
2404.03715_2041166_7	Moreover, DNO enjoys monotonic improvement across iterations that help it improve even over a strong teacher (such as GPT-4).
2404.11502_2048953_0	  In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications.
2404.13149_2050600_3	Prompting approaches of the pre-trained LLMs that elicit a model's reasoning process, such as chain-of-thought, may help to improve the trustworthiness of the generated responses.
2404.14082_2051533_7	Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.
2404.15310_2052761_11	Moreover, GPT-4 could deliver logical and concrete reasoning as potential teacher guidelines.
2404.16297_2053748_4	As a remedy, we propose some actionable recommendations to help improve applying LLM in Fuzzing and conduct preliminary evaluations on DBMS fuzzing.
2404.19256_2056707_2	This phenomenon can be viewed as a form of social compensation, where the AI makes decisions based not on predefined goals but on its human partner's deficiencies in relation to the team's performance objectives.
2405.00715_2057927_4	We introduced a new approach, DistillDirect, for performing on-policy reinforcement learning with Gemini 1.0 Pro as the teacher model.
2405.00995_2058207_5	Knowledge workers also expressed worries about Gen AI undermining trust in the relationship between instructor and student and discussed potential solutions, such as pedagogy readiness, to mitigate them.
2405.00995_2058207_6	Additionally, participants recognized Gen AI's potential to democratize knowledge by accelerating the learning process and act as an accessible research assistant.
2405.06800_2064012_0	  Large Language Models (LLMs) are becoming vital tools that help us solve and understand complex problems by acting as digital assistants.
2405.08828_2066040_2	The primary aim of this study is to contribute to the methodological discussion regarding the integration of AI tools, offering a practical guide to validation for using GPT as a collaborative research assistant.
2405.09186_2066398_0	  Language models (LMs) as conversational assistants recently became popular tools that help people accomplish a variety of tasks.
2405.09186_2066398_4	To help accelerate the development of LMs as conversational assistants, we propose a novel automatic evaluation task: HumanRankEval (HRE).
2405.13052_2070264_5	A chatbot mimicking ChatGPT's default behavior of acting as a helpful assistant led to markedly inferior personality inferences and lower user experience ratings but still captured psychologically meaningful information for some of the personality traits (mean r=.117, range=[-.004, .209]).
2405.13890_2071102_0	  As large language models (LLMs) become more powerful and ubiquitous, systems like ChatGPT are increasingly used by students to help them with writing tasks.
2405.13890_2071102_2	To that end, we plan to conduct a user study that will record the user writing process and present them with the opportunity to use ChatGPT as an AI assistant.
2405.14713_2071925_3	Our approach leverages Large Language Models (LLMs) and prompt engineering to generate tutor layout and contents based on high-level requirements provided by educators as inputs.
2405.15485_2072697_1	Motivated by the use of LLMs as a general scientific assistant, this paper assesses the domain knowledge of LLMs through its understanding of different mathematical skills required to solve problems.
2405.17821_2075033_4	Specifically, when a model hallucinates based on the original image, the transformed images -- altered in aspects such as orientation, scale, or color -- provide alternative viewpoints that help recalibrate the model's predictions.
2405.18137_2075349_6	In practice, the adversary could host the resulting full-precision model on an LLM community hub such as Hugging Face, exposing millions of users to the threat of deploying its malicious quantized version on their devices.
2405.19635_2076847_4	This approach leverages a larger LLM as a ''teacher'' to create guidance prompts, paired with a smaller ''student'' model to finalize responses.
2405.19635_2076847_9	When utilizing ChatGPT as teacher model and Llama2-70B as the student model, we can achieve 95.00% of ChatGPT's performance at 52% of the cost.
2405.19691_2076903_2	To help teachers address such risks, we conducted a two-phase iterative design process that comprises surveys, interviews, and prototype demonstration involving six EFL (English as a Foreign Language) teachers, who integrated ChatGPT into semester-long English essay writing classes.
2406.03079_2081367_6	Furthermore, our findings emphasize the importance of realizing that ChatGPT could be a valuable instructor even for novice fraudsters, as well as understanding and safely deploying complex language models, particularly in the context of cryptocurrency frauds.
2406.04236_2082524_4	We use a constraint-based formulation which views a visual question as having a set of visual or textual constraints that the model's generated answer must satisfy to be correct (e.g. What movie directed by the director in this photo has won a Golden Globe?).
2406.06560_2084848_11	As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: help identify undesirable annotator biases, understand model performance better, scale feedback to unseen data, or adapt models to individual user or group preferences.
2406.06575_2084863_1	Large language models (LLM) have the potential to help improve productivity by serving as conversational agents that effectively function as subject-matter experts.
2406.08680_2086968_0	  Automatically assessing classroom discussion quality is becoming increasingly feasible with the help of new NLP advancements such as large language models (LLMs).
2406.09288_2087576_5	In this paper, we introduce LMTX (Large language Model as Teacher for eXtreme classification), a novel framework that bridges the gap between these two approaches.
2406.09444_2087732_3	The proposed method takes the previous hidden layer as history and implements a layer-by-layer prediction of the teacher model autoregressively.
2406.10273_2088561_17	Therefore, experts can leverage LLMs as an effective complementing companion in risk analysis within a condensed timeframe.
2406.11858_2090146_5	The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.
2406.12665_2090953_8	Thus, CollabStory is a resource that could help propel an understanding as well as the development of new techniques to discern the use of multiple LLMs.
2406.12775_2091063_1	Motivated by this, we study how LLMs answer multi-hop queries such as "The spouse of the performer of Imagine is".
2406.13903_2092191_2	A novel aspect of the research involved using GPT-4 as a 'teacher' to create complex questions, with GPT-3.5 as the 'student' responding to these challenges.
2406.13972_2092260_3	To evaluate LLMs' realistic repair capabilities, (1) we introduce an extensive, non-crawled benchmark, referred to as TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code.
2406.15259_2093547_6	Since CoT is reported to perform poorly with small LLMs, we adopted a strategy in which a large LLM (GPT-4), acting as a Teacher, generates CoT-based instructions to fine-tune a small model, Llama-2-7B, which plays the role of a Student.
2407.00087_2098474_3	With advanced AI models (Teacher), such as GPT-4 and Claude 3 Opus, we can request various types of detailed feedback that are expensive for humans to provide.
2407.02048_2100435_8	The findings highlight the potential of AI and ChatGPT in particular, as an innovative cutting-edge educational tool that can both enhance the learning experience and help achieve the Sustainable Development Goals (SDGs) through education.
2407.02606_2100993_3	This method effectively combines edge devices and LLMs to help elderly people in their daily activities, such as reminding them to take pills or handling emergencies like falls.
2407.09709_2108096_2	For example, current attempts at designing general graph models either transform graph data into a language format for LLM-based prediction or still train a GNN model with LLM as an assistant.
2407.10362_2108749_3	Importantly, in contrast to previous scientific benchmarks, we expect that an AI system that can achieve consistently high scores on the more difficult LAB-Bench tasks would serve as a useful assistant for researchers in areas such as literature search and molecular cloning.
2407.11072_2109459_9	Our work highlights the need to secure LLM prompts against manipulation as well as rigorously auditing code generated with the help of LLMs.
2407.11360_2109747_3	It delves into the strategies humans are developing and refining to help mitigate risks such as bias, misinformation, and privacy breaches, that influence and shape Gen AI's evolution.
2407.12861_2111248_2	We pose the following research question: Given a text excerpt referencing a paper, could an LM act as a research assistant to correctly identify the referenced paper?
2407.12899_2111286_3	DreamStory consists of (1) an LLM acting as a story director and (2) an innovative Multi-Subject consistent Diffusion model (MSD) for generating consistent multi-subject across the images.
2407.13692_2112079_9	Our results suggest legibility training against small verifiers as a practical avenue for increasing legibility of large LLMs to humans, and thus could help with alignment of superhuman models.
2407.14769_2113156_1	Despite AI's potential as a valuable assistant, its role in complex medical data analysis often oversimplifies human-AI collaboration dynamics.
2407.16154_2114541_1	Knowledge Distillation (KD) has emerged as an effective strategy to improve the performance of a smaller LLM (i.e., the student model) by transferring knowledge from a high-performing LLM (i.e., the teacher model).
2407.19256_2117643_12	As LLMs evolve, they could become key tools in CCM to help improve patient outcomes and optimize healthcare delivery.
2407.19492_2117879_1	This paper proposes Heads Up eXperience (HUX), an AI system designed to bridge this gap, serving as a constant companion across the extended reality (XR) environments.
2407.19586_2117973_3	Our theory has a close analogy to a familiar insight in financial economics on the impossibility of an informationally efficient market [Grossman and Stiglitz (1980)]: If generative AI models can provide all the content humans need at low variable costs, then there is no incentive for humans to spend costly resources on content creation as they cannot profit from it.
2407.21202_2119589_0	  Nowadays, we delegate many of our decisions to Artificial Intelligence (AI) that acts either in solo or as a human companion in decisions made to support several sensitive domains, like healthcare, financial services and law enforcement.
2408.00946_2121127_4	From inception theories up to current methodologies, this paper provides an integrated view of dealing with better total uncertainty as well as complexities of uncertainty in AI that help us understand its meaning and value across different domains.
2408.03354_2123535_6	Various ways to enhance the model were uncovered, such as the need to help the LLM distinguish between stories and past events, as well as being careful with verb tenses in prompts.
2408.03506_2123687_0	  This paper presents a compute-efficient approach to pre-training a Language Model-the "1.5-Pints"-in only 9 days, while outperforming state-of-the-art models as an instruction-following assistant.
2408.04112_2124293_0	  Large language models (LLMs) can help writers build story worlds by generating world elements, such as factions, characters, and locations.
2408.04645_2124826_0	  This study evaluates the performance of Large Language Models (LLMs) as an Artificial Intelligence-based tutor for a university course.
2408.04775_2124956_2	We employ a student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as student models and GPT-4o as the teacher, to dynamically select between prompt refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.
2408.05534_2125715_6	To help decide when and how to use LLMs in human-subject studies, we propose model-model agreement as a predictor of whether a given task is suitable for LLMs at all, and model confidence as a means to select specific samples where LLMs can safely replace human annotators.
2408.08321_2128502_2	We explored the feasibility of utilizing ChatGPT as a virtual assistant to provide navigation directions.
2408.10947_2131128_4	Therefore, our research introduces a benchmark to evaluate the questioning capability in education as a teacher of LLMs through evaluating their generated educational questions, utilizing Anderson and Krathwohl's taxonomy across general, monodisciplinary, and interdisciplinary domains.
2408.10947_2131128_7	Our results indicate that GPT-4 demonstrates significant potential in teaching general, humanities, and science courses; Claude2 appears more apt as an interdisciplinary teacher.
2408.11043_2131224_3	The novelty of this work lies in strategizing the research inquiry as one that is augmented by an LLM that serves as a novice research assistant.
2408.14512_2134693_7	Experiments show that our graph token embeddings help the LLM predictor achieve state-of-the-art performance on unseen datasets and tasks compared to other methods using LLMs as predictors.
2408.16235_2136416_2	We first design a latent mean-teacher framework that integrates both labeled and unlabeled data, as well as their latent vectors, into model training.
2408.16984_2137165_5	Finally, we argue that these limitations motivate a reframing of the targets of AI alignment: Instead of alignment with the preferences of a human user, developer, or humanity-writ-large, AI systems should be aligned with normative standards appropriate to their social roles, such as the role of a general-purpose assistant.
2408.17097_2137278_4	Our approach employs an LLM as a ''teacher'' model through zero-shot prompting to generate teaching CoT rationales, followed by a CoT ''student'' model that is fine-tuned by the generated teaching data for learning to reason about performance declines.
2409.00558_2138190_3	Specifically, given an input textual prompt, our scheme consists of three stages: 1) We leverage LLM as the director to first decompose the complex query into several sub-prompts that indicate individual concepts within the video~(\textit{e.g.}, scene, objects, motions), then we let LLM to invoke pre-trained expert models to obtain corresponding 3D representations of concepts.
2409.04056_2141688_3	Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM.
2409.09047_2146679_0	  The effect of large language models (LLMs) in education is debated: Previous research shows that LLMs can help as well as hurt learning.
2409.11654_2149286_6	We envision a future where AI Virtual Cells help identify new drug targets, predict cellular responses to perturbations, as well as scale hypothesis exploration.
2409.12586_2150218_5	These important tokens are then provided as rationales to a student model, aiming to distill the knowledge of the teacher model.
2409.13099_2150731_0	  As AI-generated summaries proliferate, how can we help people understand the veracity of those summaries?
2409.13343_2150975_4	Developers generally express positive attitudes towards AI, viewing it as an efficiency-enhancing assistant rather than a job replacement threat.
2409.14206_2151838_4	Therefore, we propose CORE as an assistant that combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for a Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements to ensure an intuitive understanding of procedure steps, reliability, offline availability, and flexibility in terms of response style and procedure updates.
2409.14924_2152556_9	This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications.
2409.17027_2154659_3	Although this story, generated by a large language model, is captivating, one may wonder -- how would the story have unfolded if the model had chosen "Captain Maeve" as the protagonist instead?
2409.17434_2155066_5	It also advises public sector developers to classify their code as "Open" to use Gen-AI Coding Assistant tools on the Cloud like GitHub Copilot and to consider self-hosted tools like Codeium or Code Llama for confidential code to leverage technology efficiently within the public sector framework.
2409.17946_2155578_6	Specifically, we poison small-scale language models through full-parameter fine-tuning to serve as the teacher model.
2409.18999_2156631_6	Using data augmented by GPT-4 Omni, which involves generating new training examples and transforming existing data, we significantly improved the accuracy of FinBERT, preparing it to serve as a teacher model.
2410.00163_2158364_0	  This study evaluates the performance of large language models (LLMs) as medical agents in Portuguese, aiming to develop a reliable and relevant virtual assistant for healthcare professionals.
2410.03017_2161218_3	We introduce Tutor CoPilot, a novel Human-AI approach that leverages a model of expert thinking to provide expert-like guidance to tutors as they tutor.
2410.03032_2161233_7	Users perceived CounterQuill as a writing partner and thus were more willing to post the co-written counterspeech online compared to the one written with ChatGPT.
2410.03083_2161284_2	Specifically, we formulate the proposed term of effective training tokens to be a combination of two readily-computed indicators of text: (i) text diversity and (ii) syntheticity as measured by a teacher model.
2410.07122_2165323_5	Specifically, the large cloud model acts as a teacher, guiding and promoting the learning of the end model, which significantly reduces the end model's reliance on large-scale, high-quality data and thereby addresses the data bottleneck in traditional end model training, offering a new paradigm for the rapid deployment of industry applications.
2410.07397_2165598_7	We suggest that this principle can help make human-AI collaboration more fruitful, as well as shed light on how humans make scientific modeling choices.
2410.07461_2165662_4	Besides the already intriguing observation that the choice of calibration data significantly impacts the performance of pruned LLMs, our results also uncover several subtle and often unexpected findings, summarized as follows: (1) C4 is not the optimal choice for LLM pruning, even among commonly used pre-training datasets; (2) arithmetic datasets, when used as calibration data, performs on par or even better than pre-training datasets; (3) pruning with downstream datasets does not necessarily help the corresponding downstream task, compared to pre-training data; (4) ICL is widely beneficial to all data categories, whereas CoT is only useful on certain tasks.
2410.09268_2167469_3	While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality.
2410.09318_2167519_0	  While Large language model (LLM)-based programming assistants such as CoPilot and ChatGPT can help improve the productivity of professional software developers, they can also facilitate cheating in introductory computer programming courses.
2410.09343_2167544_4	ELICIT serves as a plug-and-play performance booster to enable adaptive elicitation of model capabilities.
2410.09937_2168138_3	Such research is critical to help ensure current law students are positioned to fully exploit this technology as they embark on their legal careers but to also assist existing legal firms to better leverage their AI skillset both operationally and in helping to formulate future legal frameworks for regulating this technology across industries.
2410.11863_2170064_1	The assistant allows a user to specify the operations in natural language, attempting to generate a Python script for the desired operations, prompting the LLM to revise the script as needed until it executes correctly.
2410.11864_2170065_1	As a human-AI team, we together advocate for a shift toward viewing AI as a learning partner, akin to a student who learns from interactions with humans.
2410.11864_2170065_4	By reframing AI as a dynamic partner, a model emerges in which AI systems develop alongside humans, learning from human interactions and feedback loops including reflections on team conversations.
2410.13648_2171849_7	We further show that we can help models do better at (b) and (c) via interventions such as reminding the model of its earlier mental state answer and mental-state-specific chain-of-thought prompting, raising the action prediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment accuracies (e.g., from 15.3% to 94.7% in GPT-4o).
2410.14166_2172367_5	Compared with strategies such as finetuning and in-context learning that are commonly adopted to enhance performance on new or challenging tasks, we show that engaging reasoning is the most robust and efficient way to help LLMs better perceive tasks with more accurate responses.   
2410.14252_2172453_1	These intelligent home assistant frameworks, such as those based on high-performance LLMs like GPT-4, have greatly expanded their functional range and application scenarios by computing on the cloud, enriching user experience and diversification.
2410.14395_2172596_1	Those include using AI as a language tutor, creating learning materials, or assessing learner output.
2410.14425_2172626_4	Specifically, we first train a small-scale language model through full-parameter fine-tuning to serve as the clean teacher model.
2410.14609_2172810_9	Additionally, through the relaxation of the objective, we propose a multi-teacher distillation, using multiple LLMs as teachers, yielding additional gains, and outperforming the teachers themselves in in-domain experiments.
2410.16215_2174416_3	We first conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a 1.9B parameter student LLM, validating the effectiveness of PD.
2410.16215_2174416_5	We conduct extensive experiments to explore the design space of pre-training distillation and find better configurations and interesting conclusions, such as larger student LLMs generally benefiting more from pre-training distillation, while a larger teacher LLM does not necessarily guarantee better results.
2410.16229_2174430_9	CONAN can also be used as an assistant for Large Language Models (LLMs), providing LLMs with external knowledge in shorter code document lengths to improve their effectiveness on various code tasks.
2410.21819_2180020_5	To explore the causes, we hypothesize that LLMs may favor outputs that are more familiar to them, as indicated by lower perplexity.
2410.24148_2182349_4	In this paper, we propose to utilize vision language models (VLMs) such as generative pre-trained transformer (GPT), GEMINI, large language and vision assistant (LLAVA), PaliGemma, and Microsoft Florence2 to recognize facial attributes such as race, gender, age, and emotion from images with human faces.
2411.00780_2183207_6	Based on our findings, we envision MLMs as a teacher for knowledge distillation, a machine labeler, and a part of the ensembled and tiered seasonality detection system, which can empower ads ranking systems with enriched seasonal information.
2411.02725_2185152_4	Key insights for LLM tutor use are as follows: NNES students signed up for the LLM tutor at a similar rate to native English speakers (NES); NNES students used the system at a lower rate than NES students -- to a small effect; NNES students asked significantly more questions in languages other than English compared to NES students, with many of the questions being multilingual by incorporating English programming keywords.
2411.03495_2185922_3	We present here the study of several dimensions: 1) identifying error patterns made by simulated students on secondary-level math exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating their effectiveness in generating hints that enable simulated students to self-correct; and 3) testing the best-performing prompts, based on their ability to produce relevant hints and facilitate error correction, with Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with GPT-4o.
2411.03495_2185922_6	Interestingly, Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.
2411.05681_2188108_1	To fully achieve the potential of MaaS, a range of AI (including machine learning and data mining) algorithms are needed to learn personal requirements and needs, to optimise journey planning of each traveller and all travellers as a whole, to help transport service operators and relevant governmental bodies to operate and plan their services, and to detect and prevent cyber attacks from various threat actors including dishonest and malicious travellers and transport operators.
2411.05828_2188255_2	Focusing on the management of multiparty AI conversations, this work introduces new concepts such as the Convener Agent, Floor-Shared Conversational Space, Floor Manager, Multi-Conversant Support, and mechanisms for handling Interruptions and Uninvited Agents.
2411.07820_2190247_3	Moreover, to enhance flexibility and reduce computational costs, we propose a trainable scheme for our pipeline that utilizes a smaller, tunable model as the query optimizer, which is refined through knowledge distillation from a larger teacher model.
2411.08469_2190896_4	This approach strives to help AI systems deliver results that are as accurate, explainable, and trustworthy as possible, aligning with regulatory expectations for transparency and accountability.
2411.09261_2191688_8	Our findings reveal that LLM-generated test suites can correctly identify most valid solutions, and for most problems are at least as comprehensive as the instructor test suites.
2411.09916_2192343_4	Therefore, we conducted an observational study with 22 participants using ChatGPT as a coding assistant in a non-trivial SE task to understand the practices, challenges, and opportunities for using LLMs for SE tasks.
2411.10718_2193145_0	  This study examines the transformative potential of Generative AI (GenAI) in teacher education within developing countries, focusing on Ghana, where challenges such as limited pedagogical modeling, performance-based assessments, and practitioner-expertise gaps hinder progress.
2411.11856_2194283_2	Large Language Models (LLMs) are emerging as a potential tool to help generate fully functioning HDL code, but most works have focused on generation in the single-shot capacity: i.e., run and evaluate, a process that does not leverage debugging and, as such, does not adequately reflect a realistic development process.
2411.12761_2195188_4	AI as a research tool (ART), AI as a research assistant (ARA), and AI as a research participant (ARP).
2411.13226_2195653_1	We focus on a specific privacy risk where LLMs may help identify the authorship of anonymous texts, which challenges the effectiveness of anonymity in real-world systems such as anonymous peer review systems.
2411.13800_2196227_0	  Use of large language models such as ChatGPT (GPT-4) for mental health support has grown rapidly, emerging as a promising route to assess and help people with mood disorders, like depression.
2411.16707_2199134_1	It positions AI as a versatile research assistant rather than a mere problem-solving tool.
2411.19638_2202065_2	The framework employs a Generative Pretrained Transformer (GPT) model as the teacher model to develop an IPTC Media Topic training dataset through automatic annotation of news articles in Slovenian, Croatian, Greek, and Catalan.
2412.01072_2203450_6	To address the gap, we investigate the use of federated learning as a privacy-preserving approach that enables private entities to fine-tune LLMs on proprietary and decentralized data, facilitating the collaboration between clients to fully utilize their data to help enhance software development and maintenance.
2412.01282_2203660_1	Meanwhile, the great need for capable aritificial intelligence on mobile devices also arises, such as the AI assistant software.
2412.01353_2203731_1	Leveraging this data, AI-based systems can be developed that help in assessing the mental health of individuals, such as suicide risk.
2412.01617_2203995_3	To explore this, we analysed user interactions with ChatGPT, particularly those outside of its marketed use as task-oriented assistant.
2412.06040_2208418_5	In Study 2 (N = 684), we tested whether spillover persisted when the agent was individuated with a name and described as an AI or human, rather than specifically as a chatbot or personal assistant.
2412.06603_2208981_0	  AI assistants are being created to help software engineers conduct a variety of coding-related tasks, such as writing, documenting, and testing code.
2412.07031_2209409_6	As long as these steps are taken, LLM outputs can be used in empirical research with the familiar econometric guarantees we desire.
2412.08054_2210432_8	Apart from that, an incredible Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU) module is designed and we incorporate the aggregated global knowledge compendium as a teacher to teach LLM agents the usage of tools.
2412.09173_2211551_5	By virtue of the decidable nature of formats, we propose to Reinforce Format Faithfulness (ReFF) to help LLMs generate formatted output as instructed without compromising general quality.
2412.09416_2211794_4	We assess reliability of the popular Prometheus2 and Llama-3.1-8B LLMs as evaluators and analyze each tutor's pedagogical abilities, highlighting which LLMs are good tutors and which ones are more suitable as question-answering systems.
2412.11300_2213678_1	Previous research in science education has highlighted the potential for generative AI in various education-related areas, including generating valuable discussion material, solving physics problems, and acting as a tutor.
2412.11300_2213678_7	As such, our findings show that generative AI tools may handle some questions and problems and thus demonstrate their potential to help distribute teachers' workload more equitably during laboratory sessions.
2412.11536_2213914_6	The central element of this work is the use of a teacher model - the LLM as a judge - to generate training data.
2412.12107_2214485_4	The competencies follow a logical progression and serve as a roadmap for individuals seeking to get familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.
2412.12117_2214495_2	We review the pros and cons of AI in the writing process, emphasizing process-based assessments, creativity-driven tasks, and AI as a supplement to teacher guidance.
2412.15047_2217425_4	Despite its imperfections, users responded positively to the model and highlighted its use as a tool that can help them catch mistakes, inform them of risks they were unaware of, and encourage self-reflection.
2412.15896_2218274_7	Furthermore, we show that the LLM is able to help resolve disagreements among human experts, especially in tasks such as identifying cases of negative targeting.
2412.19819_2222197_3	This limitation impedes the practical application of chip LLMs, including serving as assistant chatbots for hardware design engineers.
2501.00031_2223615_3	We leveraged state-of-the-art LLMs (Gemini and OpenAI models) and medical ontologies (RxNorm and SNOMED) as teacher labelers for medication, disease, and symptom extraction.
2501.00359_2223943_1	To explore expression of local narratives, we conducted a workshop with 20 participants utilizing Generative AI (GenAI) to support visual narratives, asking them to use Stable Diffusion to create images of familiar cultural heritage sites, as well as images of unfamiliar ones for comparison.
2501.00953_2224537_5	Primary focus is on the part of the system that makes decisions, known as the dialogue manager.
2501.02229_2225813_4	Having fine-tuned the LLMs specifically for smart contract code classification should help in getting better results when detecting several types of well-known vulnerabilities, such as Reentrancy, Integer Overflow, Timestamp Dependency and Dangerous Delegatecall.
2501.03923_2227507_3	In this context, explainable AI (XAI) emerges as a solution that could help to understand disease-associated mechanisms when combined with efficient NN models.
2501.05224_2228808_2	To help establish best practices for employing LLMs in zero-shot settings, we also assess the ability of LLMs as judges, finding that they are able to replicate the preferences of human judges.
2501.05455_2229039_5	For example, can concepts such as common mode failures from downstream safety be used to help assess the strength of AI guardrails?
2501.06607_2230191_1	This paper describes the AI Drawing Partner, which is a co-creative drawing agent that also serves as a research platform to model co-creation.
2501.07919_2231503_0	  Home Energy Management Systems (HEMSs) help households tailor their electricity usage based on power system signals such as energy prices.
2501.08243_2231827_6	Evaluations of our multi-agent system with the help of practitioners as well as using automated checks demonstrate enhanced accuracy, responsiveness, and effectiveness over non-agentic approaches across complex workflows.
2501.09171_2232755_0	  Many believe that use of generative AI as a private tutor has the potential to shrink access and achievement gaps between students and schools with abundant resources versus those with fewer resources.
2501.10551_2234135_6	We found that factors such as gender, race, and perceived self-efficacy can help predict different AI usage patterns.
2501.11935_2235519_2	Since the majority of students' experiences in online self-learning have come through using search engines such as Google, evaluating AI tools in this context can help us address these gaps.
2501.12697_2236281_1	Existing research in ZS-VQA has proposed to leverage knowledge graphs or large language models (LLMs), respectively, as external information sources to help VQA model comprehend images and questions.
2501.14877_2238461_7	We also find that synthetic QAs, though imperfect, can yield similar model rankings as teacher-written QAs.
2501.15247_2238831_6	While generative AI shows potential as a personalized tutor, further evaluation is needed to assess its effectiveness.
2501.16548_2240132_0	  As the climate crisis deepens, artificial intelligence (AI) has emerged as a contested force: some champion its potential to advance renewable energy, materials discovery, and large-scale emissions monitoring, while others underscore its growing carbon footprint, water consumption, and material resource demands.
2501.18948_2242532_3	Meanwhile, Human-Centered AI (HCAI), which envisions AI as a collaborator augmenting human capabilities and aligning with societal values, remains a fugitive from the mainstream narrative.
2501.19361_2242945_1	Although these LLMs are marketed as helpful creative assistants, several works have shown that using an LLM as a creative partner results in a narrower set of creative outputs.
2501.19377_2242961_0	  In this work, we present and evaluate SELMA, a Speech-Enabled Language Model for virtual Assistant interactions that integrates audio and text as inputs to a Large Language Model (LLM).
2502.00012_2243003_2	Complexity theory can help illuminate the features of AI that pose central challenges for policymakers, such as feedback loops induced by training AI models on synthetic data and the interconnectedness between AI systems and critical infrastructure.
2502.01493_2244484_4	These attributes foster balanced interaction, enabling AI to act as a responsive partner, evolving with users over time.
2502.01671_2244662_4	We include detailed descriptions of our LCA to act as a tutorial, road map, and inspiration for other computer engineers to perform similar LCAs to help us all understand the environmental impacts of our chips and of AI.   
2502.03129_2246120_3	Specifically, a teacher LLM is employed to generate TEN rationales as supervision data, which are then used to teach and fine-tune a student LLM.
2502.04390_2247381_3	We implement two key components inspired by human cognition: (1) Dissonance and Familiarity Awareness, analyzing model behavior to classify information as novel, familiar, or dissonant; and (2) Targeted Network Updates, which track neural activity to identify frequently used (stubborn) and rarely used (plastic) neurons.
2502.04964_2247955_3	Our investigation reveals distinctive characteristics of LLMs as probabilistic models, which help to explain why these UQ methods underperform in certain tasks.
2502.09532_2252523_7	Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM.
2502.12102_2255093_4	As AI agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-AI interactions.
2502.12134_2255125_4	Specifically, we employ a lightweight assistant model to generate instance-specific soft thought tokens speculatively as the initial chain of thoughts, which are then mapped into the LLM's representation space via a projection module.
2502.14080_2257071_6	It uses zero-shot sentiment analysis with LLMs and prompt engineering, achieving 86\% accuracy in classifying student-teacher interactions as positive or negative.
2502.14865_2257856_6	Our goal is to establish AI as a reliable partner in preserving cultural heritage, ensuring that technological advancements contribute meaningfully to historical discovery.
2502.17730_2260721_3	To investigate this, we conducted randomized controlled trials (RCTs) where teams of three participants worked together under a randomly assigned manager - either human or AI - who was presented as male, female, or gender-neutral.
2502.17855_2260846_2	Participants envisioned AI playing multidimensional roles, such as an operational assistant, personal trainer, group coach, and evaluator, as solutions to address unique instructional and operational challenges in K-12 PE classes.
2502.18357_2261348_1	In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s).
2502.18476_2261467_2	However, with the help of automated tools and models such as OpenAI Codex and GPT-4, many aspects of the Software Development Life Cycle (SDLC) have been made possible.
2502.19557_2262548_2	Extracting reliable reward signals directly from teacher models is challenging, as LLMs are optimized for generation rather than evaluation, often resulting in biased or inconsistent assessments.
2502.20541_2263532_1	The system leverages the capabilities of a sophisticated language model to serve as an intelligent research assistant, enhancing the efficiency and comprehensiveness of literature reviews in the nanotechnology domain.
2503.00144_2264456_3	To explore user preferences for AI-supported programming learning tools, we conducted a participatory design study with 15 undergraduate novice programmers and 10 instructors to gather insights on their desired help features and control preferences, as well as a follow-up survey with 172 introductory programming students.   
2503.00596_2264908_1	This paper proposes a novel backdoor threat attacking the LLM-as-a-Judge evaluation regime, where the adversary controls both the candidate and evaluator model.
2503.01704_2266016_1	Edge Computing (EC) as a physically closer computing resource to the end users can help to reduce the communication delay for serving end users' tasks for LLM-dependent services.
2503.02099_2266411_4	Our findings indicate that LLMs can effectively function as educational analysts, turning diverse data into teacher-friendly insights that are well-received by educators.
2503.02250_2266562_4	In this paper, through a synthesis of related literature and extensive examples of existing AI systems intended to mimic humans, we develop a conceptual framework to help foreground key axes of design variations and provide analytical scaffolding to foster greater recognition of the design choices available to developers, as well as the possible ethical implications these choices might have.
2503.04743_2269055_7	I conclude with why building a system safety discipline can help us overcome limitations in the European AI Act, as well as how the discipline can help shape sustainable investments into Public Interest AI.
2503.05839_2270151_6	The system's architecture includes key components such as a bootloader, boot manager, and bootloader updater to facilitate seamless firmware updates.
2503.09838_2274150_0	  We present BioSpark, a system for analogical innovation designed to act as a creativity partner in reducing the cognitive effort in finding, mapping, and creatively adapting diverse inspirations.
2503.13440_2277752_6	Subsequently, we employ a single-stage distillation process, using the pre-trained VLM as the teacher model to transfer knowledge to the MaTVLM, further enhancing convergence speed and performance.
2503.13533_2277845_0	  As artificial intelligence (AI) technology becomes increasingly prevalent in the filed of education, there is a growing need for mathematics teacher education students (MTES) to demonstrate proficiency in the integration of AI with the technological pedagogical content knowledge (AI-TPACK).
2503.16071_2280383_0	  Memory, additional information beyond the training of large language models (LLMs), is crucial to various real-world applications, such as personal assistant.
2503.16536_2280848_1	The system transforms narrative elements-such as protagonist goals, antagonist challenges, and environmental settings-into game levels with both spatial and gameplay constraints.
2503.17994_2282306_7	Specifically, on the step-level, we decompose the generation task into decision steps with powerful prompt engineering and inspire LLM to serve as instructor for architecture search based on its internal knowledge.
2503.19607_2283919_2	As Minecraft has an extensive player base and a rich ecosystem of pre-built AI agents, we hope this contribution can help to facilitate research quickly in the design of new collaborative agents and in understanding different human factors within HMT.
2503.21735_2286047_10	Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation.
2503.22040_2286352_2	We propose a framework for social scientists to incorporate LLMs into text annotation, either as the primary coding decision-maker or as a coding assistant.
2504.00463_2289166_0	  Existing state-of-the-art AI-Generated image detection methods mostly consider extracting low-level information from RGB images to help improve the generalization of AI-Generated image detection, such as noise patterns.
2504.00907_2289610_8	To the best of our knowledge, this is the first demonstration of adapting MLLMs as VLA agents that can act and ask for help using LLM-generated rewards with online RL.
2504.03105_2291808_0	  As AI takes on increasingly complex roles in human-computer interaction, fundamental questions arise: how can HCI help maintain the user as the primary agent while augment human cognition and intelligence?
2504.03966_2292669_8	Despite these benefits and positive perception of AI tools, concerns emerged regarding over-reliance on AI, accuracy limitations, and ethical issues such as plagiarism and reduced student-teacher interaction.
2504.04253_2292956_6	Finally, we present our vision for a user-centered system that leverages GenAI not only for automation but as an intelligent collaborator in visual data exploration.
2504.05333_2294036_9	The expected utility assessment approach presented here is intended to help AI developers and deployment decision makers to navigate the subtle but substantial impact of counterfactuals so as to better ensure that beneficial AI capabilities are used.
2504.08670_2297373_4	These strategies -- long refined in Disney animation -- function as multimodal scaffolds for attention, understanding, and emotional attunement, thereby forming a structured design grammar familiar to children and transferable to AI interface design.
2504.09283_2297986_9	We argue that AI agent interfaces, such as software IDEs like Cursor and Windsurf, should provide affordances for impact analysis and help users validate AI retrieval independently from generation.
2504.09720_2298423_0	  This study explores NotebookLM, a Google Gemini powered AI platform that integrates Retrieval Augmented Generation (RAG), as a collaborative physics tutor, an area of research that is developing quickly.
2504.09720_2298423_1	In our implementation, NotebookLM was configured as an AI physics collaborative tutor to support students in solving conceptually oriented physics problems using a collaborative, Socratic approach.
2504.09720_2298423_2	When deployed as a collaborative tutor, the system restricts student interaction to a chat only interface, promoting controlled and guided engagement.
2504.10101_2298804_0	  The dominant metaphor of LLMs-as-minds leads to misleading conceptions of machine agency and is limited in its ability to help both users and developers build the right degree of trust and understanding for outputs from LLMs.
2504.11146_2299849_4	As students completed three code writing and debugging tasks, they had the option to receive guardrailed help or use a "See Solution" feature which disabled the guardrails and generated a verbatim response from the underlying model.
2504.11496_2300199_0	  This paper introduces IEA-plugin, a novel AI agent-based reasoning module developed as a new front-end for the Intelligent Engineering Assistant (IEA).
2504.13471_2302174_5	In the first stage, we construct an optimal performance prototype system by transforming complex tasks into a function call-based LLM-driven pipeline, which serves as a teacher model to generate high-quality data.
2504.13700_2302403_4	Informed by the findings, we introduce visual prompts as a complementary input modality to text prompts, which help clarify user intent and improve LLMs' interpretation abilities.
2504.13882_2302585_3	Using a public dataset from the Teacher-Student Chatroom Corpus, our system classifies each tutoring strategy as either being employed as desired or undesired.
2504.13903_2302606_4	Experienced developers are more likely to perceive AI as a junior colleague, a content generator, or assign it no role, whereas less experienced developers primarily view AI as a teacher.
2504.14928_2303631_0	  Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions.
2504.17028_2305731_10	Consequently, this paper and its corresponding GitHub materials may serve as an initial guide for other university research groups and courses related to machine learning, climate science, and data science to develop research and education programs on AI weather forecasting, and hence help democratize the AI NWP in the digital economy.
2504.18340_2307043_3	Here, we present Chemma, a fully fine-tuned LLM with 1.28 million pairs of Q&A about reactions, as an assistant to accelerate organic chemistry synthesis.
2504.19275_2307978_2	By employing a mixed-method approach combining theoretical frameworks (auteur theory, human-technology relations) and case studies (The Safe Zone, Fast & Furious 7, The Brutalist), the research reveals that positioning AI as an "embodiment tool" rather than an independent "alterity partner" preserves human authorship and artistic integrity.
2504.21769_2310472_5	Leveraging the emergent capabilities of Large Language Models (LLMs) in reasoning and generating human-like responses, we introduce LLM-iTeach -- a novel IIL framework that utilizes an LLM as an interactive teacher to enhance agent performance while alleviating the dependence on human resources.
2504.21769_2310472_8	We evaluate LLM-iTeach against baseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a state-of-the-art IIL method using a human teacher, on various robotic manipulation tasks.
2505.00831_2311391_2	We present SmallPlan -- a novel framework leveraging LLMs as teacher models to train lightweight Small Language Models (SLMs) for high-level path planning tasks.
2505.01563_2312123_6	At each step of problem-solving, AI agents are asked what they would do as a tutor or as a learner.
2505.01681_2312241_2	By treating a large language model (LLM), DeepSeek-R1, as an equal partner, we establish a closed-loop, iterative workflow in which the LLM proposes, refines, and reasons about near-wall turbulence models under adverse pressure gradients (APGs), system rotation, and surface roughness.
2505.02975_2313535_3	This paper examines these dynamics and advocates for participatory design approaches that position older adults as active decision makers in shaping AI assistant functionality.
2505.03163_2313723_4	Findings indicate that while LLMs could enhance personalized learning and reduce teacher workload, barriers such as poor connectivity, lack of AI training, and parental skepticism hinder adoption.
2505.06120_2316680_1	As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange.
2505.06428_2316988_1	However, current explanation mechanisms primarily help AI researchers and engineers in debugging and monitoring their AI systems, and may not address the specific questions of end-users, such as passengers, about AVs in various scenarios.
2505.06803_2317363_3	To reduce this gap, we introduce a cross-modal distillation framework, where an LLM in one modality serves as the teacher and another as the student, with knowledge transfer in sound classes predicted as more challenging to the student by a heuristic model.
2505.07105_2317665_4	To help the student model learn more effectively from the teacher model, we first train the teacher LLM as a classification model with soft targets.
2505.07105_2317665_6	Instead of using the same training data as the teacher model, we significantly expand the student model dataset by generating unlabeled data and labeling it with the teacher model predictions.
2505.08083_2318643_5	This exploration of teacher-AI collaboration highlights how LLM can help teachers include CRP components into their instructional practices efficiently, especially in global priorities for future-ready education, such as AI literacy.
2505.09334_2319894_7	We developed and trained a lightweight student model, Distilled Custom Student Network (DCSNet) using ResNet50 as the teacher.
2505.09970_2320530_1	Recent LLMs, such as DeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through the generation of ample intermediate tokens, which help build a strong premise before producing the final output tokens.
astro-ph/0201481_2336328_7	The system 6.6454.5 is found to contain a 4.97-day Cepheid, which cannot be definitely classified as Type I or Type II, with an unexpectedly brighter companion.