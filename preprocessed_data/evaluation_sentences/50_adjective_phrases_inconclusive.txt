4_acl_7_46407_0	Language models (LMs) are vulnerable to exploitation for adversarial misuse.	Language models (LMs)	Language models (LMs)	model	vulnerable
4_arx_2005.06620_1286415_1	While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue.	these autonomous and intelligent systems	systems	system	autonomous and intelligent
4_arx_2408.08878_2129059_6	Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI.	responsible AI	AI	AI	responsible
4_arx_2402.05827_2003466_5	RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations?	communicative AI	AI	AI	communicative
4_arx_1904.13086_1118126_10	The results demonstrate the descriptive value of the ResQu model to predict behavior and perceptions of responsibility by considering the characteristics of the human, the intelligent system, the environment and some systematic behavioral biases.	the intelligent system	system	system	intelligent
4_acl_45_49661_1	We show that an “attentive” RNN-LM (with 11M parameters) achieves a better perplexity than larger RNN-LMs (with 66M parameters) and achieves performance comparable to an ensemble of 10 similar sized RNN-LMs.	an "attentive" RNN-LM	RNN-LM	LM	attentive
4_acl_1_30970_8	Moreover, our error analysis shows that language models are generally less sensitive to the changes in claim length and source than the SVM model.	language models	models	model	sensitive
4_acl_159_43725_0	Modern large language models are sensitive to prompts, and another synonymous expression or a typo may lead to unexpected results for the model.	Modern large language models	large language models	model	sensitive
4_acl_335_27056_3	We find that LMs are highly sensitive to epistemic markers in prompts, with accuracies varying more than 80%.	LMs	LMs	LM	sensitive
4_arx_2411.10954_2193381_5	Our findings show that LLMs are sensitive in handling both multilingual and dialectal variations.	LLMs	LLMs	LLM	sensitive
4_arx_2410.11009_2169210_3	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of an AI writing model.	a smart reply system	reply system	system	smart
4_arx_2408.01168_2121349_3	The paper argues that current LLM architectures are inherently untrustworthy due to their reliance on correlations of sequential patterns of word embedding vectors.	current LLM architectures	LLM architectures	LLM architectures	untrustworthy
4_acl_12_46472_3	Analysis shows that LLMs are sensitive to subtle contextual changes and often rely on surface-level cues.	LLMs	LLMs	LLM	sensitive
4_arx_2405.16310_2073522_7	These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.	untrustworthy LLMs	LLMs	LLM	untrustworthy
4_arx_2302.12601_1797535_0	  Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description.	creative AI	AI	AI	creative
4_arx_1906.03595_1135781_6	This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.	collaborative creative AI	AI	AI	collaborative creative
4_acl_128_54380_3	Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.	the competitive word-level model	word-level model	model	competitive
4_arx_2001.07641_1233054_2	However, given, e.g., economic incentives to create dishonest AI, to what extent can we trust explanations?	dishonest AI	AI	AI	dishonest
4_arx_2502.18676_2261667_3	We outline the conceptual foundations of Thoughtful AI, illustrate its potential through example projects, and envision how this paradigm can transform human-AI interaction in the future.	  Thoughtful AI	  AI	AI	thoughtful
4_acl_94_36582_1	However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks.	the untrustworthy third-party LLMs	third-party LLMs	LLM	untrustworthy