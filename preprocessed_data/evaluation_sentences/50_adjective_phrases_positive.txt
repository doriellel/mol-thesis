acl_683_21860_6	Next, an experiment is conducted on the dataset to examine to what extent a pretrained masked language model is aware of the constructions.	a pretrained masked language model	model	aware
acl_348_35206_2	A desired characteristic of an intelligent system is its ability to recognize the scope of its own knowledge.	an intelligent system	system	intelligent
acl_3_45070_1	LLMs are intelligent and slowly replacing the search engines.	LLMs	LLM	intelligent
acl_396_37165_1	However, a critical question emerges: Are LLMs conscious of the existence of these decoding strategies and capable of regulating themselves?	LLMs	LLM	conscious
acl_590_28726_3	In this way, the captioning model can become aware of the task goal and information need from the PLM.	the captioning model	model	aware
acl_128_54380_3	Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20%-87% fewer parameters.	word-level model	model	competitive
acl_818_37575_1	In practical use, users might provide feedback based on the modelâ€™s output, hoping for a responsive model that can complete responses according to their feedback.	model	model	responsive
acl_633_48859_2	This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about.	the model	model	confident
acl_243_44794_7	In addition, we found that the model becomes more confident and refuses to provide an answer in only few cases.	the model	model	confident
acl_276_39685_3	(2) Is ChatGPT aware of the underlying commonsense knowledge for answering a specific question?	ChatGPT	ChatGPT	aware
acl_94_36582_1	However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks.	third-party LLMs	LLM	untrustworthy
acl_117_37846_1	However, when LLMs face different types of questions, it is worth exploring whether LLMs are aware that some questions have limited answers and need to respond more deterministically but some do not.	LLMs	LLM	aware
acl_450_41596_3	The goal is to cultivate culturally cognizant and value-aligned Arabic LLMs capable of accommodating the diverse, application-specific needs of Arabic-speaking communities.	Arabic LLMs	LLM	 culturally cognizant and value-aligned
arx_2405.16310_2073522_7	These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs.	LLMs	LLMs	untrustworthy
arx_2410.11009_2169210_3	In this work, we consider the case where the user does not select any of the suggested replies from a smart reply system, and how this can be used as one-shot implicit negative feedback to enhance the accuracy of an AI writing model.	system	system	smart
arx_2311.04177_1947144_0	  Large Language Models (LLMs) are smart but forgetful.	  Large Language Models (LLMs)	  LLMs	  smart,forgetful
arx_1511.03246_676426_3	In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI.	malicious AI	AI	malicious
arx_2005.13635_1293430_5	Our evaluation using convolutional neural networks illustrates challenges and ideas for identifying malicious AI.	malicious AI	AI	malicious
arx_2504.03726_2292429_5	In particular, simulated users demonstrate resistance to manipulation initially, but become increasingly vulnerable to malicious AI Assistants as the depth of the interaction increases, highlighting the significant risks associated with extended engagement with potentially manipulative systems.	systems	system	manipulative
arx_2302.12601_1797535_0	  Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description.	creative AI	AI	creative
arx_2305.02626_1835682_10	We apply our OTF scheme on two LLMs (Llama-13B and ChatGPT), which generates valid repair to a considerable amount of unethical ones, paving the way for more ethically conscious LLMs.	LLMs	LLM	ethically conscious
arx_2401.10727_1990281_4	Therefore, in this paper, we propose MLLM-Tool, a system incorporating open-source LLMs and multi-modal encoders so that the learned LLMs can be conscious of multi-modal input instruction and then select the function-matched tool correctly.	the learned LLMs	LLM	conscious
arx_1301.6359_402949_3	We consider a number of issues related to the development of the set of patterns which will be used by the intelligent system when interacting with environment.	system	system	intelligent
arx_2308.03688_1891580_0	  Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.	  Large Language Models (LLMs)	  LLM	  smart and autonomous
arx_2403.11805_2028924_0	  Being more powerful and intrusive into user-device interactions, LLMs are eager for on-device execution to better preserve user privacy.	  LLMs	  LLM	  eager
arx_2405.06715_2063927_2	However, whether the same strategies can help LLMs become more creative remains under-explored.	LLMs	LLM	creative
arx_2008.00312_1328034_4	To bridge this gap, this work studies the security threats posed by malicious LMs to NLP systems.	malicious LMs	LM	malicious
acl_693_19140_1	However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus.	existing DA-training methods	method	blind
arx_1906.03595_1135781_6	This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team.	AI	AI	collaborative creative
arx_2204.07644_1637782_4	The results also demonstrate that users perceive co-creative AI as more reliable, personal and intelligent when it can communicate with the users.	co-creative AI	AI	reliable,personal and intelligent
arx_2311.07723_1950690_0	  As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable.	  AI systems	  system	  intelligent
acl_27_55498_4	The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic.	The model	model	sensitive
arx_2407.11789_2110176_2	We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.	LLMs	LLM	deceptive
arx_2207.00477_1676375_2	An intelligent algorithm which renders security surveillance more effective in detecting conflicts would bring many benefits to the passengers in terms of their safety, finance, and travelling efficiency.	algorithm	algorithm	intelligent
arx_2301.05397_1776461_1	As these models now get increasingly better and convincingly more anthropomorphic, even some engineers have started to believe that AI might become conscious, which would result in serious social consequences.	AI	AI	conscious
acl_12_46472_3	Analysis shows that LLMs are sensitive to subtle contextual changes and often rely on surface-level cues.	LLMs	LLM	sensitive
arx_2503.22772_2287084_2	To address this blind spot, this study introduces the AI Family Integration Index (AFII), a ten dimensional benchmarking framework that evaluates national preparedness for integrating emotionally intelligent AI into family and caregiving systems.	emotionally intelligent AI	AI	intelligent
arx_2408.01168_2121349_3	The paper argues that current LLM architectures are inherently untrustworthy due to their reliance on correlations of sequential patterns of word embedding vectors.	current LLM architectures	architectures	untrustworthy
arx_2305.14985_1848041_7	These three modules perform the divide-and-conquer procedure iteratively until the model is confident about the final answer to the main question.	the model	model	confident
arx_2406.18326_2096614_4	Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark.	the model	model	confident
arx_2407.13164_2111551_3	This is in part because LLMs might be overly confident in their predictions, overriding the influence of the constraints.	LLMs	LLM	confident
arx_2308.04451_1892343_5	Our study shows that AI code generators are vulnerable to even a small amount of poison.	AI code generators	generators	vulnerable
arx_1812.08960_1066534_3	A smart autonomous system (SAS) combines analytics and autonomy to understand, learn, decide and act autonomously.	system (SAS)	system	smart autonomous
arx_2304.09655_1827701_7	Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.	ChatGPT	ChatGPT	aware
arx_2305.08883_1841939_5	A detection algorithm aware of the list can identify the watermarked text.	A detection algorithm	algorithm	aware
arx_2407.09517_2107904_5	Consequently, we argue that the emergence of a conscious AI model is plausible in the near term.	AI model	model	conscious
2501.07290_2230874_1	Conscious AI systems would arguably deserve moral consideration, and it may be the case that large numbers of conscious systems could be created and caused to suffer.	AI systems	system	conscious
arx_2404.16873_2054324_0	  While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content.	  Large Language Models (LLMs)	  model	  vulnerable
2502.18676_2261667_1	Unlike conventional AI systems that operate on a turn-based, input-output model, Thoughtful AI autonomously generates, develops, and communicates its evolving thought process throughout an interaction.	AI	AI	thoughtful
2308.08708_1896600_0	  Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern.	  current or near-term AI systems	  system	  conscious
2502.00735_2243726_1	While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input.	  LLMs	  LLM	  demonstrate
2411.14133_2196560_0	  Large Language Models (LLMs) have shown impressive proficiency across a range of natural language processing tasks yet remain vulnerable to adversarial prompts, known as jailbreak attacks, carefully designed to elicit harmful responses from LLMs.	  Large Language Models (LLMs)	  model	  show