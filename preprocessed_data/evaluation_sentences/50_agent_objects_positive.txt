acl_260_9141_4	The final submission was chosen based on the best performances which was achieved by the BERT+BiLSTM model.	the BERT+BiLSTM model	model	achieve
acl_75_14800_1	However, existing studies into language modelling with BERT have been mostly limited to English-language material and do not pay enough attention to the implicit knowledge of language, such as semantic roles, presupposition and negations, that can be acquired by the model during training.	the model	model	acquire
acl_502_20526_4	We find that 4 pretrained transfomer LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.	the LM	LM	learn
acl_23_33157_0	Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.	the LLMs	LLM	hold
acl_119_34984_3	However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge.	the LLMs	LLM	perceive
acl_46_41679_2	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.	the language model	model	see
acl_143_43709_5	Our experiments show that these errors can be identified with high accuracy by an LLM.	an LLM	LLM	identify
acl_3_26185_65	The text was translated by both ChatGPT and a translator who is an academic in the field of translation and has 10 years of experience.	ChatGPT	ChatGPT	translate
acl_511_29547_1	To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.	LLMs	LLM	acquire
acl_98_33764_7	Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency.	LLMs	LLM	generate
acl_738_35585_4	Since a fallacious procedure is generally considered fake and thus harmless by LLMs, it helps bypass the safeguard mechanism.	LLMs	LLM	consider
acl_304_37076_3	However their explicitly mention of malicious intent will be easily recognized and defended by LLMs.	LLMs	LLM	recognize,defend
acl_305_37077_7	This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals.	GPT-4	GPT-4	conduct
acl_430_37198_2	In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by LLMs.	LLMs	LLM	interpret
acl_600_45881_2	In this paper, we introduce a new multilingual parallel dataset SHADES to help address this issue, designed for examining culturally-specific stereotypes that may be learned by LLMs.	LLMs	LLM	learn
acl_687_35537_5	However, this ability is inconsistent: with a minimal reformulation of the task, some LMs were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computational principles of semantic property inference are yet to be mastered by LMs.	LMs	LM	master
arx_1811.00189_1044822_2	A remarkable feature of RAE is that the image can be correctly recognized and used by the AI model specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.	the AI model	model	recognize,use
arx_1811.01439_1046072_2	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break.	the complex system	system	make a decision
arx_2105.13818_1476377_2	By applying our experimental pipeline to LMs trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models.	these models	model	acquire
arx_2204.03332_1633470_10	We also demonstrate, that the considered system possesses a counter-intuitive relationship between workload and performance, which nevertheless is correctly inferred by the proposed simulation model.	the proposed simulation model	model	infer
arx_2001.08625_1234038_4	Examination prioritization was performed by the AI, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.	the AI	AI	perform
arx_2301.11767_1782831_2	In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.	the AI system	system	learn	
arx_1809.04258_1024274_3	The results preliminarily reveal that it is a relationship between the ontology-based attributions and the corresponding predicted indicator that can be learnt by AI for predicting the SE, which suggests the proposed model has a potential in AI-assisted SE prediction.	AI	AI	learn
arx_1811.00189_1044822_0	  In this study, we propose a new methodology to control how user's data is recognized and used by AI via exploiting the properties of adversarial examples.	  AI	  AI	  recognize,use
1907.08625_1153161_6	These features are best interpreted by a self-consistent relativistic reflection model.	a self-consistent relativistic reflection model	model	interpret
arx_1910.04404_1188323_0	  Explanation is necessary for humans to understand and accept decisions made by an AI system when the system's goal is known.	an AI system	system	make a decision
arx_1910.12583_1196502_2	Solidarity as an AI principle (1) shares the prosperity created by AI, implementing mechanisms to redistribute the augmentation of productivity for all; and shares the burdens, making sure that AI does not increase inequality and no human is left behind.	AI	AI	create
arx_1907.12932_1157468_4	We demonstrate that qualitatively similar behaviour to the experiments is exhibited by a previously established, depth-averaged mathematical model; a consequence of the model's intricate solution structure.	a previously established, depth-averaged mathematical model	model	exhibit
arx_2004.11543_1276313_6	Each lesson in the curriculum is learnt by a deep reinforcement learning model.	a deep reinforcement learning model	model	learn
arx_2012.08285_1396163_1	The goal of this article is to paint a vision of a new air interface which is partially designed by AI to enable optimized communication schemes for any hardware, radio environment, and application.	AI	AI	design
arx_2106.07921_1485685_1	I suggest that up to 50% of a radiologists work in 2021 will be performed by AI-models in 2025.	AI-models	model	perform
arx_2110.14419_1552562_1	Drawing upon the political philosophy of John Rawls, it holds that the basic structure of society should be understood as a composite of socio-technical systems, and that the operation of these systems is increasingly shaped and influenced by AI.	AI	AI	shape,influence
arx_2205.08123_1652535_3	Results: After the exclusion of cases not meeting the study criteria, 9579 cases were analysed by AI.	AI	AI	analyse
arx_2204.06916_1637054_2	Typically, the advice generated by AI is judged by a human and either deemed reliable or rejected.	AI	AI	generate
arx_2012.05628_1393506_5	This method minimises the amount of training and prevents losing information during adaptation that was learned by GPT-2.	GPT-2	GPT-2	learn
arx_2012.09755_1397633_5	Specifically, the structural features identified by our algorithm were found to be related to clinical observations of glaucoma.	our algorithm	algorithm	identify
arx_2207.00691_1676589_8	The results indicate that biases equating American identity with being White are learned by language-and-image AI, and propagate to downstream applications of such models.	language-and-image AI	AI	learn
acl_10_8527_2	The former is concerned with the generation of explanations for decisions taken by AI systems, while the latter is concerned with the way explanations are given to users and received by them.	AI systems	system	take a decision
acl_137_12015_5	We demonstrate that the sentence representations discovered by our model achieve better quality than previous methods that extract representations from pretrained transformers on text similarity tasks, style transfer (an example of controlled generation), and single-sentence classification tasks in the GLUE benchmark, while using fewer parameters than large pretrained models.	our model	model	discover
arx_2011.13169_1385917_2	The need for explainable AI does not stem only from ethical and moral grounds but also from stricter legislation around the world mandating clear and justifiable explanations of any decision taken or assisted by AI.	AI	AI	take a decision,assist a decision
arx_1712.07473_926072_0	  One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm.	the algorithm	algorithm	face
arx_1812.01714_1059288_3	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.	our model	model	learn
arx_2007.15619_1327133_1	This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model.	the model	model	identify
arx_2010.01869_1358199_0	  In this paper we investigate the linguistic knowledge learned by a Neural Language Model (NLM) before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems.	  a Neural Language Model (NLM)	  model	  learn
arx_2011.03195_1375943_6	Medical diagnosis model is responsible for human life and we need to be confident enough to treat a patient as instructed by a black-box model.	  a black-box model	  model	  instruct
acl_750_35597_0	We present a large-scale study of linguistic bias exhibited by ChatGPT covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-”standard” varieties from around the world).	ChatGPT	ChatGPT	exhibit
arx_2302.06852_1791786_1	The simulations are grounded by a neuro-symbolic language that both enables question answering of what is learned by the AI methods and provides a means of explainability.	the AI methods	method	learn
arx_1806.10698_996338_7	In addition, we found that the triage advice recommended by the AI System was, on average, safer than that of human doctors, when compared to the ranges of acceptable triage provided by independent expert judges, with only a minimal reduction in appropriateness.	the AI system	system	recommend
2311.11045_1954012_4	We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model.	the larger model	model	use
arx_1902.01811_1082895_7	The turbulent effects are taken into account by a stochastic aerodynamic force model where the underlying velocity fluctuations are reconstructed from a $k$-$\epsilon$ turbulence description of the airflow.	a stochastic aerodynamic force model	model	take into account