1_acl_586_6176_1	While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context.	LMs	LMs	LM	derive	inc
1_acl_5_9514_1	In some applications, however, having an additional context can help the model make the right prediction, e.g., by taking the domain or the time of writing into account.	the model	model	model	make a prediction	inc
1_acl_65_19388_5	The human evaluation found that our topic model creates coherent topics.	our topic model	topic model	model	create	inc
1_acl_22_31716_3	Focusing on universal quantification, we provide a theoretical foundation for these empirical findings by proving that LLMs cannot learn certain fundamental semantic properties including semantic entailment and consistency as they are defined in formal semantics.	LLMs	LLMs	LLM	learn	inc
1_acl_163_34648_5	Our evaluation on both automated metrics and qualitative human evaluation suggests that by incorporating end-user specifications into the conversion process, our model can create presentations that are not only informative but also tailored to expectations and cognitive abilities of target audience.	our model	model	model	create	inc
1_acl_11_43395_1	For example, a model should correctly identify kimchi (Korean food) in an image both when an Asian woman is eating it, as well as an African man is eating it.	a model	model	model	identify	inc
1_arx_2304.10592_1828638_0	The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images.	The recent GPT-4	GPT-4	GPT-4	demonstrate	inc
1_acl_78_25975_8	The semantic dependency feature serves as a global signal and helps the model learn simile knowledge that can be applied to unseen domains.	the model	model	model	learn	inc
1_arx_2012.11995_1399873_3	Our results also show that pre-training on structured data does not always make the model acquire ability that can be transferred to natural language downstream tasks.	the model	model	model	acquire	inc
1_arx_2304.09161_1827207_1	In this perspectives paper, we discuss possible ways for LLMs to support relevance judgments along with concerns and issues that arise.	LLMs	LLMs	LLM	support	inc
1_acl_34_15815_4	As the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually.	the system	system	system	learn	inc
1_arx_2110.10185_1548328_5	The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable.	the generation system	generation system	system	act	inc
1_arx_1205.3313_342314_2	The model does not differentiate between aerosol particles, cloud droplets, drizzle or rain drops.	The model	model	model	differentiate	inc
1_arx_0807.4086_75079_10	The second is the choice between models of HIV dynamics, where one model makes the distinction between activated CD4+ T lymphocytes and the other does not.	one model	model	model	make a distinction	inc
1_acl_261_9142_1	Our proposed model learns to extract textual features using a BiGRU-based deep neural network supported by a Hierarchical Attention architecture to focus on the most relevant areas in the text.	Our proposed model	model	model	learn	inc
1_arx_1809.03964_1023980_3	Our proposed model considers historical air pollution records and historical meteorological data.	Our proposed model	model	model	consider	inc
1_arx_2212.07414_1763591_5	Our algorithm considers the channel conditions during the dynamic weight selection process.	Our algorithm	algorithm	algorithm	consider	inc
1_arx_2107.06031_1500043_3	This Machine Learning model also explains the relationship between the input factors and fuel consumption, quantifying the individual contribution of each one of them.	This Machine Learning model	Machine Learning model	model	explain	inc
1_arx_2304.09337_1827383_2	It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention.	the model	model	model	interpret	inc
1_arx_2207.08333_1684231_3	We observed that the VL model does not interpret the overall context of an input image but instead shows biases toward a specific object or shape that forms the local context.	the VL model	VL model	model	interpret	inc