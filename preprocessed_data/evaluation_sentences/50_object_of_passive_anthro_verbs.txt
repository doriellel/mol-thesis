acl_260_9141_4	The final submission was chosen based on the best performances which was achieved by the BERT+BiLSTM model.
acl_75_14800_1	However, existing studies into language modelling with BERT have been mostly limited to English-language material and do not pay enough attention to the implicit knowledge of language, such as semantic roles, presupposition and negations, that can be acquired by the model during training.
acl_502_20526_4	We find that 4 pretrained transfomer LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.
acl_23_33157_0	Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.
acl_119_34984_3	However, even state-of-the-art large language models (LLMs) still face challenges in such scenarios, primarily due to the following hurdles: (1) LLMs are not explicitly trained to deal with ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may vary depending on the possessed knowledge.
acl_46_41192_3	MONITOR is designed to compute the distance between the probability distributions of a valid output and its counterparts produced by the same LLM probing the same fact using different styles of prompts and contexts.
acl_46_41679_2	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.
acl_12_34879_2	When a digit is read or generated by a causal language model it does not know its place value (e.g. thousands vs. hundreds) until the entire number is processed.
acl_1_42012_5	We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths.
acl_143_43709_5	Our experiments show that these errors can be identified with high accuracy by an LLM.
acl_3_26185_65	The text was translated by both ChatGPT and a translator who is an academic in the field of translation and has 10 years of experience.
acl_511_29547_1	To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.
acl_98_33764_7	Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency.
acl_738_35585_4	Since a fallacious procedure is generally considered fake and thus harmless by LLMs, it helps bypass the safeguard mechanism.
acl_304_37076_3	However their explicitly mention of malicious intent will be easily recognized and defended by LLMs.
acl_305_37077_7	This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals.
acl_430_37198_2	In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by LLMs.
acl_600_45881_2	In this paper, we introduce a new multilingual parallel dataset SHADES to help address this issue, designed for examining culturally-specific stereotypes that may be learned by LLMs.
acl_282_44833_0	Progress in AI is often demonstrated by new models claiming improved performance on tasks measuring model capabilities.
acl_687_35537_5	However, this ability is inconsistent: with a minimal reformulation of the task, some LMs were found to pick up on shallow, non-semantic heuristics from their inputs, suggesting that the computational principles of semantic property inference are yet to be mastered by LMs.
acl_14_32176_3	Extensive experiments are conducted on Causal Question Answering (CQA), where IBE-Eval is tasked to select the most plausible causal explanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama 2).
acl_7_34206_4	A positive correlation of 0.40 was found between the emotion intensity scores reproduced by GPT-4 and those manually annotated by humans.
arx_1610.02937_778284_8	The synthetic PM10 record predicted by the model was found to correlate with the PM10 observations with a correlation coefficient close to 0.80 with a confidence greater than 99%.
arx_1811.00189_1044822_2	A remarkable feature of RAE is that the image can be correctly recognized and used by the AI model specified by the user because the authorized AI can recover the original image from the RAE exactly by eliminating adversarial perturbation.
arx_1811.01439_1046072_2	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break.
arx_2104.14506_1461924_5	The end users can be domain experts, regulatory agencies, managers and executive board members, data scientists, users that use AI, with or without awareness, or someone who is affected by the decisions of an AI model.
arx_2105.13818_1476377_2	By applying our experimental pipeline to LMs trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models.
arx_2204.03332_1633470_10	We also demonstrate, that the considered system possesses a counter-intuitive relationship between workload and performance, which nevertheless is correctly inferred by the proposed simulation model.
arx_2001.08625_1234038_4	Examination prioritization was performed by the AI, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.
arx_2301.11767_1782831_2	In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.
arx_0906.5497_132048_3	We find that the observed behaviour is explained by a model including the effects associated with the variations of pressure and density.
arx_1809.04258_1024274_3	The results preliminarily reveal that it is a relationship between the ontology-based attributions and the corresponding predicted indicator that can be learnt by AI for predicting the SE, which suggests the proposed model has a potential in AI-assisted SE prediction.
arx_1811.00189_1044822_0	  In this study, we propose a new methodology to control how user's data is recognized and used by AI via exploiting the properties of adversarial examples.
1907.08625_1153161_6	These features are best interpreted by a self-consistent relativistic reflection model.
arx_1910.04404_1188323_0	  Explanation is necessary for humans to understand and accept decisions made by an AI system when the system's goal is known.
arx_1910.12583_1196502_2	Solidarity as an AI principle (1) shares the prosperity created by AI, implementing mechanisms to redistribute the augmentation of productivity for all; and shares the burdens, making sure that AI does not increase inequality and no human is left behind.
arx_1907.12932_1157468_4	We demonstrate that qualitatively similar behaviour to the experiments is exhibited by a previously established, depth-averaged mathematical model; a consequence of the model's intricate solution structure.
arx_2002.10965_1248388_3	For the sake of simplicity, a simple single-cell scenario is considered, where the optimization of the BS and IRS phase shifts is solved by a low-complexity trellis-based algorithm.
arx_2004.11543_1276313_6	Each lesson in the curriculum is learnt by a deep reinforcement learning model.
arx_2012.08285_1396163_1	The goal of this article is to paint a vision of a new air interface which is partially designed by AI to enable optimized communication schemes for any hardware, radio environment, and application.
arx_2106.07921_1485685_1	I suggest that up to 50% of a radiologists work in 2021 will be performed by AI-models in 2025.
arx_2110.14419_1552562_1	Drawing upon the political philosophy of John Rawls, it holds that the basic structure of society should be understood as a composite of socio-technical systems, and that the operation of these systems is increasingly shaped and influenced by AI.
arx_2205.08123_1652535_3	Results: After the exclusion of cases not meeting the study criteria, 9579 cases were analysed by AI.
arx_2204.06916_1637054_2	Typically, the advice generated by AI is judged by a human and either deemed reliable or rejected.
arx_1806.08544_994184_4	The game is designed to be fun to play for humans, and is directly playable by General Video Game AI agents.
arx_1812.01714_1059288_3	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.
arx_1905.10083_1128519_5	However, research on edge intelligence is still in its infancy stage, and a dedicated venue for exchanging the recent advances of edge intelligence is highly desired by both the computer system and artificial intelligence communities.
arx_2012.05628_1393506_5	This method minimises the amount of training and prevents losing information during adaptation that was learned by GPT-2.
arx_2012.09755_1397633_5	Specifically, the structural features identified by our algorithm were found to be related to clinical observations of glaucoma.
arx_2207.00691_1676589_8	The results indicate that biases equating American identity with being White are learned by language-and-image AI, and propagate to downstream applications of such models.
acl_10_8527_2	The former is concerned with the generation of explanations for decisions taken by AI systems, while the latter is concerned with the way explanations are given to users and received by them.
acl_137_12015_5	We demonstrate that the sentence representations discovered by our model achieve better quality than previous methods that extract representations from pretrained transformers on text similarity tasks, style transfer (an example of controlled generation), and single-sentence classification tasks in the GLUE benchmark, while using fewer parameters than large pretrained models.
arx_2011.13169_1385917_2	The need for explainable AI does not stem only from ethical and moral grounds but also from stricter legislation around the world mandating clear and justifiable explanations of any decision taken or assisted by AI.
arx_1712.07473_926072_0	  One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm.
arx_1812.01714_1059288_3	Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model.
arx_2007.15619_1327133_1	This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model.
arx_2010.01869_1358199_0	  In this paper we investigate the linguistic knowledge learned by a Neural Language Model (NLM) before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems.
arx_2011.03195_1375943_6	Medical diagnosis model is responsible for human life and we need to be confident enough to treat a patient as instructed by a black-box model.
acl_183_18630_5	On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3.
acl_750_35597_0	We present a large-scale study of linguistic bias exhibited by ChatGPT covering ten dialects of English (Standard American English, Standard British English, and eight widely spoken non-”standard” varieties from around the world).
acl_65_4796_0	In this paper we investigate the linguistic knowledge learned by a Neural Language Model (NLM) before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems.