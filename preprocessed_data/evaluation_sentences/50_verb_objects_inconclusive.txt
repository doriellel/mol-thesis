2_acl_502_20526_4	We find that 4 pretrained transfomer LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM.	the LM	LM	LM	learn	inc
2_acl_143_43709_5	Our experiments show that these errors can be identified with high accuracy by an LLM.	an LLM	LLM	LLM	identify	inc
2_acl_511_29547_1	To maintain the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge.	LLMs	LLMs	LLM	acquire	inc
2_acl_98_33764_7	Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency.	LLMs	LLMs	LLM	generate	inc
2_acl_600_45881_2	In this paper, we introduce a new multilingual parallel dataset SHADES to help address this issue, designed for examining culturally-specific stereotypes that may be learned by LLMs.	LLMs	LLMs	LLM	learn	inc
2_arx_2105.13818_1476377_2	By applying our experimental pipeline to LMs trained on various filtered corpora, we are able to gain stronger insights into the semantic generalizations that are acquired by these models.	these models	models	model	acquire	inc
2_arx_2001.08625_1234038_4	Examination prioritization was performed by the AI, classifying eight different pathological findings ranked in descending order of urgency: pneumothorax, pleural effusion, infiltrate, congestion, atelectasis, cardiomegaly, mass and foreign object.	the AI	AI	AI	perform	inc
2_arx_2301.11767_1782831_2	In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system.	the AI system	AI system	system	learn	inc	
2_arx_2106.07921_1485685_1	I suggest that up to 50% of a radiologists work in 2021 will be performed by AI-models in 2025.	AI-models	AI-models	model	perform	inc
2_arx_2012.05628_1393506_5	This method minimises the amount of training and prevents losing information during adaptation that was learned by GPT-2.	GPT-2	GPT-2	GPT-2	learn	inc
2_arx_2012.09755_1397633_5	Specifically, the structural features identified by our algorithm were found to be related to clinical observations of glaucoma.	our algorithm	algorithm	algorithm	identify	inc
2_arx_2007.15619_1327133_1	This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model.	the model	model	model	identify	inc
2_arx_2302.06852_1791786_1	The simulations are grounded by a neuro-symbolic language that both enables question answering of what is learned by the AI methods and provides a means of explainability.	the AI methods	AI methods	method	learn	inc
2_acl_46_41679_2	However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.	the language model	language model	model	see	inc
2_acl_430_37198_2	In this paper, we identify that such demonstration bias may primarily stem from the semantic ambiguity induced by demonstrations, i.e., a demonstration may indicate multiple input-to-label mappings and its mapping can be interpreted differently in different contexts by LLMs.	LLMs	LLMs	LLM	interpret	inc
2_arx_1907.08625_1153161_6	These features are best interpreted by a self-consistent relativistic reflection model.	a self-consistent relativistic reflection model	relativistic reflection model	model	interpret	inc
2_acl_23_33157_0	Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves.	the LLMs	LLMs	LLM	hold knowledge	inc
2_arx_2311.11045_1954012_4	We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model.	the larger model	model	model	use	inc
2_arx_1811.01439_1046072_2	These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break.	the complex system	system	system	make a decision	inc
2_acl_46_41193_3	MONITOR is designed to compute the distance between the probability distributions of a valid output and its counterparts produced by the same LLM probing the same fact using different styles of prompts and contexts.	the same LLM	LLM	LLM	produce	inc
//////
3_acl_696_6286_1	How should we train a language model in this scenario?	a language model	language model	model	train	  inc
3_arx_2309.11000_1915804_0	  This paper explores the potential of constructing an AI spoken dialogue system that "thinks how to respond" and "thinks how to speak" simultaneously, which more closely aligns with the human speech production process compared to the current cascade pipeline of independent chatbot and Text-to-Speech (TTS) modules.	  an AI spoken dialogue system	  AI spoken dialogue system	  system	  construct	  inc
3_acl_27_42781_1	A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output.	LLMs	LLMs	LLM	correct	inc
3_acl_27_42781_3	This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches.	LLMs	LLMs	LLM	correct	inc
3_2305.01937_1834993_4	We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.	the LLMs	LLMs	LLM	present	inc
3_2306.03856_1857004_0	  We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language understanding and translation capability as well as a human-like translation approach.	  a large language model	  model	  prompt

3_acl_3_33872_4	Variations of this vignette are used for role-prompting a commercial LLM, GPT-4, instructing the LLM to take on the role described in the patient vignette and act accordingly.	the LLM	LLM	instruct
3_acl_212_35072_4	Instead of attempting to answer all questions, we explore a refusal mechanism that instructs LLMs to refuse to answer challenging questions in order to avoid errors.	LLMs	LLM	instruct
3_acl_3_25435_1	For each of the languages English, Farsi, Faroese, Mandarin and Russian, we instructed GPT-4, through C-LARA, to write six different texts, using prompts chosen to obtain texts of widely differing character.	GPT-4	GPT-4	instruct
3_arx_2107.05383_1499395_1	We asked the world's best language model, GPT-3, fifteen difficult questions about the nature, value, and future of library and information science (LIS), topics that receive perennial attention from LIS scholars.	the world's best language model	model	ask
3_arx_2304.00385_1818431_9	For earlier patches that passed all the tests, we further ask the LLM to generate alternative variations of the original plausible patches.	the LLM	LLM	ask
3_arx_2303.14956_1814753_3	In this work, we propose a simple and efficient approach to instruct large language model (LLM) to extract a variety of structures from texts.	large language model (LLM)	model	instruct
3_arx_2307.08487_1879482_5	Specifically, we instruct the model to complete a regular task, such as translation, with the text to be translated containing malicious instructions.	the model	model	model	instruct
3_acl_11_41931_7	In the second experiment, we ask the LLMs to numerically rate various aspects of the musical cultures of different countries.	the LLMs	LLM	LLM	ask
3_acl_867_37623_4	Leveraging the in-context learning capability of LLMs, we ask the LLM to summarise the instances in which the ML model makes mistakes and the correlation between primary predictions and true labels.	the LLM	LLM	LLM	ask	p2
3_acl_870_25020_4	We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.	the LLMs	LLMs	LLM	ask	p2
3_acl_794_28930_3	We introduce a new task, “less likely brainstorming,” that asks a model to generate outputs that humans think are relevant but less likely to happen.	a model	model	ask
3_acl_599_29635_5	Last, we reveal that asking the LLM to explain its own ratings consistently improves the correlation between the ChatGPT and human ratings and pushes state-of-the-art (SoTA) correlations on two meta-evaluation datasets.	the LLM	LLM	ask
3_acl_966_30002_2	We ask several LLMs and humans to write such a story and conduct a human evalution involving various criteria such as fluency, coherence, originality, humor, and style.	several LLMs	LLM	ask
3_acl_11_31225_2	To explore this line of research, this paper uses a case study, namely, finding the best prompting strategy for asking ChatGPT to define new words based on morphological connections.	ChatGPT	ChatGPT	ask
3_acl_870_25020_4	We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.	the LLMs	LLMs	LLM	present	inc
3_acl_7_30789_3	We then introduce these pairs into translation prompts, instructing ChatGPT to use the correct translations of the domain entities.	ChatGPT	ChatGPT	ChatGPT	instruct	inc
3_acl_5_46527_1	Different prompts are tested to instruct the LLM to clean the text without changing the structure, vocabulary or specialized lexicon.	the LLM	LLM	LLM	instruct	inc
3_acl_1_46431_8	In a case study on Tsez, we ask the LLM to automatically create and follow linguistic instructions, reducing errors on a confusing grammatical feature.	the LLM	LLM	LLM	ask	inc
3_acl_920_38624_10	We show that choosing the best policy to interact with the LLM can reduce cost by ~90% while giving better or comparable performance, compared to communicating with the LLM in the original LRL.	the LLM	LLM	LLM	interact with	inc