68_5568_1	MAIA will employ cutting-edge machine learning and natural language processing technologies to build multilingual AI agent assistants, eliminating language barriers.
689_6279_3	We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short.
24_20048_0	It is still a pipe dream that personal AI assistants on the phone and AR glasses can assist our daily life in addressing our questions like “how to adjust the date for this watch?”
341_22477_5	We distill only one aspect–the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model.
58_25282_3	In DeepPavlov Dream, multi-skill Generative AI Assistant consists of NLP components that extract features from user utterances, conversational skills that generate or retrieve a response, skill and response selectors that facilitate choice of relevant skills and the best response, as well as a conversational orchestrator that enables creation of multi-skill Generative AI Assistants scalable up to industrial grade AI assistants.
65_25714_5	The results highlight the few-shot learning capabilities of large-language models, particularly OpenAI’s GPT-3, in the role of AI teachers.
183_26904_4	Our objective is to capture the breadth of interactions between a human user and an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively.
794_28930_0	A human decision-maker benefits the most from an AI assistant that corrects for their biases.
296_32458_0	In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
766_32928_7	On CRAFT biomedical parsing, for example, 3-stage MCKD with 50 labeled examples outperforms an LLM teacher and vanilla KD by 7.5% and 3.7% parsing F1, respectively, and matches the performance of supervised finetuning with 500 labeled examples.
3_34388_0	The development of conversational AI assistants is an iterative process with many components involved.
3_34388_2	This paper introduces the challenges in evaluating and improving a generative AI assistant for enterprise that is under active development and how we address these challenges.
39_34906_4	Recognizing the complexity of this writing task, we built an LLM-powered assistant into the workers’ interface to aid in drafting and refining their comments.
279_35138_4	Indeed, factors such as an individual’s writing confidence and familiarity with AI writing assistants are shown to moderate the impact of AI assistance disclosure on their writing quality evaluations.
889_35732_0	Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users.
977_35817_1	Recently, studies have proposed a Knowledge Distillation (KD) approach, reasoning distillation, which transfers such reasoning ability of LLMs through fine-tuning language models of multi-step rationales generated by LLM teachers.
665_37427_0	Emotional Intelligence (EI), consisting of emotion perception, emotion cognition and emotion expression, plays the critical roles in improving user interaction experience for the current large language model (LLM) based conversational general AI assistants.
665_37427_5	Extensive experiments on two representative LLM-based assistants, Flan-T5 and LLaMA-2-Chat, demonstrate the effectiveness of MoEI to improving EI while maintain GI.
204_37931_5	Our findings propose a significant shift towards preemptive strategies for hallucination mitigation in LLM assistants, promising improvements in reliability, applicability, and interpretability.
458_38173_3	To address this, we introduce RealInstruct, the first benchmark designed to evaluate LLMs’ ability to follow real-world multi-constrained instructions by leveraging queries real users asked AI assistants.
649_38360_0	AI personal assistants deployed via robots or wearables require embodied understanding to collaborate with humans effectively.
209_39619_2	Many existing studies adopt static evaluation, where they assess AI assistants’ API call based on pre-defined dialogue histories.
209_39619_7	Testing four AI assistants using our crafted benchmark, our method further mirrored human evaluation compared to conventional static evaluations.
889_40299_8	This evaluation benchmark provides LLMs with a highly challenging and differentiating task that is crucial to an effective AI assistant.
113_41260_10	We discuss these challenges, demonstrate that a dedicated prompt can improve the performance, and propose a blueprint of an LLM-supporter that actively (but sensitively) seeks user context to provide personalized, empathetic, and reliable responses.
132_41279_2	However, the exploration of LLM-based personalized medical assistant remains relatively scarce.
358_41505_5	Leveraging the strong language abilities of LLMs, we instruct LLM teachers to synthesize diverse contexts and anticipate more potential errors for the student.
50_42804_0	We describe a class of tasks called decision-oriented dialogues, in which AI assistants such as large language models (LMs) must collaborate with one or more humans via natural language to help them make complex decisions.
50_42804_2	In each of these settings, AI assistants and users have disparate abilities that they must combine to arrive at the best decision: Assistants can access and process large amounts of information, while users have preferences and constraints external to the system.
254_43821_0	With the rapid development of large language models, AI assistants like ChatGPT have become increasingly integrated into people’s works and lives but are limited in personalized services.
254_43821_1	In this paper, we present a plug-and-play framework that could facilitate personalized large language model assistants with evolving conditional memory.
306_44857_7	Together, our work lays foundation for further studies on clarifying interactions with LM assistants.
13_45033_5	In this paper, the credit product customization is studied by developing an LLM-based financial AI assistant for the credit loan business.

